{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6e288-cb7d-4fb3-90b6-f756c6f7e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = \"../../evaluation/output_evals/wmt\"\n",
    "DIRECTION_PAIRS = [\n",
    "    'en_de', 'en_es', 'en_fr',\n",
    "    'en_it', 'en_nl', 'en_pt', 'en_zh'\n",
    "]\n",
    "SYSTEM_NAMES = [\n",
    "    \"aya_canary-v2\",\n",
    "    \"aya_seamlessm4t\",\n",
    "    \"canary-v2\",\n",
    "    \"gemma_canary-v2\",\n",
    "    \"gemma_seamlessm4t\",\n",
    "    \"owsm4.0-ctc\",\n",
    "    \"qwen2audio-7b\",\n",
    "    \"tower_canary-v2\",\n",
    "    \"tower_seamlessm4t\",\n",
    "    \"voxtral-small-24b\",\n",
    "    \"aya_owsm4.0-ctc\",\n",
    "    \"aya_whisper\",\n",
    "    \"desta2-8b\",\n",
    "    \"gemma_owsm4.0-ctc\",\n",
    "    \"gemma_whisper\",\n",
    "    \"phi4multimodal\",\n",
    "    \"seamlessm4t\",\n",
    "    \"tower_owsm4.0-ctc\",\n",
    "    \"tower_whisper\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f116926-9de7-4ac9-bbe1-ff06999af068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results_summaries(base_dir, direction_pairs, system_names):\n",
    "    \"\"\"\n",
    "    Loads all result summaries from a directory structure.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str or Path): The base directory for the evaluation outputs.\n",
    "        direction_pairs (list): A list of language direction strings (e.g., 'en_de').\n",
    "        system_names (list): A list of system name strings.\n",
    "\n",
    "    Returns:\n",
    "        dict: A nested dictionary containing the loaded data, structured as\n",
    "              {direction: {system: [results]}}.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    all_results = {}\n",
    "\n",
    "    # Use itertools.product to cleanly iterate over all combinations\n",
    "    for direction, system in itertools.product(direction_pairs, system_names):\n",
    "        summary_path = base_path / system / direction / 'results.jsonl'\n",
    "        \n",
    "        # Initialize the nested dictionary structure\n",
    "        if direction not in all_results:\n",
    "            all_results[direction] = {}\n",
    "\n",
    "        try:\n",
    "            with summary_path.open('r', encoding='utf-8') as f:\n",
    "                all_results[direction][system] = [json.loads(line) for line in f]\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File not found, skipping: {summary_path}\")\n",
    "            all_results[direction][system] = None # Or [] if you prefer an empty list\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in {summary_path}: {e}\")\n",
    "            all_results[direction][system] = None\n",
    "\n",
    "    return all_results\n",
    "\n",
    "def convert_results_to_dataframe(results_data):\n",
    "    \"\"\"\n",
    "    Converts the nested dictionary of results into a single pandas DataFrame.\n",
    "\n",
    "    Each row corresponds to a single entry, with 'direction' and 'system'\n",
    "    columns added, and all 'metrics' unpacked into separate columns.\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    for direction, systems in results_data.items():\n",
    "        for system, records in systems.items():\n",
    "            if records is None:\n",
    "                continue\n",
    "            for record in records:\n",
    "                # Separate metrics from the record\n",
    "                metrics = record.pop(\"metrics\", {})  # safely get metrics\n",
    "                # Merge everything into one flat dict\n",
    "                flat_record = {\n",
    "                    \"direction\": direction,\n",
    "                    \"system\": system,\n",
    "                    **record,\n",
    "                    **metrics,  # unpack metrics into top-level keys\n",
    "                }\n",
    "                all_records.append(flat_record)\n",
    "\n",
    "    if not all_records:\n",
    "        print(\"No records were found to create a DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(all_records)\n",
    "\n",
    "    # Put identifying info up front\n",
    "    original_cols = [c for c in df.columns if c not in [\"direction\", \"system\"]]\n",
    "    df = df[[\"direction\", \"system\"] + original_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_strict_scores(df):\n",
    "    \"\"\"\n",
    "    Computes mean metric scores and strict scores grouped by (system, accent).\n",
    "    \n",
    "    Expects columns:\n",
    "      - system\n",
    "      - accent\n",
    "      - xcomet_qe_score\n",
    "      - metricx_qe_score\n",
    "      - linguapy_score (list/tuple of [flag, lang])\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- Split linguapy_score into two separate columns ---\n",
    "    df[[\"linguapy_flag\", \"linguapy_lang\"]] = pd.DataFrame(\n",
    "        df[\"linguapy_score\"].tolist(), index=df.index\n",
    "    )\n",
    "\n",
    "    # --- Define penalties ---\n",
    "    penalty_by_metric = {\n",
    "        \"metricx_qe\": 25,\n",
    "        \"xcomet_qe\": 0,\n",
    "    }\n",
    "\n",
    "    # --- Strict score per row ---\n",
    "    for metric in penalty_by_metric.keys():\n",
    "        df[f\"{metric}_strict\"] = df.apply(\n",
    "            lambda row: row[f\"{metric}_score\"]\n",
    "            if row[\"linguapy_flag\"] == 0\n",
    "            else penalty_by_metric[metric],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "    # --- Aggregate by system × accent ---\n",
    "    agg_cols = {\n",
    "        \"linguapy_flag\": \"mean\",  # average from 0–1\n",
    "    }\n",
    "    for metric in penalty_by_metric.keys():\n",
    "        agg_cols[f\"{metric}_score\"] = \"mean\"\n",
    "        agg_cols[f\"{metric}_strict\"] = \"mean\"\n",
    "\n",
    "    result = (\n",
    "        df.groupby([\"system\"])\n",
    "        .agg(agg_cols)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"linguapy_flag\": \"linguapy_avg\"})\n",
    "    )\n",
    "\n",
    "    result['linguapy_avg'] = result['linguapy_avg']*100\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb5a6c-3dc3-44fc-856c-cf08770cd516",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full = load_results_summaries(BASE_DIR, DIRECTION_PAIRS, SYSTEM_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f85c6d-08e0-443f-83e8-c085c655ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_results_to_dataframe(results_full)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e0a86-b0d8-465c-a0b6-0559b752f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = {\n",
    "    \"linguapy_avg\":\"LinguaPy\",\n",
    "    \"metricx_qe_strict\":\"QEMetricX_24-Strict-linguapy\",\n",
    "    \"xcomet_qe_strict\": \"XCOMET-QE-Strict-linguapy\"\n",
    "}\n",
    "\n",
    "#Collapse and get the metrics balanced by the linguapy score\n",
    "for pair in DIRECTION_PAIRS:\n",
    "    sub_df = df[df['direction']==pair]\n",
    "    sub_df = compute_strict_scores(sub_df)\n",
    "    #Standardize col names\n",
    "    sub_df = sub_df.rename(columns=col_map)\n",
    "    #Save \n",
    "    sub_df.to_csv(f\"wmt_{pair}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0d8ed-720d-49ec-97b6-27a044200cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
