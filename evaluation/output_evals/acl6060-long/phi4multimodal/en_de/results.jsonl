{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, heute werde ich unsere Forschungsarbeit vorstellen, die das Erlernen der deduktiven Beweisführung als komplexe rationale Extraktion darstellt.", "metrics": {"bleu_score": 13.20376974315548, "chrf_score": 50.62436212588868, "xcomet_score": 0.9765291213989258, "xcomet_qe_score": 0.9817510843276978, "metricx_score": 2.6296756267547607, "metricx_qe_score": 3.2923176288604736, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Bytedance AI Lab, und dies ist eine gemeinsame Arbeit mit Cheryle von der University of Texas at Austin und Wei Luo von SUTD.", "metrics": {"bleu_score": 52.16120234660553, "chrf_score": 77.13477602213104, "xcomet_score": 0.8215571641921997, "xcomet_qe_score": 0.8267221450805664, "metricx_score": 5.002933502197266, "metricx_qe_score": 4.767119884490967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen.", "metrics": {"bleu_score": 74.19446627365011, "chrf_score": 80.89316601602657, "xcomet_score": 0.9814042448997498, "xcomet_qe_score": 0.9854676723480225, "metricx_score": 1.536429524421692, "metricx_qe_score": 0.7237764596939087, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, in denen multistep thinking hilfreich ist.", "metrics": {"bleu_score": 14.043459416399545, "chrf_score": 39.66662985659817, "xcomet_score": 0.8949695229530334, "xcomet_qe_score": 0.9050993919372559, "metricx_score": 3.1007487773895264, "metricx_qe_score": 3.1232340335845947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Bild ist es aus dem Paper, in dem sie prompt to solve the math problem in a few-shot learning scenario.", "metrics": {"bleu_score": 12.586347848916265, "chrf_score": 35.11952295579061, "xcomet_score": 0.47683340311050415, "xcomet_qe_score": 0.6915229558944702, "metricx_score": 19.778522491455078, "metricx_qe_score": 17.903200149536133, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite können wir sehen, wenn wir einige Beispiele mit nur Fragen und Antworten geben, können wir die richtigen Antworten nicht erhalten. Aber", "metrics": {"bleu_score": 28.295596283263503, "chrf_score": 63.48951027477493, "xcomet_score": 0.9041878581047058, "xcomet_qe_score": 0.9043804407119751, "metricx_score": 4.4285478591918945, "metricx_qe_score": 0.9153355956077576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir mehr reasoning description geben, ist das Modell in der Lage, die reasoning description vorherzusagen und auch die richtige Vorhersage hier zu machen.", "metrics": {"bleu_score": 35.14496293851645, "chrf_score": 44.644467130453684, "xcomet_score": 0.763618528842926, "xcomet_qe_score": 0.7847268581390381, "metricx_score": 7.839119911193848, "metricx_qe_score": 7.457121849060059, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, interpretierbare multistep reasoning als output zu haben. Und", "metrics": {"bleu_score": 37.59663529467017, "chrf_score": 49.161531694491494, "xcomet_score": 0.8359676599502563, "xcomet_qe_score": 0.9059551954269409, "metricx_score": 8.852635383605957, "metricx_qe_score": 6.954204082489014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "wir denken, dass method problem eine einfache Anwendung ist, um solche reasoning abilities zu evaluieren.", "metrics": {"bleu_score": 16.54274233399128, "chrf_score": 44.34074567806271, "xcomet_score": 0.7404155135154724, "xcomet_qe_score": 0.7776807546615601, "metricx_score": 13.551583290100098, "metricx_qe_score": 12.492005348205566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Problemaufstellung müssen wir die Fragen lösen und die numerischen Antworten erhalten.", "metrics": {"bleu_score": 37.81244085822863, "chrf_score": 62.58219972066993, "xcomet_score": 0.9989743232727051, "xcomet_qe_score": 0.999722957611084, "metricx_score": 0.9046556353569031, "metricx_qe_score": 0.9775353670120239, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen werden uns auch die mathematischen Ausdrücke gegeben, die zu dieser bestimmten Antwort führen.", "metrics": {"bleu_score": 22.250253290431033, "chrf_score": 71.75971891313668, "xcomet_score": 0.9704475402832031, "xcomet_qe_score": 0.9763143658638, "metricx_score": 1.8847498893737793, "metricx_qe_score": 3.1157209873199463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "So gelten bestimmte Annahmen auch.", "metrics": {"bleu_score": 7.509307647752128, "chrf_score": 39.78507160493507, "xcomet_score": 0.8911038637161255, "xcomet_qe_score": 0.8985816240310669, "metricx_score": 4.923757076263428, "metricx_qe_score": 6.018733501434326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Präzision der Zahlen bekannt ist.", "metrics": {"bleu_score": 59.230330720232516, "chrf_score": 64.34667867626159, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.098772406578064, "metricx_qe_score": 1.010690450668335, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential.", "metrics": {"bleu_score": 88.43946454355333, "chrf_score": 93.2282436226332, "xcomet_score": 0.9847314357757568, "xcomet_qe_score": 0.9869264364242554, "metricx_score": 0.6797162294387817, "metricx_qe_score": 1.0274807214736938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplexe Operatoren in diese grundlegenden Operatoren zerlegt werden.", "metrics": {"bleu_score": 28.73539322585947, "chrf_score": 78.63083248287911, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.30813220143318176, "metricx_qe_score": 0.3041715621948242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "So kann frühere Arbeit in method problem in die Kategorien sequence to sequence und sequence to tree model einordnen.", "metrics": {"bleu_score": 2.5197593442434796, "chrf_score": 28.145794041164997, "xcomet_score": 0.5858052968978882, "xcomet_qe_score": 0.644026517868042, "metricx_score": 13.234135627746582, "metricx_qe_score": 11.215188026428223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "In traditionellen sequence to sequence-Modellen wird der Ausdruck in eine bestimmte Sequenz für die Generierung umgewandelt. Und", "metrics": {"bleu_score": 20.105373454060025, "chrf_score": 59.652398646975854, "xcomet_score": 0.8021815419197083, "xcomet_qe_score": 0.7776730060577393, "metricx_score": 3.4189703464508057, "metricx_qe_score": 2.74703049659729, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "es ist ziemlich einfach zu implementieren. Und es kann sich auf viele komplizierte Probleme verallgemeinern.", "metrics": {"bleu_score": 26.92050880955931, "chrf_score": 71.47162601734475, "xcomet_score": 0.982561469078064, "xcomet_qe_score": 0.9689338207244873, "metricx_score": 0.27007120847702026, "metricx_qe_score": 0.3448669910430908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Leistung ist im Allgemeinen nicht besser als die Strukturmodell. Und es fehlt an interpretierbarer Vorhersage.", "metrics": {"bleu_score": 12.439007351913624, "chrf_score": 48.967872569310984, "xcomet_score": 0.9629237651824951, "xcomet_qe_score": 0.9658071994781494, "metricx_score": 3.820493698120117, "metricx_qe_score": 3.611661434173584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber diese Richtung ist immer noch ziemlich beliebt wegen des Transformer-Modells.", "metrics": {"bleu_score": 18.63640680706656, "chrf_score": 67.8783703105927, "xcomet_score": 0.9893600940704346, "xcomet_qe_score": 0.9687775373458862, "metricx_score": 1.045961618423462, "metricx_qe_score": 2.071913719177246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In tree-basierten Modellen strukturieren wir diese Ausdrücke in einer Baumform und folgen einer vorbestimmten Traversal in Baumgenerationen.", "metrics": {"bleu_score": 48.06604068305993, "chrf_score": 83.61228040145555, "xcomet_score": 0.8824367523193359, "xcomet_qe_score": 0.8614473342895508, "metricx_score": 4.595090389251709, "metricx_qe_score": 5.362050533294678, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren und bis wir die Blätter, die die Quantitäten sind, kommen. Hier ist", "metrics": {"bleu_score": 20.63374693198514, "chrf_score": 52.00365630672824, "xcomet_score": 0.6833993196487427, "xcomet_qe_score": 0.7242051959037781, "metricx_score": 9.16629409790039, "metricx_qe_score": 6.726337432861328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "das Gute, dass es tatsächlich diese binäre Baumstruktur gibt. Und es ist ziemlich kontextuell, weil wir zuerst den Operator generieren und dann am Ende die Quantitäten generieren.", "metrics": {"bleu_score": 32.239421202256004, "chrf_score": 59.784010956541955, "xcomet_score": 0.7586233019828796, "xcomet_qe_score": 0.7986034154891968, "metricx_score": 7.768362522125244, "metricx_qe_score": 8.672700881958008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, dass es auch einige wiederholte Berechnungen enthält.", "metrics": {"bleu_score": 7.141816289329644, "chrf_score": 57.23715639913344, "xcomet_score": 0.9647543430328369, "xcomet_qe_score": 0.9744996428489685, "metricx_score": 0.6736822128295898, "metricx_qe_score": 0.4804321527481079, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "So hier, in diesem Ausdruck, a mal 3 plus 3, wird tatsächlich zweimal generiert. Aber eigentlich sollten wir die Ergebnisse wiederverwenden.", "metrics": {"bleu_score": 28.59826603326731, "chrf_score": 66.39015455789536, "xcomet_score": 0.8313885927200317, "xcomet_qe_score": 0.8332550525665283, "metricx_score": 3.9015610218048096, "metricx_qe_score": 4.613401889801025, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserer vorgeschlagenen Methode wollen wir diese Probleme in einem schrittweisen und interpretierbaren Weg lösen. So, zum Beispiel", "metrics": {"bleu_score": 15.774545980684183, "chrf_score": 65.89038831522437, "xcomet_score": 0.8785768747329712, "xcomet_qe_score": 0.8818726539611816, "metricx_score": 1.4485900402069092, "metricx_qe_score": 2.9181101322174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "hier in der zweiten Stufe, können wir diese Divisoren erhalten, die 27 sind. Und", "metrics": {"bleu_score": 12.03921753741131, "chrf_score": 41.938531610227834, "xcomet_score": 0.7917687892913818, "xcomet_qe_score": 0.8090801239013672, "metricx_score": 5.309115886688232, "metricx_qe_score": 3.481579303741455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "wir können auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden. Und", "metrics": {"bleu_score": 80.65008590125565, "chrf_score": 92.83483533301062, "xcomet_score": 0.9670027494430542, "xcomet_qe_score": 0.9606258869171143, "metricx_score": 2.1818411350250244, "metricx_qe_score": 0.38815808296203613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "in diesen Schritten erhalten wir tatsächlich die", "metrics": {"bleu_score": 37.68499164492418, "chrf_score": 70.90367498774486, "xcomet_score": 0.8449234962463379, "xcomet_qe_score": 0.8681098222732544, "metricx_score": 7.875180721282959, "metricx_qe_score": 9.311519622802734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Quotienten.", "metrics": {"bleu_score": 0.0, "chrf_score": 19.707436446636983, "xcomet_score": 0.20080581307411194, "xcomet_qe_score": 0.14855031669139862, "metricx_score": 10.863476753234863, "metricx_qe_score": 18.055788040161133, "linguapy_score": [1, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse der vierten Stufe erhalten. Und dann können wir die Dividenden erhalten.", "metrics": {"bleu_score": 26.311146497186694, "chrf_score": 55.98976224029484, "xcomet_score": 0.8787052631378174, "xcomet_qe_score": 0.8618736267089844, "metricx_score": 4.404383659362793, "metricx_qe_score": 5.8436994552612305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Quantitäten zu generieren.", "metrics": {"bleu_score": 5.675727444525874, "chrf_score": 51.71629692299224, "xcomet_score": 0.9925411939620972, "xcomet_qe_score": 0.9968172311782837, "metricx_score": 0.6374936103820801, "metricx_qe_score": 0.6939017176628113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "So macht der Prozess genauer.", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 62.52168665558091, "xcomet_score": 0.8925579786300659, "xcomet_qe_score": 0.8740758299827576, "metricx_score": 3.2687501907348633, "metricx_qe_score": 4.841055393218994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir mit einer Reihe von Quantitäten, die in den Fragen präsentiert werden, und auch einige Konstanten als unsere initialen Zustände.", "metrics": {"bleu_score": 40.52703418562333, "chrf_score": 58.65711996875559, "xcomet_score": 0.9462792277336121, "xcomet_qe_score": 0.951906681060791, "metricx_score": 3.9651012420654297, "metricx_qe_score": 4.182649612426758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird durch ei, j, op dargestellt, wobei", "metrics": {"bleu_score": 14.991106946711685, "chrf_score": 70.69426902566104, "xcomet_score": 0.973610520362854, "xcomet_qe_score": 0.9787259697914124, "metricx_score": 4.6109395027160645, "metricx_qe_score": 4.988421440124512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "wir einen Operator von qi zu qj durchführen. Und dieser Ausdruck ist tatsächlich gerichtet.", "metrics": {"bleu_score": 13.843927738579898, "chrf_score": 65.11718074068219, "xcomet_score": 0.8829712867736816, "xcomet_qe_score": 0.9200568199157715, "metricx_score": 4.510349273681641, "metricx_qe_score": 4.51862907409668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir auch eine Subtraktion mit vor, um die entgegengesetzte Richtung darzustellen.", "metrics": {"bleu_score": 29.13055375496153, "chrf_score": 63.15808869328469, "xcomet_score": 0.9166141748428345, "xcomet_qe_score": 0.8994218111038208, "metricx_score": 3.240018129348755, "metricx_qe_score": 2.8428878784179688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "So", "metrics": {"bleu_score": 0.0, "chrf_score": 1.4367816091954022, "xcomet_score": 0.18516945838928223, "xcomet_qe_score": 0.15905927121639252, "metricx_score": 20.213048934936523, "metricx_qe_score": 12.814602851867676, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "in einem formalen deduktiven System, zu einem Zeitpunkt t, wenden wir den Operator zwischen den QI und QJ-Paaren an. Und dann erhalten wir diese neuen Ausdrücke, die", "metrics": {"bleu_score": 14.482839108969983, "chrf_score": 63.32688197700204, "xcomet_score": 0.8545213341712952, "xcomet_qe_score": 0.8771349191665649, "metricx_score": 6.0559539794921875, "metricx_qe_score": 3.1198949813842773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "wir zu den nächsten Zuständen hinzufügen, um eine neue Menge zu erhalten. So visualisieren", "metrics": {"bleu_score": 45.608395453519385, "chrf_score": 66.34671006160558, "xcomet_score": 0.6727756857872009, "xcomet_qe_score": 0.5702435374259949, "metricx_score": 5.999970436096191, "metricx_qe_score": 5.603671073913574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "diese Folien die Entwicklung der Zustände, bei der wir den Ausdruck zu den aktuellen Zuständen hinzufügen.", "metrics": {"bleu_score": 6.833557619127329, "chrf_score": 49.05828810259686, "xcomet_score": 0.8529828190803528, "xcomet_qe_score": 0.8487138748168945, "metricx_score": 9.266731262207031, "metricx_qe_score": 9.416976928710938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zuerst ein vortrainiertes Modell, das kann birds oder roberta sein. Und dann kodieren wir den Satz und dann erhalten wir diese quantitativen Darstellungen.", "metrics": {"bleu_score": 29.412019100399252, "chrf_score": 63.890620094397235, "xcomet_score": 0.8308855295181274, "xcomet_qe_score": 0.8384568095207214, "metricx_score": 5.41731595993042, "metricx_qe_score": 4.775668144226074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir die quantitativen Darstellungen erhalten, können wir mit der Inferenz beginnen.", "metrics": {"bleu_score": 57.57575636202256, "chrf_score": 71.35111714233179, "xcomet_score": 0.9995086193084717, "xcomet_qe_score": 0.9968060255050659, "metricx_score": 0.6714885234832764, "metricx_qe_score": 1.1515507698059082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel, um die Darstellung für Q1 zu erhalten, geteilt durch Q2 und dann multipliziert mit Q3.", "metrics": {"bleu_score": 26.921813416893176, "chrf_score": 69.80328410151444, "xcomet_score": 0.9252926111221313, "xcomet_qe_score": 0.9396580457687378, "metricx_score": 3.3404288291931152, "metricx_qe_score": 5.556107521057129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paardarstellung, was im Grunde nur die Konkatentation zwischen Q1 und Q2 ist. Und dann wenden wir ein Feedforward-Netzwerk an, das durch den Operator parametrisiert ist.", "metrics": {"bleu_score": 52.779661808438526, "chrf_score": 78.38798659361831, "xcomet_score": 0.9429067969322205, "xcomet_qe_score": 0.8856809139251709, "metricx_score": 3.152674674987793, "metricx_qe_score": 3.0474681854248047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir die Ausdrucksdarstellung, Q1 geteilt durch Q2.", "metrics": {"bleu_score": 21.139352947609474, "chrf_score": 70.92721354852421, "xcomet_score": 0.9929014444351196, "xcomet_qe_score": 0.9828095436096191, "metricx_score": 0.6572422981262207, "metricx_qe_score": 1.0765573978424072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis können wir in der Inferenzphase auch die falsche Ausdrucksdarstellung erhalten.", "metrics": {"bleu_score": 44.80304273880272, "chrf_score": 79.17056007285527, "xcomet_score": 0.9966275691986084, "xcomet_qe_score": 0.9819611310958862, "metricx_score": 1.1431818008422852, "metricx_qe_score": 1.4838669300079346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind alle möglichen Ausdrücke gleich 3 mal der Anzahl der Operatoren.", "metrics": {"bleu_score": 48.764850158827386, "chrf_score": 75.55530895894795, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8537548780441284, "metricx_qe_score": 1.308647871017456, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute hier ist, dass wir die Suchraum einfach kontrollieren können, um diese Suchraum zu kontrollieren. Zum Beispiel,", "metrics": {"bleu_score": 27.19326877457978, "chrf_score": 53.06864919010217, "xcomet_score": 0.6510627865791321, "xcomet_qe_score": 0.6319901347160339, "metricx_score": 5.900090217590332, "metricx_qe_score": 7.683475971221924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "wenn dieser Ausdruck nicht erlaubt ist, können wir diesen Ausdruck einfach aus unserem Suchraum entfernen.", "metrics": {"bleu_score": 56.55183553484675, "chrf_score": 78.84272686209498, "xcomet_score": 0.9545150995254517, "xcomet_qe_score": 0.9446285963058472, "metricx_score": 0.8763003349304199, "metricx_qe_score": 1.4149882793426514, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "So machen wir in der zweiten Stufe dasselbe, aber die einzige Unterschied ist, dass die", "metrics": {"bleu_score": 21.502703953169373, "chrf_score": 50.53221296364746, "xcomet_score": 0.6561424136161804, "xcomet_qe_score": 0.7551190853118896, "metricx_score": 14.240164756774902, "metricx_qe_score": 8.620355606079102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "vorher berechnete Ausdruckung.", "metrics": {"bleu_score": 3.564186929405141, "chrf_score": 35.772420287228194, "xcomet_score": 0.7800642251968384, "xcomet_qe_score": 0.7754854559898376, "metricx_score": 4.957772254943848, "metricx_qe_score": 8.925366401672363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir diese endgültige Ausdrucksdarstellung, Q3 mal Q4. Und", "metrics": {"bleu_score": 3.6672995332980713, "chrf_score": 53.23804640138108, "xcomet_score": 0.9414823055267334, "xcomet_qe_score": 0.8553411960601807, "metricx_score": 2.7235305309295654, "metricx_qe_score": 1.1860036849975586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "wir können auch sehen, dass die Anzahl der möglichen Ausdrücke von der vorherigen Stufe anders ist.", "metrics": {"bleu_score": 41.0234958813199, "chrf_score": 73.14363757130077, "xcomet_score": 0.9333648681640625, "xcomet_qe_score": 0.8974896669387817, "metricx_score": 2.9375789165496826, "metricx_qe_score": 3.233609437942505, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "So macht es es schwer, die Beam Search zu verwenden, weil die Wahrscheinlichkeit der Verteilung zwischen diesen beiden Stufen ungleich ist. So ist die", "metrics": {"bleu_score": 8.30109546282258, "chrf_score": 53.53167635992918, "xcomet_score": 0.7315735220909119, "xcomet_qe_score": 0.7436413764953613, "metricx_score": 9.133906364440918, "metricx_qe_score": 6.937337398529053, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Trainingsmethode ähnlich wie die Training eines sequence to sequence-Modells, bei dem wir den Verlust an jedem Zeitpunkt optimieren.", "metrics": {"bleu_score": 30.51327880362441, "chrf_score": 58.35974431599714, "xcomet_score": 0.7843503355979919, "xcomet_qe_score": 0.8191130757331848, "metricx_score": 4.685413360595703, "metricx_qe_score": 5.4111809730529785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir tau, um den Zeitpunkt darzustellen, an dem wir diesen generativen Prozess beenden. Und", "metrics": {"bleu_score": 12.401006001680987, "chrf_score": 55.26493123206393, "xcomet_score": 0.9283875823020935, "xcomet_qe_score": 0.934705376625061, "metricx_score": 4.063736915588379, "metricx_qe_score": 2.1899900436401367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "hier ist der Raum anders, weil der Raum an jedem Zeitpunkt anders ist. Und", "metrics": {"bleu_score": 9.773838390025208, "chrf_score": 24.10284125592272, "xcomet_score": 0.3794752359390259, "xcomet_qe_score": 0.14556854963302612, "metricx_score": 17.278682708740234, "metricx_qe_score": 15.644237518310547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "es erlaubt uns auch, bestimmte Einschränkungen aus früheren Kenntnissen einzuführen.", "metrics": {"bleu_score": 34.48444257953326, "chrf_score": 60.72598894720716, "xcomet_score": 0.959915816783905, "xcomet_qe_score": 0.9537832736968994, "metricx_score": 1.045348882675171, "metricx_qe_score": 1.233511209487915, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "So führen wir Experimente mit den gängigen method problem Datensätzen durch, wie mawps, math 23k, math qa und swem. Und", "metrics": {"bleu_score": 19.38341802345665, "chrf_score": 44.64356239398279, "xcomet_score": 0.7201155424118042, "xcomet_qe_score": 0.6735807061195374, "metricx_score": 9.935492515563965, "metricx_qe_score": 9.82591438293457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "hier zeigen wir die Ergebnisse im Vergleich zu den bisherigen besten Ansätzen.", "metrics": {"bleu_score": 73.24967962619755, "chrf_score": 90.03341852520049, "xcomet_score": 0.9543061256408691, "xcomet_qe_score": 0.9475771188735962, "metricx_score": 0.40264853835105896, "metricx_qe_score": 0.46402594447135925, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Leistung ist roberta deduktive reasoner.", "metrics": {"bleu_score": 7.267884212102741, "chrf_score": 37.84317791941598, "xcomet_score": 0.8457202911376953, "xcomet_qe_score": 0.7980450391769409, "metricx_score": 4.192409038543701, "metricx_qe_score": 5.703368186950684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und wir verwenden nicht im Gegensatz zu den anderen Ansätzen die Beam Search", "metrics": {"bleu_score": 12.490948835673715, "chrf_score": 44.579766886179804, "xcomet_score": 0.8923524618148804, "xcomet_qe_score": 0.8816851377487183, "metricx_score": 5.726566314697266, "metricx_qe_score": 8.049050331115723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": ". Die besten Ansätze sind oft tree-basierte Modelle.", "metrics": {"bleu_score": 12.41950196698629, "chrf_score": 59.89802671666647, "xcomet_score": 0.8706156015396118, "xcomet_qe_score": 0.9563118815422058, "metricx_score": 6.302257537841797, "metricx_qe_score": 4.640315055847168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "So ist unsere reasoner in der Lage, signifikant besser zu sein als diese tree-basierte Modelle.", "metrics": {"bleu_score": 17.026024721767097, "chrf_score": 53.13748054222699, "xcomet_score": 0.8567124605178833, "xcomet_qe_score": 0.845131516456604, "metricx_score": 7.0919599533081055, "metricx_qe_score": 6.763636589050293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absolute Zahl auf math qa oder swem nicht wirklich hoch ist.", "metrics": {"bleu_score": 39.67088290836578, "chrf_score": 65.60054559059778, "xcomet_score": 0.8531837463378906, "xcomet_qe_score": 0.8434003591537476, "metricx_score": 4.888681411743164, "metricx_qe_score": 4.7293853759765625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Also untersuchen wir die Ergebnisse auf swem. Und", "metrics": {"bleu_score": 31.55984539112946, "chrf_score": 57.06706102057634, "xcomet_score": 0.8310617208480835, "xcomet_qe_score": 0.8778020739555359, "metricx_score": 4.9587531089782715, "metricx_qe_score": 3.8587963581085205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "dieser Datensatz ist herausfordernd, weil der Autor versucht, dem NLP-Modell etwas hinzuzufügen, wie zum Beispiel die Hinzufügung von irrelevanten Informationen und zusätzlichen Quantitäten. So finden wir", "metrics": {"bleu_score": 17.316911765058936, "chrf_score": 66.59857941004415, "xcomet_score": 0.877609372138977, "xcomet_qe_score": 0.8611851930618286, "metricx_score": 5.967713832855225, "metricx_qe_score": 4.95782470703125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "in unserer Vorhersage einige der Zwischenwerte, die tatsächlich negativ sind.", "metrics": {"bleu_score": 17.776006114427847, "chrf_score": 63.02892160071705, "xcomet_score": 0.9520500302314758, "xcomet_qe_score": 0.9011008739471436, "metricx_score": 5.966036319732666, "metricx_qe_score": 6.751833438873291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, in diesen Fragen, fragen wir, wie viele Äpfel hat Jake?", "metrics": {"bleu_score": 25.947507140745756, "chrf_score": 62.637246099219176, "xcomet_score": 0.9739278554916382, "xcomet_qe_score": 0.9701756238937378, "metricx_score": 1.6128623485565186, "metricx_qe_score": 1.7279052734375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie 17 weniger Beeren und Steven hat 8 Beeren, was völlig irrelevant ist.", "metrics": {"bleu_score": 52.500844009281, "chrf_score": 75.8887109064396, "xcomet_score": 0.759903073310852, "xcomet_qe_score": 0.7938930988311768, "metricx_score": 5.507142543792725, "metricx_qe_score": 5.120838165283203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "So macht unser Modell eine Vorhersage wie diese, die ist, die 35 multipliziert. Und", "metrics": {"bleu_score": 31.18181497809656, "chrf_score": 56.94114237961002, "xcomet_score": 0.36243143677711487, "xcomet_qe_score": 0.3749731481075287, "metricx_score": 18.26934051513672, "metricx_qe_score": 18.5742244720459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "wir beobachten, dass diese beiden Ausdrücke tatsächlich ähnliche Ergebnisse haben.", "metrics": {"bleu_score": 52.50459577889848, "chrf_score": 71.38034197780108, "xcomet_score": 0.9733293056488037, "xcomet_qe_score": 0.9551255702972412, "metricx_score": 0.5571971535682678, "metricx_qe_score": 0.5936722159385681, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "So können wir diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse negativ machen, so dass wir die Antwort korrekt machen können.", "metrics": {"bleu_score": 10.190322065968884, "chrf_score": 52.518965186893695, "xcomet_score": 0.8306393623352051, "xcomet_qe_score": 0.7996435165405273, "metricx_score": 2.400144100189209, "metricx_qe_score": 2.699782133102417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "So verbessern wir die Leistung einiger Modelle. Zum Beispiel, für birds, verbess", "metrics": {"bleu_score": 3.04281210061706, "chrf_score": 23.137916149397924, "xcomet_score": 0.22784604132175446, "xcomet_qe_score": 0.16020673513412476, "metricx_score": 11.97098159790039, "metricx_qe_score": 13.618096351623535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "ern wir 7 Punkte. Und dann für die roberta-basierte Modell, verbessern wir 2 Punkte. Also hat", "metrics": {"bleu_score": 2.452552641442349, "chrf_score": 27.786741188997784, "xcomet_score": 0.2872864902019501, "xcomet_qe_score": 0.5924638509750366, "metricx_score": 22.70071792602539, "metricx_qe_score": 17.729347229003906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "die bessere Sprachmodell eine bessere Sprachverständnisfähigkeit. Also ist die Zahl hier für roberta höher und niedriger für birds. Und", "metrics": {"bleu_score": 10.108901518669624, "chrf_score": 61.960055476399155, "xcomet_score": 0.6697887182235718, "xcomet_qe_score": 0.6212318539619446, "metricx_score": 11.142948150634766, "metricx_qe_score": 11.791340827941895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "wir versuchen auch, die Schwierigkeit hinter all diesen Datensätzen zu analysieren.", "metrics": {"bleu_score": 67.03420896351791, "chrf_score": 92.86636345890457, "xcomet_score": 0.8954851627349854, "xcomet_qe_score": 0.8174564838409424, "metricx_score": 0.7077906131744385, "metricx_qe_score": 1.011418342590332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der nicht verwendeten Quantitäten als irrelevant angesehen werden kann.", "metrics": {"bleu_score": 51.072310908001, "chrf_score": 58.272425560864086, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5360602736473083, "metricx_qe_score": 0.45528504252433777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "So können wir die Prozentsätze der Sätze mit und ohne Quantitäten sehen. Und hier haben wir die größte Portion. Und", "metrics": {"bleu_score": 4.389951910012477, "chrf_score": 30.453429227419175, "xcomet_score": 0.43500223755836487, "xcomet_qe_score": 0.6601887941360474, "metricx_score": 13.681035041809082, "metricx_qe_score": 10.158278465270996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "hier zeigen wir auch die Gesamtleistung.", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 96.91453964283662, "xcomet_score": 0.9695428609848022, "xcomet_qe_score": 0.9749259352684021, "metricx_score": 0.2486199587583542, "metricx_qe_score": 0.37873098254203796, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für die Sätze ohne Quantitäten ist die Gesamtleistung tatsächlich höher als die Gesamtleistung.", "metrics": {"bleu_score": 29.43543418414033, "chrf_score": 49.48508625865819, "xcomet_score": 0.6473041772842407, "xcomet_qe_score": 0.5299339294433594, "metricx_score": 7.384922981262207, "metricx_qe_score": 9.054037094116211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber mit diesen Sätzen mit einer nicht verwendeten Quantität ist die Gesamtleistung tatsächlich viel schlechter als die Gesamtleistung.", "metrics": {"bleu_score": 28.339296176052862, "chrf_score": 56.0933445848861, "xcomet_score": 0.6739047765731812, "xcomet_qe_score": 0.6583387851715088, "metricx_score": 5.2382588386535645, "metricx_qe_score": 5.8734517097473145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für mawps haben wir nicht wirklich zu viele dieser Fälle, also ignorieren wir diesen Teil.", "metrics": {"bleu_score": 20.455163269401236, "chrf_score": 60.34763047125017, "xcomet_score": 0.8321015238761902, "xcomet_qe_score": 0.8016800880432129, "metricx_score": 4.293412685394287, "metricx_qe_score": 5.063895225524902, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "So", "metrics": {"bleu_score": 0.0, "chrf_score": 1.497005988023952, "xcomet_score": 0.1951659619808197, "xcomet_qe_score": 0.1464654803276062, "metricx_score": 24.568029403686523, "metricx_qe_score": 19.825105667114258, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "schließen", "metrics": {"bleu_score": 0.0, "chrf_score": 5.1250904396863355, "xcomet_score": 0.3784281015396118, "xcomet_qe_score": 0.14682313799858093, "metricx_score": 10.132885932922363, "metricx_qe_score": 23.037425994873047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "wir", "metrics": {"bleu_score": 0.0, "chrf_score": 1.803588575680336, "xcomet_score": 0.20968791842460632, "xcomet_qe_score": 0.15535733103752136, "metricx_score": 20.690031051635742, "metricx_qe_score": 17.53066635131836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.27108293771743774, "xcomet_qe_score": 0.23310334980487823, "metricx_score": 8.173208236694336, "metricx_qe_score": 15.32159423828125, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.28625214099884033, "xcomet_qe_score": 0.13521863520145416, "metricx_score": 8.782315254211426, "metricx_qe_score": 22.40188980102539, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.23041966557502747, "xcomet_qe_score": 0.1323399394750595, "metricx_score": 13.341413497924805, "metricx_qe_score": 21.48493194580078, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.30634844303131104, "xcomet_qe_score": 0.1311989426612854, "metricx_score": 10.495829582214355, "metricx_qe_score": 11.064939498901367, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3789137005805969, "xcomet_qe_score": 0.2348582148551941, "metricx_score": 10.185952186584473, "metricx_qe_score": 13.350894927978516, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "unsere Arbeit ab. Zuerst ist unser Modell tatsächlich ziemlich effizient. Und", "metrics": {"bleu_score": 52.055103630534376, "chrf_score": 74.11545090160936, "xcomet_score": 0.8072477579116821, "xcomet_qe_score": 0.7878793478012085, "metricx_score": 6.636661529541016, "metricx_qe_score": 5.128396034240723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "wir sind in der Lage, interpretierbare Lösungen zu liefern. Und", "metrics": {"bleu_score": 33.18077402843942, "chrf_score": 56.19844501032991, "xcomet_score": 0.9445992708206177, "xcomet_qe_score": 0.9354285001754761, "metricx_score": 3.2617552280426025, "metricx_qe_score": 0.8520054817199707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "wir können einige priorielle Kenntnisse als Einschränkungen einbeziehen, was die Leistung verbessern kann.", "metrics": {"bleu_score": 12.107470158860226, "chrf_score": 49.04336551136608, "xcomet_score": 0.9401190280914307, "xcomet_qe_score": 0.9424614906311035, "metricx_score": 3.657513380050659, "metricx_qe_score": 3.1552622318267822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und die zugrunde Mechanismus, der nicht nur für method problem solving tasks, sondern auch für andere Aufgaben, die multistep reasoning beinhalten, gilt.", "metrics": {"bleu_score": 32.54455687469726, "chrf_score": 49.88496561387423, "xcomet_score": 0.7345735430717468, "xcomet_qe_score": 0.788314700126648, "metricx_score": 14.637383460998535, "metricx_qe_score": 13.540078163146973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch einige Einschränkungen.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 17.381555149340585, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, kann der Speicherverbrauch ziemlich hoch sein.", "metrics": {"bleu_score": 83.94327083733333, "chrf_score": 93.01356276863744, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.45400747656822205, "metricx_qe_score": 0.47154533863067627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, dass die Wahrscheinlichkeit der Verteilung zwischen den verschiedenen Zeitstufen ungleich ist. Also ist dies das", "metrics": {"bleu_score": 7.851008461709069, "chrf_score": 39.60824723986528, "xcomet_score": 0.6226575970649719, "xcomet_qe_score": 0.7507404088973999, "metricx_score": 16.202655792236328, "metricx_qe_score": 16.0655460357666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Ende des Vortrags. Und Fragen sind willkommen. Vielen Dank.", "metrics": {"bleu_score": 15.018527368048874, "chrf_score": 47.773199949009644, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5220657587051392, "metricx_qe_score": 0.37774157524108887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Antoine und komme von der Universität Maastricht.", "metrics": {"bleu_score": 37.59014232678325, "chrf_score": 70.63393687532201, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.06067747622728348, "metricx_qe_score": 0.07090809941291809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, die sich mit einem neuen Datensatz für die Ermittlung von Rechtsartikeln befasst.", "metrics": {"bleu_score": 42.26640079441617, "chrf_score": 66.10864730490592, "xcomet_score": 0.9617674350738525, "xcomet_qe_score": 0.963358461856842, "metricx_score": 1.0771311521530151, "metricx_qe_score": 0.8001958131790161, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen,", "metrics": {"bleu_score": 52.53819788848316, "chrf_score": 80.6790619000123, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5351028442382812, "metricx_qe_score": 0.07517820596694946, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "aber die Mehrheit der Bürger hat wenig bis gar keine Kenntnisse über ihre Rechte und grundlegenden Rechts", "metrics": {"bleu_score": 27.805272316398217, "chrf_score": 59.0252984992931, "xcomet_score": 0.8894250392913818, "xcomet_qe_score": 0.8935878276824951, "metricx_score": 1.3196821212768555, "metricx_qe_score": 0.6503376364707947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "verfahren.", "metrics": {"bleu_score": 0.0, "chrf_score": 1.9730820868412344, "xcomet_score": 0.1488843709230423, "xcomet_qe_score": 0.13016442954540253, "metricx_score": 23.0393009185791, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen Menschen und dem Recht zu überbrücken, indem wir ein effektives Erfassenssystem für Rechtsartikel entwickeln.", "metrics": {"bleu_score": 48.43025957347058, "chrf_score": 72.5940750130032, "xcomet_score": 0.981157660484314, "xcomet_qe_score": 0.9856356382369995, "metricx_score": 1.8982802629470825, "metricx_qe_score": 1.2859411239624023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte eine kostenlose, professionelle Rechtsberatung für ungeschulte Menschen bieten.", "metrics": {"bleu_score": 20.448007360218387, "chrf_score": 63.617262699997504, "xcomet_score": 0.9656492471694946, "xcomet_qe_score": 0.9775583744049072, "metricx_score": 0.5487595796585083, "metricx_qe_score": 0.2909058630466461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit der Hauptleistung dieser Arbeit befassen, lassen Sie uns zunächst das Problem der Ermittlung von Rechtsartikeln beschreiben. Angesichts", "metrics": {"bleu_score": 13.566979610140004, "chrf_score": 56.793217792640185, "xcomet_score": 0.7420375347137451, "xcomet_qe_score": 0.7511104345321655, "metricx_score": 6.322226047515869, "metricx_qe_score": 2.1675076484680176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "einer einfachen Frage zu einem Rechtsanliegen, wie z. B. \"Was ist mein Risiko, wenn ich vertrauliche Informationen missbrauche?\", ist", "metrics": {"bleu_score": 7.066026049079721, "chrf_score": 38.74839848892703, "xcomet_score": 0.7387505173683167, "xcomet_qe_score": 0.5708953142166138, "metricx_score": 10.184446334838867, "metricx_qe_score": 6.171231269836426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "ein Modell erforderlich, um alle relevanten Rechtsartikel aus einer großen Gesetzesdatenbank zu finden.", "metrics": {"bleu_score": 17.727122852412712, "chrf_score": 54.24051272906165, "xcomet_score": 0.9677491188049316, "xcomet_qe_score": 0.9675540924072266, "metricx_score": 2.329981803894043, "metricx_qe_score": 1.9651458263397217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsabrufaufgabe birgt ihre eigenen Herausforderungen.", "metrics": {"bleu_score": 5.630400552901077, "chrf_score": 53.589355782513636, "xcomet_score": 0.9821320176124573, "xcomet_qe_score": 1.0, "metricx_score": 0.7164700031280518, "metricx_qe_score": 0.20130273699760437, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Erstens handelt es sich um zwei Arten von Sprache:", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 68.1980218599912, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2898779511451721, "metricx_qe_score": 0.658079981803894, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "die alltägliche Sprache für die Fragen und die komplexe Sprache der Rechtsartikel.", "metrics": {"bleu_score": 40.826691498313366, "chrf_score": 54.61899460894952, "xcomet_score": 0.9691832065582275, "xcomet_qe_score": 0.9697380065917969, "metricx_score": 1.179693341255188, "metricx_qe_score": 1.333221197128296, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in der Sprachverteilung machen es für ein System schwieriger, relevante Kandidaten zu finden, da es eine Interpretation erfordert, die eine natürliche Frage in eine juristische Frage umwandelt, die der Terminologie der Rechtsartikel entspricht. Darüber", "metrics": {"bleu_score": 47.19883810249203, "chrf_score": 68.77950813049324, "xcomet_score": 0.925769567489624, "xcomet_qe_score": 0.8835654854774475, "metricx_score": 5.493973255157471, "metricx_qe_score": 1.0969890356063843, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "hinaus ist das Gesetz kein Stapel unabhängiger Artikel, der als eigenständige Informationsquelle behandelt werden kann, wie Nachrichten oder Rezepte.", "metrics": {"bleu_score": 15.22279083021855, "chrf_score": 53.89891049279857, "xcomet_score": 0.9635217189788818, "xcomet_qe_score": 0.9666684865951538, "metricx_score": 4.055630683898926, "metricx_qe_score": 3.9141154289245605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen ist es eine strukturierte Sammlung von Rechtsbestimmungen, die nur im Gesamtkontext, zusammen mit den angrenzenden Informationen, den Feldern und Unterkategorien, die sie zugeordnet sind, und ihrer Platzierung in der Gesetzesstruktur, einen ganzheitlichen Sinn haben.", "metrics": {"bleu_score": 20.711440277246748, "chrf_score": 50.994595428561496, "xcomet_score": 0.9708034992218018, "xcomet_qe_score": 0.9719069600105286, "metricx_score": 1.094518780708313, "metricx_qe_score": 1.0133682489395142, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich sind Rechtsartikel in kurzen Paragraphen, die in der Regel die typische Erfassungsgröße in den meisten Erfassungsarbeiten sind.", "metrics": {"bleu_score": 12.691046181801012, "chrf_score": 38.484986224389075, "xcomet_score": 0.8212616443634033, "xcomet_qe_score": 0.8339629173278809, "metricx_score": 10.444497108459473, "metricx_qe_score": 11.764217376708984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Sie sind lange Dokumente, die bis zu 6.000 Wörter lang sein können, wobei der längste bis zu 5.790 Wörter lang ist.", "metrics": {"bleu_score": 30.123786461877344, "chrf_score": 61.72363549899773, "xcomet_score": 0.9253779649734497, "xcomet_qe_score": 0.9144092798233032, "metricx_score": 2.002972364425659, "metricx_qe_score": 3.083569288253784, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben großes Interesse an vielen Rechtsaufgaben wie Rechtsurteilungsvorhersage oder automatisierte Vertragsprüfung geweckt,", "metrics": {"bleu_score": 19.13555863464113, "chrf_score": 59.20089074739495, "xcomet_score": 0.9580622911453247, "xcomet_qe_score": 0.9540450572967529, "metricx_score": 1.5031275749206543, "metricx_qe_score": 2.2328104972839355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "aber die Ermittlung von Rechtsartikeln ist aufgrund des Mangels an großen, hochwertigen Label-Datensätzen weitgehend unberührt geblieben.", "metrics": {"bleu_score": 36.84981984538113, "chrf_score": 65.78875969722766, "xcomet_score": 0.908362090587616, "xcomet_qe_score": 0.8646035194396973, "metricx_score": 2.5422253608703613, "metricx_qe_score": 3.218566417694092, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit präsentieren wir einen neuen, französischsprachigen, bürgerzentrierten Datensatz, um zu untersuchen, inwieweit ein Erfassungsmodell die Effizienz und Zuverlässigkeit eines Rechtsfachmanns bei der Aufgabe der", "metrics": {"bleu_score": 17.883203057979372, "chrf_score": 52.39292835771777, "xcomet_score": 0.7211704850196838, "xcomet_qe_score": 0.7811505794525146, "metricx_score": 8.929944038391113, "metricx_qe_score": 9.70327377319336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Ermittlung von Rechtsartikeln annähern kann. Unser belgisches Erfassungsdatensatz besteht aus mehr als 1.100 juristischen Fragen, die von belgischen Bürgern gestellt wurden.", "metrics": {"bleu_score": 56.831473804927576, "chrf_score": 72.94620077677547, "xcomet_score": 0.8150486946105957, "xcomet_qe_score": 0.7897447347640991, "metricx_score": 8.547333717346191, "metricx_qe_score": 11.318565368652344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen decken eine breite Palette von Themen ab, von Familie, Wohnung, Geld bis hin zu Arbeit und Sozialversicherung.", "metrics": {"bleu_score": 49.73249616761811, "chrf_score": 69.60131564447688, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20765163004398346, "metricx_qe_score": 0.11424732208251953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jede der Fragen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als 22.633 Rechtsartikeln aus den belgischen Rechtsordnungen gekennzeichnet.", "metrics": {"bleu_score": 60.09638585283707, "chrf_score": 76.31293726475153, "xcomet_score": 0.9851154088973999, "xcomet_qe_score": 0.9813120365142822, "metricx_score": 3.6513943672180176, "metricx_qe_score": 3.5309550762176514, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns nun darüber sprechen, wie wir diesen Datensatz erstellt haben.", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 86.45749888209666, "xcomet_score": 0.9983378648757935, "xcomet_qe_score": 0.9987733364105225, "metricx_score": 0.8484037518501282, "metricx_qe_score": 1.5787975788116455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst haben wir eine große Korpus von Rechtsartikeln erstellt.", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 63.84093805010115, "xcomet_score": 0.9647558927536011, "xcomet_qe_score": 0.9569860100746155, "metricx_score": 3.103180170059204, "metricx_qe_score": 4.225494384765625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich zugängliche belgische Rechtsordnungen berücksichtigt und alle ihre Artikel sowie die entsprechenden Abschnittsüberschriften extrahiert.", "metrics": {"bleu_score": 66.7278568794606, "chrf_score": 88.03872312642895, "xcomet_score": 0.9906935095787048, "xcomet_qe_score": 0.9879075884819031, "metricx_score": 0.930711030960083, "metricx_qe_score": 0.9954535365104675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann haben wir juristische Fragen mit Verweisen auf relevante Rechtsartikel gesammelt. Um dies", "metrics": {"bleu_score": 26.58483576665878, "chrf_score": 53.025389176795244, "xcomet_score": 0.8908205032348633, "xcomet_qe_score": 0.8982775807380676, "metricx_score": 5.966552734375, "metricx_qe_score": 4.283066749572754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "zu tun, haben wir uns mit einem belgischen Anwaltsbüro zusammengetan, das jedes Jahr etwa 4.000 E-Mails von belgischen Bürgern erhält, die sich mit persönlichen Rechtsfragen befasst.", "metrics": {"bleu_score": 35.72387899918221, "chrf_score": 61.64818913836964, "xcomet_score": 0.788180947303772, "xcomet_qe_score": 0.7774554491043091, "metricx_score": 3.6267189979553223, "metricx_qe_score": 3.2889509201049805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ein Team von erfahrenen Juristen die häufigsten belgischen Rechtsfragen beantwortet.", "metrics": {"bleu_score": 62.325761569522825, "chrf_score": 71.52194621192339, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4632852077484131, "metricx_qe_score": 0.6281445622444153, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir sammelten Tausende von Fragen, die mit Kategorien, Unterkategorien und juristischen Verweisen zu relevanten Rechtsartikeln annotiert wurden.", "metrics": {"bleu_score": 26.52951833482444, "chrf_score": 62.05112325741899, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.41779834032058716, "metricx_qe_score": 0.5046453475952148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir die juristischen Verweise überprüft und die Fragen herausgesucht, deren Verweise nicht in einer der in Betracht gezogenen Rechtsordnungen enthalten sind.", "metrics": {"bleu_score": 39.61867597457339, "chrf_score": 64.73488536205105, "xcomet_score": 0.9743443727493286, "xcomet_qe_score": 0.9577466249465942, "metricx_score": 1.948789119720459, "metricx_qe_score": 2.0201210975646973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden mit den entsprechenden Artikel-IDs aus unserem großen Korpus abglichen.", "metrics": {"bleu_score": 19.684661233415397, "chrf_score": 49.030204855605064, "xcomet_score": 0.9584628343582153, "xcomet_qe_score": 0.9480811357498169, "metricx_score": 1.7271863222122192, "metricx_qe_score": 1.3105498552322388, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende haben wir 1.108 Fragen, die sorgfältig mit den IDs der relevanten Artikel aus unserem großen Korpus gekennzeichnet wurden.", "metrics": {"bleu_score": 52.17815896177006, "chrf_score": 67.37964966629602, "xcomet_score": 0.9666897058486938, "xcomet_qe_score": 0.9428730010986328, "metricx_score": 3.9153568744659424, "metricx_qe_score": 7.726769924163818, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus kommt jede Frage mit einer Hauptkategorie und einer Kette von Unterkategorien,", "metrics": {"bleu_score": 11.359354890271161, "chrf_score": 69.04115908001523, "xcomet_score": 0.9591781497001648, "xcomet_qe_score": 0.9475528597831726, "metricx_score": 2.1745007038116455, "metricx_qe_score": 2.3096530437469482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "und jeder Artikel kommt mit einer Kette von Unterkategorien in der Struktur des Gesetzes.", "metrics": {"bleu_score": 11.633270842295033, "chrf_score": 37.82088100871698, "xcomet_score": 0.9246000051498413, "xcomet_qe_score": 0.9245821237564087, "metricx_score": 3.9033446311950684, "metricx_qe_score": 4.416914463043213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der aktuellen Arbeit nicht verwendet, aber könnten für zukünftige Forschung zu Rechtsinformationen oder Rechtsklassifizierung von Interesse sein.", "metrics": {"bleu_score": 37.04667384137806, "chrf_score": 62.05093207074632, "xcomet_score": 0.9780735969543457, "xcomet_qe_score": 0.9878494739532471, "metricx_score": 2.0286614894866943, "metricx_qe_score": 1.6041847467422485, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unseres Datensatzes an.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen 5 und 44 Wörtern lang, mit einem Mittelwert von 40 Wörtern.", "metrics": {"bleu_score": 47.0871306001523, "chrf_score": 76.9301631733176, "xcomet_score": 0.8199232816696167, "xcomet_qe_score": 0.9850072860717773, "metricx_score": 4.836437702178955, "metricx_qe_score": 4.632862091064453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einem Mittelwert von 77 Wörtern, wobei 142 von ihnen mehr als 1.000 Wörter lang sind, wobei", "metrics": {"bleu_score": 47.2402846675108, "chrf_score": 63.14772109502097, "xcomet_score": 0.9364434480667114, "xcomet_qe_score": 0.9166826009750366, "metricx_score": 5.331677436828613, "metricx_qe_score": 2.329230308532715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "der längste bis zu 5.790 Wörter lang", "metrics": {"bleu_score": 28.319415510892387, "chrf_score": 59.554934672751905, "xcomet_score": 0.9652029275894165, "xcomet_qe_score": 0.9381659030914307, "metricx_score": 0.8394116759300232, "metricx_qe_score": 1.1807841062545776, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "ist. Insgesamt decken die Fragen eine breite Palette von Themen ab, wobei etwa 85% von ihnen sich mit Familie, Wohnung, Geld oder Justiz befassen, während", "metrics": {"bleu_score": 23.676728665312076, "chrf_score": 44.38749343663579, "xcomet_score": 0.7766321897506714, "xcomet_qe_score": 0.7996025681495667, "metricx_score": 7.614858627319336, "metricx_qe_score": 8.536670684814453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "die verbleibenden 15% sich mit Sozialversicherung, Ausländern oder Arbeit befassen.", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 38.73466597667318, "xcomet_score": 0.9552727937698364, "xcomet_qe_score": 0.9624451398849487, "metricx_score": 4.039389133453369, "metricx_qe_score": 3.693484306335449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel stammen aus 32 verschiedenen belgischen Rechtsordnungen, die eine große Anzahl von Rechtsthemen abdecken.", "metrics": {"bleu_score": 30.88991773756791, "chrf_score": 62.11132622637508, "xcomet_score": 0.9938105344772339, "xcomet_qe_score": 0.9745678901672363, "metricx_score": 0.7604572176933289, "metricx_qe_score": 0.706709623336792, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus diesen Rechtsordnungen extrahiert wurden.", "metrics": {"bleu_score": 67.71111323098607, "chrf_score": 63.192045485569835, "xcomet_score": 0.9631160497665405, "xcomet_qe_score": 0.9728671312332153, "metricx_score": 1.8911515474319458, "metricx_qe_score": 3.295851230621338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens eine Frage im Datensatz abgeleitet.", "metrics": {"bleu_score": 88.43946454355333, "chrf_score": 91.1215528801453, "xcomet_score": 0.9626235961914062, "xcomet_qe_score": 0.9115943312644958, "metricx_score": 3.5700571537017822, "metricx_qe_score": 3.7930798530578613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "Und rund 80% dieser zitierten Artikel stammen aus dem Zivilgesetzbuch, dem Gerichtsordnungsgesetz, dem Strafverfolgungs- und dem Strafgesetzbuch.", "metrics": {"bleu_score": 32.098151539672635, "chrf_score": 56.62130224813146, "xcomet_score": 0.9916605949401855, "xcomet_qe_score": 0.9983149766921997, "metricx_score": 0.3004274070262909, "metricx_qe_score": 0.3434526026248932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit beträgt die mittlere Anzahl der Zitate für", "metrics": {"bleu_score": 1.8854359641630605, "chrf_score": 13.121436482922608, "xcomet_score": 0.21537145972251892, "xcomet_qe_score": 0.12277915328741074, "metricx_score": 24.34237289428711, "metricx_qe_score": 24.692617416381836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "diese zitierten Artikel 2, und", "metrics": {"bleu_score": 1.2237376376462188, "chrf_score": 8.024481713932706, "xcomet_score": 0.13615767657756805, "xcomet_qe_score": 0.13334468007087708, "metricx_score": 25.0, "metricx_qe_score": 24.933143615722656, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "weniger als 25% von ihnen werden mehr als fünfmal zitiert.", "metrics": {"bleu_score": 17.97496913141384, "chrf_score": 34.35557641033742, "xcomet_score": 0.5908148288726807, "xcomet_qe_score": 0.3156953454017639, "metricx_score": 8.107934951782227, "metricx_qe_score": 10.160635948181152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserem Datensatz haben wir mehrere Erfassungsansätze getestet, einschließlich lexikalischer und dichterarchitektonischer Ansätze.", "metrics": {"bleu_score": 15.57396418542705, "chrf_score": 48.64034701687107, "xcomet_score": 0.9224328994750977, "xcomet_qe_score": 0.8951467275619507, "metricx_score": 0.6577948331832886, "metricx_qe_score": 0.48818445205688477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalischer Ansatz eine Punktzahl für die Abfrage-Artikels-Paar zu, indem er die Summe der Gewichte jedes der Begriffe in diesem Artikel in dieser Abfrage berechnet.", "metrics": {"bleu_score": 29.368478799114776, "chrf_score": 71.7947447063768, "xcomet_score": 0.8977838158607483, "xcomet_qe_score": 0.850560188293457, "metricx_score": 2.208346366882324, "metricx_qe_score": 1.524142861366272, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TF-IDF- und BM25-Rang-Funktionen.", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 80.76566682724193, "xcomet_score": 0.98008131980896, "xcomet_qe_score": 0.9382150173187256, "metricx_score": 1.3952244520187378, "metricx_qe_score": 2.305197238922119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Die Hauptprobleme mit diesen Ansätzen besteht darin, dass sie nur Artikel abrufen können, die Schlüsselwörter enthalten, die in der Abfrage vorkommen.", "metrics": {"bleu_score": 50.7629894744918, "chrf_score": 79.90630521348103, "xcomet_score": 0.965380072593689, "xcomet_qe_score": 0.9784070253372192, "metricx_score": 0.8731990456581116, "metricx_qe_score": 0.8453333377838135, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um dieses Problem zu überwinden, experimentieren wir mit einem neuronalen Architekturansatz, der die semantische Beziehung zwischen Abfrage und Artikel erfassen kann.", "metrics": {"bleu_score": 28.984970517277347, "chrf_score": 73.1520093309541, "xcomet_score": 0.9930975437164307, "xcomet_qe_score": 0.9959101676940918, "metricx_score": 0.49603235721588135, "metricx_qe_score": 0.4338434338569641, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden einen B-Encoder, der Abfrage und Artikel in eine gemeinsame Dichtevektordarstellung abbildet und eine Relevanz zwischen Abfrage-Artikels-Paar durch die Ähnlichkeit ihrer Embeddings berechnet.", "metrics": {"bleu_score": 10.582542464758472, "chrf_score": 61.43603225107698, "xcomet_score": 0.8152459859848022, "xcomet_qe_score": 0.8120110034942627, "metricx_score": 3.4256134033203125, "metricx_qe_score": 3.60003924369812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Embeddings resultieren in der Regel aus einer Pooling-Operation auf die Ausgabe eines Wort-Embedding-Modells.", "metrics": {"bleu_score": 54.451788461394045, "chrf_score": 71.54706724894926, "xcomet_score": 0.7655990719795227, "xcomet_qe_score": 0.8828319311141968, "metricx_score": 4.452280521392822, "metricx_qe_score": 3.9025800228118896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst untersuchen wir die Effektivität von Siamese B-Encoders in einem Zero-Shot-Evaluierungs-Setup, was bedeutet, dass vortrainierte Wort-Encoder ohne zusätzliche Feinabstimmung verwendet werden.", "metrics": {"bleu_score": 23.470344741196975, "chrf_score": 69.25538581310515, "xcomet_score": 0.7942848205566406, "xcomet_qe_score": 0.7358245849609375, "metricx_score": 6.566257476806641, "metricx_qe_score": 6.308115482330322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Kontextunabhängigen Text-Encoder, nämlich Word2Vec und FastText, und dem Kontextabhängigen Embedding-Modell, nämlich Roberta und speziell Kamembert, das ein französisches Roberta-Modell ist.", "metrics": {"bleu_score": 8.218074077265651, "chrf_score": 59.280618487269464, "xcomet_score": 0.8022836446762085, "xcomet_qe_score": 0.7843335270881653, "metricx_score": 2.655505895614624, "metricx_qe_score": 1.8199509382247925, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus trainieren wir unsere eigenen B-Encoder auf unseren Datensätzen.", "metrics": {"bleu_score": 13.741214343226053, "chrf_score": 54.63661773009366, "xcomet_score": 0.8628522157669067, "xcomet_qe_score": 0.8598613142967224, "metricx_score": 7.651752948760986, "metricx_qe_score": 7.614102840423584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass wir für die Training experimentieren mit zwei Varianten des B-Encoder-Architektur,", "metrics": {"bleu_score": 28.495577603220287, "chrf_score": 69.83084189474363, "xcomet_score": 0.823158860206604, "xcomet_qe_score": 0.8711507320404053, "metricx_score": 8.144669532775879, "metricx_qe_score": 6.4894514083862305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, die eine einzigartige Wort-Encoder-Modelle verwendet, die Abfrage und Artikel in einer gemeinsamen Dichtevektor-Darstellung abbildet, und zwei-Tower, die zwei unabhängige Wort-Encoder verwendet, die Abfrage und Artikel in zwei separate Embedding-Räume abbilden.", "metrics": {"bleu_score": 11.487342022335094, "chrf_score": 51.25164225639223, "xcomet_score": 0.6078779697418213, "xcomet_qe_score": 0.6343087553977966, "metricx_score": 8.256705284118652, "metricx_qe_score": 7.414360046386719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mean, Max und CLS-Pooling sowie Punktprodukt und Kosinus für die Berechnung der Ähnlichkeit.", "metrics": {"bleu_score": 32.63230087258893, "chrf_score": 70.3618186068161, "xcomet_score": 0.7571641206741333, "xcomet_qe_score": 0.7238067388534546, "metricx_score": 4.698941230773926, "metricx_qe_score": 4.007593154907227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Basispunkts auf den Testsets,", "metrics": {"bleu_score": 31.239399369202552, "chrf_score": 68.4117382928605, "xcomet_score": 0.8635200262069702, "xcomet_qe_score": 0.8566648364067078, "metricx_score": 2.644594669342041, "metricx_qe_score": 2.6079485416412354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "mit den lexikalischen Methoden oben, den Siamese B-Encoders in einem Zero-Shot-Setup in der Mitte und den feinabgestellten B-Encoders unten.", "metrics": {"bleu_score": 30.07148781679198, "chrf_score": 62.92342935623064, "xcomet_score": 0.6882671117782593, "xcomet_qe_score": 0.7215733528137207, "metricx_score": 6.614380836486816, "metricx_qe_score": 6.175162315368652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertrifft der feinabgestellte B-Encoder alle anderen Basispunkte, die", "metrics": {"bleu_score": 17.771669724375847, "chrf_score": 71.55306009524712, "xcomet_score": 0.5592734813690186, "xcomet_qe_score": 0.605065107345581, "metricx_score": 9.10546875, "metricx_qe_score": 5.532470703125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "zwei-Tower-Modelle verbessern sich bei", "metrics": {"bleu_score": 0.164346668917794, "chrf_score": 18.674014914240583, "xcomet_score": 0.21604999899864197, "xcomet_qe_score": 0.12680219113826752, "metricx_score": 24.689037322998047, "metricx_qe_score": 22.881650924682617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "der Erholung, aber die Leistung zeigt, dass es immer noch ein starkes Basispunkt für domänenspezifische Erfassungen ist.", "metrics": {"bleu_score": 5.438469080664231, "chrf_score": 36.437781648918666, "xcomet_score": 0.39336100220680237, "xcomet_qe_score": 0.3253202438354492, "metricx_score": 15.47544002532959, "metricx_qe_score": 17.0943546295166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse des Zero-Shot-Evaluierungs-Setups der Siamese B-Encoders zeigen, dass der direkte Einsatz der Embeddings eines vortrainierten Kamembert-Modells ohne Optimierung für die Informationsabrufaufgabe schlechte Ergebnisse liefert, was mit früheren Ergebnissen übereinstimmt.", "metrics": {"bleu_score": 29.86551380628858, "chrf_score": 62.77455706762232, "xcomet_score": 0.6178455352783203, "xcomet_qe_score": 0.7412130832672119, "metricx_score": 3.6598403453826904, "metricx_qe_score": 3.350494861602783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus beobachten wir, dass der Word2Vec-basierte B-Encoder deutlich die Fast-Text- und B-Encoder-Modelle übertrifft, was darauf hindeutet, dass möglicherweise vortrainierte Wort-Encoder für die Aufgabe des Informationsabrufs besser geeignet sind als Zeichen- oder Unterwort-Embeddings, wenn sie aus der Box verwendet werden.", "metrics": {"bleu_score": 33.00017278093307, "chrf_score": 61.10042398025154, "xcomet_score": 0.5825000405311584, "xcomet_qe_score": 0.6100900173187256, "metricx_score": 6.885675430297852, "metricx_qe_score": 6.88556432723999, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl diese Ergebnisse vielversprechend sind, deuten sie auf eine große Möglichkeit für Verbesserungen hin, im Vergleich zu einem Fachjuristen, der schließlich alle relevanten Artikel zu jeder Frage abrufen und perfekte Ergebnisse erzielen kann.", "metrics": {"bleu_score": 37.94403527917792, "chrf_score": 66.4331754744953, "xcomet_score": 0.9874651432037354, "xcomet_qe_score": 0.9880557060241699, "metricx_score": 0.42625221610069275, "metricx_qe_score": 0.35313698649406433, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Schließen wir mit einer Diskussion über zwei Einschränkungen unseres Datensatzes.", "metrics": {"bleu_score": 24.808415001701817, "chrf_score": 63.1062545828626, "xcomet_score": 0.9439616203308105, "xcomet_qe_score": 0.952650785446167, "metricx_score": 0.5844011306762695, "metricx_qe_score": 0.408770889043808, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Erstens ist der Korpus der Artikel auf die 32 in Betracht genommenen belgischen Codes beschränkt, was bedeutet, dass Artikel aus Verordnungen, Verordnungen und Verordnungen nicht berücksichtigt werden.", "metrics": {"bleu_score": 11.298291228277039, "chrf_score": 48.762309256306004, "xcomet_score": 0.7574061155319214, "xcomet_qe_score": 0.7608758807182312, "metricx_score": 5.546307563781738, "metricx_qe_score": 4.77401876449585, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatz erstellt, werden alle Verweise auf diese nicht in Betracht gezogenen Artikel ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl der relevanten Artikel erhalten.", "metrics": {"bleu_score": 51.64100983465707, "chrf_score": 74.29740735912831, "xcomet_score": 0.9428501725196838, "xcomet_qe_score": 0.9253942966461182, "metricx_score": 1.6533501148223877, "metricx_qe_score": 1.8288531303405762, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dies impliziert, dass die Antwort, die in den verbleibenden relevanten Artikeln enthalten ist, möglicherweise unvollständig ist, obwohl sie immer noch vollständig angemessen ist.", "metrics": {"bleu_score": 51.42932594746845, "chrf_score": 70.4282154534474, "xcomet_score": 0.9989867210388184, "xcomet_qe_score": 0.9846134781837463, "metricx_score": 0.4830954670906067, "metricx_qe_score": 0.8602619171142578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens können nicht alle Rechtsfragen mit Statuten allein beantwortet werden.", "metrics": {"bleu_score": 7.524479007734289, "chrf_score": 48.28318459226122, "xcomet_score": 0.9981867074966431, "xcomet_qe_score": 1.0, "metricx_score": 1.4370522499084473, "metricx_qe_score": 0.49848106503486633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel kann die Frage \"Kann ich meine Mieterin oder meinen Mieter wegen zu viel Lärm vertreiben?\"", "metrics": {"bleu_score": 11.451997463067546, "chrf_score": 57.05230468907292, "xcomet_score": 0.9230971336364746, "xcomet_qe_score": 0.9155278205871582, "metricx_score": 1.5724515914916992, "metricx_qe_score": 1.4716495275497437, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "möglicherweise keine detaillierte Antwort in der Rechtsordnung haben, die eine bestimmte Lärmgrenzeilung festlegt.", "metrics": {"bleu_score": 16.312333177333368, "chrf_score": 55.46539288010703, "xcomet_score": 0.8570281863212585, "xcomet_qe_score": 0.8813134431838989, "metricx_score": 9.651326179504395, "metricx_qe_score": 9.421457290649414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte das Mietrecht eher auf Präzedenzfall und Präzedenzfall basieren, z.", "metrics": {"bleu_score": 5.199514186552214, "chrf_score": 33.01288681159662, "xcomet_score": 0.3074871897697449, "xcomet_qe_score": 0.1632530242204666, "metricx_score": 10.407934188842773, "metricx_qe_score": 6.914134979248047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "B. Die Mieterin macht zwei Partys pro Woche bis 2:00 Uhr. Daher müssen", "metrics": {"bleu_score": 23.287896954139942, "chrf_score": 43.76586458979246, "xcomet_score": 0.724008321762085, "xcomet_qe_score": 0.8411688208580017, "metricx_score": 8.030102729797363, "metricx_qe_score": 5.106294631958008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "einige Fragen besser zu der Aufgabe der Ermittlung von Rechtsartikeln geeignet sein als andere, und die Domäne der weniger geeigneten Fragen muss noch bestimmt werden.", "metrics": {"bleu_score": 38.773691135570026, "chrf_score": 65.86173177052375, "xcomet_score": 0.9396399259567261, "xcomet_qe_score": 0.8823871612548828, "metricx_score": 5.403773307800293, "metricx_qe_score": 5.0299224853515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Erfassungsmodelle weckt,", "metrics": {"bleu_score": 61.055025196087655, "chrf_score": 71.04568581905106, "xcomet_score": 0.9628506898880005, "xcomet_qe_score": 0.9534242153167725, "metricx_score": 3.5655603408813477, "metricx_qe_score": 1.9799546003341675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "die den Zugang zu Gerechtigkeit für alle verbessern.", "metrics": {"bleu_score": 9.848320372827342, "chrf_score": 44.84836575321226, "xcomet_score": 0.912274956703186, "xcomet_qe_score": 0.9686040282249451, "metricx_score": 4.341028213500977, "metricx_qe_score": 2.8765676021575928, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unseren Artikel und Code unter den folgenden Links finden. Vielen Dank.", "metrics": {"bleu_score": 20.853083928609436, "chrf_score": 52.68048733996575, "xcomet_score": 0.9040852189064026, "xcomet_qe_score": 0.9834306240081787, "metricx_score": 4.61836051940918, "metricx_qe_score": 1.8136950731277466, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir präsentieren unsere Arbeit an Valsa, einem taskunabhängigen Benchmark, der visuelle und sprachbezogene Modelle mit bestimmten linguistischen Phänomenen testet.", "metrics": {"bleu_score": 7.663653046723025, "chrf_score": 41.83686974362333, "xcomet_score": 0.8467398881912231, "xcomet_qe_score": 0.8535381555557251, "metricx_score": 2.3689351081848145, "metricx_qe_score": 1.7382419109344482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark einzurichten? Nun,", "metrics": {"bleu_score": 83.85766789076261, "chrf_score": 98.6026631059235, "xcomet_score": 0.9885283708572388, "xcomet_qe_score": 0.9705331325531006, "metricx_score": 3.250803232192993, "metricx_qe_score": 2.800140857696533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "in den letzten Jahren haben wir eine Explosion von vision- und sprachbasierten Modellen gesehen, die auf großen Mengen von Bildtextpaaren trainiert sind.", "metrics": {"bleu_score": 24.536623154740496, "chrf_score": 50.28351595078671, "xcomet_score": 0.9059708118438721, "xcomet_qe_score": 0.923485517501831, "metricx_score": 4.8375563621521, "metricx_qe_score": 4.141685962677002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle ist in der Lage, visuelle und sprachbezogene Aufgaben wie visuelle Fragebeantwortung, visuelles Common-Sense-Argument, Bildwiederherstellung, Phrase-Basierend und", "metrics": {"bleu_score": 5.849127630537949, "chrf_score": 46.03896768770428, "xcomet_score": 0.7230520248413086, "xcomet_qe_score": 0.7654881477355957, "metricx_score": 8.716808319091797, "metricx_qe_score": 7.398346900939941, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "mehr zu bewältigen. Die Genauigkeiten auf diesen spezifischen Benchmarks steigen stetig.", "metrics": {"bleu_score": 5.326342449594299, "chrf_score": 49.656886157088145, "xcomet_score": 0.8683629631996155, "xcomet_qe_score": 0.7893697023391724, "metricx_score": 10.1927490234375, "metricx_qe_score": 10.451446533203125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5102907419204712, "metricx_qe_score": 0.9778188467025757, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was versteht ein visuelle und sprachbezogener Transformer, wenn er ein hohes Ergebnis für dieses Bild und dieses Satzpaar und ein niedriges Ergebnis für dieses Bild", "metrics": {"bleu_score": 14.299133016633656, "chrf_score": 45.44036821432147, "xcomet_score": 0.6097602248191833, "xcomet_qe_score": 0.6601235866546631, "metricx_score": 9.893662452697754, "metricx_qe_score": 7.233712673187256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und dieses Satzpaar zuweisen kann?", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 14.981865389894116, "xcomet_score": 0.28057044744491577, "xcomet_qe_score": 0.38524889945983887, "metricx_score": 9.675230979919434, "metricx_qe_score": 13.416789054870605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Fokussieren sich visuelle und sprachbezogene Modelle auf das Richtige", "metrics": {"bleu_score": 5.61480827173619, "chrf_score": 35.1900058813195, "xcomet_score": 0.962568998336792, "xcomet_qe_score": 0.9597984552383423, "metricx_score": 1.2235288619995117, "metricx_qe_score": 0.8434270620346069, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "oder auf Vorurteile, wie in früheren Arbeiten gezeigt?", "metrics": {"bleu_score": 28.64190457979541, "chrf_score": 41.80686780748534, "xcomet_score": 0.9089298248291016, "xcomet_qe_score": 1.0, "metricx_score": 1.103170394897461, "metricx_qe_score": 0.9107707142829895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um Licht auf diese Aspekte zu werfen, schlagen wir einen mehr taskagnostischen Ansatz vor und führen Valsa ein, der die Sensitivität von visuellen und sprachbezogenen Modellen für spezifische linguistische Phänomene testet, die sowohl die sprachliche als auch die visuelle Modalität betreffen.", "metrics": {"bleu_score": 21.90436190972903, "chrf_score": 62.49876139508649, "xcomet_score": 0.8785272836685181, "xcomet_qe_score": 0.9100719690322876, "metricx_score": 1.9304237365722656, "metricx_qe_score": 1.5435889959335327, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Pluralität, Zählung, räumliche Beziehungen, Handlungen und Entitätsreferenz ab.", "metrics": {"bleu_score": 84.82198619370465, "chrf_score": 93.06224482870124, "xcomet_score": 0.960648775100708, "xcomet_qe_score": 0.9635065793991089, "metricx_score": 0.835306704044342, "metricx_qe_score": 1.4160702228546143, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die visuellen und sprachbezogenen Modelle diese Phänomene erfasst haben?", "metrics": {"bleu_score": 16.451929399933114, "chrf_score": 47.251959684464445, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3183087110519409, "metricx_qe_score": 0.29332733154296875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, ein Verfahren, das zuvor nur für nicht-Substantivphrasen von Ravi Shankar und Mitarbeitern und auf Zählung von uns in früheren Arbeiten angewendet wurde,", "metrics": {"bleu_score": 17.949496853184797, "chrf_score": 54.5490656021319, "xcomet_score": 0.5608673095703125, "xcomet_qe_score": 0.6938700675964355, "metricx_score": 6.81589412689209, "metricx_qe_score": 7.20319938659668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "bedeutet Foiling im Grunde, dass wir die Bildunterschrift nehmen und eine Fälschung erzeugen, indem wir die Unterschrift so ändern, dass sie das Bild nicht mehr beschreibt. Und", "metrics": {"bleu_score": 54.95726918593066, "chrf_score": 70.04316603745539, "xcomet_score": 0.8502748608589172, "xcomet_qe_score": 0.8863921761512756, "metricx_score": 3.6064019203186035, "metricx_qe_score": 2.5513975620269775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "wir machen diese Phrasenänderungen, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Handlungen und Entitätsreferenz, wobei jeder Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als einen interessanten Weg gefunden haben, um Fälschungen zu erstellen.", "metrics": {"bleu_score": 72.10993106690186, "chrf_score": 81.9350780300809, "xcomet_score": 0.833532452583313, "xcomet_qe_score": 0.8119330406188965, "metricx_score": 2.6402273178100586, "metricx_qe_score": 3.854372978210449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir im Fall der Handlungsinstrumente zwei Instrumente, eines, in dem das Handlungsverb mit einem anderen Handlungsverb ersetzt wird, und eines, in dem Subjekte vertauscht werden.", "metrics": {"bleu_score": 42.89580694490086, "chrf_score": 69.2479362936616, "xcomet_score": 0.8524268865585327, "xcomet_qe_score": 0.88400799036026, "metricx_score": 3.399308919906616, "metricx_qe_score": 4.286391735076904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählung und Referenz sind auch Teile, die mehr als ein Instrument haben. Und", "metrics": {"bleu_score": 74.87402156832427, "chrf_score": 90.52284519748042, "xcomet_score": 0.8747222423553467, "xcomet_qe_score": 0.8760188817977905, "metricx_score": 4.3776726722717285, "metricx_qe_score": 4.760275840759277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "wir erstellen diese Fälschungen, indem wir sicherstellen, dass sie das Bild nicht mehr beschreiben, dass sie grammatikalisch und ansonsten gültige Sätze sind.", "metrics": {"bleu_score": 51.35454535544818, "chrf_score": 73.94303534381586, "xcomet_score": 0.9356752038002014, "xcomet_qe_score": 0.9446876049041748, "metricx_score": 0.9228135347366333, "metricx_qe_score": 0.968295693397522, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach zu tun, da es statistisch weniger wahrscheinlich", "metrics": {"bleu_score": 14.621921527420438, "chrf_score": 37.16503047592471, "xcomet_score": 0.815817654132843, "xcomet_qe_score": 0.8663513660430908, "metricx_score": 7.480352878570557, "metricx_qe_score": 13.139629364013672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "ist, dass Pflanzen einen Mann schneiden, als dass ein Mann Pflanzen schneidet. Und große visuelle und sprachbezogene Modelle könnten dies auf", "metrics": {"bleu_score": 19.77222835775922, "chrf_score": 43.60655741646384, "xcomet_score": 0.452294260263443, "xcomet_qe_score": 0.5443010330200195, "metricx_score": 15.62574291229248, "metricx_qe_score": 15.443504333496094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "spüren. Um gültige Fälschungen zu erhalten", "metrics": {"bleu_score": 4.231118166423695, "chrf_score": 33.33960978481799, "xcomet_score": 0.255575954914093, "xcomet_qe_score": 0.15721395611763, "metricx_score": 18.143564224243164, "metricx_qe_score": 18.4713191986084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": ", nutzen wir starke Sprachmodelle, um Fälschungen vorzuschlagen.", "metrics": {"bleu_score": 58.14307369682194, "chrf_score": 80.94624430656178, "xcomet_score": 0.8535083532333374, "xcomet_qe_score": 0.7841749787330627, "metricx_score": 6.661494731903076, "metricx_qe_score": 7.65132474899292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir natürliche Sprachinferenz, oder kurz NLP, um Fälschungen zu filtern, die das Bild noch beschreiben könnten, da wir bei der Erstellung von Fälschungen sicherstellen müssen, dass sie das Bild nicht mehr beschreiben.", "metrics": {"bleu_score": 34.26635950352649, "chrf_score": 69.47002378882928, "xcomet_score": 0.9541438817977905, "xcomet_qe_score": 0.9107898473739624, "metricx_score": 0.9661859273910522, "metricx_qe_score": 1.0572662353515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLP-Modell die Fälschung mit der Unterschrift des", "metrics": {"bleu_score": 3.4738650706548713, "chrf_score": 14.355653878261379, "xcomet_score": 0.19481366872787476, "xcomet_qe_score": 0.19137685000896454, "metricx_score": 18.43841552734375, "metricx_qe_score": 7.444747447967529, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Bildes widerspricht oder neutral ist, nehmen", "metrics": {"bleu_score": 0.0, "chrf_score": 12.347828890653801, "xcomet_score": 0.12924766540527344, "xcomet_qe_score": 0.09359040856361389, "metricx_score": 22.829837799072266, "metricx_qe_score": 22.068586349487305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "wir dies als Indikator für eine gute Fälschung.", "metrics": {"bleu_score": 3.221515452693472, "chrf_score": 19.006080275188335, "xcomet_score": 0.14719362556934357, "xcomet_qe_score": 0.13520918786525726, "metricx_score": 12.853317260742188, "metricx_qe_score": 16.1372013092041, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLP-Modell die Fälschung mit der Unterschrift des Bildes widerspricht oder neutral ist, kann dies ein Indikator für eine", "metrics": {"bleu_score": 25.44244547130556, "chrf_score": 52.30642957074784, "xcomet_score": 0.4170070290565491, "xcomet_qe_score": 0.4021940231323242, "metricx_score": 8.27760124206543, "metricx_qe_score": 6.4527506828308105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "gute Fälschung sein. Aber", "metrics": {"bleu_score": 0.02853081783491091, "chrf_score": 7.30801187634195, "xcomet_score": 0.1062968522310257, "xcomet_qe_score": 0.07436808943748474, "metricx_score": 24.733089447021484, "metricx_qe_score": 24.821043014526367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "dieses Verfahren ist nicht perfekt, es ist nur ein Indikator für gültige Fälschungen.", "metrics": {"bleu_score": 37.0304683381906, "chrf_score": 72.53703657608162, "xcomet_score": 0.9691060781478882, "xcomet_qe_score": 0.8922710418701172, "metricx_score": 0.3941498398780823, "metricx_qe_score": 2.169405937194824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als drittes Maß zur Generierung gültiger Fälschungen, um menschliche Annotatoren zu verwenden, um die Daten in Valsa zu validieren.", "metrics": {"bleu_score": 15.85805301368275, "chrf_score": 67.27136341738725, "xcomet_score": 0.666885495185852, "xcomet_qe_score": 0.6491101384162903, "metricx_score": 6.794283390045166, "metricx_qe_score": 10.95904541015625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Filterung und der menschlichen Bewertung haben wir so viele Testinstanzen, wie in dieser Tabelle beschrieben.", "metrics": {"bleu_score": 56.971032152705476, "chrf_score": 75.59275791006239, "xcomet_score": 0.9985876083374023, "xcomet_qe_score": 0.9820192456245422, "metricx_score": 0.4296507239341736, "metricx_qe_score": 0.6265155076980591, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass Valsa keine Trainingsdaten liefert, sondern nur Testdaten,", "metrics": {"bleu_score": 27.422490461023802, "chrf_score": 78.16973499975288, "xcomet_score": 0.9350107908248901, "xcomet_qe_score": 0.9333579540252686, "metricx_score": 0.7179481983184814, "metricx_qe_score": 0.4739987850189209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "da es ein Zero-Shot-Benchmark ist. Es ist so konzipiert, dass es die vorhandenen Fähigkeiten von visuellen und sprachbezogenen Modellen nach der Voreinrichtung ausnutzt.", "metrics": {"bleu_score": 11.020790523837181, "chrf_score": 50.74885186776841, "xcomet_score": 0.8982517719268799, "xcomet_qe_score": 0.886773407459259, "metricx_score": 5.565772533416748, "metricx_qe_score": 5.137044906616211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmung würde es nur ermöglichen, dass Modelle Artefakte oder statistische Verzerrungen in den Daten ausnutzen. Und", "metrics": {"bleu_score": 48.06604068305993, "chrf_score": 82.66807861088445, "xcomet_score": 0.9645439386367798, "xcomet_qe_score": 0.9614236950874329, "metricx_score": 1.3161132335662842, "metricx_qe_score": 0.28622984886169434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nehmen,", "metrics": {"bleu_score": 39.832871551569504, "chrf_score": 74.72647581663135, "xcomet_score": 0.9766720533370972, "xcomet_qe_score": 0.9753387570381165, "metricx_score": 0.8347206115722656, "metricx_qe_score": 1.072186827659607, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "und da wir daran interessiert sind, zu bewerten, was die Modelle nach der Voreinrichtung gelernt haben, möchten wir die Fähigkeiten der visuellen und sprachbezogenen Modelle nach der Voreinrichtung bewerten.", "metrics": {"bleu_score": 2.1325740875921766, "chrf_score": 44.04283546079594, "xcomet_score": 0.8168261647224426, "xcomet_qe_score": 0.8170701861381531, "metricx_score": 5.157360076904297, "metricx_qe_score": 3.4893438816070557, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen Valsa mit fünf visuellen und sprachbezogenen Modellen, nämlich mit Clip, XLmert, Wilbert, Wilbert 12 in 1 und Visualbert.", "metrics": {"bleu_score": 8.952270804289075, "chrf_score": 32.7742948763323, "xcomet_score": 0.7410822510719299, "xcomet_qe_score": 0.720453679561615, "metricx_score": 4.7726593017578125, "metricx_qe_score": 4.499197483062744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren in Beschreibungen und Fälschungen.", "metrics": {"bleu_score": 46.09603493497927, "chrf_score": 77.9201941134261, "xcomet_score": 0.9126750230789185, "xcomet_qe_score": 0.7690476179122925, "metricx_score": 1.0004583597183228, "metricx_qe_score": 2.0073647499084473, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht noch relevanter für dieses Video zeigen wir unsere Permissive Metrik, die misst, ob der Bild-Satz-Alignment-Score für das richtige Bild-Satz-Paar größer ist als für das Fälschungspaar.", "metrics": {"bleu_score": 15.664350101443553, "chrf_score": 51.81827207576591, "xcomet_score": 0.7268773317337036, "xcomet_qe_score": 0.6917963027954102, "metricx_score": 6.9821343421936035, "metricx_qe_score": 5.859109878540039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit der Per", "metrics": {"bleu_score": 3.2174093287959424, "chrf_score": 21.753270006858667, "xcomet_score": 0.13188797235488892, "xcomet_qe_score": 0.13518457114696503, "metricx_score": 20.66876983642578, "metricx_qe_score": 18.41461944580078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "missiven Genauigkeit werden hier gezeigt, und sie stimmen mit den Ergebnissen aus den anderen Metriken überein.", "metrics": {"bleu_score": 6.752864072588833, "chrf_score": 33.63898727460712, "xcomet_score": 0.6150298714637756, "xcomet_qe_score": 0.31218695640563965, "metricx_score": 17.061962127685547, "metricx_qe_score": 18.63848114013672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Substantivphrasen konzentrieren, von Wilbert 12 in 1 fast gelöst werden, was zeigt, dass Modelle in der Lage sind, Objekte und ihre Präsenz in Bildern zu identifizieren.", "metrics": {"bleu_score": 51.118324967222165, "chrf_score": 73.95158210471723, "xcomet_score": 0.8337545394897461, "xcomet_qe_score": 0.8057665824890137, "metricx_score": 3.6007497310638428, "metricx_qe_score": 4.087776184082031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Aber keiner der verbleibenden Teile kann in unseren adversarischen Fälschungssettings zuverlässig gelöst werden.", "metrics": {"bleu_score": 39.07380249452502, "chrf_score": 63.327152827276656, "xcomet_score": 0.982135534286499, "xcomet_qe_score": 0.900999903678894, "metricx_score": 2.0756306648254395, "metricx_qe_score": 2.4133553504943848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen aus den Pluralität- und Zählungsinstrumenten, dass visuelle und sprachbezogene Modelle Schwierigkeiten haben, Verweise auf einzelne versus mehrere Objekte oder Zählungen in einem Bild zu unterscheiden.", "metrics": {"bleu_score": 27.418115349347215, "chrf_score": 70.0582709900365, "xcomet_score": 0.9065415859222412, "xcomet_qe_score": 0.8955947160720825, "metricx_score": 2.5879757404327393, "metricx_qe_score": 2.192237615585327, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Das Relationselement zeigt, dass visuelle und sprachbezogene Modelle Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild zu klassifizieren.", "metrics": {"bleu_score": 44.438146210688274, "chrf_score": 71.85716169750876, "xcomet_score": 0.9196200370788574, "xcomet_qe_score": 0.8979901075363159, "metricx_score": 0.8722943067550659, "metricx_qe_score": 1.3893167972564697, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und die Teilnehmer zu identifizieren, selbst wenn sie von Plausibilitätsverzerrungen unterstützt werden, wie wir in der Handlungsphase sehen.", "metrics": {"bleu_score": 60.94880572755877, "chrf_score": 80.08315982708451, "xcomet_score": 0.9570522308349609, "xcomet_qe_score": 0.9191765785217285, "metricx_score": 1.371999979019165, "metricx_qe_score": 2.002371311187744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Referenzselement herausfinden wir, dass es für visuelle und sprachbezogene Modelle schwierig ist, mehrere Verweise auf dasselbe Objekt in einem Bild mit Pronomen zu verfolgen.", "metrics": {"bleu_score": 25.47296653715805, "chrf_score": 53.501064705353876, "xcomet_score": 0.8700698614120483, "xcomet_qe_score": 0.8557021021842957, "metricx_score": 3.2001984119415283, "metricx_qe_score": 3.2416343688964844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Sanitätsscheck und weil es ein interessantes Experiment ist, bewerten wir auch zwei textbasierte Modelle, GPT 1 und GPT 2, um zu bewerten, ob Valsa von diesen einseitigen Modellen gelöst werden kann, indem wir die Perplexität der richtigen und der Fälschung von Beschreibungen und die Vorhersage des Eintrags mit der niedrigsten Perplexität vergleichen.", "metrics": {"bleu_score": 29.177415859533223, "chrf_score": 55.54727392623807, "xcomet_score": 0.602308988571167, "xcomet_qe_score": 0.6457396745681763, "metricx_score": 7.519202709197998, "metricx_qe_score": 6.757676601409912, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Und", "metrics": {"bleu_score": 0.0, "chrf_score": 0.6745514781581938, "xcomet_score": 0.22531236708164215, "xcomet_qe_score": 0.12558360397815704, "metricx_score": 18.440113067626953, "metricx_qe_score": 24.349197387695312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "es ist interessant zu sehen, dass textbasierte GPT-Modelle in einigen Fällen die Plausibilität der Welt besser erfassen als visuelle und sprachbezogene Modelle.", "metrics": {"bleu_score": 39.14571237439261, "chrf_score": 70.72237535856524, "xcomet_score": 0.9619781970977783, "xcomet_qe_score": 0.9483609199523926, "metricx_score": 0.8135640621185303, "metricx_qe_score": 0.7898170948028564, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend ist Valsa ein Benchmark, der die Linsen der linguistischen Konstrukte verwendet, um die visuelle und sprachbezogenen Modelle zu verbessern, indem sie ihre visuelle Verankerung bewerten.", "metrics": {"bleu_score": 6.597005830198427, "chrf_score": 44.83017111539709, "xcomet_score": 0.6811949014663696, "xcomet_qe_score": 0.7154898643493652, "metricx_score": 5.435550689697266, "metricx_qe_score": 5.365865707397461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass visuelle und sprachbezogene Modelle Objekte und ihre Präsenz in Bildern gut identifizieren können, wie durch das Existenzstück gezeigt, aber Schwierigkeiten haben, ihre visuelle und sprachliche Abhängigkeit und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen werden, sich an linguistische Indikatoren zu halten.", "metrics": {"bleu_score": 30.03176583547575, "chrf_score": 65.67058043358071, "xcomet_score": 0.8759363889694214, "xcomet_qe_score": 0.8667718172073364, "metricx_score": 3.07062029838562, "metricx_qe_score": 3.0567827224731445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir würden die Community wirklich ermutigen, Valsa zur Messung des Fortschritts in der Sprachverankerung mit visuellen und sprachbezogenen Modellen zu verwenden.", "metrics": {"bleu_score": 12.66181659642763, "chrf_score": 55.786215027771725, "xcomet_score": 0.8165795803070068, "xcomet_qe_score": 0.802374005317688, "metricx_score": 2.7907261848449707, "metricx_qe_score": 3.214486598968506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und Valsa könnte auch als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach der Training oder Feinabstimmung bewertet werden können, um zu sehen, ob ein Datensatz die von Valsa getesteten Aspekte verbessert.", "metrics": {"bleu_score": 36.14998898389039, "chrf_score": 66.79701335404815, "xcomet_score": 0.9565664529800415, "xcomet_qe_score": 0.9710415005683899, "metricx_score": 2.6338515281677246, "metricx_qe_score": 2.339005470275879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie an Valsa interessiert sind, schauen Sie sich die Valsa-Daten auf Github an. Und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren.", "metrics": {"bleu_score": 50.34086982829309, "chrf_score": 70.29503140909324, "xcomet_score": 0.9778878688812256, "xcomet_qe_score": 0.9784561395645142, "metricx_score": 0.9384616613388062, "metricx_qe_score": 0.959559440612793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hello, my name is Kamisaka from the University of Tokyo.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 33.77961990717068, "xcomet_score": 0.654700756072998, "xcomet_qe_score": 0.8127047419548035, "metricx_score": 15.31931209564209, "metricx_qe_score": 12.447051048278809, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "I will be presenting a paper entitled \"RNSUM: A Large Scale Dataset for Automatic Release Note Generation via Commit Log Summarization\".", "metrics": {"bleu_score": 31.20848453730729, "chrf_score": 65.87993438939596, "xcomet_score": 0.9792364835739136, "xcomet_qe_score": 0.9832456111907959, "metricx_score": 7.3538641929626465, "metricx_qe_score": 19.77253532409668, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "I will explain in this order.", "metrics": {"bleu_score": 6.770186228657864, "chrf_score": 10.974150648347857, "xcomet_score": 0.9948517084121704, "xcomet_qe_score": 1.0, "metricx_score": 3.8239552974700928, "metricx_qe_score": 2.650315523147583, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "First, I will introduce the automatic release note generation that we are working on in this research.", "metrics": {"bleu_score": 2.6643211213888947, "chrf_score": 23.227721927796765, "xcomet_score": 0.891423761844635, "xcomet_qe_score": 0.9646339416503906, "metricx_score": 21.258604049682617, "metricx_qe_score": 22.91103744506836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "metrics": {"bleu_score": 1.821226775481922, "chrf_score": 24.79958379901938, "xcomet_score": 0.9462594985961914, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "The image shows the release notes for version 2.6.4 of the Juvia library. Release notes", "metrics": {"bleu_score": 2.908317710573757, "chrf_score": 24.904322442148942, "xcomet_score": 0.35927438735961914, "xcomet_qe_score": 0.4306265413761139, "metricx_score": 10.24699878692627, "metricx_qe_score": 7.88444185256958, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "play an important role in open source development, but they are time-consuming to prepare manually.", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 15.873220298575873, "xcomet_score": 0.6057964563369751, "xcomet_qe_score": 0.7477718591690063, "metricx_score": 24.286420822143555, "metricx_qe_score": 24.198543548583984, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Therefore, it would be very useful to be able to automatically generate high-quality release notes.", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 23.014987266371318, "xcomet_score": 0.9832890033721924, "xcomet_qe_score": 1.0, "metricx_score": 23.675657272338867, "metricx_qe_score": 23.16858673095703, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "I will refer to two previous researches on automatic release note generation.", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 19.979560126463262, "xcomet_score": 0.949289083480835, "xcomet_qe_score": 0.996638298034668, "metricx_score": 17.358795166015625, "metricx_qe_score": 23.47049903869629, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "The first is a system called Alana, released in 2014. It takes a rule", "metrics": {"bleu_score": 3.0235785635823293, "chrf_score": 16.31787701564488, "xcomet_score": 0.42000812292099, "xcomet_qe_score": 0.5629035234451294, "metricx_score": 14.236260414123535, "metricx_qe_score": 13.95565414428711, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "-based approach, for example, using the change extractor to extract core differences, library changes, and document changes from the differences between releases, and finally combining them.", "metrics": {"bleu_score": 1.5899760062266224, "chrf_score": 21.636361146991383, "xcomet_score": 0.6928673386573792, "xcomet_qe_score": 0.8001121878623962, "metricx_score": 25.0, "metricx_qe_score": 22.78709602355957, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "The most notable feature of this system is the issue extractor in the upper right corner", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 20.11526455578904, "xcomet_score": 0.8098422288894653, "xcomet_qe_score": 0.9895409345626831, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": ", which must be linked to the issue tracker and can only be applied to projects that use JIRA.", "metrics": {"bleu_score": 2.1658158394365654, "chrf_score": 12.70557213923513, "xcomet_score": 0.9233143329620361, "xcomet_qe_score": 0.9736732244491577, "metricx_score": 13.475987434387207, "metricx_qe_score": 8.110016822814941, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "In other words, it cannot be used for many projects on GitHub.", "metrics": {"bleu_score": 3.1443446386286733, "chrf_score": 17.81513150895167, "xcomet_score": 0.9936354160308838, "xcomet_qe_score": 1.0, "metricx_score": 23.9570255279541, "metricx_qe_score": 23.97871208190918, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "The second is GriF, recently announced in 2020. It is available on the internet", "metrics": {"bleu_score": 5.816635421147515, "chrf_score": 19.11325429427179, "xcomet_score": 0.24599887430667877, "xcomet_qe_score": 0.5787606239318848, "metricx_score": 12.43985366821289, "metricx_qe_score": 8.928329467773438, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "and can be installed via pip.", "metrics": {"bleu_score": 3.823246852690463, "chrf_score": 16.54236871553594, "xcomet_score": 0.7616453170776367, "xcomet_qe_score": 0.9224554300308228, "metricx_score": 22.434772491455078, "metricx_qe_score": 22.423513412475586, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "This system has a simple learning-based text classification model and outputs one of four labels, such as features or bug fixes, for each input commit message.", "metrics": {"bleu_score": 1.5301683686839007, "chrf_score": 20.891351151727935, "xcomet_score": 0.6954190731048584, "xcomet_qe_score": 0.7791920900344849, "metricx_score": 25.0, "metricx_qe_score": 24.681058883666992, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "The image is a sample usage that returns a corrective or bug fixes label. GriF's training data is fair", "metrics": {"bleu_score": 1.9146030690102511, "chrf_score": 16.39753223683367, "xcomet_score": 0.2485215812921524, "xcomet_qe_score": 0.5683256387710571, "metricx_score": 17.11642837524414, "metricx_qe_score": 19.37375831604004, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "ly small, about 5,000, and will be shown in the experiments described below.", "metrics": {"bleu_score": 2.6935542467877966, "chrf_score": 18.626556002996637, "xcomet_score": 0.3493131697177887, "xcomet_qe_score": 0.44431284070014954, "metricx_score": 24.456666946411133, "metricx_qe_score": 22.545169830322266, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "The performance of the text classification model is not high.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 28.08065473429809, "xcomet_score": 0.9921655654907227, "xcomet_qe_score": 1.0, "metricx_score": 24.607242584228516, "metricx_qe_score": 24.076751708984375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "I present two related researches, but there are problems of limited applicability and scarce data resources.", "metrics": {"bleu_score": 2.416027466056967, "chrf_score": 19.774861973279407, "xcomet_score": 0.9632470607757568, "xcomet_qe_score": 0.9882595539093018, "metricx_score": 19.232818603515625, "metricx_qe_score": 22.751209259033203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Our paper solves these two problems and automatically generates high-quality release notes. For the limited applica", "metrics": {"bleu_score": 2.2869567780619007, "chrf_score": 28.05080001706155, "xcomet_score": 0.79548180103302, "xcomet_qe_score": 0.8391284346580505, "metricx_score": 16.433759689331055, "metricx_qe_score": 15.083633422851562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "bility problem, we propose a high-quality class-based summarization method, using only commit messages as input.", "metrics": {"bleu_score": 2.1409907800309074, "chrf_score": 19.361000401630495, "xcomet_score": 0.60211580991745, "xcomet_qe_score": 0.8119947910308838, "metricx_score": 17.05693817138672, "metricx_qe_score": 14.974006652832031, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "This proposed method can be used for all English repositories.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 27.010498425578067, "xcomet_score": 0.986614465713501, "xcomet_qe_score": 1.0, "metricx_score": 22.206113815307617, "metricx_qe_score": 21.217655181884766, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "For the second problem of scarce data resources, we built a rnsum dataset consisting of about 82,000 pieces of data by collecting data from public GitHub repositories using the GitHub API.", "metrics": {"bleu_score": 1.3355980882200826, "chrf_score": 24.335830735170656, "xcomet_score": 0.9528967142105103, "xcomet_qe_score": 0.9484032988548279, "metricx_score": 20.292564392089844, "metricx_qe_score": 16.016590118408203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Next, I describe our dataset.", "metrics": {"bleu_score": 5.693025330278465, "chrf_score": 11.85105222900829, "xcomet_score": 0.9070061445236206, "xcomet_qe_score": 0.9825937747955322, "metricx_score": 6.368530750274658, "metricx_qe_score": 4.606191635131836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Here is an example of data, the", "metrics": {"bleu_score": 0.0, "chrf_score": 12.76837855816698, "xcomet_score": 0.5640395879745483, "xcomet_qe_score": 0.8946778178215027, "metricx_score": 10.774674415588379, "metricx_qe_score": 6.821700572967529, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "left side is the commit message and the right side is the release note. The release notes are labeled as improv", "metrics": {"bleu_score": 1.727223799216787, "chrf_score": 19.269816065110632, "xcomet_score": 0.6968264579772949, "xcomet_qe_score": 0.8118853569030762, "metricx_score": 11.152777671813965, "metricx_qe_score": 14.276717185974121, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "ements, bug fixes, etc. We have set up", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 8.390487783670988, "xcomet_score": 0.15772150456905365, "xcomet_qe_score": 0.2654320001602173, "metricx_score": 22.003202438354492, "metricx_qe_score": 17.452728271484375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "a task that takes the commit messages as input and outputs the labeled release notes.", "metrics": {"bleu_score": 1.9046304733974748, "chrf_score": 12.730386469624467, "xcomet_score": 0.5831366777420044, "xcomet_qe_score": 0.8938035368919373, "metricx_score": 24.704465866088867, "metricx_qe_score": 22.94332504272461, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "This can be regarded as a summarization task.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 14.295159593378065, "xcomet_score": 0.9716808795928955, "xcomet_qe_score": 1.0, "metricx_score": 20.048583984375, "metricx_qe_score": 21.963693618774414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "We have predefined four labels, features, improvements, bug fixes, duplications, removals, and breaking changes.", "metrics": {"bleu_score": 2.568331954752977, "chrf_score": 14.718761776530625, "xcomet_score": 0.7624318599700928, "xcomet_qe_score": 0.952267050743103, "metricx_score": 17.81633758544922, "metricx_qe_score": 19.891075134277344, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "These labels are set based on previous research and other factors. The release notes", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 17.262899545451422, "xcomet_score": 0.5210357904434204, "xcomet_qe_score": 0.8541423082351685, "metricx_score": 14.383094787597656, "metricx_qe_score": 12.246346473693848, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "on the bottom right and extracted commit release notes shown on the bottom left.", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 14.682765907912273, "xcomet_score": 0.3545418381690979, "xcomet_qe_score": 0.8096885681152344, "metricx_score": 17.51858901977539, "metricx_qe_score": 16.86740493774414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "At this time, it is necessary to detect the four labels that have been set up in advance.", "metrics": {"bleu_score": 2.276859592073037, "chrf_score": 12.61611232021051, "xcomet_score": 0.9029947519302368, "xcomet_qe_score": 0.9740556478500366, "metricx_score": 24.835649490356445, "metricx_qe_score": 23.323139190673828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "But the labels are not always consistent with each repository.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 27.995197924948904, "xcomet_score": 0.9830354452133179, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "metrics": {"bleu_score": 3.2342452920962157, "chrf_score": 12.986361140332663, "xcomet_score": 0.9223816990852356, "xcomet_qe_score": 0.976652979850769, "metricx_score": 23.846590042114258, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "We prepared a vocabulary list of art study labels for each of these notational variations.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 22.466464345939368, "xcomet_score": 0.5540128946304321, "xcomet_qe_score": 0.7261790037155151, "metricx_score": 24.3818302154541, "metricx_qe_score": 22.61420249938965, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Use it to detect the release note class and correct the text of the list that follows as the release note sentence for the class.", "metrics": {"bleu_score": 1.4445809981770859, "chrf_score": 14.950792649277394, "xcomet_score": 0.4363328218460083, "xcomet_qe_score": 0.7691205739974976, "metricx_score": 14.962030410766602, "metricx_qe_score": 12.184439659118652, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Next is the commit message.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 15.932447125353958, "xcomet_score": 0.9521411657333374, "xcomet_qe_score": 1.0, "metricx_score": 6.193855285644531, "metricx_qe_score": 4.522240161895752, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Commit messages are not tied to each release.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 17.317815384752922, "xcomet_score": 0.9485031366348267, "xcomet_qe_score": 1.0, "metricx_score": 22.43446922302246, "metricx_qe_score": 24.628185272216797, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "As shown in the image below, if the current release is version 2.5.19, we need to identify the previous release version 2.5.18 and get it diff.", "metrics": {"bleu_score": 1.6360115411488572, "chrf_score": 27.9125671088281, "xcomet_score": 0.9237803220748901, "xcomet_qe_score": 0.8862358331680298, "metricx_score": 7.2147321701049805, "metricx_qe_score": 6.196479320526123, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "metrics": {"bleu_score": 1.506189323093867, "chrf_score": 14.976700876998244, "xcomet_score": 0.7807122468948364, "xcomet_qe_score": 0.9952493906021118, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "We created a heuristic matching rule to get the previous and next versions. Date set analysis.", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 21.496556767866075, "xcomet_score": 0.681839108467102, "xcomet_qe_score": 0.8973179459571838, "metricx_score": 24.23183250427246, "metricx_qe_score": 23.578266143798828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "In the end, 7,", "metrics": {"bleu_score": 0.0, "chrf_score": 5.2908443127502345, "xcomet_score": 0.11289016902446747, "xcomet_qe_score": 0.08534718304872513, "metricx_score": 14.729974746704102, "metricx_qe_score": 9.417632102966309, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "200 repositories and 82,000 pieces of data were", "metrics": {"bleu_score": 0.0, "chrf_score": 29.991368375796686, "xcomet_score": 0.29103943705558777, "xcomet_qe_score": 0.22209958732128143, "metricx_score": 22.731624603271484, "metricx_qe_score": 11.648469924926758, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "collected. Also, the average number of release note tokens is 63, which is quite high for a summarization task.", "metrics": {"bleu_score": 3.644667088679882, "chrf_score": 18.61547278598988, "xcomet_score": 0.7023694515228271, "xcomet_qe_score": 0.7136161923408508, "metricx_score": 13.500457763671875, "metricx_qe_score": 17.142536163330078, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Also, the number of unique tokens is quite large, at 8,830,000.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 17.648864763556933, "xcomet_score": 0.9468779563903809, "xcomet_qe_score": 0.9774491786956787, "metricx_score": 12.532268524169922, "metricx_qe_score": 6.158252716064453, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "This is due to the large number of class and method names found in the repository.", "metrics": {"bleu_score": 2.2869567780619007, "chrf_score": 24.909345329170186, "xcomet_score": 0.6741563081741333, "xcomet_qe_score": 0.944046139717102, "metricx_score": 20.201841354370117, "metricx_qe_score": 20.205881118774414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Next, I explain the proposed method.", "metrics": {"bleu_score": 4.8734989388136185, "chrf_score": 11.473247279151618, "xcomet_score": 0.8828529119491577, "xcomet_qe_score": 0.9788587093353271, "metricx_score": 11.824790000915527, "metricx_qe_score": 9.131855010986328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "The class-wise extractive then abstractive summarization model consists of two neural modules,", "metrics": {"bleu_score": 0.0, "chrf_score": 27.268462232984458, "xcomet_score": 0.925987958908081, "xcomet_qe_score": 0.9784634113311768, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "a classifier using BERT or KoBERT, and a generator using BART.", "metrics": {"bleu_score": 6.837203339116283, "chrf_score": 30.29142140949313, "xcomet_score": 0.9226422309875488, "xcomet_qe_score": 0.9620075225830078, "metricx_score": 17.46871566772461, "metricx_qe_score": 14.651628494262695, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "First, CEAS uses a classifier to classify each commit message into five release note classes, features, improvements, bug fixes, and others.", "metrics": {"bleu_score": 2.0169761684760625, "chrf_score": 19.978202293982473, "xcomet_score": 0.8506567478179932, "xcomet_qe_score": 0.8884028792381287, "metricx_score": 25.0, "metricx_qe_score": 22.629281997680664, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "The commit messages classified as others are discarded.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 15.148812870655807, "xcomet_score": 0.8883017301559448, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 17.182674407958984, "metricx_qe_score": 19.416208267211914, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Then, CEAS applies a generator to the four labeled documents independently and generates release notes for each class.", "metrics": {"bleu_score": 2.276859592073037, "chrf_score": 23.291036496125948, "xcomet_score": 0.8725832104682922, "xcomet_qe_score": 0.9977201223373413, "metricx_score": 23.12588119506836, "metricx_qe_score": 24.8162899017334, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In this task, the direct correspondences between commit messages and release notes are not known, therefore to train the classi", "metrics": {"bleu_score": 1.727223799216787, "chrf_score": 25.235229757473544, "xcomet_score": 0.484420508146286, "xcomet_qe_score": 0.7773085832595825, "metricx_score": 17.494800567626953, "metricx_qe_score": 21.018856048583984, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "fier, classifier assigns pseudo labels to each input commit message using the first ten characters of each commit message. We model the class-wise abstractive sum", "metrics": {"bleu_score": 1.6504045595709425, "chrf_score": 20.34168534892476, "xcomet_score": 0.3188381791114807, "xcomet_qe_score": 0.6387587785720825, "metricx_score": 18.78125, "metricx_qe_score": 16.85249900817871, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "marization approach by two different methods. The first model, which we", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 15.28075382832105, "xcomet_score": 0.30725133419036865, "xcomet_qe_score": 0.4257453680038452, "metricx_score": 21.84622573852539, "metricx_qe_score": 15.233625411987305, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "call CAS, consists of a single seq2seq network and generates a single long release note text given a concatenation of input commit messages. The output text can be divided into classified segments based", "metrics": {"bleu_score": 1.2557690800697192, "chrf_score": 20.304374285661005, "xcomet_score": 0.28758636116981506, "xcomet_qe_score": 0.6342611312866211, "metricx_score": 18.560802459716797, "metricx_qe_score": 14.757232666015625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "on special class-specific endpoint symbols.", "metrics": {"bleu_score": 1.5330462064343475, "chrf_score": 12.121084762630147, "xcomet_score": 0.360015332698822, "xcomet_qe_score": 0.8485361337661743, "metricx_score": 24.629316329956055, "metricx_qe_score": 23.658218383789062, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "The second method, which we call CSM, consists of four different seq2seq networks, each corresponding to one of the release note classes.", "metrics": {"bleu_score": 2.042946039568498, "chrf_score": 20.476055997864563, "xcomet_score": 0.566455602645874, "xcomet_qe_score": 0.786673367023468, "metricx_score": 23.548891067504883, "metricx_qe_score": 19.683626174926758, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, let me explain the experiment.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 26.796654172203443, "xcomet_score": 0.8704924583435059, "xcomet_qe_score": 0.9931985139846802, "metricx_score": 6.0354461669921875, "metricx_qe_score": 6.029204845428467, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Five methods were compared, CEAS, CSING, CSM, clustering, and previous study GRIFF.", "metrics": {"bleu_score": 5.109276028583519, "chrf_score": 22.053839321637934, "xcomet_score": 0.4337722063064575, "xcomet_qe_score": 0.7129154205322266, "metricx_score": 16.81153106689453, "metricx_qe_score": 10.732501983642578, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "metrics": {"bleu_score": 3.2525808457905, "chrf_score": 20.074776807321552, "xcomet_score": 0.8125563859939575, "xcomet_qe_score": 0.869450569152832, "metricx_score": 23.77151107788086, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Since it is difficult to count the number of sentences, they are treated as one long sentence.", "metrics": {"bleu_score": 1.8504430829513174, "chrf_score": 14.79982235835419, "xcomet_score": 0.8740671873092651, "xcomet_qe_score": 1.0, "metricx_score": 14.228155136108398, "metricx_qe_score": 6.186426162719727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "The BLEU is penalized when the system outputs a short sentence.", "metrics": {"bleu_score": 3.7052472057637615, "chrf_score": 18.71909867078073, "xcomet_score": 0.9508985280990601, "xcomet_qe_score": 0.9690887928009033, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "This penalty results in a lower BLEU value in the experiment results described next.", "metrics": {"bleu_score": 3.1251907639724417, "chrf_score": 16.03338403164838, "xcomet_score": 0.8752952814102173, "xcomet_qe_score": 0.9938522577285767, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Finally, we calculate the specificity because the BLEU and can not be calculated if the release notes are empty.", "metrics": {"bleu_score": 2.2789551664661816, "chrf_score": 15.670264484087667, "xcomet_score": 0.6360571384429932, "xcomet_qe_score": 0.8180229067802429, "metricx_score": 15.384474754333496, "metricx_qe_score": 14.897049903869629, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "A high specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "metrics": {"bleu_score": 1.8721971830722224, "chrf_score": 16.661899465653892, "xcomet_score": 0.9330336451530457, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Here are the results.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 21.383207021509556, "xcomet_score": 0.9305862188339233, "xcomet_qe_score": 1.0, "metricx_score": 4.0917158126831055, "metricx_qe_score": 4.641719818115234, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Since the dataset contains email addresses, hash values, etc., we also evaluated the cleaned dataset, which excludes them.", "metrics": {"bleu_score": 2.352622489487909, "chrf_score": 18.15784090522978, "xcomet_score": 0.9714467525482178, "xcomet_qe_score": 0.9959530830383301, "metricx_score": 19.601192474365234, "metricx_qe_score": 22.88079261779785, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CEAS and CS achieved BLEU scores more than 10 points higher than the baselines.", "metrics": {"bleu_score": 2.923637789252517, "chrf_score": 20.31762427512909, "xcomet_score": 0.7415558099746704, "xcomet_qe_score": 0.7871781587600708, "metricx_score": 17.031940460205078, "metricx_qe_score": 15.289186477661133, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "In particular, on the cleaned test set, the score gap between the proposed method and the baselines jumped to more than 20 points.", "metrics": {"bleu_score": 1.4445809981770859, "chrf_score": 19.910557956252813, "xcomet_score": 0.9041718244552612, "xcomet_qe_score": 0.9163751006126404, "metricx_score": 21.530086517333984, "metricx_qe_score": 23.076204299926758, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "These results indicate that CEAS and CS are significantly effective.", "metrics": {"bleu_score": 4.069582841180382, "chrf_score": 24.340047634192256, "xcomet_score": 0.7008665800094604, "xcomet_qe_score": 0.8017503023147583, "metricx_score": 22.918289184570312, "metricx_qe_score": 19.404659271240234, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "CSAS got a better BLEU score than CSAS, suggesting that combining a classifier and a generator is effective and training the classifier using pseudo lab", "metrics": {"bleu_score": 1.337625779258248, "chrf_score": 26.434297238686828, "xcomet_score": 0.18830952048301697, "xcomet_qe_score": 0.3513708710670471, "metricx_score": 22.630428314208984, "metricx_qe_score": 21.456459045410156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "els, a high coverage of CSAS can be achieved properly.", "metrics": {"bleu_score": 1.3630842714584204, "chrf_score": 6.863947116676912, "xcomet_score": 0.23734518885612488, "xcomet_qe_score": 0.4850817620754242, "metricx_score": 21.748266220092773, "metricx_qe_score": 21.63697624206543, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "CSAS much tended to be higher BLEU than C", "metrics": {"bleu_score": 0.0, "chrf_score": 12.798162275026195, "xcomet_score": 0.19926157593727112, "xcomet_qe_score": 0.45118948817253113, "metricx_score": 23.311180114746094, "metricx_qe_score": 21.27993392944336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "SAS, suggesting that it is also effective to independently develop different abstractive summarization models for each release note class.", "metrics": {"bleu_score": 1.5474934839449572, "chrf_score": 20.172814452112974, "xcomet_score": 0.6645717620849609, "xcomet_qe_score": 0.8491959571838379, "metricx_score": 20.98666000366211, "metricx_qe_score": 22.202285766601562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Here is an error analysis.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 30.45194982048806, "xcomet_score": 0.9729211330413818, "xcomet_qe_score": 0.9827612638473511, "metricx_score": 3.1606991291046143, "metricx_qe_score": 3.051785469055176, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "CS methods tend to output shorter sentences than human reference sentences.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 21.799146629993853, "xcomet_score": 0.8114050626754761, "xcomet_qe_score": 0.8963682651519775, "metricx_score": 24.410505294799805, "metricx_qe_score": 23.880599975585938, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In the figure on the right, the reference sentence has three or four sentences, while CS has only one.", "metrics": {"bleu_score": 2.2731543567022867, "chrf_score": 18.761604820896626, "xcomet_score": 0.8012449741363525, "xcomet_qe_score": 0.8370479345321655, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "The reason for this smaller sentence length is that in the training data, only 33% of the sentences are present in the features label and 40% in the improvements label.", "metrics": {"bleu_score": 1.7705303846970066, "chrf_score": 18.701409124545517, "xcomet_score": 0.7148213982582092, "xcomet_qe_score": 0.7709090709686279, "metricx_score": 19.15023422241211, "metricx_qe_score": 7.812635898590088, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Furthermore, CS methods cannot generate accurate release notes without additional information.", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 23.04753482293023, "xcomet_score": 0.7807689905166626, "xcomet_qe_score": 0.8929965496063232, "metricx_score": 23.749610900878906, "metricx_qe_score": 21.74984359741211, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding pull request or issue.", "metrics": {"bleu_score": 1.123099644603982, "chrf_score": 19.152486915898926, "xcomet_score": 0.8089067935943604, "xcomet_qe_score": 0.9679672718048096, "metricx_score": 25.0, "metricx_qe_score": 24.304933547973633, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "The example below shows the two commit messages in the input are related and should be combined into one sentence, but it fails to do so. Finally, a conclusion.", "metrics": {"bleu_score": 1.5883027492953543, "chrf_score": 18.10676510686592, "xcomet_score": 0.7720953226089478, "xcomet_qe_score": 0.8703559637069702, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "We have built a new", "metrics": {"bleu_score": 0.0, "chrf_score": 5.892255892255891, "xcomet_score": 0.12705077230930328, "xcomet_qe_score": 0.11955952644348145, "metricx_score": 20.20524024963379, "metricx_qe_score": 11.717573165893555, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "dataset for automatic release note generation.", "metrics": {"bleu_score": 2.7869730680842904, "chrf_score": 17.979712586017175, "xcomet_score": 0.40787848830223083, "xcomet_qe_score": 0.8943209052085876, "metricx_score": 21.73714256286621, "metricx_qe_score": 16.491363525390625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "We have also formulated the task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "metrics": {"bleu_score": 1.4471307949925738, "chrf_score": 21.43986514820124, "xcomet_score": 0.9932026863098145, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Our experiment shows that the proposed methods generate less noisy release notes at higher coverage than the baselines.", "metrics": {"bleu_score": 2.0244462660665508, "chrf_score": 24.535064907823052, "xcomet_score": 0.781511664390564, "xcomet_qe_score": 0.9150978922843933, "metricx_score": 23.561750411987305, "metricx_qe_score": 22.928699493408203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Please check out our dataset on GitHub. Thank you.", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 18.762946018176557, "xcomet_score": 0.9992223978042603, "xcomet_qe_score": 0.9991161823272705, "metricx_score": 5.20416259765625, "metricx_qe_score": 4.980619430541992, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Hallo", "metrics": {"bleu_score": 0.0, "chrf_score": 4.081632653061225, "xcomet_score": 0.5901482701301575, "xcomet_qe_score": 0.2832525372505188, "metricx_score": 1.2308553457260132, "metricx_qe_score": 0.2530963122844696, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": ", mein Name ist Asaf Farahri und", "metrics": {"bleu_score": 21.191828141393902, "chrf_score": 51.1141786651061, "xcomet_score": 0.25781214237213135, "xcomet_qe_score": 0.3211856484413147, "metricx_score": 11.834246635437012, "metricx_qe_score": 6.0204877853393555, "linguapy_score": [1, "ICELANDIC"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "ich werde unser Papier vorstellen, few-shot tabellarische Datenerweiterung mit feinabgestimmten Transformerarchitekturen.", "metrics": {"bleu_score": 6.299392144493405, "chrf_score": 46.00323798208685, "xcomet_score": 0.710783839225769, "xcomet_qe_score": 0.6807365417480469, "metricx_score": 4.938780307769775, "metricx_qe_score": 5.935805320739746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der vorhandenen Merkmale.", "metrics": {"bleu_score": 67.1312968442336, "chrf_score": 79.16035975781641, "xcomet_score": 0.9989907741546631, "xcomet_qe_score": 1.0, "metricx_score": 0.5036998987197876, "metricx_qe_score": 0.546424388885498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind diese Merkmale begrenzt.", "metrics": {"bleu_score": 48.892302243490086, "chrf_score": 67.94521403127803, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5901244878768921, "metricx_qe_score": 0.4549185335636139, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Merkmalsgenerierung mit einer anderen Datenquelle kann wesentliche Informationen hinzufügen.", "metrics": {"bleu_score": 50.93330917854971, "chrf_score": 70.18286677031487, "xcomet_score": 0.9320366382598877, "xcomet_qe_score": 0.9913594722747803, "metricx_score": 0.6989138722419739, "metricx_qe_score": 0.5671430826187134, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische tabellarische Datenerweiterung mit freier Textquelle.", "metrics": {"bleu_score": 26.52899261800746, "chrf_score": 65.04508820429437, "xcomet_score": 0.9681949019432068, "xcomet_qe_score": 0.9654335975646973, "metricx_score": 2.0888547897338867, "metricx_qe_score": 1.0252277851104736, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, wir haben eine tabellarische Datenbank und eine Wissensdatenbank.", "metrics": {"bleu_score": 28.997844147152072, "chrf_score": 71.59217411840518, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3788937032222748, "metricx_qe_score": 0.4705314338207245, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen einen automatischen Prozess, der Intitielinking und Textanalyse beinhaltet, um neue Merkmale aus dem Text der Wissensdatenbank zu extrahieren.", "metrics": {"bleu_score": 36.5406409928865, "chrf_score": 65.92170757570675, "xcomet_score": 0.9071778059005737, "xcomet_qe_score": 0.9078033566474915, "metricx_score": 3.867628812789917, "metricx_qe_score": 4.1155266761779785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework, FIST, ist genau dieser automatische Prozess.", "metrics": {"bleu_score": 47.987820666906615, "chrf_score": 72.86892868037287, "xcomet_score": 0.8522303104400635, "xcomet_qe_score": 0.8497434258460999, "metricx_score": 4.6842217445373535, "metricx_qe_score": 4.5992841720581055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns ein Beispiel an. In einem Datensatz, der in FIST eingegeben wird", "metrics": {"bleu_score": 19.31121451390497, "chrf_score": 58.526379144863505, "xcomet_score": 0.88393235206604, "xcomet_qe_score": 0.8867153525352478, "metricx_score": 4.861733436584473, "metricx_qe_score": 5.269213676452637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": ", ist das Ziel der Universit", "metrics": {"bleu_score": 5.854497694024015, "chrf_score": 26.671743565119737, "xcomet_score": 0.1451726108789444, "xcomet_qe_score": 0.13135120272636414, "metricx_score": 22.755380630493164, "metricx_qe_score": 21.061405181884766, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "ät, Universitäten in niedrige und hohe Universitäten einzuordnen.", "metrics": {"bleu_score": 3.9778149665594618, "chrf_score": 40.822668210006604, "xcomet_score": 0.6789833307266235, "xcomet_qe_score": 0.6997466683387756, "metricx_score": 12.898553848266602, "metricx_qe_score": 12.648283958435059, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "als Wissensdatenbank verwenden wir Wikipedia.", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 74.6925250927119, "xcomet_score": 0.9872515201568604, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2004576176404953, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von FIST ist Entitätserkennung,", "metrics": {"bleu_score": 32.260135189272866, "chrf_score": 58.98589905239324, "xcomet_score": 0.7953649759292603, "xcomet_qe_score": 0.7937560081481934, "metricx_score": 4.797037124633789, "metricx_qe_score": 4.926974773406982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "wenn jede Entität. In diesem Beispiel ist der Name der Universität mit einer Entität in der Wissensdatenbank verknüpft. Und", "metrics": {"bleu_score": 21.640076381354273, "chrf_score": 70.90102331314898, "xcomet_score": 0.8738193511962891, "xcomet_qe_score": 0.9402921199798584, "metricx_score": 6.6612653732299805, "metricx_qe_score": 5.738167762756348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "der Text der Entitäten der Wissensdatenbank wird in den Datensatz eingefügt.", "metrics": {"bleu_score": 13.188274750399428, "chrf_score": 52.75962279696991, "xcomet_score": 0.9741976261138916, "xcomet_qe_score": 0.961198091506958, "metricx_score": 1.1142432689666748, "metricx_qe_score": 1.6941779851913452, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text die Wikipedia-Überschrift.", "metrics": {"bleu_score": 48.88290318657944, "chrf_score": 64.14402296808989, "xcomet_score": 0.991176962852478, "xcomet_qe_score": 0.998886227607727, "metricx_score": 3.757812976837158, "metricx_qe_score": 4.147747993469238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Merkmale aus dem Text extrahieren.", "metrics": {"bleu_score": 12.299063759171652, "chrf_score": 36.499282224624125, "xcomet_score": 0.9870694875717163, "xcomet_qe_score": 0.996326208114624, "metricx_score": 1.6041650772094727, "metricx_qe_score": 1.1547502279281616, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen eine Merkmalsextraktion, die Textanalyse beinhaltet.", "metrics": {"bleu_score": 6.443030905386945, "chrf_score": 38.94597988329412, "xcomet_score": 0.978779673576355, "xcomet_qe_score": 0.9883664846420288, "metricx_score": 4.483780384063721, "metricx_qe_score": 3.7611424922943115, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist das Hauptthema dieses Papiers und ich werde in den nächsten Folien darauf eingehen.", "metrics": {"bleu_score": 9.93252700661181, "chrf_score": 46.29776570779004, "xcomet_score": 0.9661332368850708, "xcomet_qe_score": 0.9703331589698792, "metricx_score": 1.7914354801177979, "metricx_qe_score": 2.2777178287506104, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Merkmalsextraktion gibt es eine Merkmersynthesephase, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren.", "metrics": {"bleu_score": 40.80917315547267, "chrf_score": 52.72728833378324, "xcomet_score": 0.9484546184539795, "xcomet_qe_score": 0.982609748840332, "metricx_score": 2.147432804107666, "metricx_qe_score": 1.634864330291748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "FIST generiert neue Merkmale in der Anzahl der ursprünglichen Klassen.", "metrics": {"bleu_score": 23.26303536297059, "chrf_score": 47.26136923890659, "xcomet_score": 0.7064801454544067, "xcomet_qe_score": 0.7563989162445068, "metricx_score": 5.262946605682373, "metricx_qe_score": 5.5674943923950195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen,", "metrics": {"bleu_score": 88.01117367933934, "chrf_score": 98.12893305910325, "xcomet_score": 0.9895354509353638, "xcomet_qe_score": 0.9922080039978027, "metricx_score": 0.2057073414325714, "metricx_qe_score": 0.2756565511226654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "also generiert FIST zwei neue Merkmale. Aber", "metrics": {"bleu_score": 13.888095170058955, "chrf_score": 42.38399958279063, "xcomet_score": 0.7727053761482239, "xcomet_qe_score": 0.8791872262954712, "metricx_score": 8.485281944274902, "metricx_qe_score": 5.923835754394531, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "wenn der Datensatz fünf Klassen hat, generiert FIST fünf neue Merkmale.", "metrics": {"bleu_score": 35.24025452531097, "chrf_score": 63.19702098494702, "xcomet_score": 0.8601429462432861, "xcomet_qe_score": 0.8524208068847656, "metricx_score": 5.6302666664123535, "metricx_qe_score": 6.0412516593933105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jedes Merkmal repräsentiert die Wahrscheinlichkeit für jede Klasse.", "metrics": {"bleu_score": 41.80134288483487, "chrf_score": 66.03373064615856, "xcomet_score": 0.9946569204330444, "xcomet_qe_score": 0.9989062547683716, "metricx_score": 0.4736848473548889, "metricx_qe_score": 0.4538906514644623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, nämlich Transformer-basierte Sprachmodelle wie BERT, GPT, XLNET usw. Aber", "metrics": {"bleu_score": 39.60970942970262, "chrf_score": 70.66718061870223, "xcomet_score": 0.9499878883361816, "xcomet_qe_score": 0.9517571926116943, "metricx_score": 2.3139543533325195, "metricx_qe_score": 1.021578311920166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "es ist unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten trainieren können.", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 65.1452103716508, "xcomet_score": 0.9695035219192505, "xcomet_qe_score": 0.9501659274101257, "metricx_score": 1.024689793586731, "metricx_qe_score": 1.4941507577896118, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird eine Zielaufgabe feinabstimmen.", "metrics": {"bleu_score": 18.190371142855746, "chrf_score": 46.17836033531512, "xcomet_score": 0.9232780933380127, "xcomet_qe_score": 0.862409770488739, "metricx_score": 2.9387569427490234, "metricx_qe_score": 4.720671653747559, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Merkmersynthesephase können wir ein vortrainiertes Sprachmodell herunterladen und das Sprachmodell über den Zieldatensatz feinabstimmen.", "metrics": {"bleu_score": 49.431938572733344, "chrf_score": 72.28594410091497, "xcomet_score": 0.9763420820236206, "xcomet_qe_score": 0.9369813203811646, "metricx_score": 1.4617809057235718, "metricx_qe_score": 1.9611507654190063, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist das Ziel, den Text in zwei Klassen zu klassifizieren, abstr und Klasse, in die wir uns einordnen.", "metrics": {"bleu_score": 10.500547675498797, "chrf_score": 40.21706674744476, "xcomet_score": 0.3866595923900604, "xcomet_qe_score": 0.3594135344028473, "metricx_score": 9.529500007629395, "metricx_qe_score": 12.972249984741211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhalten das Sprachmodelloutput, das die Wahrscheinlichkeit für jede Klasse ist, und verwenden es als neue Merkmale.", "metrics": {"bleu_score": 26.808424913615276, "chrf_score": 63.41569026125118, "xcomet_score": 0.9434733390808105, "xcomet_qe_score": 0.9521700143814087, "metricx_score": 4.39605712890625, "metricx_qe_score": 3.940295457839966, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem mit diesem Ansatz ist, dass Datensätze möglicherweise nur wenige verschiedene Entitätstexte enthalten.", "metrics": {"bleu_score": 50.096893227219766, "chrf_score": 73.47957538763008, "xcomet_score": 0.9702054262161255, "xcomet_qe_score": 0.9643897414207458, "metricx_score": 1.1113203763961792, "metricx_qe_score": 0.9473501443862915, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Beispiel enthält fast die Hälfte der Datensätze weniger als 400 Proben. Und die kleinste Datensatz enthält 35 Proben.", "metrics": {"bleu_score": 46.78134833959514, "chrf_score": 61.7100879666494, "xcomet_score": 0.9264757037162781, "xcomet_qe_score": 0.9069105386734009, "metricx_score": 3.388124942779541, "metricx_qe_score": 4.051177978515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Um also ein Sprachmodell über diesen Datensatz zu feinabstimmen, ist es unwahrscheinlich.", "metrics": {"bleu_score": 12.571192676522521, "chrf_score": 57.28822682064685, "xcomet_score": 0.8866815567016602, "xcomet_qe_score": 0.8184447288513184, "metricx_score": 7.458907604217529, "metricx_qe_score": 5.924704551696777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können die Vorwissen über voranalysierte Datensätze nutzen,", "metrics": {"bleu_score": 18.60045401920258, "chrf_score": 60.29295313289662, "xcomet_score": 0.9703277349472046, "xcomet_qe_score": 0.9854819178581238, "metricx_score": 0.6971282958984375, "metricx_qe_score": 0.37662869691848755, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "weil wir FIST über mehrere Datensätze anwenden. Wir können die n-1 Datensätze verwenden, um Informationen über die n-1 Datensätze zu sammeln und diese Informationen verwenden, wenn wir den n-ten Datensatz analysieren. Was", "metrics": {"bleu_score": 47.37307128658456, "chrf_score": 77.77286510596879, "xcomet_score": 0.5312427878379822, "xcomet_qe_score": 0.514109194278717, "metricx_score": 5.485948085784912, "metricx_qe_score": 4.379021167755127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "wir vorschlagen, ist, eine weitere Feinabstimmungsphase hinzuzufügen,", "metrics": {"bleu_score": 39.281465090051306, "chrf_score": 85.91979812651074, "xcomet_score": 0.9396392703056335, "xcomet_qe_score": 0.9268840551376343, "metricx_score": 1.4870847463607788, "metricx_qe_score": 1.6633237600326538, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "eine vorläufige Multi-Task-Feinabstimmung, bei der wir das", "metrics": {"bleu_score": 11.044795567078939, "chrf_score": 67.50253180487665, "xcomet_score": 0.8132953643798828, "xcomet_qe_score": 0.7776767611503601, "metricx_score": 6.8656086921691895, "metricx_qe_score": 4.119953632354736, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodell über n-1 Datensätze feinabstimmen. Und", "metrics": {"bleu_score": 4.410363736106611, "chrf_score": 46.46749735068345, "xcomet_score": 0.8987331390380859, "xcomet_qe_score": 0.8570070266723633, "metricx_score": 3.057438373565674, "metricx_qe_score": 1.1868000030517578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "dann führen wir eine weitere Feinabstimmungsphase durch, bei der wir das Sprachmodell über den Zieldatensatz feinabstimmen.", "metrics": {"bleu_score": 40.88284408961525, "chrf_score": 67.77059873146138, "xcomet_score": 0.8708512187004089, "xcomet_qe_score": 0.8310178518295288, "metricx_score": 1.6757159233093262, "metricx_qe_score": 3.1014153957366943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der Stand der Technik bei Multi-Task-Feinabstimmung heißt MTDNN.", "metrics": {"bleu_score": 5.669791110976001, "chrf_score": 46.523102923700364, "xcomet_score": 0.9711282253265381, "xcomet_qe_score": 0.9829262495040894, "metricx_score": 1.3998258113861084, "metricx_qe_score": 2.3252999782562256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Bei MTDNN werden die Anzahl der Aufgaben in der Trainingssache beibehalten.", "metrics": {"bleu_score": 9.642085430897602, "chrf_score": 48.273293396573806, "xcomet_score": 0.8142517805099487, "xcomet_qe_score": 0.8071125745773315, "metricx_score": 8.014681816101074, "metricx_qe_score": 6.558413505554199, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es vier Aufgaben in der Trainingssache. Also führt MTDNN vier Köpfe ein, die aus dem Trainingssache ausgewählt", "metrics": {"bleu_score": 17.806500123241516, "chrf_score": 46.91982849723274, "xcomet_score": 0.6516373753547668, "xcomet_qe_score": 0.6456356048583984, "metricx_score": 11.329780578613281, "metricx_qe_score": 9.920158386230469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "werden. Und wenn die zufällige Charge aus der Trainingssache zu", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 29.376236565062552, "xcomet_score": 0.3121650815010071, "xcomet_qe_score": 0.15270376205444336, "metricx_score": 16.234987258911133, "metricx_qe_score": 14.915410995483398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "einer einzelnen Satzklassifizierungsaufgabe gehört, wird sie durch den ersten Kopf ausgeführt. Und wenn die zufällige Charge zu", "metrics": {"bleu_score": 5.988582875155427, "chrf_score": 42.66462492488198, "xcomet_score": 0.6457023620605469, "xcomet_qe_score": 0.6227614879608154, "metricx_score": 14.003609657287598, "metricx_qe_score": 15.19996452331543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "einer Paarwörter-Ranking-Aufgabe gehört, wird sie durch den letzten Kopf ausgeführt.", "metrics": {"bleu_score": 4.372564651695467, "chrf_score": 32.82802691024339, "xcomet_score": 0.6081817150115967, "xcomet_qe_score": 0.629082202911377, "metricx_score": 11.023942947387695, "metricx_qe_score": 11.852543830871582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario, in dem tabellarische Datensätze die Anzahl der Klassen vari", "metrics": {"bleu_score": 22.62944003945279, "chrf_score": 76.57663838431084, "xcomet_score": 0.8557329177856445, "xcomet_qe_score": 0.9001750946044922, "metricx_score": 6.355175495147705, "metricx_qe_score": 6.121774196624756, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "ieren, führt", "metrics": {"bleu_score": 0.0, "chrf_score": 6.3071914885170415, "xcomet_score": 0.11635956168174744, "xcomet_qe_score": 0.08910124003887177, "metricx_score": 18.430280685424805, "metricx_qe_score": 13.870779991149902, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDNN die Anzahl der Klassen, Köpfe, Ausgabeschichten", "metrics": {"bleu_score": 8.125165710854512, "chrf_score": 28.331465920655514, "xcomet_score": 0.8812921047210693, "xcomet_qe_score": 0.8364971280097961, "metricx_score": 9.616103172302246, "metricx_qe_score": 8.711832046508789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "und zusätzlich eine neue Kopf für eine neue Aufgabe mit einem neuen Datensatz ein.", "metrics": {"bleu_score": 6.9536217213398395, "chrf_score": 46.615013930956636, "xcomet_score": 0.7062835693359375, "xcomet_qe_score": 0.7089565992355347, "metricx_score": 11.483147621154785, "metricx_qe_score": 12.764627456665039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, genannt taskreformulierte Feinabstimmung, führt in unserer Aufgabe", "metrics": {"bleu_score": 4.214712925133274, "chrf_score": 24.64262822317379, "xcomet_score": 0.27879655361175537, "xcomet_qe_score": 0.1602732241153717, "metricx_score": 19.624435424804688, "metricx_qe_score": 20.05268096923828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3472827076911926, "xcomet_qe_score": 0.1529785841703415, "metricx_score": 2.9576406478881836, "metricx_qe_score": 5.898624897003174, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.4810939431190491, "xcomet_qe_score": 0.24127714335918427, "metricx_score": 8.598962783813477, "metricx_qe_score": 9.667980194091797, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "die Aufgabe von der Klassifizierung des Textes in zwei Klassen in die Klassifizierung des Textes, des Abstracts und der Klasse in True oder False um.", "metrics": {"bleu_score": 44.773799347756686, "chrf_score": 65.89093387895252, "xcomet_score": 0.77271968126297, "xcomet_qe_score": 0.7961387634277344, "metricx_score": 6.680704593658447, "metricx_qe_score": 6.882230281829834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Also trainieren wir das Sprachmodell, um den Abstract in die Klasse zu klassifizieren, um zu bestimmen, ob der Abstract zur Klasse gehört oder nicht.", "metrics": {"bleu_score": 20.972012760145876, "chrf_score": 54.52230487963102, "xcomet_score": 0.6171883344650269, "xcomet_qe_score": 0.632297158241272, "metricx_score": 4.8120527267456055, "metricx_qe_score": 5.814255714416504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Labelvektor in Xs Fall besteht immer aus zwei Klassen.", "metrics": {"bleu_score": 17.71015781757256, "chrf_score": 41.83231305616032, "xcomet_score": 0.9486937522888184, "xcomet_qe_score": 0.9437494874000549, "metricx_score": 4.193061351776123, "metricx_qe_score": 4.968564033508301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist der Algorithmus für unsere reformulierte Feinabstimmungsansatz.", "metrics": {"bleu_score": 27.77619034011791, "chrf_score": 79.62471860512723, "xcomet_score": 0.9439646005630493, "xcomet_qe_score": 0.9157601594924927, "metricx_score": 2.4809155464172363, "metricx_qe_score": 4.05236291885376, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Also führen wir die gesamte Framework, einen", "metrics": {"bleu_score": 4.8734989388136185, "chrf_score": 26.978906671502482, "xcomet_score": 0.3951196074485779, "xcomet_qe_score": 0.6808711290359497, "metricx_score": 13.047629356384277, "metricx_qe_score": 5.225757598876953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Datensatz ein, führen", "metrics": {"bleu_score": 7.545383788761362, "chrf_score": 26.71109958002112, "xcomet_score": 0.5278177261352539, "xcomet_qe_score": 0.708893358707428, "metricx_score": 5.478024959564209, "metricx_qe_score": 4.507509231567383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "die Entitätserkennungphase aus,", "metrics": {"bleu_score": 8.9730240870212, "chrf_score": 31.655902059252245, "xcomet_score": 0.6054842472076416, "xcomet_qe_score": 0.615243673324585, "metricx_score": 9.900352478027344, "metricx_qe_score": 12.745046615600586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "extrahieren den Text aus der Wissensdatenbank, der in diesem Beispiel die Wikipedia-Überschrift", "metrics": {"bleu_score": 20.814076895812715, "chrf_score": 58.635279464041446, "xcomet_score": 0.8591153621673584, "xcomet_qe_score": 0.8489033579826355, "metricx_score": 7.707704544067383, "metricx_qe_score": 6.751957416534424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "ist, reformulieren die Aufgabe in eine Satzklassifizierungsaufgabe, wenden", "metrics": {"bleu_score": 23.769263662838707, "chrf_score": 56.522959577489196, "xcomet_score": 0.4345173239707947, "xcomet_qe_score": 0.325116902589798, "metricx_score": 12.138110160827637, "metricx_qe_score": 11.469927787780762, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "das Sprachmodell auf den neuen Task an und berechnen die Wahrscheinlichkeit für jede Klasse. Und notieren,", "metrics": {"bleu_score": 10.21619866588636, "chrf_score": 54.459589067872095, "xcomet_score": 0.7328764200210571, "xcomet_qe_score": 0.6702272295951843, "metricx_score": 5.1790852546691895, "metricx_qe_score": 4.687606334686279, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "dass das Sprachmodell bereits über n-1 Datensätze mit einer vorläufigen Multi-Task-Feinabstimmung feinabgestimmt wurde.", "metrics": {"bleu_score": 19.69434741959044, "chrf_score": 69.93466022658454, "xcomet_score": 0.9452774524688721, "xcomet_qe_score": 0.9237358570098877, "metricx_score": 2.8602585792541504, "metricx_qe_score": 3.829821825027466, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Outputvektor des Sprachmodells als neu generierte Merkmalsvektor in der Anzahl der Klassen.", "metrics": {"bleu_score": 50.28248236576277, "chrf_score": 72.04827235526756, "xcomet_score": 0.9479763507843018, "xcomet_qe_score": 0.9495737552642822, "metricx_score": 1.8178906440734863, "metricx_qe_score": 2.11850643157959, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Framework zu bewerten, verwenden wir einen 17 tabellarischen Klassifizierungsdatensatz, der in Größe, Features, Balance und anfänglicher Leistung variiert. Und", "metrics": {"bleu_score": 11.601529016234949, "chrf_score": 47.97692335454831, "xcomet_score": 0.7269550561904907, "xcomet_qe_score": 0.6279845237731934, "metricx_score": 7.2375640869140625, "metricx_qe_score": 7.3998236656188965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "als Wissensdatenbank verwenden wir Wikipedia.", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 74.6925250927119, "xcomet_score": 0.9872515201568604, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.22770874202251434, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir entwerfen unsere Experiment, indem wir FIST über 16 Datensätze trainieren und auf den 17. Datensatz anwenden.", "metrics": {"bleu_score": 38.60080841767298, "chrf_score": 57.36907805516213, "xcomet_score": 0.8339741230010986, "xcomet_qe_score": 0.7446921467781067, "metricx_score": 6.6941351890563965, "metricx_qe_score": 6.084041595458984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in eine Folds- und eine Crossvalidierung auf.", "metrics": {"bleu_score": 11.665983889812088, "chrf_score": 41.41703262837874, "xcomet_score": 0.7446480393409729, "xcomet_qe_score": 0.778337299823761, "metricx_score": 7.8193359375, "metricx_qe_score": 8.650469779968262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Merkmale und bewerten sie mit fünf Klassifizierungsalgorithmen.", "metrics": {"bleu_score": 59.230330720232516, "chrf_score": 60.398258586765806, "xcomet_score": 0.9892740249633789, "xcomet_qe_score": 0.9979798793792725, "metricx_score": 0.5621857047080994, "metricx_qe_score": 0.2406126856803894, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine architektonische Basis.", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 66.89615731406529, "xcomet_score": 0.8250821828842163, "xcomet_qe_score": 0.8196760416030884, "metricx_score": 6.734484672546387, "metricx_qe_score": 7.957483291625977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse für unser Experiment.", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 80.45081663502715, "xcomet_score": 0.9799407720565796, "xcomet_qe_score": 0.9850043058395386, "metricx_score": 0.20770743489265442, "metricx_qe_score": 0.07273373007774353, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Framework mit der Zieldatensatzfeinabstimmung, der Zielaufgabenfeinabstimmung und der MTDNN-Vorabstimmungsfeinabstimmung vergleichen.", "metrics": {"bleu_score": 24.45160953921343, "chrf_score": 66.24695740550686, "xcomet_score": 0.9222831726074219, "xcomet_qe_score": 0.950558066368103, "metricx_score": 2.294926643371582, "metricx_qe_score": 4.601699352264404, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz erreicht die beste Leistung, die beste Leistung. Während", "metrics": {"bleu_score": 21.586404366478295, "chrf_score": 42.49543377586703, "xcomet_score": 0.2995639145374298, "xcomet_qe_score": 0.4573604166507721, "metricx_score": 11.283175468444824, "metricx_qe_score": 8.066629409790039, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "MTDNN zwei Prozent Verbesserung gegenüber der Zieldatensatzfeinabstimmung erreicht, erreicht", "metrics": {"bleu_score": 37.20090803840517, "chrf_score": 77.18232574763387, "xcomet_score": 0.8820245265960693, "xcomet_qe_score": 0.8658113479614258, "metricx_score": 6.287517547607422, "metricx_qe_score": 9.257218360900879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "unser Ansatz sechs Prozent Verbesserung.", "metrics": {"bleu_score": 7.509307647752128, "chrf_score": 44.67832674647219, "xcomet_score": 0.9129869937896729, "xcomet_qe_score": 0.9291293621063232, "metricx_score": 6.106825351715088, "metricx_qe_score": 7.724414348602295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Datensätze ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt. Und die Verbesserung der vorläufigen Multi-Task-Feinabstimmungsphase abnimmt auf 1,5 Prozent.", "metrics": {"bleu_score": 37.40109994112765, "chrf_score": 77.48040878218498, "xcomet_score": 0.9216307401657104, "xcomet_qe_score": 0.9282562136650085, "metricx_score": 3.3394317626953125, "metricx_qe_score": 4.208367347717285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung steigt im Vergleich zur Zielaufgabenfeinabstimmung um 11 Prozent.", "metrics": {"bleu_score": 17.742293692152224, "chrf_score": 59.1291405364899, "xcomet_score": 0.9622433185577393, "xcomet_qe_score": 0.9944909811019897, "metricx_score": 1.6757183074951172, "metricx_qe_score": 3.8113064765930176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für Summen ermöglicht FIST few-shot-Erweiterung. In unserem Experiment verwenden wir 35 Proben.", "metrics": {"bleu_score": 12.011055432195764, "chrf_score": 45.193742053684204, "xcomet_score": 0.6983397006988525, "xcomet_qe_score": 0.6764683723449707, "metricx_score": 7.914106369018555, "metricx_qe_score": 7.862884521484375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben, Datensätze", "metrics": {"bleu_score": 67.16877364745231, "chrf_score": 88.51122076785693, "xcomet_score": 0.9821959733963013, "xcomet_qe_score": 0.9810739755630493, "metricx_score": 0.6847674250602722, "metricx_qe_score": 1.463226079940796, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "und behält die Modellkopfhöhe bei.", "metrics": {"bleu_score": 6.916271812933183, "chrf_score": 31.07094238184572, "xcomet_score": 0.8479441404342651, "xcomet_qe_score": 0.8525400757789612, "metricx_score": 4.546646595001221, "metricx_qe_score": 4.716383934020996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulierungsphase hinzu,", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 97.32778252515094, "xcomet_score": 0.9697567820549011, "xcomet_qe_score": 0.9371447563171387, "metricx_score": 0.6531243920326233, "metricx_qe_score": 0.8033447265625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "es erweitert das Trainingssache und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaarklassifizierungsaufgabe verwenden können. Vielen Dank.", "metrics": {"bleu_score": 52.37705041286052, "chrf_score": 73.73530707913889, "xcomet_score": 0.8258734941482544, "xcomet_qe_score": 0.8249496221542358, "metricx_score": 5.0626349449157715, "metricx_qe_score": 6.433320999145508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo", "metrics": {"bleu_score": 0.0, "chrf_score": 4.081632653061225, "xcomet_score": 0.5901482701301575, "xcomet_qe_score": 0.2832525372505188, "metricx_score": 1.2308553457260132, "metricx_qe_score": 0.2530963122844696, "linguapy_score": [1, "SOTHO"]}}
