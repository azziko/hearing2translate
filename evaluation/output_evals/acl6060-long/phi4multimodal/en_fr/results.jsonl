{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous. Aujourd'hui, je vais présenter notre travail de recherche, l'apprentissage à raisonner, résoudre les problèmes de mathématiques comme une extraction complexe de", "metrics": {"bleu_score": 25.07414148550991, "chrf_score": 63.986589801051686, "xcomet_score": 0.3200615346431732, "xcomet_qe_score": 0.40699049830436707, "metricx_score": 11.315196990966797, "metricx_qe_score": 9.907411575317383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "raisonnement. Je suis Alan de l'AI Lab, et ce est un travail conjoint avec Cheryle de l'Université de Texas à Austin et Wei de l'Université de Stanford.", "metrics": {"bleu_score": 18.905190742398112, "chrf_score": 39.55802844258006, "xcomet_score": 0.18748697638511658, "xcomet_qe_score": 0.1995711624622345, "metricx_score": 13.704171180725098, "metricx_qe_score": 12.17569637298584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "D'abord, j'aimerais parler de notre motivation pour le raisonnement.", "metrics": {"bleu_score": 81.55395405382076, "chrf_score": 93.0752935281529, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2342201471328735, "metricx_qe_score": 1.3327620029449463, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, nous montrons des exemples où le raisonnement multistap est utile.", "metrics": {"bleu_score": 29.13055375496153, "chrf_score": 63.811149933772136, "xcomet_score": 0.8944147825241089, "xcomet_qe_score": 0.9012024402618408, "metricx_score": 5.665180683135986, "metricx_qe_score": 6.798416614532471, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, cette figure est prise du papier de Pal, où ils font des exemples pour résoudre le problème de mathématiques dans un scénario d'apprentissage en flux.", "metrics": {"bleu_score": 12.045422179467963, "chrf_score": 48.05879331945032, "xcomet_score": 0.44732627272605896, "xcomet_qe_score": 0.461266428232193, "metricx_score": 8.850278854370117, "metricx_qe_score": 7.047108173370361, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, sur le côté gauche, nous pouvons voir si nous donnons quelques exemples avec des questions et des réponses, nous ne pourrons pas obtenir les bonnes réponses.", "metrics": {"bleu_score": 52.919093623904345, "chrf_score": 73.14993548105434, "xcomet_score": 0.9467812776565552, "xcomet_qe_score": 0.9424934387207031, "metricx_score": 3.066462993621826, "metricx_qe_score": 3.2145814895629883, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous donnons plus de description de raisonnement, le modèle est capable de prédire la description de raisonnement et de faire une prédiction correcte. Donc,", "metrics": {"bleu_score": 32.95103291209691, "chrf_score": 66.53674072491278, "xcomet_score": 0.7990514039993286, "xcomet_qe_score": 0.8402068018913269, "metricx_score": 5.442535877227783, "metricx_qe_score": 4.8993000984191895, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "il est bon d'avoir des prédictions interprétables et multistap.", "metrics": {"bleu_score": 6.68986069184485, "chrf_score": 37.18051529479436, "xcomet_score": 0.39849063754081726, "xcomet_qe_score": 0.5074391961097717, "metricx_score": 10.611865043640137, "metricx_qe_score": 9.516776084899902, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons que le problème de mathématiques est une application simple pour évaluer de telles capacités de raisonnement.", "metrics": {"bleu_score": 42.3878416043135, "chrf_score": 71.97219068934696, "xcomet_score": 0.8084723949432373, "xcomet_qe_score": 0.8971787691116333, "metricx_score": 5.050540924072266, "metricx_qe_score": 4.9154815673828125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans notre configuration de problème, étant donné les questions, nous devons résoudre ces questions et obtenir les réponses numériques.", "metrics": {"bleu_score": 56.53615736486091, "chrf_score": 79.36971269924612, "xcomet_score": 0.9567040205001831, "xcomet_qe_score": 0.9315601587295532, "metricx_score": 1.4727730751037598, "metricx_qe_score": 1.8868499994277954, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans nos ensembles de données, nous avons également les expressions mathématiques qui mènent à cette réponse particulière.", "metrics": {"bleu_score": 29.17020530085422, "chrf_score": 69.71640808531882, "xcomet_score": 0.9861466884613037, "xcomet_qe_score": 0.9835292100906372, "metricx_score": 2.81820011138916, "metricx_qe_score": 3.665184736251831, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, certaines hypothèses s'appliquent également, comme dans le travail précédent.", "metrics": {"bleu_score": 44.08231875586728, "chrf_score": 75.65656091353962, "xcomet_score": 0.9973632097244263, "xcomet_qe_score": 1.0, "metricx_score": 1.7546559572219849, "metricx_qe_score": 2.420076847076416, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que la précision des quantités est connue,", "metrics": {"bleu_score": 88.01117367933934, "chrf_score": 97.84655470454004, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.2672227621078491, "metricx_qe_score": 1.2956738471984863, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "et nous considérons seulement des opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentielle.", "metrics": {"bleu_score": 75.36856024777303, "chrf_score": 89.87898296308742, "xcomet_score": 0.9276741743087769, "xcomet_qe_score": 0.8532313108444214, "metricx_score": 0.8933855891227722, "metricx_qe_score": 1.0854313373565674, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les opérateurs complexes peuvent être décomposés en ces opérateurs de base.", "metrics": {"bleu_score": 54.52353574508255, "chrf_score": 71.27259756912969, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6503652334213257, "metricx_qe_score": 0.5866933465003967, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, le travail précédent en résolution de problèmes de mathématiques peut être classé en modèles séquence à séquence et séquence à arbre.", "metrics": {"bleu_score": 40.06495574896902, "chrf_score": 69.76151851662314, "xcomet_score": 0.7253940105438232, "xcomet_qe_score": 0.7491565942764282, "metricx_score": 4.882413387298584, "metricx_qe_score": 4.980818748474121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, les modèles traditionnels séquence à séquence convertissent l'expression en une séquence spécifique pour la génération.", "metrics": {"bleu_score": 52.92031904718659, "chrf_score": 83.6047769850137, "xcomet_score": 0.8504502773284912, "xcomet_qe_score": 0.7578902244567871, "metricx_score": 2.2258036136627197, "metricx_qe_score": 2.468925952911377, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est assez facile à implémenter. Et il peut généraliser à de nombreux problèmes complexes.", "metrics": {"bleu_score": 19.601663253740664, "chrf_score": 54.407423849807735, "xcomet_score": 0.7784817218780518, "xcomet_qe_score": 0.8065643310546875, "metricx_score": 5.369080543518066, "metricx_qe_score": 4.7753400802612305, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les inconvénients sont que les performances ne sont généralement pas meilleures que les modèles structurels. Et il manque d'interprétabilité pour la prédiction.", "metrics": {"bleu_score": 19.422069098763885, "chrf_score": 73.16155168845297, "xcomet_score": 0.9039380550384521, "xcomet_qe_score": 0.9493113160133362, "metricx_score": 2.3077850341796875, "metricx_qe_score": 1.2716484069824219, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en fait, cette direction est encore très populaire en raison des modèles de transformateurs.", "metrics": {"bleu_score": 54.15789031416762, "chrf_score": 68.56489224876356, "xcomet_score": 0.7894517183303833, "xcomet_qe_score": 0.7971757650375366, "metricx_score": 4.981964111328125, "metricx_qe_score": 3.4542808532714844, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans les modèles basés sur les arbres, nous structurons ces expressions en forme d'arbre et suivons une génération d'arbre pré-ordonnée.", "metrics": {"bleu_score": 32.945674428970754, "chrf_score": 65.34220335861957, "xcomet_score": 0.9380334615707397, "xcomet_qe_score": 0.9578434228897095, "metricx_score": 3.64762020111084, "metricx_qe_score": 2.8678972721099854, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, nous générons les opérateurs, et nous atteignons les feuilles, qui sont les quantités.", "metrics": {"bleu_score": 41.709417232262034, "chrf_score": 62.52200563788289, "xcomet_score": 0.8160029649734497, "xcomet_qe_score": 0.7478479146957397, "metricx_score": 5.701746463775635, "metricx_qe_score": 7.277438640594482, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, la bonne chose est que nous générons en fait l'expression entière, plutôt que de générer des opérateurs ou", "metrics": {"bleu_score": 8.826968976856115, "chrf_score": 29.620409879290037, "xcomet_score": 0.20998027920722961, "xcomet_qe_score": 0.21862056851387024, "metricx_score": 23.453105926513672, "metricx_qe_score": 14.160221099853516, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "des quantités individuelles.", "metrics": {"bleu_score": 2.002152301552759, "chrf_score": 11.457745256660742, "xcomet_score": 0.11822935938835144, "xcomet_qe_score": 0.13598157465457916, "metricx_score": 22.310562133789062, "metricx_qe_score": 24.973094940185547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ce", "metrics": {"bleu_score": 0.0, "chrf_score": 2.165009780234449, "xcomet_score": 0.14862923324108124, "xcomet_qe_score": 0.131100594997406, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.31645333766937256, "xcomet_qe_score": 0.14650873839855194, "metricx_score": 16.129854202270508, "metricx_qe_score": 15.134315490722656, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "qui", "metrics": {"bleu_score": 0.0, "chrf_score": 3.0552463229024855, "xcomet_score": 0.1328319013118744, "xcomet_qe_score": 0.13200806081295013, "metricx_score": 24.484161376953125, "metricx_qe_score": 23.167064666748047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.4885859787464142, "xcomet_qe_score": 0.23158060014247894, "metricx_score": 8.075092315673828, "metricx_qe_score": 5.832947731018066, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5037374496459961, "xcomet_qe_score": 0.35680055618286133, "metricx_score": 10.351645469665527, "metricx_qe_score": 13.931723594665527, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.25583842396736145, "xcomet_qe_score": 0.15113277733325958, "metricx_score": 9.856759071350098, "metricx_qe_score": 9.73199462890625, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5179845690727234, "xcomet_qe_score": 0.24087300896644592, "metricx_score": 8.803046226501465, "metricx_qe_score": 13.710304260253906, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5168715715408325, "xcomet_qe_score": 0.23647698760032654, "metricx_score": 8.727363586425781, "metricx_qe_score": 7.755617618560791, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "rend le processus plus précis.", "metrics": {"bleu_score": 84.64817248906144, "chrf_score": 87.96704715576904, "xcomet_score": 0.6229040622711182, "xcomet_qe_score": 0.23100364208221436, "metricx_score": 4.039564609527588, "metricx_qe_score": 3.6190404891967773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans notre système de déduction, nous commençons avec un groupe de quantités présentées dans les questions, et aussi, incluant certains constantes comme nos états initiaux.", "metrics": {"bleu_score": 28.58234714815033, "chrf_score": 63.70936039123626, "xcomet_score": 0.881887674331665, "xcomet_qe_score": 0.887697696685791, "metricx_score": 5.775565147399902, "metricx_qe_score": 6.319488525390625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, l'expression est représentée par Eijop,", "metrics": {"bleu_score": 31.356006812336346, "chrf_score": 76.34411058742027, "xcomet_score": 0.9356495141983032, "xcomet_qe_score": 0.9122203588485718, "metricx_score": 1.4857629537582397, "metricx_qe_score": 2.6570563316345215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "où nous effectuons l'opérateur de QI à QJ. Et cette expression est en fait dirigée.", "metrics": {"bleu_score": 40.08565305996452, "chrf_score": 82.39394389589252, "xcomet_score": 0.8711235523223877, "xcomet_qe_score": 0.8680152893066406, "metricx_score": 4.89646053314209, "metricx_qe_score": 7.5496063232421875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, nous avons aussi une soustraction inverse ici pour représenter l", "metrics": {"bleu_score": 17.860139602946813, "chrf_score": 48.7833548455189, "xcomet_score": 0.548432469367981, "xcomet_qe_score": 0.5669578909873962, "metricx_score": 9.189420700073242, "metricx_qe_score": 4.889006614685059, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "'opération opposée.", "metrics": {"bleu_score": 0.0, "chrf_score": 9.525098766321557, "xcomet_score": 0.1305924952030182, "xcomet_qe_score": 0.15683509409427643, "metricx_score": 18.932710647583008, "metricx_qe_score": 15.743422508239746, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans un système de déduction formel, à un temps t, nous appliquons l'opérateur entre les paires QI et QJ. Et puis nous obtenons cette nouvelle expression.", "metrics": {"bleu_score": 27.99197972499588, "chrf_score": 65.45844563879764, "xcomet_score": 0.9494584798812866, "xcomet_qe_score": 0.9821940660476685, "metricx_score": 2.4300477504730225, "metricx_qe_score": 2.350184440612793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "Nous l'ajoutons aux états suivants pour devenir un nouveau quantitatif.", "metrics": {"bleu_score": 11.208466750961147, "chrf_score": 62.566220142639374, "xcomet_score": 0.833670973777771, "xcomet_qe_score": 0.8129053115844727, "metricx_score": 4.992040634155273, "metricx_qe_score": 4.6950907707214355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ces diapositives visualisent l'évolution de ces états, où nous ajoutons des expressions aux états actuels.", "metrics": {"bleu_score": 15.874376125672237, "chrf_score": 54.840682823897026, "xcomet_score": 0.9636185169219971, "xcomet_qe_score": 0.9734723567962646, "metricx_score": 4.139451503753662, "metricx_qe_score": 4.4293365478515625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans nos implémentations, nous utilisons d'abord un modèle de langage pré-entraîné, qui peut être birds ou roberta. Et puis nous codons une phrase, et puis nous obtenons ces représentations de quantités.", "metrics": {"bleu_score": 33.90119427935996, "chrf_score": 68.21183409418761, "xcomet_score": 0.603752851486206, "xcomet_qe_score": 0.6691474914550781, "metricx_score": 7.386668682098389, "metricx_qe_score": 6.829282283782959, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, une fois que nous obtenons les représentations de quantités, nous pouvons commencer à faire des inférences. Donc,", "metrics": {"bleu_score": 63.50869045864349, "chrf_score": 89.79206700736829, "xcomet_score": 0.8020021915435791, "xcomet_qe_score": 0.8131996393203735, "metricx_score": 5.960984230041504, "metricx_qe_score": 6.015807628631592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "nous montrons un exemple de Q1 pour obtenir la représentation de Q1 divisé par Q2 et multiplié par Q3.", "metrics": {"bleu_score": 13.009989244255205, "chrf_score": 62.332593604248366, "xcomet_score": 0.927282452583313, "xcomet_qe_score": 0.9089063405990601, "metricx_score": 7.591344833374023, "metricx_qe_score": 7.0537495613098145, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "D'abord, nous obtenons la paire de représentations, qui est simplement la concaténation entre Q1 et Q2. Et puis nous appliquons un réseau de feedback, qui est paramétrisé par l'opérateur.", "metrics": {"bleu_score": 23.31032103432022, "chrf_score": 58.98196166452141, "xcomet_score": 0.7217430472373962, "xcomet_qe_score": 0.7742040157318115, "metricx_score": 7.442095756530762, "metricx_qe_score": 6.382068634033203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et puis nous obtenons la représentation de l'expression, Q1 divisé par Q2.", "metrics": {"bleu_score": 29.873929042581253, "chrf_score": 72.78317617422371, "xcomet_score": 0.9761612415313721, "xcomet_qe_score": 0.9932553768157959, "metricx_score": 3.07232666015625, "metricx_qe_score": 3.6103882789611816, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en pratique, dans la phase d'inférence, nous pourrions être en mesure d'obtenir une expression incorrecte aussi.", "metrics": {"bleu_score": 18.204978472688992, "chrf_score": 67.56880247580483, "xcomet_score": 0.9840086698532104, "xcomet_qe_score": 0.9757822751998901, "metricx_score": 3.7493348121643066, "metricx_qe_score": 4.3263468742370605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, tous les expressions possibles sont égales à trois fois le nombre d'opérateurs.", "metrics": {"bleu_score": 39.56716729452429, "chrf_score": 73.19201002369793, "xcomet_score": 0.9887847304344177, "xcomet_qe_score": 0.9816473126411438, "metricx_score": 2.695141315460205, "metricx_qe_score": 3.9360828399658203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, la bonne chose ici est que nous pouvons facilement ajouter des contraintes pour contrôler ce espace de recherche", "metrics": {"bleu_score": 43.63348254246557, "chrf_score": 76.31557048125181, "xcomet_score": 0.8699607849121094, "xcomet_qe_score": 0.8618022203445435, "metricx_score": 1.780623435974121, "metricx_qe_score": 2.4077162742614746, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": ".", "metrics": {"bleu_score": 0.0, "chrf_score": 1.0570824524312894, "xcomet_score": 0.3309841752052307, "xcomet_qe_score": 0.14184018969535828, "metricx_score": 17.585172653198242, "metricx_qe_score": 19.948368072509766, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est qu'il y a une quantité supplémentaire. Donc,", "metrics": {"bleu_score": 68.12455364200612, "chrf_score": 81.51448874624492, "xcomet_score": 0.8308717012405396, "xcomet_qe_score": 0.7934406399726868, "metricx_score": 6.193626403808594, "metricx_qe_score": 6.396876335144043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "cette quantité vient de l'expression calculée précédemment.", "metrics": {"bleu_score": 20.612390921238426, "chrf_score": 62.62349967305978, "xcomet_score": 0.9890203475952148, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7470162510871887, "metricx_qe_score": 1.0106453895568848, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, enfin, nous pouvons obtenir cette expression finale, Q3 multiplié par Q4.", "metrics": {"bleu_score": 37.2513379914096, "chrf_score": 70.59436976708704, "xcomet_score": 0.9916538000106812, "xcomet_qe_score": 0.9948521852493286, "metricx_score": 1.8122525215148926, "metricx_qe_score": 1.6423083543777466, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pouvons également voir le nombre d'expressions possibles différentes de la précédente.", "metrics": {"bleu_score": 23.38911621379157, "chrf_score": 61.91174872358277, "xcomet_score": 0.8309046030044556, "xcomet_qe_score": 0.9434628486633301, "metricx_score": 5.1514410972595215, "metricx_qe_score": 5.557718276977539, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, de cette différence, il est difficile d'appliquer une stratégie de recherche de bande. Donc, le processus d'entraînement est simila", "metrics": {"bleu_score": 2.6459536968224975, "chrf_score": 32.65798157650585, "xcomet_score": 0.21744988858699799, "xcomet_qe_score": 0.22616036236286163, "metricx_score": 15.890976905822754, "metricx_qe_score": 18.081127166748047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "ire à l'entraînement d'un modèle séquence à séquence, où nous optimisons la perte à chaque étape.", "metrics": {"bleu_score": 35.26463405484997, "chrf_score": 53.425693729021916, "xcomet_score": 0.2628806233406067, "xcomet_qe_score": 0.386816143989563, "metricx_score": 13.347996711730957, "metricx_qe_score": 14.138761520385742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons cette tau pour représenter quand nous terminons ce processus de génération.", "metrics": {"bleu_score": 35.96201863014832, "chrf_score": 61.693295389838475, "xcomet_score": 0.8808608055114746, "xcomet_qe_score": 0.9074781537055969, "metricx_score": 3.851003646850586, "metricx_qe_score": 4.863706588745117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent du modèle séquence à séquence, parce que l'espace est différent à chaque étape, tandis que dans les modèles traditionnels séquence à séquence, c'est le nombre de vocabulaire.", "metrics": {"bleu_score": 45.5174872968905, "chrf_score": 77.6818700242895, "xcomet_score": 0.4267832040786743, "xcomet_qe_score": 0.41722822189331055, "metricx_score": 7.81475830078125, "metricx_qe_score": 8.217390060424805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela permet également d'imposer certaines contraintes de connaissances précédentes. Donc,", "metrics": {"bleu_score": 35.24025452531097, "chrf_score": 71.19927996174624, "xcomet_score": 0.9049375057220459, "xcomet_qe_score": 0.9003112316131592, "metricx_score": 7.448853969573975, "metricx_qe_score": 6.9282379150390625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "nous conduisons des expériences sur les ensembles de données de mathématiques couramment utilisés, MATH, WPS, MATH23K, MATHQA et SWAMP.", "metrics": {"bleu_score": 14.476355589511376, "chrf_score": 57.303057164434165, "xcomet_score": 0.46942198276519775, "xcomet_qe_score": 0.6147977113723755, "metricx_score": 6.145539283752441, "metricx_qe_score": 5.409960746765137, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons brièvement les résultats par rapport aux approches précédentes.", "metrics": {"bleu_score": 55.68544122775911, "chrf_score": 62.87664279696828, "xcomet_score": 0.9381738901138306, "xcomet_qe_score": 0.9691835641860962, "metricx_score": 2.176848888397217, "metricx_qe_score": 3.292755365371704, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, notre meilleur modèle de performance est le Roberta Deductive Reasoner.", "metrics": {"bleu_score": 13.065113298388567, "chrf_score": 55.574659769844295, "xcomet_score": 0.8541848063468933, "xcomet_qe_score": 0.8545137643814087, "metricx_score": 5.638093948364258, "metricx_qe_score": 5.078045845031738, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "Et en fait, nous n'utilisons pas de recherche de bande en contraste.", "metrics": {"bleu_score": 11.553042398410115, "chrf_score": 29.299420855743776, "xcomet_score": 0.35278207063674927, "xcomet_qe_score": 0.3971415162086487, "metricx_score": 6.44735860824585, "metricx_qe_score": 11.278205871582031, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, les meilleures approches sont souvent des modèles basés sur les arbres.", "metrics": {"bleu_score": 31.521648650847876, "chrf_score": 60.65777989203275, "xcomet_score": 0.9708890914916992, "xcomet_qe_score": 0.9854799509048462, "metricx_score": 1.9608458280563354, "metricx_qe_score": 1.7143967151641846, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, notre raison est capable de surpasser de manière significative ces modèles basés sur les arbres.", "metrics": {"bleu_score": 11.750296943620288, "chrf_score": 51.524549946644925, "xcomet_score": 0.6885743141174316, "xcomet_qe_score": 0.6762338876724243, "metricx_score": 7.186404228210449, "metricx_qe_score": 6.445669651031494, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons voir que le nombre absolu sur MATHQA ou SWAMP n'est pas vraiment élevé.", "metrics": {"bleu_score": 25.38262477544204, "chrf_score": 66.33844683478345, "xcomet_score": 0.8128652572631836, "xcomet_qe_score": 0.8195281028747559, "metricx_score": 3.3855676651000977, "metricx_qe_score": 2.9792842864990234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, nous investiguons davantage les résultats sur SWAMP.", "metrics": {"bleu_score": 15.187207110382285, "chrf_score": 43.065773344356494, "xcomet_score": 0.9661312103271484, "xcomet_qe_score": 0.957288384437561, "metricx_score": 1.028417944908142, "metricx_qe_score": 2.013352394104004, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "Et ce jeu de données est difficile parce que l'auteur essaie de confondre le modèle NLP en ajoutant des informations et des quantités supplémentaires.", "metrics": {"bleu_score": 17.309726565301855, "chrf_score": 47.39403152592308, "xcomet_score": 0.7412502765655518, "xcomet_qe_score": 0.7418185472488403, "metricx_score": 3.309560537338257, "metricx_qe_score": 3.4390273094177246, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans nos prédictions, nous trouvons certains des valeurs intermédiaires négatives.", "metrics": {"bleu_score": 19.787914654203938, "chrf_score": 62.62630958459062, "xcomet_score": 0.9237992763519287, "xcomet_qe_score": 0.937321126461029, "metricx_score": 5.239261627197266, "metricx_qe_score": 4.541055679321289, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans ces questions, nous demandons combien d'appels a Jake,", "metrics": {"bleu_score": 39.28923897444128, "chrf_score": 64.28526239653326, "xcomet_score": 0.46560636162757874, "xcomet_qe_score": 0.4809247553348541, "metricx_score": 16.886987686157227, "metricx_qe_score": 13.497209548950195, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous avons des informations supplémentaires, comme 17, moins quelques poires, et Steven a 8 poires, ce qui est totalement inintégré.", "metrics": {"bleu_score": 27.27080913820611, "chrf_score": 58.73699708924829, "xcomet_score": 0.24477872252464294, "xcomet_qe_score": 0.2585597038269043, "metricx_score": 20.03274154663086, "metricx_qe_score": 20.034936904907227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, notre modèle fait des prédictions comme ces, qui est en fait produire des valeurs négatives.", "metrics": {"bleu_score": 19.51797195341104, "chrf_score": 54.74129160158332, "xcomet_score": 0.7144689559936523, "xcomet_qe_score": 0.7303519248962402, "metricx_score": 8.66144847869873, "metricx_qe_score": 9.294716835021973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous observons ces deux expressions ont en fait des scores similaires. Donc,", "metrics": {"bleu_score": 44.80304273880272, "chrf_score": 67.02357453796944, "xcomet_score": 0.6129870414733887, "xcomet_qe_score": 0.6225697994232178, "metricx_score": 6.409364223480225, "metricx_qe_score": 5.621519565582275, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "nous pouvons en fait limiter cet espace de recherche en supprimant ces résultats négatifs, de sorte que nous pouvons obtenir la réponse correcte. Donc,", "metrics": {"bleu_score": 34.77547633382432, "chrf_score": 71.98415018388373, "xcomet_score": 0.7848876714706421, "xcomet_qe_score": 0.7549865245819092, "metricx_score": 5.898329734802246, "metricx_qe_score": 6.270659446716309, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "nous trouvons que ces contraintes améliorent considérablement pour certains modèles.", "metrics": {"bleu_score": 19.767437766271104, "chrf_score": 58.43949349848931, "xcomet_score": 0.9698507785797119, "xcomet_qe_score": 0.9404426217079163, "metricx_score": 3.691227436065674, "metricx_qe_score": 5.45850133895874, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, pour les modèles de birds, nous améliorons 7 points. Et ensuite, pour le modèle Roberta, nous améliorons 2 points.", "metrics": {"bleu_score": 13.567362988748167, "chrf_score": 40.503739150279635, "xcomet_score": 0.493167906999588, "xcomet_qe_score": 0.6173069477081299, "metricx_score": 10.214213371276855, "metricx_qe_score": 10.305197715759277, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, les modèles de langage plus bons ont une meilleure capacité de compréhension du langage. Donc, le nombre ici est plus élevé pour Roberta et plus bas pour birds.", "metrics": {"bleu_score": 30.82966598071329, "chrf_score": 48.03494883413653, "xcomet_score": 0.7062473893165588, "xcomet_qe_score": 0.8363845944404602, "metricx_score": 13.458517074584961, "metricx_qe_score": 10.325373649597168, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous essayons également d'analyser la difficulté derrière tous ces ensembles de données. Donc,", "metrics": {"bleu_score": 49.582717346593746, "chrf_score": 87.10806249010585, "xcomet_score": 0.6783678531646729, "xcomet_qe_score": 0.627642035484314, "metricx_score": 6.061929702758789, "metricx_qe_score": 7.858373641967773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "nous supposons que le nombre de quantités inutilisées peut être considéré comme une information inintégré.", "metrics": {"bleu_score": 60.58398690011477, "chrf_score": 81.76087243942601, "xcomet_score": 0.7616771459579468, "xcomet_qe_score": 0.7005221247673035, "metricx_score": 10.285050392150879, "metricx_qe_score": 11.988901138305664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, nous avons le pourcentage de ces échantillons avec des quantités inutilisées. Et le SWAMP a la plus grande proportion.", "metrics": {"bleu_score": 26.031926346229746, "chrf_score": 64.07522634084367, "xcomet_score": 0.8367578983306885, "xcomet_qe_score": 0.8071960806846619, "metricx_score": 5.046263694763184, "metricx_qe_score": 6.077125549316406, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons également la performance globale. Donc,", "metrics": {"bleu_score": 80.70557274927978, "chrf_score": 97.84678570430657, "xcomet_score": 0.5955917835235596, "xcomet_qe_score": 0.6057796478271484, "metricx_score": 4.910081386566162, "metricx_qe_score": 4.937910079956055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "pour ceux des échantillons sans quantités inutilisées, la performance est en fait plus élevée que la performance globale.", "metrics": {"bleu_score": 52.75855485130294, "chrf_score": 78.25497718445023, "xcomet_score": 0.678135871887207, "xcomet_qe_score": 0.48494210839271545, "metricx_score": 6.367778301239014, "metricx_qe_score": 8.275297164916992, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais avec ceux des échantillons avec des quantités inutilisées, c'est en fait beaucoup pire que la performance globale. Donc,", "metrics": {"bleu_score": 35.562549056277234, "chrf_score": 74.47460037435776, "xcomet_score": 0.783031702041626, "xcomet_qe_score": 0.7768834233283997, "metricx_score": 8.956896781921387, "metricx_qe_score": 8.962119102478027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "pour MAWPS, nous n'avons pas vraiment trop de cas de disette, donc je peux ignorer cette partie.", "metrics": {"bleu_score": 53.74512308135862, "chrf_score": 68.63896527180894, "xcomet_score": 0.671646773815155, "xcomet_qe_score": 0.6285494565963745, "metricx_score": 8.497970581054688, "metricx_qe_score": 9.37629222869873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, en fin de compte, nous voulons montrer l'interprétabilité à travers un exemple de question et de prédiction.", "metrics": {"bleu_score": 31.642571776698524, "chrf_score": 68.45280836661223, "xcomet_score": 0.5831094980239868, "xcomet_qe_score": 0.7255201935768127, "metricx_score": 4.465012073516846, "metricx_qe_score": 6.49722957611084, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, notre modèle fait en fait une prédiction incorrecte à la première étape.", "metrics": {"bleu_score": 33.332626955359885, "chrf_score": 51.893997463855726, "xcomet_score": 1.0, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.1545710563659668, "metricx_qe_score": 1.3514705896377563, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, nous pouvons corréler cette expression avec la phrase ici. Donc,", "metrics": {"bleu_score": 53.42227899599143, "chrf_score": 64.57340990988965, "xcomet_score": 0.7487455606460571, "xcomet_qe_score": 0.8757206797599792, "metricx_score": 5.381664276123047, "metricx_qe_score": 5.718323707580566, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "nous pensons que cette phrase pourrait être trompeuse pour le modèle et conduire à des prédictions incorrectes.", "metrics": {"bleu_score": 19.209534151258666, "chrf_score": 65.06817614608782, "xcomet_score": 0.9878135919570923, "xcomet_qe_score": 0.9754633903503418, "metricx_score": 1.0446068048477173, "metricx_qe_score": 0.730716347694397, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Donc,", "metrics": {"bleu_score": 0.0, "chrf_score": 3.0547904607450693, "xcomet_score": 0.14052820205688477, "xcomet_qe_score": 0.12695781886577606, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "nous essayons de reformuler la phrase pour être quelque chose comme, le nombre d'arbres de paires est 35 de moins que les arbres d'arbres. Donc,", "metrics": {"bleu_score": 10.724968136892782, "chrf_score": 43.59601577619407, "xcomet_score": 0.17892122268676758, "xcomet_qe_score": 0.1852494180202484, "metricx_score": 19.202836990356445, "metricx_qe_score": 18.57561492919922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "nous faisons en sorte que la phrase transmet des significations plus précises, de sorte que le modèle est capable de faire la prédiction correcte.", "metrics": {"bleu_score": 12.142567939068623, "chrf_score": 59.99134921150798, "xcomet_score": 0.7755256295204163, "xcomet_qe_score": 0.9038412570953369, "metricx_score": 4.065814018249512, "metricx_qe_score": 3.245898723602295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, cette étude montre comment les prédictions interprétables nous aident à comprendre le comportement du modèle.", "metrics": {"bleu_score": 77.7811122305422, "chrf_score": 89.81919572056965, "xcomet_score": 0.997299313545227, "xcomet_qe_score": 1.0, "metricx_score": 1.0263452529907227, "metricx_qe_score": 0.7807973623275757, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, pour conclure notre travail, d'abord, notre modèle est en fait assez efficace,", "metrics": {"bleu_score": 58.87721637284629, "chrf_score": 80.98713491864183, "xcomet_score": 0.9395658373832703, "xcomet_qe_score": 0.9423151016235352, "metricx_score": 2.198051691055298, "metricx_qe_score": 1.5519875288009644, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "et nous sommes en mesure de fournir des solutions interprétables.", "metrics": {"bleu_score": 40.009985513101846, "chrf_score": 67.72787552405639, "xcomet_score": 0.9774610996246338, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.5640242099761963, "metricx_qe_score": 2.0082314014434814, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pouvons facilement incorporer certaines connaissances comme contraintes, ce qui peut aider à améliorer les performances.", "metrics": {"bleu_score": 26.61333274890312, "chrf_score": 70.22206029649752, "xcomet_score": 0.9711090326309204, "xcomet_qe_score": 0.9862632751464844, "metricx_score": 1.1938625574111938, "metricx_qe_score": 1.307368278503418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et la dernière chose est que le mécanisme ne s'applique pas seulement aux tâches de résolution de problèmes de mathématiques, mais aussi à d'autres tâches impliquant un raisonnement multistap. Mais", "metrics": {"bleu_score": 46.916376464350485, "chrf_score": 71.33491967603936, "xcomet_score": 0.5111502408981323, "xcomet_qe_score": 0.4676752984523773, "metricx_score": 8.590909004211426, "metricx_qe_score": 6.544096946716309, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "nous avons aussi certaines limitations.", "metrics": {"bleu_score": 10.682175159905853, "chrf_score": 54.76905131554087, "xcomet_score": 0.9895421266555786, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3504874110221863, "metricx_qe_score": 0.262734591960907, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0386240482330322, "metricx_qe_score": 1.0148998498916626, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est que, comme mentionné, la probabilité de distribution est inégale à chaque étape. Donc, il est également difficile d'appliquer une stratégie de recherche de bande.", "metrics": {"bleu_score": 33.717839884228574, "chrf_score": 57.028173315300975, "xcomet_score": 0.752514660358429, "xcomet_qe_score": 0.7853388786315918, "metricx_score": 6.440925121307373, "metricx_qe_score": 6.627893924713135, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, c'est la fin de la présentation. Et les questions sont les bienvenues. Merci.", "metrics": {"bleu_score": 45.05700411689425, "chrf_score": 57.81759787516707, "xcomet_score": 0.9911282658576965, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.305374026298523, "metricx_qe_score": 0.8749066591262817, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je suis de l'Université de Maastricht.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.34782254695892334, "metricx_qe_score": 0.36702096462249756, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter mon travail conjoint avec Gerry, qui porte sur un nouveau ensemble de données pour la récupération d'articles juridiques.", "metrics": {"bleu_score": 18.465221092138684, "chrf_score": 56.03262636059455, "xcomet_score": 0.7532304525375366, "xcomet_qe_score": 0.6855165958404541, "metricx_score": 3.1014089584350586, "metricx_qe_score": 3.144299268722534, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions juridiques sont un élément intégral de la vie de beaucoup de gens,", "metrics": {"bleu_score": 23.793665482062607, "chrf_score": 51.33406361099668, "xcomet_score": 0.9815149903297424, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.2509803771972656, "metricx_qe_score": 0.9450914859771729, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "mais la majorité des citoyens n'ont pas de connaissance de leurs droits et des procédures juridiques.", "metrics": {"bleu_score": 21.34415818339933, "chrf_score": 62.06738630294606, "xcomet_score": 0.7700859904289246, "xcomet_qe_score": 0.9477211236953735, "metricx_score": 3.8145864009857178, "metricx_qe_score": 2.6405210494995117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent pas se permettre l'assistance d'un avocat sont laissés sans protection ou, pire, exploités.", "metrics": {"bleu_score": 45.78279464993954, "chrf_score": 64.9643797567472, "xcomet_score": 0.9978137016296387, "xcomet_qe_score": 1.0, "metricx_score": 1.324082374572754, "metricx_qe_score": 1.5499095916748047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les gens et la loi en développant un système de récupération efficace pour les articles juridiques.", "metrics": {"bleu_score": 50.62835959915033, "chrf_score": 67.78646953761584, "xcomet_score": 0.776246190071106, "xcomet_qe_score": 0.7910192012786865, "metricx_score": 4.1308369636535645, "metricx_qe_score": 3.7890446186065674, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "Un tel système pourrait fournir un service juridique gratuit et professionnel pour les humains peu qualifiés.", "metrics": {"bleu_score": 38.98938932918354, "chrf_score": 68.29778969316193, "xcomet_score": 0.9553588628768921, "xcomet_qe_score": 0.9702937602996826, "metricx_score": 1.4152480363845825, "metricx_qe_score": 1.0724142789840698, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de plonger dans la contribution principale de ce travail, décrivons d'abord le problème de la récupération d'articles juridiques.", "metrics": {"bleu_score": 30.91327937802876, "chrf_score": 63.64183123477288, "xcomet_score": 0.8228570222854614, "xcomet_qe_score": 0.7521935701370239, "metricx_score": 4.603663444519043, "metricx_qe_score": 3.5558910369873047, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "En fonction d'une simple question sur un sujet juridique, comme : \"Quelles sont les conséquences si je viole la confidentialité professionnelle ?\"", "metrics": {"bleu_score": 34.07909355129019, "chrf_score": 62.15784456796979, "xcomet_score": 0.8477247953414917, "xcomet_qe_score": 0.9563151597976685, "metricx_score": 2.4343631267547607, "metricx_qe_score": 2.8953120708465576, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est requis pour récupérer tous les articles juridiques pertinents d'un large corpus de législation.", "metrics": {"bleu_score": 18.002829271425153, "chrf_score": 55.213289022040556, "xcomet_score": 0.9906104803085327, "xcomet_qe_score": 1.0, "metricx_score": 1.3800705671310425, "metricx_qe_score": 1.8059356212615967, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche d'extraction d'informations comporte ses propres défis.", "metrics": {"bleu_score": 16.735949370018847, "chrf_score": 71.23755647779986, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6165517568588257, "metricx_qe_score": 1.2201344966888428, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "D'abord, il s'agit de deux types de langage", "metrics": {"bleu_score": 25.271148634948997, "chrf_score": 52.18874581247667, "xcomet_score": 0.7653416395187378, "xcomet_qe_score": 0.933899998664856, "metricx_score": 4.272486686706543, "metricx_qe_score": 2.9800667762756348, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": ": le langage naturel commun pour les questions et le langage juridique complexe pour les articles.", "metrics": {"bleu_score": 29.48993986902436, "chrf_score": 68.46418300667261, "xcomet_score": 0.6503807306289673, "xcomet_qe_score": 0.5308960676193237, "metricx_score": 5.936506748199463, "metricx_qe_score": 6.816078186035156, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence de distribution de langage rend plus difficile pour un système de récupérer des candidats, car il nécessite un système d'interprétation inhérent qui peut traduire une question naturelle en une question juridique qui correspond à la terminologie des articles.", "metrics": {"bleu_score": 50.92495025595958, "chrf_score": 74.8921688500485, "xcomet_score": 0.5749847888946533, "xcomet_qe_score": 0.4629939794540405, "metricx_score": 9.141284942626953, "metricx_qe_score": 9.086650848388672, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le droit n'est pas une série d'articles indépendants qui peuvent être traités comme une source d'information complète, comme les nouvelles ou les recettes, mais plutôt une", "metrics": {"bleu_score": 34.56583319732667, "chrf_score": 64.7084426160803, "xcomet_score": 0.6883095502853394, "xcomet_qe_score": 0.7960225343704224, "metricx_score": 7.600189208984375, "metricx_qe_score": 3.729282855987549, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "collection structurée de dispositions juridiques qui ont un sens complet seulement lorsqu'elles sont considérées dans leur contexte global, c'est-à-dire avec les informations complémentaires de leurs articles voisins, des champs et des sous-catégories auxquels ils appartiennent, et de leur place dans la structure de la loi.", "metrics": {"bleu_score": 39.34497407924205, "chrf_score": 71.32265460758263, "xcomet_score": 0.6307613253593445, "xcomet_qe_score": 0.5912822484970093, "metricx_score": 4.440698146820068, "metricx_qe_score": 4.1207780838012695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles juridiques sont des paragraphes, qui sont généralement le type de récupération dans la plupart des travaux de récupération.", "metrics": {"bleu_score": 28.033342055977098, "chrf_score": 54.72126158288605, "xcomet_score": 0.2903117537498474, "xcomet_qe_score": 0.27506786584854126, "metricx_score": 15.93942928314209, "metricx_qe_score": 13.88017463684082, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, ils sont de longs documents pouvant atteindre jusqu'à 6 000 mots.", "metrics": {"bleu_score": 13.926006611436186, "chrf_score": 46.69499790176628, "xcomet_score": 0.9532374143600464, "xcomet_qe_score": 0.9558854699134827, "metricx_score": 4.999637603759766, "metricx_qe_score": 5.638021469116211, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les avancées récentes en NLP ont suscité un grand intérêt pour de nombreuses tâches juridiques, telles que la prédiction de jugements juridiques ou la revue automatique des contrats.", "metrics": {"bleu_score": 30.19000247924445, "chrf_score": 55.32538052032545, "xcomet_score": 0.8293232917785645, "xcomet_qe_score": 0.9666393995285034, "metricx_score": 2.176736354827881, "metricx_qe_score": 2.4104971885681152, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la récupération d'articles juridiques a été principalement négligée en raison du manque d'ensembles de données étiquetés de grande taille et de haute qualité.", "metrics": {"bleu_score": 20.87037146733082, "chrf_score": 56.81531974406083, "xcomet_score": 0.6300987005233765, "xcomet_qe_score": 0.7039589881896973, "metricx_score": 3.991400957107544, "metricx_qe_score": 3.3429083824157715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce travail, nous présentons un nouvel ensemble de données, en français, centré sur les citoyens, pour étudier si un modèle de récupération peut approcher l'efficacité et la fiabilité d'un expert juridique pour la tâche de récupération d'articles juridiques. Notre ensemble de données de", "metrics": {"bleu_score": 29.455725945145048, "chrf_score": 64.78571196786946, "xcomet_score": 0.1581445038318634, "xcomet_qe_score": 0.2607187032699585, "metricx_score": 10.319955825805664, "metricx_qe_score": 8.39040470123291, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "récupération d'articles juridiques (PZ) se compose de plus de 1 100 questions posées par des citoyens belges.", "metrics": {"bleu_score": 26.415417801170204, "chrf_score": 53.61048521981817, "xcomet_score": 0.3662702441215515, "xcomet_qe_score": 0.3303346037864685, "metricx_score": 11.803224563598633, "metricx_qe_score": 12.734395980834961, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent un large éventail de sujets, de la famille, de l'habitation, de l'argent, au travail et à la sécurité sociale.", "metrics": {"bleu_score": 50.03557455114012, "chrf_score": 70.44003510251365, "xcomet_score": 0.967288076877594, "xcomet_qe_score": 1.0, "metricx_score": 2.3102633953094482, "metricx_qe_score": 1.0999096632003784, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque question a été étiquetée par des juristes expérimentés avec des références à des articles pertinents de plus de 22 633 articles de codes de loi.", "metrics": {"bleu_score": 46.9224979976816, "chrf_score": 61.50756532848375, "xcomet_score": 0.705862283706665, "xcomet_qe_score": 0.7209820747375488, "metricx_score": 6.997366428375244, "metricx_qe_score": 5.858953475952148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons maintenant comment nous avons collecté cet ensemble de données.", "metrics": {"bleu_score": 17.423472443716534, "chrf_score": 62.88643653551068, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6652271151542664, "metricx_qe_score": 0.5937368273735046, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous avons compilé un corpus de textes juridiques.", "metrics": {"bleu_score": 32.866572599159944, "chrf_score": 59.335451352981735, "xcomet_score": 0.8522629737854004, "xcomet_qe_score": 0.9750090837478638, "metricx_score": 1.5679901838302612, "metricx_qe_score": 1.3806569576263428, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons considéré 32 codes juridiques publics et extrait tous leurs articles ainsi que les titres de section correspondants.", "metrics": {"bleu_score": 46.224858609442805, "chrf_score": 64.3030271852764, "xcomet_score": 0.788501501083374, "xcomet_qe_score": 0.9651553630828857, "metricx_score": 2.7342300415039062, "metricx_qe_score": 3.818455219268799, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous avons rassemblé des questions juridiques avec des références à des articles pertinents.", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 79.39112674962838, "xcomet_score": 0.9847924709320068, "xcomet_qe_score": 0.9914045333862305, "metricx_score": 3.4262728691101074, "metricx_qe_score": 3.7098922729492188, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous avons collaboré avec un cabinet d'avocats belge qui reçoit chaque année environ 4 000 e-mails de citoyens belges qui demandent des conseils sur des questions juridiques personnelles.", "metrics": {"bleu_score": 39.162127614717114, "chrf_score": 70.84965749807549, "xcomet_score": 0.8737505674362183, "xcomet_qe_score": 0.9830029010772705, "metricx_score": 1.198920488357544, "metricx_qe_score": 0.6683032512664795, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'accéder à leurs sites web, où leur équipe d'experts juridiques aborde les questions juridiques les plus courantes en Belgique.", "metrics": {"bleu_score": 57.933111950702816, "chrf_score": 73.56155303368935, "xcomet_score": 0.9989012479782104, "xcomet_qe_score": 1.0, "metricx_score": 1.8391649723052979, "metricx_qe_score": 1.2545732259750366, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons collecté des milliers de questions annotées avec des catégories, des sous-catégories et des références juridiques pertinentes.", "metrics": {"bleu_score": 72.30924742291003, "chrf_score": 85.90173337504578, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9578990936279297, "metricx_qe_score": 1.6989952325820923, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons passé les références juridiques et filtré les questions dont les références ne sont pas des articles dans l'un des codes de loi que nous avons considérés.", "metrics": {"bleu_score": 69.57838925817522, "chrf_score": 83.88555681238228, "xcomet_score": 0.827683687210083, "xcomet_qe_score": 0.8633514046669006, "metricx_score": 3.4828298091888428, "metricx_qe_score": 6.351833820343018, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été associées et converties en identifiants d'articles correspondants de notre corpus.", "metrics": {"bleu_score": 50.353378875558576, "chrf_score": 85.18452794241482, "xcomet_score": 0.980873703956604, "xcomet_qe_score": 1.0, "metricx_score": 1.7352043390274048, "metricx_qe_score": 2.3300812244415283, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement terminé avec 1 108 questions, chacune soigneusement étiquetée avec les identifiants des articles correspondants de notre large corpus de 22 633 articles juridiques.", "metrics": {"bleu_score": 31.707477064407705, "chrf_score": 55.66209485737467, "xcomet_score": 0.6622434854507446, "xcomet_qe_score": 0.6833363771438599, "metricx_score": 2.008432388305664, "metricx_qe_score": 1.5965855121612549, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question comprend une catégorie principale et une concaténation de sous-catégories,", "metrics": {"bleu_score": 31.645000185694006, "chrf_score": 63.044622657463755, "xcomet_score": 0.9360949993133545, "xcomet_qe_score": 0.9630590081214905, "metricx_score": 4.983740329742432, "metricx_qe_score": 5.239212512969971, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "et chaque article comprend une concaténation de leurs sous-titres dans la structure de la loi.", "metrics": {"bleu_score": 37.340019572537415, "chrf_score": 53.84371759713997, "xcomet_score": 0.695279598236084, "xcomet_qe_score": 0.715603232383728, "metricx_score": 7.7700886726379395, "metricx_qe_score": 7.283252239227295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Cette information supplémentaire n'est pas utilisée dans le travail actuel, mais pourrait être d'intérêt pour des recherches futures sur la récupération d'informations juridiques ou la classification juridique.", "metrics": {"bleu_score": 26.227973733387945, "chrf_score": 70.46651605381726, "xcomet_score": 0.9818964004516602, "xcomet_qe_score": 1.0, "metricx_score": 1.9568891525268555, "metricx_qe_score": 1.8340986967086792, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons quelques caractéristiques de nos ensembles de données.", "metrics": {"bleu_score": 17.869400568145597, "chrf_score": 53.634061214757104, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6071538329124451, "metricx_qe_score": 0.6590412855148315, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions sont entre 5 et 44 mots de long, avec une moyenne de 40 mots.", "metrics": {"bleu_score": 19.672746885239153, "chrf_score": 43.908134433954125, "xcomet_score": 0.9452879428863525, "xcomet_qe_score": 0.9719467759132385, "metricx_score": 8.00399398803711, "metricx_qe_score": 6.805660247802734, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur moyenne de 77 mots, avec 142 d'entre eux dépassant 1 000 mots,", "metrics": {"bleu_score": 45.07770836049692, "chrf_score": 61.88832254815885, "xcomet_score": 0.6476567983627319, "xcomet_qe_score": 0.9333581924438477, "metricx_score": 1.0254011154174805, "metricx_qe_score": 0.7660099864006042, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "le plus long étant de 5 790 mots.", "metrics": {"bleu_score": 15.99024219628172, "chrf_score": 28.680835996148353, "xcomet_score": 0.5929186344146729, "xcomet_qe_score": 0.6209163069725037, "metricx_score": 3.7126731872558594, "metricx_qe_score": 3.2355077266693115, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, les questions couvrent un large éventail de sujets, avec environ 85 % d'entre elles étant sur la famille, l'habitation, l'argent ou la justice,", "metrics": {"bleu_score": 31.563472334290076, "chrf_score": 46.596432356866835, "xcomet_score": 0.9047418832778931, "xcomet_qe_score": 0.9512526392936707, "metricx_score": 2.8809292316436768, "metricx_qe_score": 2.095365285873413, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que les 15 % restantes concernent la sécurité sociale, les étrangers ou le travail.", "metrics": {"bleu_score": 61.43605910690176, "chrf_score": 74.42980188867362, "xcomet_score": 0.9563506245613098, "xcomet_qe_score": 0.9602503776550293, "metricx_score": 1.8641420602798462, "metricx_qe_score": 1.6200798749923706, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers, car ils proviennent de 32 différents codes belges qui couvrent un large nombre de sujets juridiques.", "metrics": {"bleu_score": 24.76980256562108, "chrf_score": 68.12543416167745, "xcomet_score": 0.9419686794281006, "xcomet_qe_score": 0.9913451671600342, "metricx_score": 1.141031265258789, "metricx_qe_score": 0.9545113444328308, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles collectés de chaque code.", "metrics": {"bleu_score": 33.69422210259076, "chrf_score": 62.53044452013105, "xcomet_score": 0.6477377414703369, "xcomet_qe_score": 0.9030683040618896, "metricx_score": 3.2317821979522705, "metricx_qe_score": 4.721570014953613, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Outre les 22 633 articles, seulement 1 612 sont référencés comme pertinents à au moins une question dans les ensembles", "metrics": {"bleu_score": 32.31884273221535, "chrf_score": 48.678064201427254, "xcomet_score": 0.4528682231903076, "xcomet_qe_score": 0.49151885509490967, "metricx_score": 8.166797637939453, "metricx_qe_score": 6.165454864501953, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "de données. Environ 80 % de ces articles cités proviennent du code civil, des codes judiciaires, des codes d'enquête criminelle ou des codes pénaux.", "metrics": {"bleu_score": 77.31212403166649, "chrf_score": 82.08291290846573, "xcomet_score": 0.5841498374938965, "xcomet_qe_score": 0.6133907437324524, "metricx_score": 7.524824142456055, "metricx_qe_score": 8.09017562866211, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant ce temps, 18 des 32 codes ont moins de cinq articles mentionnés comme pertinents à au moins une question.", "metrics": {"bleu_score": 64.7084148066781, "chrf_score": 74.9961277870475, "xcomet_score": 0.7199501991271973, "xcomet_qe_score": 0.8038008213043213, "metricx_score": 3.41618013381958, "metricx_qe_score": 2.6123483180999756, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être expliqué par le fait que ces codes se concentrent moins sur les individus et leurs préoccupations.", "metrics": {"bleu_score": 64.87066897882097, "chrf_score": 81.87888529616528, "xcomet_score": 0.9918901920318604, "xcomet_qe_score": 1.0, "metricx_score": 2.9485809803009033, "metricx_qe_score": 3.074148416519165, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "En général, le nombre moyen de citations pour ces articles cités est de 2, et moins de 25 % d'entre eux sont cités plus de cinq fois.", "metrics": {"bleu_score": 68.67874073466739, "chrf_score": 71.26958334042381, "xcomet_score": 0.9853521585464478, "xcomet_qe_score": 0.9984973669052124, "metricx_score": 0.9449299573898315, "metricx_qe_score": 0.7506762742996216, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos ensembles de données, nous avons évalué plusieurs approches de récupération, y compris des architectures lexicales et denses.", "metrics": {"bleu_score": 18.931747781986427, "chrf_score": 66.89450041071241, "xcomet_score": 0.7917467951774597, "xcomet_qe_score": 0.8769586086273193, "metricx_score": 3.714057683944702, "metricx_qe_score": 3.2298519611358643, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "En fonction d'une question et d'un article, un modèle lexical attribue une note au pair de question-article en calculant la somme sur la question des poids de chaque terme dans cet article.", "metrics": {"bleu_score": 30.089097165137417, "chrf_score": 57.79715762429808, "xcomet_score": 0.6508811712265015, "xcomet_qe_score": 0.7156256437301636, "metricx_score": 8.628402709960938, "metricx_qe_score": 6.899426460266113, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec les fonctions de classement standard Tfidf et bm25.", "metrics": {"bleu_score": 56.375603152592916, "chrf_score": 77.77304686567737, "xcomet_score": 0.8694617748260498, "xcomet_qe_score": 0.8582327365875244, "metricx_score": 3.5795719623565674, "metricx_qe_score": 5.273530960083008, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que des articles contenant des mots clés présents dans la question.", "metrics": {"bleu_score": 36.8693323731296, "chrf_score": 76.81013049518795, "xcomet_score": 0.8696900606155396, "xcomet_qe_score": 0.875492513179779, "metricx_score": 3.94960880279541, "metricx_qe_score": 2.8258628845214844, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons avec une architecture basée sur le réseau neuronal qui peut capturer la relation sémantique entre les questions et les articles.", "metrics": {"bleu_score": 30.1860476134146, "chrf_score": 75.94978276677517, "xcomet_score": 0.8926030397415161, "xcomet_qe_score": 0.9592201709747314, "metricx_score": 3.462116241455078, "metricx_qe_score": 1.2488163709640503, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle de bioncordeur qui mappe les questions et les articles dans un espace dense, et calcule une note de pair de question-article en fonction de la similarité de leurs embeddings.", "metrics": {"bleu_score": 12.844103798351675, "chrf_score": 44.78175676463458, "xcomet_score": 0.2303633838891983, "xcomet_qe_score": 0.3672712445259094, "metricx_score": 11.627763748168945, "metricx_qe_score": 9.921780586242676, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces embeddings résultent généralement d'une opération de pooling sur l'output d'un modèle d'embedding de mots.", "metrics": {"bleu_score": 33.08478035107363, "chrf_score": 57.65746741022508, "xcomet_score": 0.6283562779426575, "xcomet_qe_score": 0.7292876243591309, "metricx_score": 8.96333122253418, "metricx_qe_score": 9.272939682006836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des bioncordeurs en configuration de zéro shot, c'est-à-dire que les modèles d'embedding de mots prétrains sont appliqués sans aucune fine-tuning supplémentaire.", "metrics": {"bleu_score": 21.862687073093415, "chrf_score": 56.43490109624507, "xcomet_score": 0.3179791271686554, "xcomet_qe_score": 0.37420016527175903, "metricx_score": 10.280341148376465, "metricx_qe_score": 9.735459327697754, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec un encodeur de texte indépendant du contexte, à savoir word2vec et fasttext, et avec des bioncordeurs basés sur le contexte, à savoir roberta et plus spécifiquement, camembert, qui est un modèle", "metrics": {"bleu_score": 41.36567310102827, "chrf_score": 63.21837360167702, "xcomet_score": 0.17719979584217072, "xcomet_qe_score": 0.38309910893440247, "metricx_score": 9.00895881652832, "metricx_qe_score": 9.39132308959961, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "de bioncordeur en français.", "metrics": {"bleu_score": 1.1524190727977786, "chrf_score": 9.281430935611008, "xcomet_score": 0.11539854109287262, "xcomet_qe_score": 0.12382851541042328, "metricx_score": 23.104694366455078, "metricx_qe_score": 21.78036880493164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous expérimentons avec deux architectures de bioncordeur basées sur", "metrics": {"bleu_score": 16.81150862430929, "chrf_score": 47.71155254058441, "xcomet_score": 0.22213681042194366, "xcomet_qe_score": 0.15136805176734924, "metricx_score": 11.782567024230957, "metricx_qe_score": 6.431509017944336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "le camembert, qui mappent les questions et les articles ensemble dans un espace dense partagé, et deux architectures de bioncordeur séparées, qui codent les questions et les articles dans des espaces d'embedding séparés.", "metrics": {"bleu_score": 8.864218939539864, "chrf_score": 35.133872972067806, "xcomet_score": 0.2632177472114563, "xcomet_qe_score": 0.3067980706691742, "metricx_score": 16.045555114746094, "metricx_qe_score": 14.582855224609375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec le pooling moyen, maximum et classé, ainsi que le produit de point et le cosinus pour calculer les similarités.", "metrics": {"bleu_score": 27.748702735605818, "chrf_score": 63.355210346823185, "xcomet_score": 0.6219980120658875, "xcomet_qe_score": 0.6581171154975891, "metricx_score": 6.745011806488037, "metricx_qe_score": 5.9169602394104, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre ligne de base sur les ensembles de test,", "metrics": {"bleu_score": 40.52587697205425, "chrf_score": 79.58644663208034, "xcomet_score": 0.7077355980873108, "xcomet_qe_score": 0.7001294493675232, "metricx_score": 4.9397382736206055, "metricx_qe_score": 5.275661945343018, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "avec les méthodes lexicales ci-dessus, les bioncordeurs en français évalués en configuration de zéro shot au milieu, et les bioncordeurs finement ajustés en dessous.", "metrics": {"bleu_score": 35.54022947649312, "chrf_score": 64.85429533403577, "xcomet_score": 0.25172752141952515, "xcomet_qe_score": 0.3063349425792694, "metricx_score": 14.362338066101074, "metricx_qe_score": 13.090616226196289, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Globalement, les bioncordeurs finement ajustés surpassent toutes les autres lignes", "metrics": {"bleu_score": 10.420976973984883, "chrf_score": 33.269068208440125, "xcomet_score": 0.46086663007736206, "xcomet_qe_score": 0.727020263671875, "metricx_score": 7.092316627502441, "metricx_qe_score": 6.566393852233887, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "de base, les bioncordeurs deux-tours s'améliorant sur leurs variantes en français.", "metrics": {"bleu_score": 1.4120406935148155, "chrf_score": 29.049155457452958, "xcomet_score": 0.12615950405597687, "xcomet_qe_score": 0.12034841626882553, "metricx_score": 23.7908935546875, "metricx_qe_score": 22.6820125579834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que bm25 sous-performe considérablement les bioncordeurs entraînés, ses performances indiquent qu'il est toujours un point de référence pour la récupération spécifique au domaine.", "metrics": {"bleu_score": 25.17158586534333, "chrf_score": 54.33584411294506, "xcomet_score": 0.5935181379318237, "xcomet_qe_score": 0.6734013557434082, "metricx_score": 5.744406700134277, "metricx_qe_score": 5.655898094177246, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation de zéro shot des bioncordeurs en français, nous constatons que l'utilisation directe des embeddings d'un modèle de bioncordeur prétraité sans optimisation pour la tâche de récupération d'informations donne des résultats médiocres, ce qui est cohérent avec les résultats précédents.", "metrics": {"bleu_score": 40.117428231088816, "chrf_score": 69.78091358347285, "xcomet_score": 0.256135493516922, "xcomet_qe_score": 0.2881564199924469, "metricx_score": 11.065062522888184, "metricx_qe_score": 10.47268295288086, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous observons que le bioncordeur basé sur word2vec surpasse les bioncordeurs basés sur fasttext et camembert, suggérant que les embeddings de niveau de mot prétraités sont peut-être plus appropriés pour la tâche de récupération d'informations. Bien que ces résultats soient", "metrics": {"bleu_score": 13.817232841832709, "chrf_score": 43.22850708180578, "xcomet_score": 0.24989840388298035, "xcomet_qe_score": 0.19567255675792694, "metricx_score": 15.480501174926758, "metricx_qe_score": 15.477030754089355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "prometteurs, ils suggèrent de nombreuses opportunités d'amélioration par rapport à un expert juridique qui peut finalement récupérer tous les articles pertinents pour n'importe quelle question et ainsi obtenir des scores parfaits.", "metrics": {"bleu_score": 37.3051658485178, "chrf_score": 69.03495707926568, "xcomet_score": 0.8510768413543701, "xcomet_qe_score": 0.903555154800415, "metricx_score": 4.875335693359375, "metricx_qe_score": 4.7256598472595215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Concluons en discutant de deux limitations de nos ensembles de données.", "metrics": {"bleu_score": 40.637982820134425, "chrf_score": 82.10162257276062, "xcomet_score": 0.997802734375, "xcomet_qe_score": 1.0, "metricx_score": 1.037343978881836, "metricx_qe_score": 1.554450511932373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, le corpus d'articles est limité aux articles collectés des 32 codes juridiques considérés, qui ne couvrent pas l'ensemble du droit belge, car les articles des décrets, des directives et des ordonnances sont manquants.", "metrics": {"bleu_score": 38.61475539013174, "chrf_score": 75.11165090945131, "xcomet_score": 0.9627796411514282, "xcomet_qe_score": 0.9759697914123535, "metricx_score": 1.628318428993225, "metricx_qe_score": 2.316793203353882, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant la construction de l'ensemble de données, toutes les références à ces articles non collectés sont ignorées, ce qui fait que certaines questions finissent par avoir seulement une fraction de leurs articles initialement pertinents.", "metrics": {"bleu_score": 55.325785690273236, "chrf_score": 73.93251352041918, "xcomet_score": 0.9789948463439941, "xcomet_qe_score": 0.965958297252655, "metricx_score": 3.5040550231933594, "metricx_qe_score": 4.2621259689331055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cela signifie que la réponse contenue dans les articles restants peut être incomplète, bien qu'elle soit toujours complète.", "metrics": {"bleu_score": 40.50806732122789, "chrf_score": 56.80136693882785, "xcomet_score": 0.8604063987731934, "xcomet_qe_score": 0.8985278606414795, "metricx_score": 4.613461017608643, "metricx_qe_score": 3.86944317817688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous devons noter que toutes les questions juridiques ne peuvent pas être répondues avec des articles juridiques seuls.", "metrics": {"bleu_score": 15.732647746232502, "chrf_score": 55.36527635829424, "xcomet_score": 0.9878799915313721, "xcomet_qe_score": 0.9986158609390259, "metricx_score": 5.132433891296387, "metricx_qe_score": 4.224023342132568, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question : \"Peux-je expulser mon locataire s'il fait trop de bruit ?\" ne", "metrics": {"bleu_score": 32.59481888833584, "chrf_score": 69.5259703676406, "xcomet_score": 0.44380930066108704, "xcomet_qe_score": 0.3935840129852295, "metricx_score": 4.233234405517578, "metricx_qe_score": 1.2896318435668945, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "peut pas avoir une réponse détaillée dans le droit qui quantifie un seuil spécifique de bruit à l'aide de l'expulsion.", "metrics": {"bleu_score": 28.810417059823518, "chrf_score": 62.49727368779766, "xcomet_score": 0.5015289187431335, "xcomet_qe_score": 0.4898325204849243, "metricx_score": 11.947339057922363, "metricx_qe_score": 12.391507148742676, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le droit foncier devrait probablement se baser davantage sur le cas-law et trouver des précédents similaires à leur situation actuelle.", "metrics": {"bleu_score": 32.26401831048377, "chrf_score": 67.22250649794054, "xcomet_score": 0.5311028957366943, "xcomet_qe_score": 0.5320103168487549, "metricx_score": 10.762345314025879, "metricx_qe_score": 11.04774284362793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire fait deux parties par semaine jusqu'à 2 a.m.", "metrics": {"bleu_score": 14.518776736981415, "chrf_score": 50.95255718027758, "xcomet_score": 0.7753633856773376, "xcomet_qe_score": 0.8085529804229736, "metricx_score": 6.879688262939453, "metricx_qe_score": 4.482480049133301, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "En effet, certaines questions sont mieux adaptées que d'autres à la tâche de récupération d'articles juridiques. Le domaine des moins appropriés reste à déterminer.", "metrics": {"bleu_score": 48.28087159330548, "chrf_score": 69.47682964157627, "xcomet_score": 0.7943265438079834, "xcomet_qe_score": 0.6218945980072021, "metricx_score": 4.44442892074585, "metricx_qe_score": 5.419702529907227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que notre travail suscite l'intérêt pour développer des modèles de récupération d'articles juridiques pratiques et fiables qui", "metrics": {"bleu_score": 15.226277779914144, "chrf_score": 59.412485656434846, "xcomet_score": 0.46564581990242004, "xcomet_qe_score": 0.30130520462989807, "metricx_score": 8.0791654586792, "metricx_qe_score": 2.506077289581299, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "peuvent améliorer l'accès à la justice pour tous.", "metrics": {"bleu_score": 61.86101569833724, "chrf_score": 75.2115503534564, "xcomet_score": 0.6765183210372925, "xcomet_qe_score": 0.7842096090316772, "metricx_score": 5.867031574249268, "metricx_qe_score": 5.03897762298584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre papier, ensemble de données et code à l'adresse suivante. Merci.", "metrics": {"bleu_score": 24.26438274389041, "chrf_score": 56.76125450069509, "xcomet_score": 0.9472694396972656, "xcomet_qe_score": 0.9847553968429565, "metricx_score": 3.927717924118042, "metricx_qe_score": 3.6048011779785156, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour. Nous présentons notre travail sur VAlues, un benchmark indépendant de la tâche destiné à tester les modèles visionnels et linguistiques avec des phénomènes linguistiques spécifiques.", "metrics": {"bleu_score": 37.949474302414075, "chrf_score": 66.140161810662, "xcomet_score": 0.7516359090805054, "xcomet_qe_score": 0.8742095232009888, "metricx_score": 6.097175121307373, "metricx_qe_score": 5.748813152313232, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous mis en place ce benchmark ?", "metrics": {"bleu_score": 7.80152171018653, "chrf_score": 41.754358084675694, "xcomet_score": 0.9379007816314697, "xcomet_qe_score": 0.9825607538223267, "metricx_score": 3.311422348022461, "metricx_qe_score": 3.130063533782959, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Au cours des dernières années, nous avons observé une explosion de modèles visionnels et linguistiques basés sur les transformateurs pré-entraînés sur de grandes quantités d'images-textes.", "metrics": {"bleu_score": 25.56874410164234, "chrf_score": 64.33693915776317, "xcomet_score": 0.8013574481010437, "xcomet_qe_score": 0.9085202217102051, "metricx_score": 4.050339221954346, "metricx_qe_score": 4.390951156616211, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque un de ces modèles pousse l'état de l'art sur les tâches spécifiques telles que la réponse visuelle, la compréhension visuelle, la récupération d'images, le soutien du langage, le raisonnement visuel, la référence d'entité, etc.", "metrics": {"bleu_score": 16.088986597586107, "chrf_score": 53.00158762885967, "xcomet_score": 0.4179210364818573, "xcomet_qe_score": 0.49632176756858826, "metricx_score": 4.712108135223389, "metricx_qe_score": 5.2166218757629395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc reçu un message : les exactitudes sur ces benchmarks spécifiques augmentent constamment.", "metrics": {"bleu_score": 38.95283722840476, "chrf_score": 55.852350298785524, "xcomet_score": 0.8966947197914124, "xcomet_qe_score": 0.9358856678009033, "metricx_score": 5.810474872589111, "metricx_qe_score": 5.264533519744873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous ce que les modèles ont réellement appris ?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.452160120010376, "metricx_qe_score": 2.2402255535125732, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce que les visionnels et les linguistiques ont compris lorsqu'ils ont attribué un score élevé à cette image et à cette phrase correspondante,", "metrics": {"bleu_score": 10.191309092306701, "chrf_score": 56.122749683924944, "xcomet_score": 0.5835450291633606, "xcomet_qe_score": 0.7760097980499268, "metricx_score": 6.995321273803711, "metricx_qe_score": 6.8289995193481445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "et un score faible à une autre ?", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 18.62160424116946, "xcomet_score": 0.7238098382949829, "xcomet_qe_score": 0.5943836569786072, "metricx_score": 6.376877784729004, "metricx_qe_score": 7.4290337562561035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Se concentrent-ils sur le bon sujet,", "metrics": {"bleu_score": 1.8155431088372649, "chrf_score": 25.313494607757107, "xcomet_score": 0.21221289038658142, "xcomet_qe_score": 0.11003483831882477, "metricx_score": 11.567485809326172, "metricx_qe_score": 9.958355903625488, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "ou se concentrent-ils sur les biais, comme le montre le travail précédent ?", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 78.83122027684237, "xcomet_score": 0.9508404731750488, "xcomet_qe_score": 0.9540202021598816, "metricx_score": 1.1698737144470215, "metricx_qe_score": 1.771613597869873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour mieux éclairer cette question, nous proposons une approche plus agnostique et introduisons VAlues, qui teste la sensibilité des modèles visionnels et linguistiques à des phénomènes linguistiques qui affectent à la fois les modalités linguistiques et visuelles.", "metrics": {"bleu_score": 42.401226435909436, "chrf_score": 65.84949310217083, "xcomet_score": 0.6640342473983765, "xcomet_qe_score": 0.7881374359130859, "metricx_score": 5.549720764160156, "metricx_qe_score": 6.293257713317871, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la référence d'entité.", "metrics": {"bleu_score": 77.92435436699043, "chrf_score": 86.90824453826674, "xcomet_score": 0.8527242541313171, "xcomet_qe_score": 0.8938506841659546, "metricx_score": 2.7295618057250977, "metricx_qe_score": 4.138844966888428, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment tester si les modèles ont capturé ces phénomènes ?", "metrics": {"bleu_score": 33.94734963795361, "chrf_score": 67.47806688058049, "xcomet_score": 0.7488911747932434, "xcomet_qe_score": 0.5099207758903503, "metricx_score": 2.2007837295532227, "metricx_qe_score": 4.01768684387207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant le procédé de foiling, une méthode appliquée précédemment aux modèles visionnels et linguistiques uniquement pour les phrases non-verbales par Ravi Shekar et collaborateurs, et sur le comptage par nous dans le travail précédent.", "metrics": {"bleu_score": 8.912985517299546, "chrf_score": 57.00809026682323, "xcomet_score": 0.479209840297699, "xcomet_qe_score": 0.4932646155357361, "metricx_score": 7.588844299316406, "metricx_qe_score": 6.748691082000732, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Foiling signifie que nous prenons la légende d'une image et produisons un foil en modifiant la légende de telle manière qu'elle ne décrit plus l'image.", "metrics": {"bleu_score": 63.068437684145124, "chrf_score": 76.43818097463385, "xcomet_score": 0.8280662298202515, "xcomet_qe_score": 0.9091333150863647, "metricx_score": 4.199425220489502, "metricx_qe_score": 7.039804935455322, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous faisons ces altérations de phrases en nous concentrant sur six pièces spécifiques, telles que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la référence d'entité, où chaque pièce peut consister en un ou plusieurs instruments.", "metrics": {"bleu_score": 43.500942068472234, "chrf_score": 62.4764531120104, "xcomet_score": 0.3359733819961548, "xcomet_qe_score": 0.39620453119277954, "metricx_score": 8.772235870361328, "metricx_qe_score": 12.051098823547363, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas des actions, nous avons deux instruments, l'un dans lequel le verbe de l'action est changé avec une action différente, et l'autre dans lequel les actants sont échangés.", "metrics": {"bleu_score": 50.80461715083114, "chrf_score": 79.05186781369376, "xcomet_score": 0.6840508580207825, "xcomet_qe_score": 0.6449560523033142, "metricx_score": 6.001044750213623, "metricx_qe_score": 6.705021858215332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la référence d'entité ont également plus d'un instrument.", "metrics": {"bleu_score": 20.640765449620034, "chrf_score": 56.48184713230854, "xcomet_score": 0.6891615390777588, "xcomet_qe_score": 0.6630704402923584, "metricx_score": 5.5420684814453125, "metricx_qe_score": 5.853355407714844, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces foils en nous assurant qu'ils ne décrivent plus l'image, qu'ils sont des phrases grammaticales et valides.", "metrics": {"bleu_score": 60.66229224098696, "chrf_score": 80.44169140170528, "xcomet_score": 0.714873731136322, "xcomet_qe_score": 0.8553265333175659, "metricx_score": 5.435791969299316, "metricx_qe_score": 7.614741325378418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas facile de le faire, car un foil peut être statistiquement moins probable que la légende originale.", "metrics": {"bleu_score": 50.17720231456745, "chrf_score": 71.24475599604426, "xcomet_score": 0.7077116966247559, "xcomet_qe_score": 0.6032850742340088, "metricx_score": 7.082024097442627, "metricx_qe_score": 10.439044952392578, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien qu'il ne soit pas impossible, il est statistiquement moins probable que les plantes coupent un homme, que l'homme coupe les plantes. Les grands modèles visionnels et linguistiques pourraient capter cela.", "metrics": {"bleu_score": 53.77844302797146, "chrf_score": 79.80561022801876, "xcomet_score": 0.8244810700416565, "xcomet_qe_score": 0.8648914098739624, "metricx_score": 3.8637423515319824, "metricx_qe_score": 3.958512544631958, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des valides, nous prenons l'action.", "metrics": {"bleu_score": 50.16513759455242, "chrf_score": 70.74752120627075, "xcomet_score": 0.3465062379837036, "xcomet_qe_score": 0.3409242033958435, "metricx_score": 8.972362518310547, "metricx_qe_score": 9.999774932861328, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, nous utilisons des modèles linguistiques forts pour proposer des foils.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 69.48837944984217, "xcomet_score": 0.864690899848938, "xcomet_qe_score": 0.9813841581344604, "metricx_score": 3.4114136695861816, "metricx_qe_score": 5.793243408203125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence naturelle, ou court-short, pour filtrer les foils qui pourraient encore décrire l'image, car lors de la construction des foils, nous devons nous assurer qu'ils ne décrivent plus l'image.", "metrics": {"bleu_score": 70.93980710628281, "chrf_score": 86.94056287794616, "xcomet_score": 0.486727774143219, "xcomet_qe_score": 0.5725531578063965, "metricx_score": 10.871521949768066, "metricx_qe_score": 12.954699516296387, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle d'inférence naturelle pr", "metrics": {"bleu_score": 1.2976955971595585, "chrf_score": 19.36916524955551, "xcomet_score": 0.22139783203601837, "xcomet_qe_score": 0.15296109020709991, "metricx_score": 23.146804809570312, "metricx_qe_score": 20.23992156982422, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.29705384373664856, "xcomet_qe_score": 0.24178072810173035, "metricx_score": 15.038116455078125, "metricx_qe_score": 9.483627319335938, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "édit le foil pour contredire ou être", "metrics": {"bleu_score": 2.728678841781033, "chrf_score": 15.201626470608307, "xcomet_score": 0.11002905666828156, "xcomet_qe_score": 0.13630886375904083, "metricx_score": 25.0, "metricx_qe_score": 22.466753005981445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "neutre par rapport à la légende, nous prenons cela comme un indicateur de valides. Si un modèle", "metrics": {"bleu_score": 34.13492488439465, "chrf_score": 55.06769277508052, "xcomet_score": 0.26662570238113403, "xcomet_qe_score": 0.21685686707496643, "metricx_score": 20.268850326538086, "metricx_qe_score": 21.440969467163086, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "d'inférence naturelle prédit le foil pour être contredit ou neutre par rapport à la légende, cela ne peut pas être un bon foil, car, par transitivité, cela donnera une description vraie de l'image. Et nous filtrons ces foils.", "metrics": {"bleu_score": 51.330212241048805, "chrf_score": 72.07587646554788, "xcomet_score": 0.22932367026805878, "xcomet_qe_score": 0.25683102011680603, "metricx_score": 15.841151237487793, "metricx_qe_score": 20.087421417236328, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais ce processus n'est pas parfait, il est juste un indicateur de valides.", "metrics": {"bleu_score": 8.561274252343834, "chrf_score": 46.305795427241165, "xcomet_score": 0.5381860136985779, "xcomet_qe_score": 0.4874938130378723, "metricx_score": 7.450418472290039, "metricx_qe_score": 7.610695838928223, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, comme troisième mesure pour générer des valides, nous employons des annotateurs humains pour valider les données utilisées dans VAlues.", "metrics": {"bleu_score": 61.706340412606124, "chrf_score": 80.05626653008714, "xcomet_score": 0.425123393535614, "xcomet_qe_score": 0.43308520317077637, "metricx_score": 10.199992179870605, "metricx_qe_score": 10.396408081054688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Après le filtrage et l'évaluation humaine, nous avons autant d'instances de test que décrit dans cette table.", "metrics": {"bleu_score": 55.745131911721316, "chrf_score": 83.6943141148942, "xcomet_score": 0.9760282635688782, "xcomet_qe_score": 0.9654290080070496, "metricx_score": 2.728954315185547, "metricx_qe_score": 2.3842852115631104, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que VAlues ne fournit pas de données d'entraînement, mais seulement des données de test,", "metrics": {"bleu_score": 53.12583871630397, "chrf_score": 73.98214817530628, "xcomet_score": 0.6996077299118042, "xcomet_qe_score": 0.7354655265808105, "metricx_score": 5.769941329956055, "metricx_qe_score": 5.910832405090332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "car c'est un benchmark de zéro shot. Il est conçu pour tirer parti des capacités des modèles visionnels et linguistiques après pré-entraînement.", "metrics": {"bleu_score": 20.34971465055458, "chrf_score": 45.05242963370473, "xcomet_score": 0.5693292617797852, "xcomet_qe_score": 0.5562138557434082, "metricx_score": 7.937854766845703, "metricx_qe_score": 8.984274864196777, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "La fine-tuning n'en permettrait qu'à ces modèles d'exploiter des artefacts ou des biais statistiques dans les données.", "metrics": {"bleu_score": 64.70107100770988, "chrf_score": 76.3308197182456, "xcomet_score": 0.6353015899658203, "xcomet_qe_score": 0.6463325023651123, "metricx_score": 7.013614654541016, "metricx_qe_score": 7.870959281921387, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons que ces modèles aiment tricher et prendre des raccourcis.", "metrics": {"bleu_score": 78.81929718099911, "chrf_score": 92.0403786041946, "xcomet_score": 0.9988827705383301, "xcomet_qe_score": 0.9844700694084167, "metricx_score": 1.3941313028335571, "metricx_qe_score": 2.720172882080078, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l'avons dit, nous sommes intéressés à évaluer quelles capacités les modèles visionnels et linguistiques ont après pré-entraînement.", "metrics": {"bleu_score": 24.670423191888208, "chrf_score": 55.16497602920294, "xcomet_score": 0.9819015264511108, "xcomet_qe_score": 1.0, "metricx_score": 3.62904953956604, "metricx_qe_score": 2.683678388595581, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles visionnels et linguistiques sur VAlues, à savoir CLIP, LXMERT, ViLBERT, ViLBERT 12 in 1 et VisualBert.", "metrics": {"bleu_score": 26.430696530349728, "chrf_score": 61.02531472035424, "xcomet_score": 0.7031953930854797, "xcomet_qe_score": 0.7910910844802856, "metricx_score": 6.489658355712891, "metricx_qe_score": 6.163224697113037, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d'évaluation les plus importantes sont la précision des modèles à classer les paires d'images et de phrases en légendes et foils.", "metrics": {"bleu_score": 38.525530198072055, "chrf_score": 70.78216169357762, "xcomet_score": 0.7840813398361206, "xcomet_qe_score": 0.7952337265014648, "metricx_score": 4.132357597351074, "metricx_qe_score": 6.287541389465332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Peut-être plus important pour ce vidéo, nous montrerons notre métrique plus permissive, la précision par paire, qui mesure si le score d'alignement d'image et de phrase est supérieur pour la paire d'image et de texte correcte que pour sa paire de lég", "metrics": {"bleu_score": 34.93309392213049, "chrf_score": 61.00693728818606, "xcomet_score": 0.5359499454498291, "xcomet_qe_score": 0.5005253553390503, "metricx_score": 8.958070755004883, "metricx_qe_score": 6.725875377655029, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "ende et de foil.", "metrics": {"bleu_score": 7.121297464907233, "chrf_score": 6.653212806534832, "xcomet_score": 0.12939128279685974, "xcomet_qe_score": 0.13710716366767883, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "DANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats avec la précision par paire sont montrés ici, et ils sont cohérents avec les résultats que nous avons obtenus d'autres métriques.", "metrics": {"bleu_score": 24.628278328271367, "chrf_score": 48.6040001009903, "xcomet_score": 0.5714524388313293, "xcomet_qe_score": 0.4782125651836395, "metricx_score": 13.72697639465332, "metricx_qe_score": 11.969400405883789, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est à noter que les instruments centrés sur les objets individuels, comme l'existence et les phrases nominales, sont presque résolus par ViLBERT 12 in 1, ce qui souligne que les modèles sont capables d'identifier les objets nommés et leur présence dans les images.", "metrics": {"bleu_score": 55.156646038081696, "chrf_score": 79.26769206322957, "xcomet_score": 0.7694587707519531, "xcomet_qe_score": 0.6712993383407593, "metricx_score": 4.5895490646362305, "metricx_qe_score": 4.859736919403076, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucun des autres instruments ne peut être résolu dans nos réglages de foiling adversaires.", "metrics": {"bleu_score": 29.12014808653287, "chrf_score": 55.48515803988455, "xcomet_score": 0.718955934047699, "xcomet_qe_score": 0.6637768745422363, "metricx_score": 7.993864059448242, "metricx_qe_score": 8.645219802856445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "Nous voyons des instruments de pluralité et de comptage, ce qui montre que les modèles visionnels et linguistiques ont du mal à distinguer les références à un seul objet par rapport à plusieurs objets, ou à les compter dans une image.", "metrics": {"bleu_score": 55.87328445535172, "chrf_score": 77.94596363903399, "xcomet_score": 0.7879395484924316, "xcomet_qe_score": 0.683102011680603, "metricx_score": 5.945059776306152, "metricx_qe_score": 6.278130054473877, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "Les instruments de relation montrent que les modèles visionnels et linguistiques ont du mal à classer correctement une relation spatiale nommée entre les objets dans une image.", "metrics": {"bleu_score": 39.60970942970262, "chrf_score": 70.18393787063798, "xcomet_score": 0.5050948858261108, "xcomet_qe_score": 0.5297777652740479, "metricx_score": 4.752381801605225, "metricx_qe_score": 6.35901403427124, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier les participants, même s'ils sont soutenus par des biais de plausibilité, comme nous voyons dans le jeu des actions.", "metrics": {"bleu_score": 66.32938289463947, "chrf_score": 85.91955529811739, "xcomet_score": 0.8003103137016296, "xcomet_qe_score": 0.854024350643158, "metricx_score": 6.174406051635742, "metricx_qe_score": 6.661782264709473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "De la pièce de référence, nous découvrons que tracer plusieurs références à la même entité dans une image par des pronoms est également difficile pour les modèles visionnels et linguistiques.", "metrics": {"bleu_score": 32.91669798948711, "chrf_score": 65.62853083851739, "xcomet_score": 0.612321138381958, "xcomet_qe_score": 0.7415524125099182, "metricx_score": 7.112835884094238, "metricx_qe_score": 6.288208961486816, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que contrôle de la santé, et parce qu'il est un exercice intéressant, nous évaluons également deux modèles textuels, GPT1 et GPT2, pour évaluer si VAlues est résolvable par ces modèles unidimensionnels en calculant la perplexité de la légende correcte et de la légende de foil.", "metrics": {"bleu_score": 22.05833531877435, "chrf_score": 50.557118213987465, "xcomet_score": 0.2059914916753769, "xcomet_qe_score": 0.2554750442504883, "metricx_score": 11.182652473449707, "metricx_qe_score": 13.362166404724121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour la légende de foil, nous prenons cela comme un indicateur que la légende de foil souffre d'un biais de plausibilité ou d'autres biais linguistiques.", "metrics": {"bleu_score": 47.14230064146414, "chrf_score": 72.5410424687986, "xcomet_score": 0.62464439868927, "xcomet_qe_score": 0.6514217853546143, "metricx_score": 7.427732467651367, "metricx_qe_score": 9.847077369689941, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est intéressant de voir que dans certains cas, les modèles textuels GPT ont capturé la plausibilité du monde mieux que les modèles visionnels et linguistiques.", "metrics": {"bleu_score": 55.72134196340852, "chrf_score": 76.5650857912923, "xcomet_score": 0.9440003037452698, "xcomet_qe_score": 0.8970210552215576, "metricx_score": 4.7370500564575195, "metricx_qe_score": 4.500484466552734, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, VAlues est un benchmark qui utilise la lentille des constructions linguistiques pour aider la communauté à améliorer les modèles visionnels et linguistiques en testant leurs capacités de fondement visuel.", "metrics": {"bleu_score": 34.137201902171995, "chrf_score": 62.688718208181136, "xcomet_score": 0.5531389713287354, "xcomet_qe_score": 0.6480709910392761, "metricx_score": 8.461055755615234, "metricx_qe_score": 8.069061279296875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que les modèles visionnels et linguistiques identifient bien les objets nommés et leur présence dans les images, comme le montre la pièce d'existence, mais ont du mal à ancrer leur interdépendance et leurs relations dans les scènes visuelles lorsqu'ils sont forcés de respecter les indicateurs linguistiques.", "metrics": {"bleu_score": 62.32695231691665, "chrf_score": 84.63443782891873, "xcomet_score": 0.7241095900535583, "xcomet_qe_score": 0.7097375392913818, "metricx_score": 5.026710510253906, "metricx_qe_score": 5.190493106842041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser VAlues pour mesurer les progrès vers l'ancrage linguistique avec les modèles visionnels et linguistiques.", "metrics": {"bleu_score": 39.6040535648539, "chrf_score": 71.07537228765996, "xcomet_score": 0.7637016773223877, "xcomet_qe_score": 0.8390594720840454, "metricx_score": 7.7387590408325195, "metricx_qe_score": 7.87001895904541, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "Et VAlues pourrait également être utilisé comme une évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou la fine-tuning pour voir si un ensemble de données aide les modèles à améliorer l'un des aspects testés par VAlues.", "metrics": {"bleu_score": 54.24535287435272, "chrf_score": 75.32814948721489, "xcomet_score": 0.8054633140563965, "xcomet_qe_score": 0.8219797611236572, "metricx_score": 8.436822891235352, "metricx_qe_score": 8.355157852172852, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si vous êtes intéressé, veuillez consulter les données VAlues sur Github, et si vous avez des questions, n'hésitez pas à nous contacter.", "metrics": {"bleu_score": 68.1113268568683, "chrf_score": 84.24680617008178, "xcomet_score": 0.9172070026397705, "xcomet_qe_score": 0.8943461179733276, "metricx_score": 5.728194713592529, "metricx_qe_score": 6.051211357116699, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kamisaka de l'Université de Tokyo.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 86.20753539504365, "xcomet_score": 0.6609129905700684, "xcomet_qe_score": 0.6494506597518921, "metricx_score": 3.4042367935180664, "metricx_qe_score": 3.54042387008667, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter un papier intitulé \"RNSUM, un ensemble de données à grande échelle pour la génération automatique de notes de version via la résumé des logs\".", "metrics": {"bleu_score": 38.84776649966735, "chrf_score": 63.177040010407026, "xcomet_score": 0.7044034004211426, "xcomet_qe_score": 0.828126072883606, "metricx_score": 2.9843788146972656, "metricx_qe_score": 2.5630979537963867, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais expliquer dans cet ordre.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 82.67586467120438, "xcomet_score": 0.9803920984268188, "xcomet_qe_score": 1.0, "metricx_score": 0.5986242294311523, "metricx_qe_score": 0.8819785118103027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "D'abord, je vais introduire la génération automatique de notes de version que nous travaillons dans cette recherche.", "metrics": {"bleu_score": 34.57341631415251, "chrf_score": 72.01815059678125, "xcomet_score": 0.8482795357704163, "xcomet_qe_score": 0.8269529938697815, "metricx_score": 5.261099338531494, "metricx_qe_score": 4.950098037719727, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "Une note de version est un document technique qui résume les changements distribués avec chaque version d'un logiciel.", "metrics": {"bleu_score": 61.699546746278635, "chrf_score": 74.01312400007507, "xcomet_score": 0.9921215772628784, "xcomet_qe_score": 0.9689801931381226, "metricx_score": 0.3132757544517517, "metricx_qe_score": 0.442744642496109, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image montre les notes de version pour la version 2.4 de la bibliothèque bj.", "metrics": {"bleu_score": 28.362685083135062, "chrf_score": 57.24738982370834, "xcomet_score": 0.3381817936897278, "xcomet_qe_score": 0.4572635591030121, "metricx_score": 6.553000450134277, "metricx_qe_score": 7.49609375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de version jouent un rôle important dans le développement open source, mais elles sont chronophages à préparer manuellement.", "metrics": {"bleu_score": 68.4145592321339, "chrf_score": 78.82464131738001, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7391065955162048, "metricx_qe_score": 0.8991613984107971, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, il serait très utile d'être en mesure de générer automatiquement des notes de version de haute qualité.", "metrics": {"bleu_score": 72.00391346486707, "chrf_score": 88.03151353091368, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7439703345298767, "metricx_qe_score": 0.6316560506820679, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais faire référence à deux recherches précédentes sur la génération automatique de notes de version.", "metrics": {"bleu_score": 57.49089871602278, "chrf_score": 71.52780582330247, "xcomet_score": 0.9873436689376831, "xcomet_qe_score": 0.9808346033096313, "metricx_score": 1.0041916370391846, "metricx_qe_score": 0.7446069121360779, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "La première est un système appelé Alena, sorti en 2014.", "metrics": {"bleu_score": 48.326978309062184, "chrf_score": 57.99558494025795, "xcomet_score": 0.3815210461616516, "xcomet_qe_score": 0.4083200991153717, "metricx_score": 5.174605369567871, "metricx_qe_score": 5.297102928161621, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il prend un approche basée sur les règles, par exemple, en utilisant l'extracteur de changements pour extraire les différences de bibliothèques et documenter les changements entre les versions, et enfin les combiner.", "metrics": {"bleu_score": 33.47515113074851, "chrf_score": 69.90380055129921, "xcomet_score": 0.6884648203849792, "xcomet_qe_score": 0.7805795669555664, "metricx_score": 5.59044885635376, "metricx_qe_score": 3.577042818069458, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La plus notable caractéristique de ce système est l'extracteur d'issues dans la coin en haut à droite,", "metrics": {"bleu_score": 26.46015952359329, "chrf_score": 65.81412394718183, "xcomet_score": 0.5829586386680603, "xcomet_qe_score": 0.7602680921554565, "metricx_score": 7.121278285980225, "metricx_qe_score": 8.244714736938477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "qui doit être lié au système de ticket d'issue, et peut être appliqué qu'à des projets qui utilisent Jira.", "metrics": {"bleu_score": 26.991220565981227, "chrf_score": 62.54437863861509, "xcomet_score": 0.5022364854812622, "xcomet_qe_score": 0.50286865234375, "metricx_score": 8.293380737304688, "metricx_qe_score": 6.7234601974487305, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres mots, il ne peut pas être utilisé pour de nombreux projets sur Github.", "metrics": {"bleu_score": 88.43946454355333, "chrf_score": 95.37430501488888, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7920345664024353, "metricx_qe_score": 1.1215450763702393, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième est Grrriff, récemment annoncé en 2020. Il", "metrics": {"bleu_score": 9.864703138979419, "chrf_score": 41.65507019401489, "xcomet_score": 0.2382066547870636, "xcomet_qe_score": 0.2212323248386383, "metricx_score": 13.738313674926758, "metricx_qe_score": 10.459282875061035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "est disponible sur Internet et peut être installé via pip.", "metrics": {"bleu_score": 29.0374612189482, "chrf_score": 79.9462891422973, "xcomet_score": 0.7246236205101013, "xcomet_qe_score": 0.8142187595367432, "metricx_score": 4.851800918579102, "metricx_qe_score": 2.597313404083252, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système a un modèle de classification de texte simple et génère une des quatre probabilités, telles que les fonctionnalités ou les corrections de bogues pour chaque message de commit.", "metrics": {"bleu_score": 37.23972325628923, "chrf_score": 61.26823808612054, "xcomet_score": 0.5462541580200195, "xcomet_qe_score": 0.6303000450134277, "metricx_score": 6.655702590942383, "metricx_qe_score": 7.523231506347656, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un usage de exemple qui retourne une note de correction de correctifs.", "metrics": {"bleu_score": 8.516412540808123, "chrf_score": 42.71750304462316, "xcomet_score": 0.5446838736534119, "xcomet_qe_score": 0.6259386539459229, "metricx_score": 9.594807624816895, "metricx_qe_score": 8.683195114135742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "La formation de Grrriff est assez petite, environ 5000, et sera montrée dans les expériences décrites ci-dessous.", "metrics": {"bleu_score": 27.70340928643106, "chrf_score": 61.990245272136, "xcomet_score": 0.537278413772583, "xcomet_qe_score": 0.4118887186050415, "metricx_score": 11.060408592224121, "metricx_qe_score": 11.714361190795898, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "La performance du modèle de classification de texte n'est pas élevée.", "metrics": {"bleu_score": 41.24914892312113, "chrf_score": 77.37520089391352, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7285580635070801, "metricx_qe_score": 1.104062795639038, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches liées, mais elles ont des problèmes d'applicabilité limitée et des ressources de données insuffisantes.", "metrics": {"bleu_score": 22.01224844905468, "chrf_score": 72.67954319340237, "xcomet_score": 0.9895923137664795, "xcomet_qe_score": 0.9888296127319336, "metricx_score": 1.5544345378875732, "metricx_qe_score": 1.5326602458953857, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre papier résout ces deux problèmes et génère automatiquement des notes de version de haute qualité.", "metrics": {"bleu_score": 88.43946454355333, "chrf_score": 90.12080363944742, "xcomet_score": 0.8465484380722046, "xcomet_qe_score": 0.8484872579574585, "metricx_score": 3.398451328277588, "metricx_qe_score": 2.2901995182037354, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le problème d'applicabilité limitée, nous proposons un moyen de résumé de classe de haute qualité en utilisant uniquement les messages de commit comme entrée.", "metrics": {"bleu_score": 42.97310736875147, "chrf_score": 68.52528746693437, "xcomet_score": 0.7255093455314636, "xcomet_qe_score": 0.803706169128418, "metricx_score": 6.000386714935303, "metricx_qe_score": 6.0621819496154785, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Ce moyen peut être utilisé pour tous les répertoires en anglais.", "metrics": {"bleu_score": 18.52797255583095, "chrf_score": 51.041060749836255, "xcomet_score": 0.9208602905273438, "xcomet_qe_score": 0.986243724822998, "metricx_score": 3.7087526321411133, "metricx_qe_score": 2.4262187480926514, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème de ressources de données insuffisantes, nous avons construit un ensemble de données RNSUM composé de 82000 pièces de données en collectant des données de répertoires publics via l'API de Github.", "metrics": {"bleu_score": 38.11468991759939, "chrf_score": 58.02820605855089, "xcomet_score": 0.878937840461731, "xcomet_qe_score": 0.9385368824005127, "metricx_score": 4.122358798980713, "metricx_qe_score": 3.3947839736938477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris notre ensemble de données.", "metrics": {"bleu_score": 22.31618068926665, "chrf_score": 54.44727132027736, "xcomet_score": 0.9921175241470337, "xcomet_qe_score": 0.9985687732696533, "metricx_score": 0.3900907635688782, "metricx_qe_score": 0.33645331859588623, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de données,", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 95.31916500738012, "xcomet_score": 0.9898669719696045, "xcomet_qe_score": 0.9842339158058167, "metricx_score": 0.8128435611724854, "metricx_qe_score": 0.5543940663337708, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "le côté gauche est le message de commit et le côté droit est la note de version.", "metrics": {"bleu_score": 26.89054715066593, "chrf_score": 55.52815730732621, "xcomet_score": 0.8370816707611084, "xcomet_qe_score": 0.8029089570045471, "metricx_score": 3.601118564605713, "metricx_qe_score": 4.0554094314575195, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de version sont étiquetées comme améliorations, corre", "metrics": {"bleu_score": 57.97215869131433, "chrf_score": 80.36841729077986, "xcomet_score": 0.6881928443908691, "xcomet_qe_score": 0.7509030699729919, "metricx_score": 7.944791316986084, "metricx_qe_score": 2.5603387355804443, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "ctions de bogues, etc", "metrics": {"bleu_score": 0.2918767892026305, "chrf_score": 5.699975873497673, "xcomet_score": 0.10776884108781815, "xcomet_qe_score": 0.13428416848182678, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": ".", "metrics": {"bleu_score": 0.0, "chrf_score": 2.7624309392265194, "xcomet_score": 0.2669934034347534, "xcomet_qe_score": 0.1514657586812973, "metricx_score": 19.97230339050293, "metricx_qe_score": 23.602760314941406, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons défini quatre étiquettes : fonctionnalités, améliorations, corrections de bogues, suppressions et changements de rupture.", "metrics": {"bleu_score": 30.990193767973174, "chrf_score": 70.11576264168234, "xcomet_score": 0.716692328453064, "xcomet_qe_score": 0.6095279455184937, "metricx_score": 5.1529364585876465, "metricx_qe_score": 5.231439590454102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces étiquettes sont fixées sur la base de recherches précédentes et d'autres facteurs.", "metrics": {"bleu_score": 33.10552213332554, "chrf_score": 53.264876853657896, "xcomet_score": 0.8386721611022949, "xcomet_qe_score": 0.8307687044143677, "metricx_score": 3.3010544776916504, "metricx_qe_score": 2.7060482501983643, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "La note de version sur le bas droit et les données extraites des messages de commit sont montrées sur le bas gauche.", "metrics": {"bleu_score": 13.566979610140004, "chrf_score": 45.3542143773232, "xcomet_score": 0.2061138153076172, "xcomet_qe_score": 0.16816851496696472, "metricx_score": 5.462538242340088, "metricx_qe_score": 4.950446605682373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce moment-là, il est nécessaire de détecter les quatre étiquettes qui ont été définies à l'avance.", "metrics": {"bleu_score": 63.85414244951875, "chrf_score": 75.7239792198563, "xcomet_score": 0.9727174043655396, "xcomet_qe_score": 0.9845625162124634, "metricx_score": 1.4975008964538574, "metricx_qe_score": 1.939568042755127, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les étiquettes ne sont pas toujours cohérentes avec chaque répertoire.", "metrics": {"bleu_score": 82.651681837938, "chrf_score": 86.2838448750937, "xcomet_score": 0.973227858543396, "xcomet_qe_score": 0.9870800375938416, "metricx_score": 2.0147407054901123, "metricx_qe_score": 1.6396645307540894, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, l' étiquette d'améliorations inclut améliorations, améliorations, optimisations, etc.", "metrics": {"bleu_score": 25.91840256221867, "chrf_score": 72.1219352431185, "xcomet_score": 0.37503623962402344, "xcomet_qe_score": 0.7009429931640625, "metricx_score": 7.351082801818848, "metricx_qe_score": 7.704287052154541, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire de notes de version pour chaque variation de notation.", "metrics": {"bleu_score": 42.254876310519364, "chrf_score": 62.84908939822799, "xcomet_score": 0.5902597904205322, "xcomet_qe_score": 0.5895668268203735, "metricx_score": 7.603106498718262, "metricx_qe_score": 10.068961143493652, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-la pour détecter la classe de note de version et corrigez le texte de la note de version qui suit comme phrase de note.", "metrics": {"bleu_score": 39.290984100672965, "chrf_score": 61.29573697688095, "xcomet_score": 0.28801071643829346, "xcomet_qe_score": 0.23506541550159454, "metricx_score": 7.473734378814697, "metricx_qe_score": 8.401314735412598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, est un message de commit.", "metrics": {"bleu_score": 21.069764742263047, "chrf_score": 47.43674250320157, "xcomet_score": 0.6190477609634399, "xcomet_qe_score": 0.8906503915786743, "metricx_score": 6.561076641082764, "metricx_qe_score": 5.6838531494140625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de commit ne sont pas liés à chaque version de release.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 72.79657441635305, "xcomet_score": 0.8415392637252808, "xcomet_qe_score": 0.8574953079223633, "metricx_score": 5.391760349273682, "metricx_qe_score": 4.649750709533691, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme montré dans l'image ci-dessous, si la version actuelle est 2.5 à 19, nous devons identifier la version précédente 2.5 à 18 et obtenir sa différence.", "metrics": {"bleu_score": 35.53763460430444, "chrf_score": 54.61012828484429, "xcomet_score": 0.5731377601623535, "xcomet_qe_score": 0.777334451675415, "metricx_score": 2.770958185195923, "metricx_qe_score": 2.6976006031036377, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "Cela est un peu fastidieux, et ce n'est pas suffisant pour simplement obtenir une liste de versions de release et regarder les versions avant et après.", "metrics": {"bleu_score": 14.37791910008819, "chrf_score": 63.59397526674536, "xcomet_score": 0.7071912288665771, "xcomet_qe_score": 0.6739633679389954, "metricx_score": 6.820195198059082, "metricx_qe_score": 6.2716779708862305, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons créé une règle heuristique pour obtenir les versions précédentes et suivantes.", "metrics": {"bleu_score": 54.084391427678554, "chrf_score": 72.22124279274853, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.30591881275177, "metricx_qe_score": 1.8109933137893677, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de", "metrics": {"bleu_score": 0.0, "chrf_score": 16.40413691715123, "xcomet_score": 0.16063664853572845, "xcomet_qe_score": 0.15761099755764008, "metricx_score": 10.722246170043945, "metricx_qe_score": 11.763280868530273, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "résumé. À la fin, 7200 répertoires et 82 000 pièces de données ont été collectées.", "metrics": {"bleu_score": 14.307778226053154, "chrf_score": 24.766488018825875, "xcomet_score": 0.33999520540237427, "xcomet_qe_score": 0.48912668228149414, "metricx_score": 6.342360973358154, "metricx_qe_score": 5.49509334564209, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de tokens de note de version est de 63, ce qui est assez élevé pour une tâche de résumé.", "metrics": {"bleu_score": 56.74773954614978, "chrf_score": 62.00045678288677, "xcomet_score": 0.6229046583175659, "xcomet_qe_score": 0.687125027179718, "metricx_score": 5.017183303833008, "metricx_qe_score": 3.5041873455047607, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre de tokens uniques est assez élevé, à 8 830 000.", "metrics": {"bleu_score": 18.322595730639303, "chrf_score": 34.825838787732145, "xcomet_score": 0.8350305557250977, "xcomet_qe_score": 0.9735326766967773, "metricx_score": 4.14923620223999, "metricx_qe_score": 1.9377777576446533, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "Cela est dû à la grande quantité de noms de classe et de méthodes trouvés dans le répertoire.", "metrics": {"bleu_score": 19.18420840845653, "chrf_score": 55.9595104132513, "xcomet_score": 0.8185887336730957, "xcomet_qe_score": 0.9233311414718628, "metricx_score": 2.5708043575286865, "metricx_qe_score": 2.6288816928863525, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris le modèle proposé.", "metrics": {"bleu_score": 19.493995755254467, "chrf_score": 40.61504918809525, "xcomet_score": 0.9416699409484863, "xcomet_qe_score": 0.9548332691192627, "metricx_score": 2.725302219390869, "metricx_qe_score": 3.2955188751220703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé de classe puis abstrait consiste en deux modules neuronaux,", "metrics": {"bleu_score": 17.055805176321822, "chrf_score": 51.14587623519027, "xcomet_score": 0.6652700304985046, "xcomet_qe_score": 0.6837664842605591, "metricx_score": 6.1385722160339355, "metricx_qe_score": 5.988956451416016, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "un classificateur utilisant ou code bart et un générateur utilisant bart.", "metrics": {"bleu_score": 27.09198854675628, "chrf_score": 68.37466236226318, "xcomet_score": 0.5597966909408569, "xcomet_qe_score": 0.6550874710083008, "metricx_score": 12.993040084838867, "metricx_qe_score": 14.146881103515625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "D'abord, CEAS utilise un classificateur pour classer chaque message de commit en cinq classes de notes de version : fonctionnalités, améliorations, corrections de bogues, suppressions et changements de rupture.", "metrics": {"bleu_score": 50.12760980737956, "chrf_score": 69.20478282325185, "xcomet_score": 0.5624328851699829, "xcomet_qe_score": 0.6385806798934937, "metricx_score": 4.021526336669922, "metricx_qe_score": 3.4303929805755615, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de commit classifiés comme autres sont rejetés.", "metrics": {"bleu_score": 27.301208627090666, "chrf_score": 56.72458645435935, "xcomet_score": 0.8622256517410278, "xcomet_qe_score": 0.9422425031661987, "metricx_score": 4.875784397125244, "metricx_qe_score": 5.4013895988464355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, CEAS applique le générateur à chaque document de note de version indépendamment et génère une note de version pour chaque classe.", "metrics": {"bleu_score": 44.18463817237388, "chrf_score": 73.96592959531206, "xcomet_score": 0.7183547019958496, "xcomet_qe_score": 0.8052898645401001, "metricx_score": 3.4629361629486084, "metricx_qe_score": 4.971240997314453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages de commit et les notes de version ne sont pas connues.", "metrics": {"bleu_score": 87.25129388059685, "chrf_score": 88.9439687610274, "xcomet_score": 0.9098104238510132, "xcomet_qe_score": 0.9083766937255859, "metricx_score": 4.108484268188477, "metricx_qe_score": 3.923499584197998, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classificateur, nous", "metrics": {"bleu_score": 4.635255558867621, "chrf_score": 26.72899962387776, "xcomet_score": 0.2246786504983902, "xcomet_qe_score": 0.1456054449081421, "metricx_score": 22.73112678527832, "metricx_qe_score": 21.206018447875977, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "modélisons le modèle de résumé abstrait en utilisant deux méthodes différentes.", "metrics": {"bleu_score": 17.45832536535669, "chrf_score": 42.143167726030015, "xcomet_score": 0.4751463532447815, "xcomet_qe_score": 0.6965922117233276, "metricx_score": 5.77908992767334, "metricx_qe_score": 4.636315822601318, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons CAS single, consiste en un réseau de séquence à séquence unique et génère un texte de note de version unique en fonction des messages de commit concaténés.", "metrics": {"bleu_score": 37.946845490636086, "chrf_score": 60.69947451102608, "xcomet_score": 0.5361528396606445, "xcomet_qe_score": 0.4384896755218506, "metricx_score": 8.501466751098633, "metricx_qe_score": 10.718367576599121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte de sortie peut être divisé en segments de classe basés sur des symboles d'endpoint spécifiques.", "metrics": {"bleu_score": 5.015684803505823, "chrf_score": 47.81714820850759, "xcomet_score": 0.870068371295929, "xcomet_qe_score": 0.9239861965179443, "metricx_score": 5.1494903564453125, "metricx_qe_score": 5.193815231323242, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons CAS multi, consiste en quatre réseaux de séquence à séquence différents, chacun correspondant à une des classes de notes de version. D'accord,", "metrics": {"bleu_score": 33.70346671329419, "chrf_score": 66.52772834327868, "xcomet_score": 0.16493698954582214, "xcomet_qe_score": 0.06155915558338165, "metricx_score": 8.405537605285645, "metricx_qe_score": 7.688580513000488, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "laissez-moi expliquer l'expérimentation.", "metrics": {"bleu_score": 5.4424142191183185, "chrf_score": 38.098677177003005, "xcomet_score": 0.6656920909881592, "xcomet_qe_score": 0.9022802710533142, "metricx_score": 2.0533666610717773, "metricx_qe_score": 1.4762637615203857, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons comparé cinq méthodes : CEAS, CAS single, CAS multi, clustering et le précédent étude G Riff.", "metrics": {"bleu_score": 14.962848372546674, "chrf_score": 44.124194191021274, "xcomet_score": 0.5603567361831665, "xcomet_qe_score": 0.6617116928100586, "metricx_score": 8.975726127624512, "metricx_qe_score": 8.658864974975586, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation, dans certains cas, les notes de version sont sorties en plusieurs phrases.", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 90.58047432035528, "xcomet_score": 0.7816237211227417, "xcomet_qe_score": 0.7042930126190186, "metricx_score": 5.304062843322754, "metricx_qe_score": 5.137981414794922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Comme il est difficile de compter le nombre de phrases, car elles sont combinées avec des espaces et traitées comme une seule phrase.", "metrics": {"bleu_score": 56.85277362397706, "chrf_score": 71.45615018271452, "xcomet_score": 0.776105523109436, "xcomet_qe_score": 0.77984619140625, "metricx_score": 6.238224029541016, "metricx_qe_score": 6.559215545654297, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bleu est pénalisé lorsque le système produit une phrase courte.", "metrics": {"bleu_score": 82.651681837938, "chrf_score": 89.67186675288784, "xcomet_score": 0.9623711109161377, "xcomet_qe_score": 0.9476519823074341, "metricx_score": 4.554554462432861, "metricx_qe_score": 6.27435302734375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cela résulte en un score bleu plus bas dans les résultats des expériences décrites ci-dessous.", "metrics": {"bleu_score": 10.75353500850704, "chrf_score": 46.04774347723123, "xcomet_score": 0.9886157512664795, "xcomet_qe_score": 0.9971194267272949, "metricx_score": 3.7503676414489746, "metricx_qe_score": 4.207742691040039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous calculons la spécificité, car rouge et bleu ne peuvent pas être calculés si les notes de version sont vides.", "metrics": {"bleu_score": 65.88303014746784, "chrf_score": 76.73197169440543, "xcomet_score": 0.9271790981292725, "xcomet_qe_score": 0.8586359620094299, "metricx_score": 2.3902359008789062, "metricx_qe_score": 2.92130184173584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une spécificité plus élevée signifie que le modèle produit correctement un texte vides dans les cas où les notes de version supposent vides. Voici", "metrics": {"bleu_score": 71.5993127858204, "chrf_score": 86.87772034709282, "xcomet_score": 0.3386417627334595, "xcomet_qe_score": 0.2774960994720459, "metricx_score": 8.9085054397583, "metricx_qe_score": 9.997902870178223, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "les résultats.", "metrics": {"bleu_score": 0.0, "chrf_score": 32.98892935351539, "xcomet_score": 0.24204929172992706, "xcomet_qe_score": 0.513332724571228, "metricx_score": 3.185957193374634, "metricx_qe_score": 1.1644279956817627, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que le dataset contient adresses e-mail, valeurs de hachage, etc., nous évaluons également le dataset nettoyé, qui exclut ces éléments.", "metrics": {"bleu_score": 18.512304388428547, "chrf_score": 47.483851378756455, "xcomet_score": 0.9210472106933594, "xcomet_qe_score": 0.8933864831924438, "metricx_score": 6.172156810760498, "metricx_qe_score": 5.219042778015137, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "CEAS et CAS ont obtenu des scores bleu plus de 10 points que les baselines.", "metrics": {"bleu_score": 21.207657858555688, "chrf_score": 42.370752339271675, "xcomet_score": 0.4860910475254059, "xcomet_qe_score": 0.6006044745445251, "metricx_score": 16.353519439697266, "metricx_qe_score": 17.073678970336914, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur le dataset nettoyé, la différence de score entre le proposé et les baselines a grimpé à plus de 20 points.", "metrics": {"bleu_score": 18.087131559310677, "chrf_score": 50.994006040900445, "xcomet_score": 0.2869452238082886, "xcomet_qe_score": 0.3709362745285034, "metricx_score": 7.844387054443359, "metricx_qe_score": 8.115097045898438, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent que CEAS et CAS sont significativement efficaces.", "metrics": {"bleu_score": 27.22179122549562, "chrf_score": 55.802864361542895, "xcomet_score": 0.4073452055454254, "xcomet_qe_score": 0.4271922707557678, "metricx_score": 13.387930870056152, "metricx_qe_score": 10.641275405883789, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "CAS a obtenu un score bleu plus élevé que CAS, suggérant que combiner un classificateur et un générateur est efficace et que l'entraînement du classificateur en utilisant des pseudo-étiquettes à chaque message de commit est possible.", "metrics": {"bleu_score": 8.836229201145114, "chrf_score": 54.03725264828866, "xcomet_score": 0.27581220865249634, "xcomet_qe_score": 0.26877328753471375, "metricx_score": 14.416228294372559, "metricx_qe_score": 15.179021835327148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "Une large couverture de CAS peut être atteinte correctement parce que le classificateur peut sélectionner les messages de commit pertinents pour chaque classe.", "metrics": {"bleu_score": 21.485473484453124, "chrf_score": 59.19309111854623, "xcomet_score": 0.579582691192627, "xcomet_qe_score": 0.6572777032852173, "metricx_score": 8.111611366271973, "metricx_qe_score": 7.8220624923706055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "CAS multi a tendance à être plus élevé que CAS single,", "metrics": {"bleu_score": 4.286580497900372, "chrf_score": 29.91567336524791, "xcomet_score": 0.3616175055503845, "xcomet_qe_score": 0.491767555475235, "metricx_score": 16.85719871520996, "metricx_qe_score": 17.007646560668945, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "suggérant que cela est également efficace. De plus, il est efficace de développer des modèles de résumé abstrait différents pour chaque classe de note de version.", "metrics": {"bleu_score": 36.34359728549337, "chrf_score": 65.65159783587184, "xcomet_score": 0.4866792559623718, "xcomet_qe_score": 0.1832943707704544, "metricx_score": 5.422595977783203, "metricx_qe_score": 6.295571327209473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Voici une analyse des erreurs.", "metrics": {"bleu_score": 32.46679154750991, "chrf_score": 77.55709249539119, "xcomet_score": 0.9845476150512695, "xcomet_qe_score": 0.9896132946014404, "metricx_score": 0.6455522179603577, "metricx_qe_score": 0.662600040435791, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes CEAS ont tendance à produire des phrases de note de version plus courtes que les phrases de note de version humaines.", "metrics": {"bleu_score": 43.600387912116446, "chrf_score": 78.24962228119401, "xcomet_score": 0.3962933421134949, "xcomet_qe_score": 0.4001891314983368, "metricx_score": 8.659329414367676, "metricx_qe_score": 7.442770957946777, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure à droite, la phrase de note de version humaine a trois ou quatre phrases, tandis que CAS a seulement une.", "metrics": {"bleu_score": 47.45748710485264, "chrf_score": 68.1476756706124, "xcomet_score": 0.6316806077957153, "xcomet_qe_score": 0.6198056936264038, "metricx_score": 9.157310485839844, "metricx_qe_score": 8.183584213256836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette tendance plus petite est que, dans les données d'entraînement, seulement 33 % des phrases sont présentes dans la classe de features et 40 % dans la classe d'améliorations.", "metrics": {"bleu_score": 18.864180856501438, "chrf_score": 48.14310751950702, "xcomet_score": 0.40466105937957764, "xcomet_qe_score": 0.5567406415939331, "metricx_score": 10.447322845458984, "metricx_qe_score": 9.32291030883789, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes CEAS ne peuvent pas générer des notes de version de release exactes sans informations supplémentaires.", "metrics": {"bleu_score": 51.0032342952127, "chrf_score": 81.42325424760891, "xcomet_score": 0.6595122218132019, "xcomet_qe_score": 0.5622327327728271, "metricx_score": 6.752686500549316, "metricx_qe_score": 7.437000751495361, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre un message de commit très sale et le texte de correction de bogues complet. Sans référence à la requête de prérequisition ou au problème", "metrics": {"bleu_score": 7.921748806115033, "chrf_score": 40.94121208894555, "xcomet_score": 0.3062167167663574, "xcomet_qe_score": 0.28082379698753357, "metricx_score": 14.739340782165527, "metricx_qe_score": 12.133023262023926, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": ", le message de commit d'entrée est lié et devrait être combiné en une seule phrase, mais il é", "metrics": {"bleu_score": 6.756180798528082, "chrf_score": 32.40364169575052, "xcomet_score": 0.2956054210662842, "xcomet_qe_score": 0.2966127097606659, "metricx_score": 17.919361114501953, "metricx_qe_score": 14.152889251708984, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "choue à le faire", "metrics": {"bleu_score": 7.545383788761362, "chrf_score": 6.22814132713996, "xcomet_score": 0.11941699683666229, "xcomet_qe_score": 0.10347357392311096, "metricx_score": 22.894372940063477, "metricx_qe_score": 20.479806900024414, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.37382936477661133, "xcomet_qe_score": 0.15948034822940826, "metricx_score": 12.271672248840332, "metricx_qe_score": 13.278233528137207, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3941587805747986, "xcomet_qe_score": 0.12588995695114136, "metricx_score": 17.730022430419922, "metricx_qe_score": 22.983081817626953, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1437925100326538, "xcomet_qe_score": 0.13020363450050354, "metricx_score": 19.038515090942383, "metricx_qe_score": 24.92869758605957, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": ".", "metrics": {"bleu_score": 0.0, "chrf_score": 3.3557046979865772, "xcomet_score": 0.17113067209720612, "xcomet_qe_score": 0.1920379400253296, "metricx_score": 15.909709930419922, "metricx_qe_score": 22.40385627746582, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Bon", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5662859678268433, "xcomet_qe_score": 0.49163341522216797, "metricx_score": 4.105462074279785, "metricx_qe_score": 0.32497796416282654, "linguapy_score": [1, "TSWANA"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "jour, je m'appelle Asaf Farhi", "metrics": {"bleu_score": 13.741272855400096, "chrf_score": 51.44032791496538, "xcomet_score": 0.16881228983402252, "xcomet_qe_score": 0.15282079577445984, "metricx_score": 11.25389575958252, "metricx_qe_score": 13.926900863647461, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "et je présenterai notre article, enrichissement rapide des données tabulaires à l'aide d'architectures de transformateurs.", "metrics": {"bleu_score": 21.975573404796936, "chrf_score": 67.39201129147266, "xcomet_score": 0.898171067237854, "xcomet_qe_score": 0.8488132953643799, "metricx_score": 5.619754791259766, "metricx_qe_score": 6.68691349029541, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Les scientifiques de données analysent et se concentrent principalement sur la manipulation des données,", "metrics": {"bleu_score": 46.84162031176824, "chrf_score": 75.20571009191566, "xcomet_score": 0.7593927383422852, "xcomet_qe_score": 0.9199492931365967, "metricx_score": 3.934692859649658, "metricx_qe_score": 3.3279266357421875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "mais parfois ces fonctionnalités sont limitées.", "metrics": {"bleu_score": 24.0785655451027, "chrf_score": 76.94819920746691, "xcomet_score": 0.9686001539230347, "xcomet_qe_score": 0.9744012951850891, "metricx_score": 0.21747228503227234, "metricx_qe_score": 0.22584828734397888, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de fonctionnalités à l'aide d'une autre source de données peut ajouter des informations substantielles.", "metrics": {"bleu_score": 63.019085559238604, "chrf_score": 85.59563264340478, "xcomet_score": 0.9069949388504028, "xcomet_qe_score": 0.8907005190849304, "metricx_score": 0.9914374947547913, "metricx_qe_score": 1.4706330299377441, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique des données tabulaires à l'aide de sources de texte externes.", "metrics": {"bleu_score": 41.421927364643544, "chrf_score": 76.59813169541488, "xcomet_score": 0.9847431182861328, "xcomet_qe_score": 1.0, "metricx_score": 0.8599205613136292, "metricx_qe_score": 0.9766317009925842, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous ayons un ensemble de données tabulaires et une base de connaissances.", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 89.73182752598848, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7479367256164551, "metricx_qe_score": 0.9663262367248535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique qui implique l'intelligence et l'analyse de texte pour extraire de nouvelles fonctionnalités de la base de connaissances.", "metrics": {"bleu_score": 62.04211920243652, "chrf_score": 81.4222579228706, "xcomet_score": 0.7198338508605957, "xcomet_qe_score": 0.73140549659729, "metricx_score": 3.9666240215301514, "metricx_qe_score": 4.264957904815674, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre, FIST, est exactement ce processus automatique.", "metrics": {"bleu_score": 51.93071778680675, "chrf_score": 85.35475993160114, "xcomet_score": 0.7016692757606506, "xcomet_qe_score": 0.45318108797073364, "metricx_score": 6.742191791534424, "metricx_qe_score": 7.3764777183532715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple.", "metrics": {"bleu_score": 6.6019821735025035, "chrf_score": 22.8797795576107, "xcomet_score": 0.20158059895038605, "xcomet_qe_score": 0.17158977687358856, "metricx_score": 4.844925403594971, "metricx_qe_score": 9.470410346984863, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans un ensemble de données alimenté par FIST, l", "metrics": {"bleu_score": 4.996872151825361, "chrf_score": 21.948778934659003, "xcomet_score": 0.1314590722322464, "xcomet_qe_score": 0.13128440082073212, "metricx_score": 24.49287986755371, "metricx_qe_score": 15.962525367736816, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "'objectif est de classer les universités en universités de rangs inférieurs et supérieurs.", "metrics": {"bleu_score": 38.044188232179025, "chrf_score": 62.31250913531975, "xcomet_score": 0.7379846572875977, "xcomet_qe_score": 0.38040977716445923, "metricx_score": 8.24801254272461, "metricx_qe_score": 8.073095321655273, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.37776264548301697, "metricx_qe_score": 0.43033844232559204, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de FIST est l'intelligence d'entité,", "metrics": {"bleu_score": 28.24099048856542, "chrf_score": 56.838607818710116, "xcomet_score": 0.336711049079895, "xcomet_qe_score": 0.4696105122566223, "metricx_score": 10.081666946411133, "metricx_qe_score": 10.240482330322266, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque chaque entité est liée à une entité au sein de la base de connaissances.", "metrics": {"bleu_score": 44.807644654473265, "chrf_score": 65.1357146319237, "xcomet_score": 0.7265175580978394, "xcomet_qe_score": 0.5560482144355774, "metricx_score": 2.688089370727539, "metricx_qe_score": 6.261187553405762, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "Et le texte de l'entité de la base est extrait et ajouté à l'ensemble de données.", "metrics": {"bleu_score": 29.213008358451262, "chrf_score": 58.913406213744594, "xcomet_score": 0.6745619177818298, "xcomet_qe_score": 0.6335662603378296, "metricx_score": 3.562539577484131, "metricx_qe_score": 5.26983118057251, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce cas, le texte est l'abstract de la page Wikipédia.", "metrics": {"bleu_score": 46.05329793777293, "chrf_score": 60.18466789132635, "xcomet_score": 0.9652774930000305, "xcomet_qe_score": 1.0, "metricx_score": 3.4598641395568848, "metricx_qe_score": 1.129764437675476, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Maintenant, nous devons générer ou extraire des fonctionnalités à partir du texte du rétroviseur.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 84.01423602138125, "xcomet_score": 0.5479313135147095, "xcomet_qe_score": 0.47070392966270447, "metricx_score": 6.114760398864746, "metricx_qe_score": 6.208062648773193, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'une phase de génération de fonctionnalités qui inclut l'analyse de texte.", "metrics": {"bleu_score": 20.79617953215787, "chrf_score": 54.01007394411792, "xcomet_score": 0.7923612594604492, "xcomet_qe_score": 0.8527778387069702, "metricx_score": 5.531298637390137, "metricx_qe_score": 6.2112250328063965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "C'est le principal atout de ce papier, et je plongerai plus en détail dans les prochaines diapositives.", "metrics": {"bleu_score": 22.537412722674855, "chrf_score": 48.521263554819164, "xcomet_score": 0.7082052230834961, "xcomet_qe_score": 0.6586751341819763, "metricx_score": 6.4848127365112305, "metricx_qe_score": 6.3679423332214355, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase de génération de fonctionnalités, il y a une phase de génération de fonctionnalités, où nous utilisons les fonctionnalités extraites pour générer un petit nombre de nouvelles fonctionnalités.", "metrics": {"bleu_score": 52.61086957134722, "chrf_score": 79.54273105038465, "xcomet_score": 0.5969147682189941, "xcomet_qe_score": 0.45533880591392517, "metricx_score": 8.05893611907959, "metricx_qe_score": 8.41463565826416, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "FIST génère des fonctionnalités dans le nombre de classes de l'ensemble de données original.", "metrics": {"bleu_score": 27.668736912821906, "chrf_score": 59.66581344775582, "xcomet_score": 0.25104230642318726, "xcomet_qe_score": 0.3846457898616791, "metricx_score": 9.906913757324219, "metricx_qe_score": 9.075445175170898, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce cas, l'ensemble de données original a deux classes", "metrics": {"bleu_score": 9.425159511373677, "chrf_score": 47.651380273373796, "xcomet_score": 0.9941680431365967, "xcomet_qe_score": 0.9875476360321045, "metricx_score": 1.9915473461151123, "metricx_qe_score": 1.438572645187378, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": ", donc FIST génère deux nouvelles fonctionnalités.", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 68.00250474288092, "xcomet_score": 0.6768835783004761, "xcomet_qe_score": 0.6829081773757935, "metricx_score": 8.49661922454834, "metricx_qe_score": 8.884109497070312, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si l'ensemble de données original a cinq classes, FIST génère cinq nouvelles fonctionnalités.", "metrics": {"bleu_score": 18.393816249638885, "chrf_score": 70.60461509250005, "xcomet_score": 0.7646777629852295, "xcomet_qe_score": 0.7853653430938721, "metricx_score": 6.769583225250244, "metricx_qe_score": 7.083215236663818, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque fonctionnalité représente la probabilité pour chaque classe.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 92.86672041709568, "xcomet_score": 0.8956412672996521, "xcomet_qe_score": 0.8998740315437317, "metricx_score": 1.7760814428329468, "metricx_qe_score": 2.313993453979492, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état de l'art de l'analyse de texte, qui est des modèles de langage basés sur les transformateurs, tels que BERT, GPT, XL, etc.", "metrics": {"bleu_score": 31.768724065877365, "chrf_score": 63.53925377489213, "xcomet_score": 0.7205873727798462, "xcomet_qe_score": 0.8395235538482666, "metricx_score": 4.760756969451904, "metricx_qe_score": 4.535482406616211, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "Mais il est peu probable que nous puissions entraîner un modèle de langage à l'aide des ensembles de données d'entrée.", "metrics": {"bleu_score": 37.12973183915444, "chrf_score": 59.24978422164807, "xcomet_score": 0.9276809692382812, "xcomet_qe_score": 0.967705488204956, "metricx_score": 2.6067559719085693, "metricx_qe_score": 2.0461435317993164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, un approche naïve sera une tâche de fine-tuning.", "metrics": {"bleu_score": 14.863756029007241, "chrf_score": 43.21682010561091, "xcomet_score": 0.6542739272117615, "xcomet_qe_score": 0.7907595634460449, "metricx_score": 7.81695556640625, "metricx_qe_score": 10.119810104370117, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la phase de génération de fonctionnalités, nous utilisons le modèle de langue pré-entraîné, nous finitions le modèle de langue sur l'ensemble de données cible.", "metrics": {"bleu_score": 20.664181816537017, "chrf_score": 53.8670402213824, "xcomet_score": 0.6207578182220459, "xcomet_qe_score": 0.7009265422821045, "metricx_score": 4.785640239715576, "metricx_qe_score": 4.505716323852539, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce cas, pour classifier le texte en classes, abstrait en classes, bas ou haut, nous", "metrics": {"bleu_score": 21.720532525066943, "chrf_score": 45.484047612904675, "xcomet_score": 0.2459891438484192, "xcomet_qe_score": 0.21584901213645935, "metricx_score": 19.690528869628906, "metricx_qe_score": 15.81758975982666, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "recevons le résultat du modèle de langue, qui est la probabilité pour chaque classe, et nous l'utilisons comme nouvelles fonctionnalités.", "metrics": {"bleu_score": 39.64513253420688, "chrf_score": 73.73557133166663, "xcomet_score": 0.8352675437927246, "xcomet_qe_score": 0.8519642949104309, "metricx_score": 2.3550925254821777, "metricx_qe_score": 3.2638354301452637, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que l'ensemble de données peut avoir peu de textes distincts.", "metrics": {"bleu_score": 32.55255736500994, "chrf_score": 73.04938300255375, "xcomet_score": 0.8719308376312256, "xcomet_qe_score": 0.9266866445541382, "metricx_score": 2.195298671722412, "metricx_qe_score": 2.4772045612335205, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, presque la moitié des ensembles de données contiennent moins de 400 échantillons, et le plus petit ensemble de données contient 35 échantillons.", "metrics": {"bleu_score": 22.90542233600848, "chrf_score": 64.35915899193108, "xcomet_score": 0.7960066795349121, "xcomet_qe_score": 0.8412407636642456, "metricx_score": 1.8472062349319458, "metricx_qe_score": 4.106289863586426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, finituner un modèle de langue sur cet ensemble de données sera inefficace.", "metrics": {"bleu_score": 28.18720423903185, "chrf_score": 62.252155876147974, "xcomet_score": 0.8757535219192505, "xcomet_qe_score": 0.9570024609565735, "metricx_score": 7.980397701263428, "metricx_qe_score": 7.688068389892578, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons utiliser la connaissance pré-analyisée des ensembles de données.", "metrics": {"bleu_score": 24.384183193426086, "chrf_score": 60.549940113450795, "xcomet_score": 0.8995493650436401, "xcomet_qe_score": 0.9121996760368347, "metricx_score": 4.888039588928223, "metricx_qe_score": 3.8252930641174316, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Puisque FIST est appliqué sur plusieurs ensembles de données, nous pouvons utiliser les ensembles de données n-1 pour recueillir des informations sur les ensembles de données n-1 et utiliser cette information lors de l'analyse de l'ensemble de données n.", "metrics": {"bleu_score": 24.01579640357113, "chrf_score": 59.39165057254051, "xcomet_score": 0.5840001702308655, "xcomet_qe_score": 0.6519129276275635, "metricx_score": 6.403476715087891, "metricx_qe_score": 6.494256973266602, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Ce que nous suggérons, c'est d'ajouter une autre phase de fine-tuning,", "metrics": {"bleu_score": 82.4236750264605, "chrf_score": 82.49323075678853, "xcomet_score": 0.8720411062240601, "xcomet_qe_score": 0.8516823053359985, "metricx_score": 4.637988090515137, "metricx_qe_score": 3.1668338775634766, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "une fine-tuning préliminaire multitâche, où nous fin", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 47.16980830985268, "xcomet_score": 0.25807270407676697, "xcomet_qe_score": 0.16616606712341309, "metricx_score": 16.1865234375, "metricx_qe_score": 13.136320114135742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "itions le modèle de langue sur les ensembles de données n-1.", "metrics": {"bleu_score": 37.95104907493076, "chrf_score": 51.75810203828406, "xcomet_score": 0.2199345827102661, "xcomet_qe_score": 0.1394248604774475, "metricx_score": 15.025369644165039, "metricx_qe_score": 15.827268600463867, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Et puis, nous exécutons une autre phase de fine-tuning, qui est une tâche de fine-tuning. Lorsque nous finitions le modèle de langue sur l'ensemble de données cible,", "metrics": {"bleu_score": 35.991632573423345, "chrf_score": 60.30454158576718, "xcomet_score": 0.47867393493652344, "xcomet_qe_score": 0.5162210464477539, "metricx_score": 9.399076461791992, "metricx_qe_score": 10.21457290649414, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "le multi-tâche à l'état de l'art,", "metrics": {"bleu_score": 5.693025330278465, "chrf_score": 18.394095140275102, "xcomet_score": 0.17254704236984253, "xcomet_qe_score": 0.18264636397361755, "metricx_score": 12.797849655151367, "metricx_qe_score": 13.02449893951416, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "appelé MTDNN, maintient un nombre de tâches dans l'ensemble de données d'entraînement.", "metrics": {"bleu_score": 36.05089705421052, "chrf_score": 58.31571713248108, "xcomet_score": 0.3163805603981018, "xcomet_qe_score": 0.4310302436351776, "metricx_score": 12.120795249938965, "metricx_qe_score": 10.620011329650879, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans ce cas, il y a quatre tâches dans l'ensemble de données d'entraînement.", "metrics": {"bleu_score": 26.760335424322005, "chrf_score": 38.837552268076806, "xcomet_score": 0.5738577842712402, "xcomet_qe_score": 0.48085495829582214, "metricx_score": 9.159900665283203, "metricx_qe_score": 5.726902484893799, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "Et il évalue le chemin de l", "metrics": {"bleu_score": 8.208611846457007, "chrf_score": 13.00541675983427, "xcomet_score": 0.1272815316915512, "xcomet_qe_score": 0.13428141176700592, "metricx_score": 22.04605484008789, "metricx_qe_score": 21.231319427490234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.25796476006507874, "xcomet_qe_score": 0.12716388702392578, "metricx_score": 12.818107604980469, "metricx_qe_score": 16.277889251708984, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "'avant-dernière.", "metrics": {"bleu_score": 0.0, "chrf_score": 8.149710523213745, "xcomet_score": 0.10910843312740326, "xcomet_qe_score": 0.1196179911494255, "metricx_score": 24.245702743530273, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, un ensemble de données tabulaires varie en nombre de classes. Donc,", "metrics": {"bleu_score": 31.46660996956415, "chrf_score": 75.909201755539, "xcomet_score": 0.7410643100738525, "xcomet_qe_score": 0.7116323709487915, "metricx_score": 5.872982978820801, "metricx_qe_score": 7.3341827392578125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "il y a de nombreuses tâches.", "metrics": {"bleu_score": 17.026116978186884, "chrf_score": 31.728092571514694, "xcomet_score": 0.9747439622879028, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.2858281135559082, "metricx_qe_score": 1.3629590272903442, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "MTDNN maintient un nombre de classes, de heads, de couches de sortie,", "metrics": {"bleu_score": 37.03014567724628, "chrf_score": 62.36536244433076, "xcomet_score": 0.6902543902397156, "xcomet_qe_score": 0.7051494121551514, "metricx_score": 9.130619049072266, "metricx_qe_score": 8.457784652709961, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "et il doit initialiser de nouveaux heads pour un ensemble de données avec une nouvelle tâche.", "metrics": {"bleu_score": 31.608817113056965, "chrf_score": 58.60029776304386, "xcomet_score": 0.4669235050678253, "xcomet_qe_score": 0.5793211460113525, "metricx_score": 9.887927055358887, "metricx_qe_score": 10.074845314025879, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche, appelée fine-tuning par reformulation de la tâche, reformule chaque ensemble de données en un problème de classification de phrase.", "metrics": {"bleu_score": 7.734255514246642, "chrf_score": 39.693540204883945, "xcomet_score": 0.5252740383148193, "xcomet_qe_score": 0.7185889482498169, "metricx_score": 7.600244522094727, "metricx_qe_score": 7.507552623748779, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "C'est un problème", "metrics": {"bleu_score": 0.0, "chrf_score": 9.304075269167672, "xcomet_score": 0.12342571467161179, "xcomet_qe_score": 0.11026833206415176, "metricx_score": 14.460199356079102, "metricx_qe_score": 15.048233032226562, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "de deux classes.", "metrics": {"bleu_score": 0.8314778786502932, "chrf_score": 10.762729942918362, "xcomet_score": 0.1280108243227005, "xcomet_qe_score": 0.15452051162719727, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Donc", "metrics": {"bleu_score": 0.0, "chrf_score": 1.0533280813776709, "xcomet_score": 0.14162497222423553, "xcomet_qe_score": 0.1450032889842987, "metricx_score": 24.847265243530273, "metricx_qe_score": 16.697864532470703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": ", nous entraînons le modèle de langue à classer un texte, l", "metrics": {"bleu_score": 5.493106946892139, "chrf_score": 24.340790993751586, "xcomet_score": 0.21364811062812805, "xcomet_qe_score": 0.12530545890331268, "metricx_score": 24.98015785217285, "metricx_qe_score": 20.477792739868164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "'abstract,", "metrics": {"bleu_score": 0.0, "chrf_score": 3.4582674639181437, "xcomet_score": 0.12511096894741058, "xcomet_qe_score": 0.12894481420516968, "metricx_score": 21.566925048828125, "metricx_qe_score": 20.238605499267578, "linguapy_score": [1, "CATALAN"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "et", "metrics": {"bleu_score": 0.0, "chrf_score": 2.5324615526291554, "xcomet_score": 0.12012706696987152, "xcomet_qe_score": 0.14428019523620605, "metricx_score": 22.530715942382812, "metricx_qe_score": 19.735395431518555, "linguapy_score": [1, "BOKMAL"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.1376691460609436, "xcomet_qe_score": 0.13215631246566772, "metricx_score": 7.765192985534668, "metricx_qe_score": 6.248663902282715, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.29320693016052246, "xcomet_qe_score": 0.11610673367977142, "metricx_score": 6.604457855224609, "metricx_qe_score": 7.763351917266846, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "la classe", "metrics": {"bleu_score": 0.0, "chrf_score": 5.250400140627457, "xcomet_score": 0.12024504691362381, "xcomet_qe_score": 0.11262135952711105, "metricx_score": 24.697839736938477, "metricx_qe_score": 24.681264877319336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.4124565124511719, "xcomet_qe_score": 0.14505784213542938, "metricx_score": 13.648260116577148, "metricx_qe_score": 7.963228702545166, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "en true ou false.", "metrics": {"bleu_score": 1.1524190727977786, "chrf_score": 4.70499487699938, "xcomet_score": 0.14122234284877777, "xcomet_qe_score": 0.1535109132528305, "metricx_score": 22.83077049255371, "metricx_qe_score": 17.308029174804688, "linguapy_score": [1, "CATALAN"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "Ou", "metrics": {"bleu_score": 0.0, "chrf_score": 0.748502994011976, "xcomet_score": 0.1488403081893921, "xcomet_qe_score": 0.11821246147155762, "metricx_score": 19.338348388671875, "metricx_qe_score": 17.103248596191406, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": ", en d'autres termes", "metrics": {"bleu_score": 0.164346668917794, "chrf_score": 4.539165698231519, "xcomet_score": 0.132258802652359, "xcomet_qe_score": 0.13407070934772491, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": ", nous entraînons le modèle de langue", "metrics": {"bleu_score": 3.2720332204836837, "chrf_score": 20.041174295695672, "xcomet_score": 0.13426581025123596, "xcomet_qe_score": 0.13757005333900452, "metricx_score": 20.847063064575195, "metricx_qe_score": 22.033309936523438, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.23577500879764557, "xcomet_qe_score": 0.12381035089492798, "metricx_score": 16.462228775024414, "metricx_qe_score": 20.504234313964844, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.4515254497528076, "xcomet_qe_score": 0.2778953015804291, "metricx_score": 10.858820915222168, "metricx_qe_score": 5.924997329711914, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "à clas", "metrics": {"bleu_score": 0.0, "chrf_score": 1.2927455272891974, "xcomet_score": 0.13258522748947144, "xcomet_qe_score": 0.1481105238199234, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.31220752000808716, "xcomet_qe_score": 0.21672064065933228, "metricx_score": 12.508068084716797, "metricx_qe_score": 6.163426876068115, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3622467517852783, "xcomet_qe_score": 0.23716911673545837, "metricx_score": 13.831912994384766, "metricx_qe_score": 12.880477905273438, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.22709991037845612, "xcomet_qe_score": 0.1316765695810318, "metricx_score": 21.842876434326172, "metricx_qe_score": 10.16723918914795, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3595518469810486, "xcomet_qe_score": 0.2662416100502014, "metricx_score": 5.03074836730957, "metricx_qe_score": 4.085866451263428, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "ser un abstract", "metrics": {"bleu_score": 0.0, "chrf_score": 2.644005130373099, "xcomet_score": 0.1208762526512146, "xcomet_qe_score": 0.1431000977754593, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "CATALAN"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "et", "metrics": {"bleu_score": 0.0, "chrf_score": 2.4338399404825166, "xcomet_score": 0.15026290714740753, "xcomet_qe_score": 0.1470421701669693, "metricx_score": 22.218059539794922, "metricx_qe_score": 18.20507049560547, "linguapy_score": [1, "BOKMAL"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "une classe", "metrics": {"bleu_score": 0.0, "chrf_score": 2.6934960908964327, "xcomet_score": 0.13777872920036316, "xcomet_qe_score": 0.13518600165843964, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3209593594074249, "xcomet_qe_score": 0.1465710550546646, "metricx_score": 13.286487579345703, "metricx_qe_score": 17.931087493896484, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.2275836169719696, "xcomet_qe_score": 0.2191668152809143, "metricx_score": 17.29458236694336, "metricx_qe_score": 19.0723934173584, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.22438043355941772, "xcomet_qe_score": 0.13017694652080536, "metricx_score": 17.605485916137695, "metricx_qe_score": 22.2198543548584, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "en true ou false", "metrics": {"bleu_score": 0.3756625385528342, "chrf_score": 3.6748890384153845, "xcomet_score": 0.12369021028280258, "xcomet_qe_score": 0.13416340947151184, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "CATALAN"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3800288438796997, "xcomet_qe_score": 0.23194606602191925, "metricx_score": 7.206099033355713, "metricx_qe_score": 11.551948547363281, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.10554730892181396, "xcomet_qe_score": 0.0831545889377594, "metricx_score": 12.068351745605469, "metricx_qe_score": 17.067914962768555, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.27820730209350586, "xcomet_qe_score": 0.10931731760501862, "metricx_score": 12.236217498779297, "metricx_qe_score": 16.78740692138672, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": ".", "metrics": {"bleu_score": 0.0, "chrf_score": 0.6640106241699867, "xcomet_score": 0.2148355394601822, "xcomet_qe_score": 0.15374431014060974, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Bon", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5662859678268433, "xcomet_qe_score": 0.49163341522216797, "metricx_score": 4.105462074279785, "metricx_qe_score": 0.32497796416282654, "linguapy_score": [1, "TSWANA"]}}
