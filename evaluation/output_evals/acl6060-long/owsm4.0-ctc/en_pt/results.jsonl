{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "pt", "output": "Olá todos. Hoje vou apresentar o nosso trabalho de pesquisa, \"Apren a racioar detaivamente\", soluolução de problemasétrica como extração de raão complexa.", "metrics": {"bleu_score": 35.218565358232375, "chrf_score": 58.08115429278018, "xcomet_score": 0.33180224895477295, "xcomet_qe_score": 0.4647725522518158, "metricx_score": 17.751691818237305, "metricx_qe_score": 17.663066864013672, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "pt", "output": "Sou Alan do Biden AI La, e é um trabalho conjunto com Chery da Universidade de Texas em Austin e Weidu da SUDD.", "metrics": {"bleu_score": 18.491805938391913, "chrf_score": 54.6942991449644, "xcomet_score": 0.40376773476600647, "xcomet_qe_score": 0.39749962091445923, "metricx_score": 14.057106018066406, "metricx_qe_score": 14.463908195495605, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, gostaria de falar da nossa motivação para racioamento.", "metrics": {"bleu_score": 40.292759186936564, "chrf_score": 72.63342640354624, "xcomet_score": 0.979999303817749, "xcomet_qe_score": 1.0, "metricx_score": 1.3190094232559204, "metricx_qe_score": 2.3016085624694824, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "pt", "output": "Estaquí mostrando ejemplos en donde razonamiento varias pasos es útil.", "metrics": {"bleu_score": 6.249439580998987, "chrf_score": 30.594785498846722, "xcomet_score": 0.701005756855011, "xcomet_qe_score": 0.7973818182945251, "metricx_score": 8.453009605407715, "metricx_qe_score": 6.998513221740723, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "pt", "output": "Esta figura es tomada del Palm donde hacenn inciones para resolver el problema de método en un corto de aprendizaje.", "metrics": {"bleu_score": 3.9592150017498815, "chrf_score": 38.28259571676036, "xcomet_score": 0.21001151204109192, "xcomet_qe_score": 0.26853203773498535, "metricx_score": 16.502277374267578, "metricx_qe_score": 15.776036262512207, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "pt", "output": "En la ladoqui, podemos ver que si damos algunas ejemplos con preguntas y respuestas, no podemos obtener las respuestas correctas.", "metrics": {"bleu_score": 10.59944676037994, "chrf_score": 45.19731753395213, "xcomet_score": 0.7272813320159912, "xcomet_qe_score": 0.7926825881004333, "metricx_score": 11.567166328430176, "metricx_qe_score": 9.021406173706055, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "pt", "output": "Pero si damos más descrición de razonamiento, el modelo es capaz predecir la descripción de razamiento y también hacer una prección correcta aquí.", "metrics": {"bleu_score": 2.264882092592075, "chrf_score": 32.060787628873804, "xcomet_score": 0.9117003083229065, "xcomet_qe_score": 0.9275760650634766, "metricx_score": 5.647737503051758, "metricx_qe_score": 6.203554630279541, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "pt", "output": "Así bueno tener razonamientometas como, y", "metrics": {"bleu_score": 4.935157841536379, "chrf_score": 20.544414675683946, "xcomet_score": 0.14805828034877777, "xcomet_qe_score": 0.15623146295547485, "metricx_score": 24.771028518676758, "metricx_qe_score": 22.30055046081543, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "pt", "output": "también creemos que el problema meta es una aplicación sencilla para evaluar habilidades de razonamiento.", "metrics": {"bleu_score": 3.0521968279991727, "chrf_score": 36.486615780032345, "xcomet_score": 0.7834481000900269, "xcomet_qe_score": 0.8152846097946167, "metricx_score": 6.471136093139648, "metricx_qe_score": 5.5881524085998535, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "pt", "output": "here in our problem setup given the questions we need to solve this question and obtain the numerical answers so in our data sets", "metrics": {"bleu_score": 0.0, "chrf_score": 21.96404935591827, "xcomet_score": 0.7561696767807007, "xcomet_qe_score": 0.8192048072814941, "metricx_score": 20.415912628173828, "metricx_qe_score": 21.427448272705078, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "pt", "output": "we are also given the mathematical expression which leads to the to this particular answer", "metrics": {"bleu_score": 1.7615754147008857, "chrf_score": 24.494095041127185, "xcomet_score": 0.46442100405693054, "xcomet_qe_score": 0.6907552480697632, "metricx_score": 25.0, "metricx_qe_score": 23.411531448364258, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "pt", "output": "as well so certain assumptions also apply as in previous work we assume", "metrics": {"bleu_score": 0.0, "chrf_score": 19.145000594869018, "xcomet_score": 0.5112959146499634, "xcomet_qe_score": 0.7646619081497192, "metricx_score": 14.191786766052246, "metricx_qe_score": 9.730314254760742, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "pt", "output": "the precision of quantities are known and we only", "metrics": {"bleu_score": 0.0, "chrf_score": 22.49501060758788, "xcomet_score": 0.2619631290435791, "xcomet_qe_score": 0.80713951587677, "metricx_score": 23.412132263183594, "metricx_qe_score": 19.884138107299805, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "pt", "output": "consider basic operators such as addition subtractions multiplication division and exponential further", "metrics": {"bleu_score": 0.0, "chrf_score": 37.08233299121093, "xcomet_score": 0.36387374997138977, "xcomet_qe_score": 0.8313822746276855, "metricx_score": 16.235902786254883, "metricx_qe_score": 8.066217422485352, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "pt", "output": "more complicated operators can be actually decomposed into these basic operators so", "metrics": {"bleu_score": 0.0, "chrf_score": 31.865010490669448, "xcomet_score": 0.9056811332702637, "xcomet_qe_score": 0.9767919778823853, "metricx_score": 23.42499542236328, "metricx_qe_score": 19.74663543701172, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "pt", "output": "previous work in method problem solving actually can categorize into sequence to sequence and sequence to tree model so traditional sequ", "metrics": {"bleu_score": 1.431306716763, "chrf_score": 27.803432785460053, "xcomet_score": 0.3328726887702942, "xcomet_qe_score": 0.7096982002258301, "metricx_score": 23.083133697509766, "metricx_qe_score": 15.007949829101562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "pt", "output": "ence to sequence model convert the expression to a specific sequence for generation and it is", "metrics": {"bleu_score": 2.0274685852177114, "chrf_score": 26.29086827001102, "xcomet_score": 0.2649594247341156, "xcomet_qe_score": 0.7223929166793823, "metricx_score": 25.0, "metricx_qe_score": 24.542011260986328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "pt", "output": "pretty easy to implement and it can generalize to many different complicated problem but", "metrics": {"bleu_score": 0.0, "chrf_score": 41.84132147867117, "xcomet_score": 0.675355076789856, "xcomet_qe_score": 0.899552583694458, "metricx_score": 25.0, "metricx_qe_score": 24.959941864013672, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "pt", "output": "the drawback of the performance is actually gen generally not better than the structure model and it is lack of the interpretability for prediction but", "metrics": {"bleu_score": 0.0, "chrf_score": 27.19715318726246, "xcomet_score": 0.388873428106308, "xcomet_qe_score": 0.7832087874412537, "metricx_score": 18.76921272277832, "metricx_qe_score": 15.843576431274414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "pt", "output": "actually this direction is still quite popular because of the transformer model so", "metrics": {"bleu_score": 2.2708927002193318, "chrf_score": 30.039986291066423, "xcomet_score": 0.9142258167266846, "xcomet_qe_score": 0.9341092109680176, "metricx_score": 25.0, "metricx_qe_score": 20.17509651184082, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "pt", "output": "in tree based models we actually structure these expressions in the tree form and follow a pre-order traversal in tree generations so here", "metrics": {"bleu_score": 0.0, "chrf_score": 24.627946510156136, "xcomet_score": 0.8105852603912354, "xcomet_qe_score": 0.8087471723556519, "metricx_score": 23.684600830078125, "metricx_qe_score": 23.958415985107422, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "pt", "output": "we keep generating the operators until we reach the leaves which are the quantities so here the good thing is that", "metrics": {"bleu_score": 0.0, "chrf_score": 19.92893624102689, "xcomet_score": 0.4426286816596985, "xcomet_qe_score": 0.7733438014984131, "metricx_score": 20.77558708190918, "metricx_qe_score": 22.07383918762207, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "pt", "output": "it actually gives us this binary tree structure and it is um but but but actually it is quite counterintivity because we generate the operator first and then at the end we generate the quantities and the second thing is that", "metrics": {"bleu_score": 0.0, "chrf_score": 22.714219632056192, "xcomet_score": 0.2785783112049103, "xcomet_qe_score": 0.6112841367721558, "metricx_score": 24.574708938598633, "metricx_qe_score": 20.66203498840332, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "pt", "output": "it also contains some repetitive computations", "metrics": {"bleu_score": 0.0, "chrf_score": 23.9568476734486, "xcomet_score": 0.9547578692436218, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 25.0, "metricx_qe_score": 21.25971794128418, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "pt", "output": "so here if we look at this expression a times three plus three is actually generated twice but in fact we should reuse the results so in our", "metrics": {"bleu_score": 0.0, "chrf_score": 19.964881065436366, "xcomet_score": 0.4378962516784668, "xcomet_qe_score": 0.7474371194839478, "metricx_score": 25.0, "metricx_qe_score": 21.34955406188965, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "pt", "output": "proposed approach we want to solve those problems in a step-by step and interpretable manners so for example", "metrics": {"bleu_score": 2.031628835361819, "chrf_score": 32.1886889904169, "xcomet_score": 0.649481475353241, "xcomet_qe_score": 0.8704860210418701, "metricx_score": 23.777315139770508, "metricx_qe_score": 23.845001220703125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "pt", "output": "here in the second step we can obtain this divisors which is 27 and we", "metrics": {"bleu_score": 0.0, "chrf_score": 19.955295580144135, "xcomet_score": 0.40397191047668457, "xcomet_qe_score": 0.8688669204711914, "metricx_score": 18.649497985839844, "metricx_qe_score": 11.046121597290039, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "pt", "output": "can also refer back to the original questions to find the relevant contents and in these steps we", "metrics": {"bleu_score": 0.0, "chrf_score": 25.61009857507405, "xcomet_score": 0.4540509879589081, "xcomet_qe_score": 0.8198195099830627, "metricx_score": 21.89133644104004, "metricx_qe_score": 16.532135009765625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "pt", "output": "obtain the divisors so", "metrics": {"bleu_score": 0.0, "chrf_score": 25.62789344566338, "xcomet_score": 0.3087128698825836, "xcomet_qe_score": 0.9353439807891846, "metricx_score": 24.409788131713867, "metricx_qe_score": 17.826519012451172, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "pt", "output": "and then at this third step we actually get the quotient all", "metrics": {"bleu_score": 0.0, "chrf_score": 13.65068722607794, "xcomet_score": 0.872044563293457, "xcomet_qe_score": 0.9163769483566284, "metricx_score": 23.125244140625, "metricx_qe_score": 21.420907974243164, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "pt", "output": "right and after these three steps we can actually reuse the results from the second step and then gets the results of the fourth step and then finally we can obtain the dividends so here we actually generate the whole", "metrics": {"bleu_score": 0.0, "chrf_score": 22.349633274364976, "xcomet_score": 0.6659330129623413, "xcomet_qe_score": 0.7014734745025635, "metricx_score": 18.154653549194336, "metricx_qe_score": 11.337646484375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "pt", "output": "expression directly rather than generating a single operators or quantities so this makes the process more accurate.", "metrics": {"bleu_score": 2.5540496664715904, "chrf_score": 25.376906633653835, "xcomet_score": 0.38889241218566895, "xcomet_qe_score": 0.9272853136062622, "metricx_score": 21.777355194091797, "metricx_qe_score": 17.461328506469727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "pt", "output": "So in our deductive system", "metrics": {"bleu_score": 0.0, "chrf_score": 9.432529519024117, "xcomet_score": 0.19916090369224548, "xcomet_qe_score": 0.5704644918441772, "metricx_score": 23.10126304626465, "metricx_qe_score": 7.351744651794434, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "pt", "output": "we first start with a bunch of quantities presented in the questions and also including some constants as our initial initial state.", "metrics": {"bleu_score": 1.5766042244954548, "chrf_score": 25.044519986611828, "xcomet_score": 0.8441674709320068, "xcomet_qe_score": 0.8767889738082886, "metricx_score": 25.0, "metricx_qe_score": 21.34977149963379, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "pt", "output": "So the expression is represented by eijo where we perform operator", "metrics": {"bleu_score": 0.0, "chrf_score": 37.982630099093704, "xcomet_score": 0.6351852416992188, "xcomet_qe_score": 0.8605688810348511, "metricx_score": 10.850564956665039, "metricx_qe_score": 9.073737144470215, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "pt", "output": "fromqi to qj and such expression is actually directed so we also have", "metrics": {"bleu_score": 0.0, "chrf_score": 21.871386547404338, "xcomet_score": 0.5254322290420532, "xcomet_qe_score": 0.8661322593688965, "metricx_score": 22.5826358795166, "metricx_qe_score": 17.062896728515625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "pt", "output": "subtraction reverse here to represent the opposite direction this is", "metrics": {"bleu_score": 0.0, "chrf_score": 24.013194819161406, "xcomet_score": 0.2580838203430176, "xcomet_qe_score": 0.7731728553771973, "metricx_score": 17.78505516052246, "metricx_qe_score": 14.142266273498535, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "pt", "output": "quite similar to relation extraction so", "metrics": {"bleu_score": 11.631736348831648, "chrf_score": 45.659786301369955, "xcomet_score": 0.6006234884262085, "xcomet_qe_score": 0.8971746563911438, "metricx_score": 17.843360900878906, "metricx_qe_score": 9.108572006225586, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "pt", "output": "in a formal deductive system at the time step T we apply the operator between theqi and qj pair and then we obtain this new expressions we add it to the to", "metrics": {"bleu_score": 1.089692270146855, "chrf_score": 25.943783998081187, "xcomet_score": 0.5244882702827454, "xcomet_qe_score": 0.7807875871658325, "metricx_score": 15.554153442382812, "metricx_qe_score": 8.657320976257324, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "pt", "output": "the next states to become a new quantity so this slides actually", "metrics": {"bleu_score": 0.0, "chrf_score": 16.03692119170594, "xcomet_score": 0.2572943866252899, "xcomet_qe_score": 0.7413424849510193, "metricx_score": 21.29660415649414, "metricx_qe_score": 16.61834716796875, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "pt", "output": "visualize the evolution of the states where we keep adding expression to the current states so in our model implementations we first use a", "metrics": {"bleu_score": 1.5732934811145336, "chrf_score": 26.99780010216311, "xcomet_score": 0.2701592445373535, "xcomet_qe_score": 0.3532397449016571, "metricx_score": 21.313613891601562, "metricx_qe_score": 21.093812942504883, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "pt", "output": "pre-traination model can which can be birds or raw hers and then we encode the sentence and then we obtain these quantity representation de quantidades quando", "metrics": {"bleu_score": 2.293771171012122, "chrf_score": 24.24755636420739, "xcomet_score": 0.22128042578697205, "xcomet_qe_score": 0.13297885656356812, "metricx_score": 25.0, "metricx_qe_score": 23.483768463134766, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "pt", "output": "termos as representações de quantidades podemos começar a fazer inferência", "metrics": {"bleu_score": 35.21740722723756, "chrf_score": 80.27838062529972, "xcomet_score": 0.9345232844352722, "xcomet_qe_score": 0.9429903626441956, "metricx_score": 5.756290912628174, "metricx_qe_score": 5.618946075439453, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "pt", "output": "aquiqui mostra um exemplo de Q1 para obter a representação de q1 dividido por q2 e times q3", "metrics": {"bleu_score": 11.88024953945528, "chrf_score": 56.68034441894068, "xcomet_score": 0.8038433790206909, "xcomet_qe_score": 0.8087785243988037, "metricx_score": 14.892200469970703, "metricx_qe_score": 14.900875091552734, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "pt", "output": "primeiro ob temosmos a representação de pare que é basicamente apenas a concatenação entre q1 e q2 e depois aplicamos uma rede which is parameterized by the operator and", "metrics": {"bleu_score": 22.234822300389055, "chrf_score": 62.66436996343329, "xcomet_score": 0.38673242926597595, "xcomet_qe_score": 0.32540449500083923, "metricx_score": 21.33949089050293, "metricx_qe_score": 18.708721160888672, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "pt", "output": "then finally we obtain the expression representation q1 divided by q2 but", "metrics": {"bleu_score": 0.0, "chrf_score": 33.74194882431654, "xcomet_score": 0.7009997963905334, "xcomet_qe_score": 0.8830041885375977, "metricx_score": 22.46721649169922, "metricx_qe_score": 15.573731422424316, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "pt", "output": "in fret in practice in the inference stage we might be able to get the incorrect incorrect expression as well", "metrics": {"bleu_score": 0.0, "chrf_score": 24.18575408908393, "xcomet_score": 0.3801654279232025, "xcomet_qe_score": 0.7022677659988403, "metricx_score": 21.887432098388672, "metricx_qe_score": 18.74171257019043, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "pt", "output": "so here all the possible expression is = 3 x ni operatori he that ychwanegu cyfy", "metrics": {"bleu_score": 0.0, "chrf_score": 22.993317302320733, "xcomet_score": 0.22729846835136414, "xcomet_qe_score": 0.25143325328826904, "metricx_score": 21.772035598754883, "metricx_qe_score": 21.523826599121094, "linguapy_score": [1, "WELSH"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "pt", "output": "i control ch enraifft os nad ywr myne can gall tyr y h yn ch yn y ail", "metrics": {"bleu_score": 0.0, "chrf_score": 12.573330458536583, "xcomet_score": 0.19770392775535583, "xcomet_qe_score": 0.10572200268507004, "metricx_score": 25.0, "metricx_qe_score": 24.478254318237305, "linguapy_score": [1, "WELSH"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "pt", "output": "gamne yr un onr unig the only difference is one more quantities so this quantity comes from the previous calculated expression so", "metrics": {"bleu_score": 0.0, "chrf_score": 20.66747125887145, "xcomet_score": 0.20645686984062195, "xcomet_qe_score": 0.12455516308546066, "metricx_score": 25.0, "metricx_qe_score": 24.820941925048828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "pt", "output": "finally we can obtain this final expression", "metrics": {"bleu_score": 0.0, "chrf_score": 7.543216895981921, "xcomet_score": 0.14508157968521118, "xcomet_qe_score": 0.1460917592048645, "metricx_score": 16.39865493774414, "metricx_qe_score": 16.6411075592041, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "pt", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5292553901672363, "xcomet_qe_score": 0.24470075964927673, "metricx_score": 7.748910427093506, "metricx_qe_score": 10.157403945922852, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "pt", "output": "q3 times q4 and", "metrics": {"bleu_score": 0.0, "chrf_score": 5.593281825348411, "xcomet_score": 0.4293871819972992, "xcomet_qe_score": 0.7247700691223145, "metricx_score": 16.286109924316406, "metricx_qe_score": 11.158473014831543, "linguapy_score": [1, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "pt", "output": "we can also see the number of all the possible expression is different from the previous step so such difference", "metrics": {"bleu_score": 0.0, "chrf_score": 24.665329967519497, "xcomet_score": 0.7405571341514587, "xcomet_qe_score": 0.797278642654419, "metricx_score": 20.303804397583008, "metricx_qe_score": 17.898239135742188, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "pt", "output": "make it hard to apply beam search because the probability distribution between these two steps is unbalanced so the", "metrics": {"bleu_score": 3.644358068198183, "chrf_score": 29.288816475423346, "xcomet_score": 0.5467914342880249, "xcomet_qe_score": 0.80796217918396, "metricx_score": 25.0, "metricx_qe_score": 24.052955627441406, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "pt", "output": "training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step and here", "metrics": {"bleu_score": 1.3149361462557834, "chrf_score": 25.412598764046667, "xcomet_score": 0.7461377382278442, "xcomet_qe_score": 0.9324690103530884, "metricx_score": 25.0, "metricx_qe_score": 23.86251449584961, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "pt", "output": "we also use this tau to represent when we should terminate the this generation process and here", "metrics": {"bleu_score": 2.2869567780619007, "chrf_score": 27.0274858711299, "xcomet_score": 0.8818679451942444, "xcomet_qe_score": 0.8658463954925537, "metricx_score": 17.309154510498047, "metricx_qe_score": 12.20770263671875, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "pt", "output": "the space is different from sequence to sequence because the space is different at each times that while in traditional sequence to sequence model it is the number of vocabulary and", "metrics": {"bleu_score": 0.0, "chrf_score": 28.101253797399384, "xcomet_score": 0.5224759578704834, "xcomet_qe_score": 0.6786623001098633, "metricx_score": 22.617746353149414, "metricx_qe_score": 18.458555221557617, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "pt", "output": "it also allows us to impose certain constraint from prior", "metrics": {"bleu_score": 0.0, "chrf_score": 21.397074802479853, "xcomet_score": 0.6872416734695435, "xcomet_qe_score": 0.9037892818450928, "metricx_score": 25.0, "metricx_qe_score": 16.880361557006836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "pt", "output": "from prior knowledge so we conduct experiments on the commonly used method problem data setsmwps method3k math qaA and swam and here we briefly shows", "metrics": {"bleu_score": 1.506189323093867, "chrf_score": 22.458680167246705, "xcomet_score": 0.27235665917396545, "xcomet_qe_score": 0.489337295293808, "metricx_score": 16.446636199951172, "metricx_qe_score": 15.40869140625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "pt", "output": "the results compared with the previous best approaches so our best performing weapon is", "metrics": {"bleu_score": 0.0, "chrf_score": 22.48115558600393, "xcomet_score": 0.31307390332221985, "xcomet_qe_score": 0.7072830200195312, "metricx_score": 21.634191513061523, "metricx_qe_score": 15.94504451751709, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "pt", "output": "Roberta deductive reason and in fact", "metrics": {"bleu_score": 0.0, "chrf_score": 24.26055786862698, "xcomet_score": 0.15736578404903412, "xcomet_qe_score": 0.23453542590141296, "metricx_score": 22.18834686279297, "metricx_qe_score": 18.034847259521484, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "pt", "output": "we do not use beam search in contrast obvious approaches using beam search all", "metrics": {"bleu_score": 4.223274988598439, "chrf_score": 31.804268802257756, "xcomet_score": 0.596558690071106, "xcomet_qe_score": 0.7744944095611572, "metricx_score": 20.259180068969727, "metricx_qe_score": 9.36143684387207, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "pt", "output": "right so the best approaches are often a treebased model so overall our reasoner is able to select", "metrics": {"bleu_score": 0.0, "chrf_score": 19.599200506902413, "xcomet_score": 0.3666868209838867, "xcomet_qe_score": 0.8166263103485107, "metricx_score": 16.32769775390625, "metricx_qe_score": 12.505002975463867, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "pt", "output": "significantly output from this tree-based model but we can see the absolute number on", "metrics": {"bleu_score": 0.0, "chrf_score": 21.49006884955944, "xcomet_score": 0.22694522142410278, "xcomet_qe_score": 0.18442754447460175, "metricx_score": 24.378496170043945, "metricx_qe_score": 19.348691940307617, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "pt", "output": "mathqaA or swam are not really high so we", "metrics": {"bleu_score": 0.0, "chrf_score": 9.01733453893667, "xcomet_score": 0.2852908968925476, "xcomet_qe_score": 0.5868818759918213, "metricx_score": 25.0, "metricx_qe_score": 18.216278076171875, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "pt", "output": "further investigate the results on swam and this", "metrics": {"bleu_score": 0.0, "chrf_score": 29.426322420841842, "xcomet_score": 0.34792113304138184, "xcomet_qe_score": 0.7887855768203735, "metricx_score": 18.243663787841797, "metricx_qe_score": 10.492362976074219, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "pt", "output": "data set is challenging because the author tried to manually adding something to confuse the nnb model like such as adding evaluate information and extra quant", "metrics": {"bleu_score": 1.337625779258248, "chrf_score": 25.91178370821182, "xcomet_score": 0.31890571117401123, "xcomet_qe_score": 0.5187437534332275, "metricx_score": 22.52733612060547, "metricx_qe_score": 17.14867401123047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "pt", "output": "ities so in our prediction we find some of the intermediate values are actually negatives", "metrics": {"bleu_score": 0.0, "chrf_score": 25.73331834137808, "xcomet_score": 0.8582925796508789, "xcomet_qe_score": 0.827588677406311, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "pt", "output": "for example in these questions we are asking how many apples does Jake have", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 19.179916940693722, "xcomet_score": 0.9433667659759521, "xcomet_qe_score": 0.985454797744751, "metricx_score": 21.70810890197754, "metricx_qe_score": 20.279052734375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "pt", "output": "but we have some extra information like 17 fewer pitchachees and Stephen have eight pitchaches which is totallylevant so our model makes some", "metrics": {"bleu_score": 1.5095250248540109, "chrf_score": 23.20385725726071, "xcomet_score": 0.2895539402961731, "xcomet_qe_score": 0.4295625388622284, "metricx_score": 23.65910530090332, "metricx_qe_score": 17.565547943115234, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "pt", "output": "prediction like this which is producing negative values and we observe these two represent these", "metrics": {"bleu_score": 0.0, "chrf_score": 21.939416006979574, "xcomet_score": 0.24492502212524414, "xcomet_qe_score": 0.8203924894332886, "metricx_score": 20.92079734802246, "metricx_qe_score": 17.285842895507812, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "pt", "output": "two expression actually have similar scores so we can actually", "metrics": {"bleu_score": 0.0, "chrf_score": 18.794856717757202, "xcomet_score": 0.38286301493644714, "xcomet_qe_score": 0.9358121156692505, "metricx_score": 21.61945343017578, "metricx_qe_score": 12.560081481933594, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "pt", "output": "limit this search space by removing like those results are negatives so that we can make the make the", "metrics": {"bleu_score": 0.0, "chrf_score": 21.680857370490635, "xcomet_score": 0.21652963757514954, "xcomet_qe_score": 0.4896521270275116, "metricx_score": 24.085689544677734, "metricx_qe_score": 20.507530212402344, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "pt", "output": "answer correct so we further find such constraint actually improves quite a lot for", "metrics": {"bleu_score": 0.0, "chrf_score": 17.885570614618047, "xcomet_score": 0.23389576375484467, "xcomet_qe_score": 0.5575159788131714, "metricx_score": 25.0, "metricx_qe_score": 21.132158279418945, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "pt", "output": "for for some model for example forögel mejoramos seven points und dann für das model Roberta mejoramos zwei points", "metrics": {"bleu_score": 1.476252438907077, "chrf_score": 28.592207080168848, "xcomet_score": 0.46680694818496704, "xcomet_qe_score": 0.6220991611480713, "metricx_score": 20.796157836914062, "metricx_qe_score": 20.282474517822266, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "pt", "output": "um besser model lenguaje model tem uma de comprensão so die Zahl hier ist superior für Roberta und inferior vo e", "metrics": {"bleu_score": 1.9300431450765245, "chrf_score": 22.413569648105995, "xcomet_score": 0.13683728873729706, "xcomet_qe_score": 0.151083305478096, "metricx_score": 21.968915939331055, "metricx_qe_score": 22.667442321777344, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "pt", "output": "também tenta alisar a dificulta detrás este assum", "metrics": {"bleu_score": 2.0315766105349127, "chrf_score": 36.415910448990545, "xcomet_score": 0.13598862290382385, "xcomet_qe_score": 0.14654025435447693, "metricx_score": 25.0, "metricx_qe_score": 24.090076446533203, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "pt", "output": "mos que el número de quantidades inusadas can be regarded as relevant information here so", "metrics": {"bleu_score": 10.511846841633776, "chrf_score": 43.65681332892777, "xcomet_score": 0.22277849912643433, "xcomet_qe_score": 0.41185399889945984, "metricx_score": 23.179977416992188, "metricx_qe_score": 21.60550308227539, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "pt", "output": "here we can see that uh we we have the lump the percentage of samples with unused quantities and the swamp data set has the largest portion and", "metrics": {"bleu_score": 0.0, "chrf_score": 21.312715226842815, "xcomet_score": 0.5823766589164734, "xcomet_qe_score": 0.5644848346710205, "metricx_score": 19.506298065185547, "metricx_qe_score": 17.173248291015625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "pt", "output": "here we also show the overall performance for those samples", "metrics": {"bleu_score": 0.0, "chrf_score": 17.045221538429395, "xcomet_score": 0.7540295720100403, "xcomet_qe_score": 0.9422651529312134, "metricx_score": 10.881179809570312, "metricx_qe_score": 8.344533920288086, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "pt", "output": "without unused quantities so the overall performance is actually higher di la performance è più altac la performance generale ma con mos", "metrics": {"bleu_score": 0.0, "chrf_score": 21.030773004172293, "xcomet_score": 0.19789227843284607, "xcomet_qe_score": 0.26774850487709045, "metricx_score": 21.556190490722656, "metricx_qe_score": 23.38172149658203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "pt", "output": "ts con una quantità inusata è molto peggio di peggio performance generale form", "metrics": {"bleu_score": 0.0, "chrf_score": 18.472447698611592, "xcomet_score": 0.16885685920715332, "xcomet_qe_score": 0.20493003726005554, "metricx_score": 18.190526962280273, "metricx_qe_score": 19.879390716552734, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "pt", "output": "Wps non abbiamo prea casos de quindi ignorre parte so finally we want to show the", "metrics": {"bleu_score": 4.776946190850103, "chrf_score": 22.184346049320027, "xcomet_score": 0.1298304945230484, "xcomet_qe_score": 0.1250413954257965, "metricx_score": 21.80144691467285, "metricx_qe_score": 22.53870964050293, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "pt", "output": "interpretability through a crash and presentation example so here our model actually makes a wrong", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 27.8118014212642, "xcomet_score": 0.26839059591293335, "xcomet_qe_score": 0.42629069089889526, "metricx_score": 23.326736450195312, "metricx_qe_score": 21.511146545410156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "pt", "output": "prediction at the at the first step so we can actually", "metrics": {"bleu_score": 0.0, "chrf_score": 10.042551737216128, "xcomet_score": 0.1498834192752838, "xcomet_qe_score": 0.17257454991340637, "metricx_score": 24.0323429107666, "metricx_qe_score": 21.771385192871094, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "pt", "output": "correlate the this expression with the sentence here all right so we", "metrics": {"bleu_score": 0.0, "chrf_score": 26.827136207259294, "xcomet_score": 0.2880445718765259, "xcomet_qe_score": 0.6869081258773804, "metricx_score": 18.311935424804688, "metricx_qe_score": 12.358561515808105, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "pt", "output": "think this sentence might be misleading the model to an incorrect predictions so here printing another 35", "metrics": {"bleu_score": 0.0, "chrf_score": 21.043654902523354, "xcomet_score": 0.2080031782388687, "xcomet_qe_score": 0.3291066884994507, "metricx_score": 23.482698440551758, "metricx_qe_score": 18.515104293823242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "pt", "output": "makes the model makes the model think it should be an addition operators so we try to revise the sentence to be", "metrics": {"bleu_score": 0.0, "chrf_score": 19.404170159153754, "xcomet_score": 0.23324362933635712, "xcomet_qe_score": 0.20099228620529175, "metricx_score": 24.646835327148438, "metricx_qe_score": 21.48443603515625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "pt", "output": "something like the number of pear trees are5 fewer than the apple trees so we make it to convey more acc", "metrics": {"bleu_score": 0.0, "chrf_score": 16.140763667445654, "xcomet_score": 0.30714938044548035, "xcomet_qe_score": 0.6326481103897095, "metricx_score": 24.12483024597168, "metricx_qe_score": 22.464706420898438, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "pt", "output": "urate semantics such that the model is able to make the prediction correct so this study shows how the", "metrics": {"bleu_score": 0.0, "chrf_score": 19.287256766658075, "xcomet_score": 0.26847153902053833, "xcomet_qe_score": 0.5453566312789917, "metricx_score": 22.16667366027832, "metricx_qe_score": 18.845054626464844, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "pt", "output": "interpretable predictions help us understand the model behavior so to", "metrics": {"bleu_score": 0.0, "chrf_score": 20.33211442100491, "xcomet_score": 0.35205769538879395, "xcomet_qe_score": 0.6781446933746338, "metricx_score": 23.83753204345703, "metricx_qe_score": 20.89530372619629, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "pt", "output": "conclude our work so first our model is actually pretty efficient and we are able", "metrics": {"bleu_score": 0.0, "chrf_score": 24.499464712256483, "xcomet_score": 0.685509204864502, "xcomet_qe_score": 0.8099948167800903, "metricx_score": 22.414125442504883, "metricx_qe_score": 17.425426483154297, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "pt", "output": "to provide interpretable solvings procedure and we can easily", "metrics": {"bleu_score": 0.0, "chrf_score": 28.043813315925075, "xcomet_score": 0.29126209020614624, "xcomet_qe_score": 0.8854293823242188, "metricx_score": 18.480209350585938, "metricx_qe_score": 12.172534942626953, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "pt", "output": "incorporate some prior knowledge as constraint which can help menkatkan ki performner.", "metrics": {"bleu_score": 2.2708927002193318, "chrf_score": 21.988862065817045, "xcomet_score": 0.2970625162124634, "xcomet_qe_score": 0.5015362501144409, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "pt", "output": "terakhir adalah mecanisme subja non hanya beku untuk tugas problem, sondern ke Aufgabe imp implica razamento multi.", "metrics": {"bleu_score": 1.09320016416171, "chrf_score": 20.18447652423735, "xcomet_score": 0.14468838274478912, "xcomet_qe_score": 0.1426743119955063, "metricx_score": 22.68755531311035, "metricx_qe_score": 23.165700912475586, "linguapy_score": [1, "INDONESIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "pt", "output": "Mas juga beberapa limitsi.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 17.219195929986366, "xcomet_score": 0.49516257643699646, "xcomet_qe_score": 0.44427061080932617, "metricx_score": 7.980397701263428, "metricx_qe_score": 4.758663654327393, "linguapy_score": [1, "INDONESIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "pt", "output": "J kita memiliki operator, konstanten konstanten, sum mem ziemlich high.", "metrics": {"bleu_score": 2.315472233965254, "chrf_score": 22.937226219996063, "xcomet_score": 0.13100212812423706, "xcomet_qe_score": 0.15025033056735992, "metricx_score": 23.704805374145508, "metricx_qe_score": 24.090351104736328, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "pt", "output": "segunda coisa é que, como dissedo, porque a distribuição de probabilidade é desequilibrada em diferentes passos tempo, por isso também é bastante difícil aplicar a estratégia de pesquisa.", "metrics": {"bleu_score": 47.78890355041061, "chrf_score": 73.63796566444985, "xcomet_score": 0.648970901966095, "xcomet_qe_score": 0.6435275077819824, "metricx_score": 6.958695888519287, "metricx_qe_score": 7.703505039215088, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "pt", "output": "Esta é o fim da palestra, e perguntas sãovindas. Obrigada. (Aplausos", "metrics": {"bleu_score": 50.31747626530137, "chrf_score": 76.14012030291481, "xcomet_score": 0.8025946617126465, "xcomet_qe_score": 0.7615985870361328, "metricx_score": 4.002632141113281, "metricx_qe_score": 6.078006744384766, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "pt", "output": "Olá. Chamo-me Antoine e sou da Universidade Mastricht.", "metrics": {"bleu_score": 28.64190457979541, "chrf_score": 66.69017284647812, "xcomet_score": 0.9683082103729248, "xcomet_qe_score": 0.9845816493034363, "metricx_score": 1.1597084999084473, "metricx_qe_score": 0.7524112462997437, "linguapy_score": [1, "YORUBA"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "pt", "output": "Vou apresentar o meu trabalho John com Jerry, que trata sobre um novo conjunto de dados para retiração de artigos estatário.", "metrics": {"bleu_score": 33.09673047735293, "chrf_score": 70.93654231533952, "xcomet_score": 0.6285033822059631, "xcomet_qe_score": 0.6647865772247314, "metricx_score": 13.121688842773438, "metricx_qe_score": 12.808505058288574, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "pt", "output": "Os questões juais são uma parte integrale da vida muitas pessoas,", "metrics": {"bleu_score": 10.600313379512592, "chrf_score": 63.005550402111, "xcomet_score": 0.7451249361038208, "xcomet_qe_score": 0.813305139541626, "metricx_score": 10.742510795593262, "metricx_qe_score": 9.137306213378906, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "pt", "output": "mas a maioria dos cidadãos têm pouco ou conhecimento sobre dos seus direitos e processos juais fundamentais as", "metrics": {"bleu_score": 29.25712720837, "chrf_score": 76.6862877197203, "xcomet_score": 0.46399080753326416, "xcomet_qe_score": 0.5113364458084106, "metricx_score": 12.252016067504883, "metricx_qe_score": 8.761951446533203, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "pt", "output": "a result many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or worst exploited all work aims to bridge the gap between people and the law by", "metrics": {"bleu_score": 1.0885011049519644, "chrf_score": 21.76177949562329, "xcomet_score": 0.3263840675354004, "xcomet_qe_score": 0.5700483918190002, "metricx_score": 20.665019989013672, "metricx_qe_score": 20.32166862487793, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "pt", "output": "developing effective retrieval system for statutory articles such a system could provide a free professional legal", "metrics": {"bleu_score": 1.5567102923487885, "chrf_score": 19.745230601548144, "xcomet_score": 0.22392192482948303, "xcomet_qe_score": 0.20011568069458008, "metricx_score": 18.916601181030273, "metricx_qe_score": 15.251877784729004, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "pt", "output": "profissional para seres inpes.", "metrics": {"bleu_score": 1.5577298727187734, "chrf_score": 17.193700150810887, "xcomet_score": 0.13922841846942902, "xcomet_qe_score": 0.14413104951381683, "metricx_score": 24.155393600463867, "metricx_qe_score": 23.188417434692383, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "pt", "output": "Antes de infund na contribuição principal deste trabalho, vamos desrever o problema da recção de artigos estat. Davido", "metrics": {"bleu_score": 22.813997135031524, "chrf_score": 62.42519567815741, "xcomet_score": 0.14921370148658752, "xcomet_qe_score": 0.2913477122783661, "metricx_score": 21.684446334838867, "metricx_qe_score": 20.619529724121094, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "pt", "output": "uma pergunta simples sobre uma assunto legal como \"O que é que eu arri se violar a confidencialidade profissional?\" é", "metrics": {"bleu_score": 6.783489805070002, "chrf_score": 52.645686883261035, "xcomet_score": 0.7137477397918701, "xcomet_qe_score": 0.7230265140533447, "metricx_score": 15.1006498336792, "metricx_qe_score": 10.25675106048584, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "pt", "output": "um modelo para recuperar todos os artigos estattivos relevantes de a large body of legislation this", "metrics": {"bleu_score": 24.74477295896412, "chrf_score": 58.536310805893585, "xcomet_score": 0.1667528748512268, "xcomet_qe_score": 0.20840924978256226, "metricx_score": 19.4572696685791, "metricx_qe_score": 19.610294342041016, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "pt", "output": "information retrieval task comes with its own set of challenges first it deals with two", "metrics": {"bleu_score": 0.0, "chrf_score": 18.920604302729764, "xcomet_score": 0.38915666937828064, "xcomet_qe_score": 0.8154031038284302, "metricx_score": 25.0, "metricx_qe_score": 18.454025268554688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "pt", "output": "types of language common", "metrics": {"bleu_score": 0.0, "chrf_score": 18.37614296652047, "xcomet_score": 0.16860191524028778, "xcomet_qe_score": 0.2763325572013855, "metricx_score": 24.836669921875, "metricx_qe_score": 20.421127319335938, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "pt", "output": "natural language for the questions and complex illegal language for the statutes this difference in", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 32.51970997281906, "xcomet_score": 0.2612239122390747, "xcomet_qe_score": 0.282637357711792, "metricx_score": 23.831459045410156, "metricx_qe_score": 21.967758178710938, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "pt", "output": "language distributions makes it harder for a system to retrieve candidatos relevantes, porque requer indiretamente um sistema de interpretação inerente que pode traduzir uma pergunta natural a uma pergunta jurídica que correspond com a terminologia dos estats.", "metrics": {"bleu_score": 28.449566521188764, "chrf_score": 65.0293316519805, "xcomet_score": 0.5638039112091064, "xcomet_qe_score": 0.6335194110870361, "metricx_score": 19.7216796875, "metricx_qe_score": 19.896297454833984, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, a lei legislativa não é um conjunto de artigos independentes que pode ser tratado como uma fonte completa de informação, tal como notícias ou receitas, por exemplo.", "metrics": {"bleu_score": 42.62566052038895, "chrf_score": 67.95257352395015, "xcomet_score": 0.9259911775588989, "xcomet_qe_score": 0.9688037633895874, "metricx_score": 2.9790546894073486, "metricx_qe_score": 3.753002643585205, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "pt", "output": "Em vez disso, é uma coleção estruturada de fors juridais que têm significado apenas quando consideraados no contexto geral, ou seja, juntamente com as informações complementarlementárias dos seus artigos vizinhos, dos campos e sub campos que pertencem e o lugar nesta estrutura da lei.", "metrics": {"bleu_score": 49.04325834692211, "chrf_score": 77.98710597897303, "xcomet_score": 0.7643840312957764, "xcomet_qe_score": 0.7907193303108215, "metricx_score": 10.452115058898926, "metricx_qe_score": 10.491003036499023, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "pt", "output": "Por fim, os artigos estatais estão num pequeno parágrafo, biasanya unit pen di besarya . A dokumenti panjang be 66000 words.", "metrics": {"bleu_score": 14.739774868924176, "chrf_score": 34.17831922356085, "xcomet_score": 0.13021723926067352, "xcomet_qe_score": 0.13484008610248566, "metricx_score": 25.0, "metricx_qe_score": 24.841480255126953, "linguapy_score": [1, "SWAHILI"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "pt", "output": "Dieju di", "metrics": {"bleu_score": 0.0, "chrf_score": 1.8684603886397606, "xcomet_score": 0.1506500393152237, "xcomet_qe_score": 0.14222921431064606, "metricx_score": 23.6644229888916, "metricx_qe_score": 22.88884925842285, "linguapy_score": [1, "LITHUANIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "pt", "output": "NLP mengha ketaran dalam banyakgas hukum, seperti predik nilai hukum atau contract otomati.", "metrics": {"bleu_score": 1.5540456119337736, "chrf_score": 17.33857972823664, "xcomet_score": 0.1424383521080017, "xcomet_qe_score": 0.2633092403411865, "metricx_score": 18.109508514404297, "metricx_qe_score": 18.495023727416992, "linguapy_score": [1, "INDONESIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "pt", "output": "tetapi penalan artiartikel permanecedo principalmente em contacto devido à falta de conjuntos de dados etiqueados e qualidade.", "metrics": {"bleu_score": 28.980080290247994, "chrf_score": 46.11561541666098, "xcomet_score": 0.14285065233707428, "xcomet_qe_score": 0.13517123460769653, "metricx_score": 18.52058982849121, "metricx_qe_score": 17.528974533081055, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "pt", "output": "Neste trabalho, apresentamos um novo conjunto de dados nativos centracidadãos para estudar se o modelo de retiração pode aproximar a eficiácia e confibilidade de um especialista judico para a tarefa de recção de artigos estat.", "metrics": {"bleu_score": 34.428001757849685, "chrf_score": 70.00588732592465, "xcomet_score": 0.20235833525657654, "xcomet_qe_score": 0.30873608589172363, "metricx_score": 17.331790924072266, "metricx_qe_score": 15.449155807495117, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "pt", "output": "ou os conjunto statutory article retrieval data set consists of more than 1100 legal questions posed by Belgian citizens", "metrics": {"bleu_score": 1.4005642087373082, "chrf_score": 25.507030347279148, "xcomet_score": 0.15018711984157562, "xcomet_qe_score": 0.5042949914932251, "metricx_score": 19.662227630615234, "metricx_qe_score": 15.542455673217773, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "pt", "output": "these questions cover a wide range of topics from family housing money to work and social security each of them has been labeled", "metrics": {"bleu_score": 1.6466642419110007, "chrf_score": 20.565088171490466, "xcomet_score": 0.6120210886001587, "xcomet_qe_score": 0.8693426847457886, "metricx_score": 17.898775100708008, "metricx_qe_score": 15.902922630310059, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "pt", "output": "by experienced jurists with references to relevants de um corpus de mais de 22600 artis jurid de de judic belgicos. Ag falar", "metrics": {"bleu_score": 7.071631420927874, "chrf_score": 29.98886885482631, "xcomet_score": 0.12496733665466309, "xcomet_qe_score": 0.13680881261825562, "metricx_score": 22.34811782836914, "metricx_qe_score": 21.592540740966797, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "pt", "output": "agora sobre como recodo este conjunto de data.", "metrics": {"bleu_score": 19.437571020720103, "chrf_score": 55.97611147558962, "xcomet_score": 0.39642494916915894, "xcomet_qe_score": 0.3999844789505005, "metricx_score": 9.694035530090332, "metricx_qe_score": 8.423028945922852, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "pt", "output": "Prime,بدأ compilando um grande grupopus de artigos jus", "metrics": {"bleu_score": 9.29675796576443, "chrf_score": 36.355098839703025, "xcomet_score": 0.19841425120830536, "xcomet_qe_score": 0.18432068824768066, "metricx_score": 21.32120132446289, "metricx_qe_score": 18.688234329223633, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "pt", "output": ".sámos 32 códigos belgis public dispo public e extraímos todos os seus artigos como as corresponding section headings.", "metrics": {"bleu_score": 12.897472346631357, "chrf_score": 44.76667694541646, "xcomet_score": 0.09073685109615326, "xcomet_qe_score": 0.11241544783115387, "metricx_score": 21.186962127685547, "metricx_qe_score": 21.572113037109375, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "pt", "output": "Then, we gathered legal questions with references to relevant statutes.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 29.769191481056723, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "pt", "output": "To do so, we partner with a Belgian law firm that receives each year around 4,000s emails from Belgian citizens who ask for advice on a personal legal issue.", "metrics": {"bleu_score": 1.4262733286728257, "chrf_score": 19.790881332344412, "xcomet_score": 0.9626073837280273, "xcomet_qe_score": 0.9698562026023865, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "pt", "output": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgian most", "metrics": {"bleu_score": 1.4183728388959305, "chrf_score": 23.63931184303829, "xcomet_score": 0.6855493187904358, "xcomet_qe_score": 0.7764394283294678, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "pt", "output": "common legal issues we collected thousands of questions annotated with categories subcategories and legal references to relevant statutes lastly we passed", "metrics": {"bleu_score": 0.0, "chrf_score": 38.81786334151486, "xcomet_score": 0.3209346532821655, "xcomet_qe_score": 0.6284773349761963, "metricx_score": 17.591646194458008, "metricx_qe_score": 13.26314640045166, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "pt", "output": "the legal references and filtered out the questions whose references were not articless in un des de jurid que consider.", "metrics": {"bleu_score": 1.9755758683310292, "chrf_score": 24.10769393707472, "xcomet_score": 0.07011435925960541, "xcomet_qe_score": 0.2549383044242859, "metricx_score": 24.118959426879883, "metricx_qe_score": 23.806793212890625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "pt", "output": "de refers corresponds e convertidas arti correspondentes de O corpus.", "metrics": {"bleu_score": 4.71728363692704, "chrf_score": 34.05564209334441, "xcomet_score": 0.13328109681606293, "xcomet_qe_score": 0.13484340906143188, "metricx_score": 21.37929916381836, "metricx_qe_score": 21.98951530456543, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "pt", "output": "Finaltermin 1108 questões, cada uma et cuidadosamente etiquetada com as IDs de artis relevante de um grande corpus de 22 2633 artigos estattivos.", "metrics": {"bleu_score": 5.187833409164963, "chrf_score": 34.83581583599623, "xcomet_score": 0.1712866574525833, "xcomet_qe_score": 0.20929139852523804, "metricx_score": 18.823366165161133, "metricx_qe_score": 16.3807430267334, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, cada pergunta tem uma categoria principal e uma concaação de subcategos,", "metrics": {"bleu_score": 39.582970805925896, "chrf_score": 79.5135442171684, "xcomet_score": 0.7402266263961792, "xcomet_qe_score": 0.8105632066726685, "metricx_score": 7.069185256958008, "metricx_qe_score": 6.145452976226807, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "pt", "output": "e cada artigos tem uma concaação da sua posteriore na estrutura da lei.", "metrics": {"bleu_score": 25.06824449449871, "chrf_score": 51.05769891857178, "xcomet_score": 0.50312340259552, "xcomet_qe_score": 0.4466240406036377, "metricx_score": 18.445049285888672, "metricx_qe_score": 19.027076721191406, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "pt", "output": "Esta informações extra não é usada no trabalho atual, mas pode ser interessante para a investigação futur sobre recção de informação jurídica ou a classificação de texto legal.", "metrics": {"bleu_score": 35.18478252285136, "chrf_score": 64.89119619598992, "xcomet_score": 0.8021798133850098, "xcomet_qe_score": 0.7685929536819458, "metricx_score": 7.449874401092529, "metricx_qe_score": 6.671529293060303, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos olharmos para algumas características dos nossos conjunto de dados.", "metrics": {"bleu_score": 27.901593935858266, "chrf_score": 75.43645369066661, "xcomet_score": 0.9366350173950195, "xcomet_qe_score": 0.9366456270217896, "metricx_score": 1.719475507736206, "metricx_qe_score": 1.3166972398757935, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "pt", "output": "A questão é: entre 5 e 44 palavras com um média de 40 palavras.", "metrics": {"bleu_score": 5.546271694289607, "chrf_score": 25.20438019695776, "xcomet_score": 0.8746430277824402, "xcomet_qe_score": 0.943638265132904, "metricx_score": 16.509708404541016, "metricx_qe_score": 12.581817626953125, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "pt", "output": "Os artigos é muito mais longos, com uma comprimento médiadio de 77 palavras, com 142 superem de 1000 palavras", "metrics": {"bleu_score": 18.229236476308348, "chrf_score": 50.002949119854314, "xcomet_score": 0.6601855754852295, "xcomet_qe_score": 0.6899105310440063, "metricx_score": 12.24374771118164, "metricx_qe_score": 9.517736434936523, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "pt", "output": ",ste 5,790 words.", "metrics": {"bleu_score": 2.634191962725227, "chrf_score": 3.6876995489030624, "xcomet_score": 0.15308848023414612, "xcomet_qe_score": 0.17838028073310852, "metricx_score": 21.874094009399414, "metricx_qe_score": 17.485219955444336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "pt", "output": "Como mencionado, a questão uma ga de temmas, circa 85% familia, housing, dinheiro ou justiça,", "metrics": {"bleu_score": 9.317818210561205, "chrf_score": 29.249786904894126, "xcomet_score": 0.1486721932888031, "xcomet_qe_score": 0.16989849507808685, "metricx_score": 20.482118606567383, "metricx_qe_score": 19.560256958007812, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "pt", "output": "terwijl de rest 15% concern segurança social, est کار.", "metrics": {"bleu_score": 9.706129029728686, "chrf_score": 27.404523901835343, "xcomet_score": 0.14583203196525574, "xcomet_qe_score": 0.18069833517074585, "metricx_score": 22.700021743774414, "metricx_qe_score": 22.373577117919922, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "pt", "output": "مقال ن, 32 farklı belژ ko konuları.", "metrics": {"bleu_score": 0.9582701933258967, "chrf_score": 3.2467786054760506, "xcomet_score": 0.12970814108848572, "xcomet_qe_score": 0.1310676783323288, "metricx_score": 25.0, "metricx_qe_score": 24.561880111694336, "linguapy_score": [1, "TURKISH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "pt", "output": "İşte bel kod .", "metrics": {"bleu_score": 1.0211566521809647, "chrf_score": 3.6120685493377893, "xcomet_score": 0.15497136116027832, "xcomet_qe_score": 0.15113034844398499, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "XHOSA"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "pt", "output": "22,633 n, sadece 1 1612 are referred to as relevant to at least one question in the data sets and around 80% percent of these", "metrics": {"bleu_score": 1.196721221977959, "chrf_score": 20.17432683199594, "xcomet_score": 0.24365369975566864, "xcomet_qe_score": 0.18414834141731262, "metricx_score": 21.36887550354004, "metricx_qe_score": 21.353574752807617, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "pt", "output": "cited articles come from either the civil code, judicial codes, criminal investigation code or penal codes.", "metrics": {"bleu_score": 2.207512285294552, "chrf_score": 29.50733724139209, "xcomet_score": 0.4198263883590698, "xcomet_qe_score": 0.8211249113082886, "metricx_score": 25.0, "metricx_qe_score": 24.5916748046875, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "pt", "output": "Meanwhile 18 out of 32 codes have less than five articles mentioned as relevant to توانضی با قیقیت که ک کمتر بر افراد و", "metrics": {"bleu_score": 0.0, "chrf_score": 16.11086763038489, "xcomet_score": 0.19999879598617554, "xcomet_qe_score": 0.1225455105304718, "metricx_score": 25.0, "metricx_qe_score": 23.952592849731445, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "pt", "output": "نگرانی های.طور داد متوسط برای این مق", "metrics": {"bleu_score": 1.2567539259667488, "chrf_score": 0.19747235387045817, "xcomet_score": 0.13917818665504456, "xcomet_qe_score": 0.13786891102790833, "metricx_score": 25.0, "metricx_qe_score": 24.808252334594727, "linguapy_score": [1, "PERSIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "pt", "output": "ال cita شده 2, de 25% cita mult de 5 or.", "metrics": {"bleu_score": 1.110273706430991, "chrf_score": 5.506298692118088, "xcomet_score": 0.11892757564783096, "xcomet_qe_score": 0.13285629451274872, "metricx_score": 23.508827209472656, "metricx_qe_score": 20.957923889160156, "linguapy_score": [1, "ESPERANTO"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "pt", "output": "با از مجموع های داده we benchmark several retrieval approaches including lexical and dense architecture", "metrics": {"bleu_score": 2.0128303461390598, "chrf_score": 19.98292132859001, "xcomet_score": 0.15003612637519836, "xcomet_qe_score": 0.12486307322978973, "metricx_score": 22.964635848999023, "metricx_qe_score": 22.394397735595703, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "pt", "output": "given a query in an article a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that", "metrics": {"bleu_score": 1.1860225816274885, "chrf_score": 19.785111357273717, "xcomet_score": 0.6647301912307739, "xcomet_qe_score": 0.7260788083076477, "metricx_score": 25.0, "metricx_qe_score": 24.18735122680664, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "pt", "output": "article we experiment with the standard TFIF and BM25 ranking functions El", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 24.919440219550946, "xcomet_score": 0.6766470670700073, "xcomet_qe_score": 0.8270665407180786, "metricx_score": 21.367515563964844, "metricx_qe_score": 16.006267547607422, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "pt", "output": "problema principal con queste app é che recuperare articoli contenn chia presenti nella que.", "metrics": {"bleu_score": 3.00988340490413, "chrf_score": 35.83433274704449, "xcomet_score": 0.22547312080860138, "xcomet_qe_score": 0.24236714839935303, "metricx_score": 18.879770278930664, "metricx_qe_score": 18.870954513549805, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "pt", "output": "Per superar esta limitamento, experimentamos una ar arquitecttecturaura basaada neuralale che captura una rela semmantica entre queries e arti.", "metrics": {"bleu_score": 5.6332622974871835, "chrf_score": 51.10718467774063, "xcomet_score": 0.23623739182949066, "xcomet_qe_score": 0.3975578844547272, "metricx_score": 17.15788459777832, "metricx_qe_score": 16.69704246520996, "linguapy_score": [1, "CATALAN"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "pt", "output": "Utilamos un model B- encodificador che mapa queries e articolis in representa representations and calculate a relevantlevance score between a query article pair by the similarity of their embeddings", "metrics": {"bleu_score": 1.1209313974917106, "chrf_score": 33.4597460081826, "xcomet_score": 0.055715736001729965, "xcomet_qe_score": 0.2254960983991623, "metricx_score": 21.854278564453125, "metricx_qe_score": 20.968475341796875, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "pt", "output": "these embeddings typically result from a pooling operation on the output of a word embedding model first we study the", "metrics": {"bleu_score": 0.0, "chrf_score": 19.403843833546752, "xcomet_score": 0.38003894686698914, "xcomet_qe_score": 0.8614609241485596, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "pt", "output": "effectiveness of Siamesebiancoders in a zero-shot evaluation setup meaning that pre-trained word embedding models are applied out of the box without any additional fine-tuning we", "metrics": {"bleu_score": 0.9320049380462183, "chrf_score": 18.732712228436775, "xcomet_score": 0.4787164032459259, "xcomet_qe_score": 0.793061375617981, "metricx_score": 23.432344436645508, "metricx_qe_score": 16.01934242248535, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "pt", "output": "experiment with context independent text encoder namely word to vec and fast text and context dependent embedding models namely Roberta and more specifically camembert which is a French Roberta model", "metrics": {"bleu_score": 1.023200946851256, "chrf_score": 38.823318334746844, "xcomet_score": 0.6972715258598328, "xcomet_qe_score": 0.8451688289642334, "metricx_score": 16.79901885986328, "metricx_qe_score": 10.064055442810059, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "pt", "output": "additionally we train our modelo baseada Cammbert Biancoder em todos os conjuntos de dados.", "metrics": {"bleu_score": 8.051321384556239, "chrf_score": 29.914475914382958, "xcomet_score": 0.41530847549438477, "xcomet_qe_score": 0.4112911522388458, "metricx_score": 20.86555290222168, "metricx_qe_score": 19.91718864440918, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "pt", "output": "Obem que para a treinoção, experimentamos com os dois sabores da arquitectura Biancoder: Si", "metrics": {"bleu_score": 20.68720601025941, "chrf_score": 57.75527304977488, "xcomet_score": 0.26310521364212036, "xcomet_qe_score": 0.19766554236412048, "metricx_score": 14.333730697631836, "metricx_qe_score": 15.032198905944824, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "pt", "output": "amese, que usa um modelo único de embe palavra que mapa a que e o artigo num espaço vector denso partilhado. e Tu Tower, que usa dois modelo independent word embedding models that encode the queryrian article separately into different embedding spaces.", "metrics": {"bleu_score": 14.812235403714448, "chrf_score": 41.30710348043274, "xcomet_score": 0.12251318991184235, "xcomet_qe_score": 0.20518621802330017, "metricx_score": 25.0, "metricx_qe_score": 23.851621627807617, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "pt", "output": "We experiment with mean, max and CLS pooling as well as dot product and cosine for computing similarities.", "metrics": {"bleu_score": 2.5197593442434796, "chrf_score": 25.698829047148088, "xcomet_score": 0.786401629447937, "xcomet_qe_score": 0.8798683881759644, "metricx_score": 25.0, "metricx_qe_score": 21.956912994384766, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "pt", "output": "Here are the results of a baseline on the test sets, with the", "metrics": {"bleu_score": 0.0, "chrf_score": 21.47913936668578, "xcomet_score": 0.3859110176563263, "xcomet_qe_score": 0.78529292345047, "metricx_score": 17.506839752197266, "metricx_qe_score": 9.512763023376465, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "pt", "output": "lexical methods above, the Siamesebian encoders evaluated in a zeroshot setup in the middle and the fine-tunedbian encoders below overall", "metrics": {"bleu_score": 1.6511053254160435, "chrf_score": 19.161986949991274, "xcomet_score": 0.6257638931274414, "xcomet_qe_score": 0.6830674409866333, "metricx_score": 23.993844985961914, "metricx_qe_score": 20.469867706298828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "pt", "output": "the fine-tuned biancoders significantly outperform all the other baselines", "metrics": {"bleu_score": 0.0, "chrf_score": 22.418716348656467, "xcomet_score": 0.5152515172958374, "xcomet_qe_score": 0.8281073570251465, "metricx_score": 22.954511642456055, "metricx_qe_score": 16.848779678344727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "pt", "output": "the two tower model improves over its siaamese variant on recall at 100 but perform similarly on the other metrics although bm25 underperformed the train", "metrics": {"bleu_score": 0.0, "chrf_score": 22.42346219929474, "xcomet_score": 0.23708412051200867, "xcomet_qe_score": 0.5709739923477173, "metricx_score": 23.486303329467773, "metricx_qe_score": 19.400537490844727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "pt", "output": "edbian encoder significantly its performance که هن برای . Re zero-shotvalu of Siamese Bicoder, we constat", "metrics": {"bleu_score": 1.1254195166774048, "chrf_score": 15.381660420145431, "xcomet_score": 0.19822201132774353, "xcomet_qe_score": 0.1094132661819458, "metricx_score": 22.43941879272461, "metricx_qe_score": 23.45393180847168, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "pt", "output": "embeings model Kammbert بدون optim, produce résultat,e finding.", "metrics": {"bleu_score": 0.33659200684734897, "chrf_score": 7.969819346964369, "xcomet_score": 0.12073413282632828, "xcomet_qe_score": 0.13564759492874146, "metricx_score": 24.421527862548828, "metricx_qe_score": 23.91461753845215, "linguapy_score": [1, "DANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "pt", "output": ",serv quecodador baseado em ultrapassou significativamente o modelo e base aves, o sugerendo que talvez incorporações nível de palavras são mais apropriadas para a tarefa do que nível de caracter ou nível subs, quando usados for da caixa.", "metrics": {"bleu_score": 10.925007340819802, "chrf_score": 48.912259082484134, "xcomet_score": 0.14219728112220764, "xcomet_qe_score": 0.1438463032245636, "metricx_score": 23.35039710998535, "metricx_qe_score": 23.59708595275879, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "pt", "output": "Embora prometmis, estes resultados su suggest ampleport for improvementement compared un expert retrieve all relevant article any question, perfect scores.", "metrics": {"bleu_score": 4.142066495688748, "chrf_score": 30.703726913877883, "xcomet_score": 0.1759013533592224, "xcomet_qe_score": 0.29592400789260864, "metricx_score": 23.026987075805664, "metricx_qe_score": 21.150911331176758, "linguapy_score": [1, "CATALAN"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "pt", "output": "Let's concludebat two limit limitations all datasets.", "metrics": {"bleu_score": 3.7954847898457067, "chrf_score": 21.972624575736933, "xcomet_score": 0.684144914150238, "xcomet_qe_score": 0.7965822815895081, "metricx_score": 19.526851654052734, "metricx_qe_score": 18.896251678466797, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "pt", "output": "First, the corpus of article is limited to thoselect 32 Belgian codes que não co toda a lei belgica, como artigos decrets, dires e ordens.", "metrics": {"bleu_score": 4.62578491874322, "chrf_score": 28.262533351936952, "xcomet_score": 0.07913641631603241, "xcomet_qe_score": 0.1296728551387787, "metricx_score": 19.885581970214844, "metricx_qe_score": 18.4190616607666, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "pt", "output": "Durante a construção de conjunto de dados, todas as referências a estes artigos não recohidos são ignoradas, o que faz que uma perguntaca com apenas uma fração do número inicial de artigos relevantes.", "metrics": {"bleu_score": 68.00337592505011, "chrf_score": 84.93462863004444, "xcomet_score": 0.8450419306755066, "xcomet_qe_score": 0.8362432718276978, "metricx_score": 7.684780120849609, "metricx_qe_score": 9.656533241271973, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "pt", "output": "Esta perda de informação implica que a resposta contída noss relevantes pode ser incompleta, embora ainda completamente adequaada.", "metrics": {"bleu_score": 17.41759647647354, "chrf_score": 60.83415058205048, "xcomet_score": 0.818311333656311, "xcomet_qe_score": 0.833764910697937, "metricx_score": 14.188377380371094, "metricx_qe_score": 12.611291885375977, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "pt", "output": "Segu lugar, devemos notar que não todas as questões jurídicaais não podem ser respostaidas com estats.", "metrics": {"bleu_score": 28.157559767629017, "chrf_score": 50.664967880230435, "xcomet_score": 0.261301189661026, "xcomet_qe_score": 0.3491366505622864, "metricx_score": 18.986494064331055, "metricx_qe_score": 18.93146514892578, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, a pergunta: \"Posso eliminar os meus s se fazemem demasiado baruido?\" não", "metrics": {"bleu_score": 23.210911117419965, "chrf_score": 47.50334376803674, "xcomet_score": 0.41003838181495667, "xcomet_qe_score": 0.2925991415977478, "metricx_score": 18.12000846862793, "metricx_qe_score": 11.4363374710083, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "pt", "output": "pode não ter uma resposta detada dentro lei legisla que quantifica um limil noised threshold at which eviction is low instead landlords", "metrics": {"bleu_score": 10.721147801499253, "chrf_score": 42.04678731462981, "xcomet_score": 0.15800116956233978, "xcomet_qe_score": 0.21958214044570923, "metricx_score": 20.88347816467285, "metricx_qe_score": 20.370962142944336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "pt", "output": "should probably rely more on case law and find precedents similar to their current situation for example the ten", "metrics": {"bleu_score": 0.0, "chrf_score": 21.66658209779493, "xcomet_score": 0.3144949674606323, "xcomet_qe_score": 0.412350594997406, "metricx_score": 25.0, "metricx_qe_score": 20.786273956298828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "pt", "output": "ant makes two parties a week until 2 aam hence some questions are better suited than", "metrics": {"bleu_score": 0.0, "chrf_score": 14.671602276479053, "xcomet_score": 0.22060757875442505, "xcomet_qe_score": 0.15715965628623962, "metricx_score": 24.397035598754883, "metricx_qe_score": 20.745635986328125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "pt", "output": "others to the task statutory article retrieval statu and the domain of the less suitable ones remains to be determinado.", "metrics": {"bleu_score": 1.3012817232777962, "chrf_score": 21.677930294342122, "xcomet_score": 0.1831807643175125, "xcomet_qe_score": 0.4521954655647278, "metricx_score": 20.965944290161133, "metricx_qe_score": 20.474946975708008, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "pt", "output": "Esperamos que todo o trabalhostimul interesse em desenvolver de modelos de artigos prática práticas e fiáveis que", "metrics": {"bleu_score": 12.12405086660239, "chrf_score": 52.75910514684349, "xcomet_score": 0.22443392872810364, "xcomet_qe_score": 0.14375348389148712, "metricx_score": 18.94188690185547, "metricx_qe_score": 18.29248046875, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "pt", "output": "possam ajudar a melhorar o acesso à justiça.", "metrics": {"bleu_score": 53.78454936756791, "chrf_score": 66.75426945904023, "xcomet_score": 0.5081149935722351, "xcomet_qe_score": 0.5543628931045532, "metricx_score": 9.29054069519043, "metricx_qe_score": 10.054845809936523, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "pt", "output": "Podem ver o nosso artigo Datset e en codifica os seguintes linkss. Obrigada", "metrics": {"bleu_score": 21.73110713781509, "chrf_score": 49.96232491417328, "xcomet_score": 0.7565413117408752, "xcomet_qe_score": 0.7607238292694092, "metricx_score": 15.413909912109375, "metricx_qe_score": 15.034672737121582, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "pt", "output": "Olá. Estamos felizes de apresentar o nosso trabalho sobre VOS, um marca independente de tarefa destinada para testar modelos de visão e linguagem com fenómenos linguüísticos específicos.", "metrics": {"bleu_score": 9.945041368991502, "chrf_score": 67.71621681581985, "xcomet_score": 0.458665668964386, "xcomet_qe_score": 0.49190405011177063, "metricx_score": 9.44647216796875, "metricx_qe_score": 10.1130952835083, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "pt", "output": "Porque é que fizmos problemas em instalar este pont?", "metrics": {"bleu_score": 14.530346490115708, "chrf_score": 28.89060218340965, "xcomet_score": 0.3738113343715668, "xcomet_qe_score": 0.6507634520530701, "metricx_score": 15.648226737976074, "metricx_qe_score": 8.301756858825684, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "pt", "output": "Be Nos últimos anos, visto uma explosão de modelos de visão e linguagem base em transformaformador pré-traininados em grandes quantidades de text de imagen.", "metrics": {"bleu_score": 19.555598541862505, "chrf_score": 66.70376997783093, "xcomet_score": 0.22349989414215088, "xcomet_qe_score": 0.2915067970752716, "metricx_score": 16.22804069519043, "metricx_qe_score": 17.19799041748047, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "pt", "output": "Cada um destes modelos impulsion a estado arte em tarefas de visão e linguagem como resposta de pergunta visual, razcioação do sentido visual, recuperação de imagen, base de frase.", "metrics": {"bleu_score": 23.811528168423497, "chrf_score": 55.61456243486839, "xcomet_score": 0.5192410945892334, "xcomet_qe_score": 0.4987630248069763, "metricx_score": 11.467556953430176, "metricx_qe_score": 11.782543182373047, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "pt", "output": "Então obメッセージました の作業の精は稳に増加しています しかし", "metrics": {"bleu_score": 0.17745041833014083, "chrf_score": 2.9823904149924076, "xcomet_score": 0.1351328045129776, "xcomet_qe_score": 0.13044412434101105, "metricx_score": 19.95659828186035, "metricx_qe_score": 20.226097106933594, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "pt", "output": "モデルが学んだのでしょうか?", "metrics": {"bleu_score": 0.0, "chrf_score": 0.4480286738351254, "xcomet_score": 0.3500479459762573, "xcomet_qe_score": 0.5422922372817993, "metricx_score": 8.56966781616211, "metricx_qe_score": 7.892442226409912, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "pt", "output": "視ジョンと言語変理解高と frase e uma pon", "metrics": {"bleu_score": 0.2574910161099668, "chrf_score": 7.238969809465205, "xcomet_score": 0.12941792607307434, "xcomet_qe_score": 0.1318845897912979, "metricx_score": 24.061054229736328, "metricx_qe_score": 23.200746536254883, "linguapy_score": [1, "JAPANESE"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "pt", "output": "tua baixa para esta.", "metrics": {"bleu_score": 26.65429557589628, "chrf_score": 54.31830767780305, "xcomet_score": 0.38847535848617554, "xcomet_qe_score": 0.30983078479766846, "metricx_score": 13.73686695098877, "metricx_qe_score": 10.964906692504883, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "pt", "output": "Os modelos de visão e linguagem se fom-se na coisa certa,", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 67.95568480909591, "xcomet_score": 0.7138891220092773, "xcomet_qe_score": 0.7131636142730713, "metricx_score": 10.344708442687988, "metricx_qe_score": 13.564915657043457, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "pt", "output": "ou fom-se em preconceitos como mostdos pelo trabalho anterior?", "metrics": {"bleu_score": 37.99178428257963, "chrf_score": 73.81235198624327, "xcomet_score": 0.7487109303474426, "xcomet_qe_score": 0.6980886459350586, "metricx_score": 10.912219047546387, "metricx_qe_score": 7.75640344619751, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "pt", "output": "Para darr mais luz sobre este aspe, proposmos uma direção agnóstica tarefa e introdumos válvules que testen a sensitivitytà de modelos vision and linguagem a fenomenome ling linguistics que afectaen both modalling linguistics and the visual mo", "metrics": {"bleu_score": 9.458216758219757, "chrf_score": 50.76836602806931, "xcomet_score": 0.22111822664737701, "xcomet_qe_score": 0.16868989169597626, "metricx_score": 19.598377227783203, "metricx_qe_score": 19.26219940185547, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "pt", "output": "dalities. We targetăm exist plurality, con, relapaes, actions and correference entity.", "metrics": {"bleu_score": 2.867273570500278, "chrf_score": 29.02758383926208, "xcomet_score": 0.14005306363105774, "xcomet_qe_score": 0.13250452280044556, "metricx_score": 19.86079216003418, "metricx_qe_score": 20.562519073486328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "pt", "output": "But como testar se modelos de vision y models have captured this phenomena by", "metrics": {"bleu_score": 6.754312828675707, "chrf_score": 37.48035805632061, "xcomet_score": 0.22273698449134827, "xcomet_qe_score": 0.2594442665576935, "metricx_score": 22.601282119750977, "metricx_qe_score": 24.21034812927246, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "pt", "output": "foiling a method previously applied for vision and language models only for noun phrases by ravi Shekhar and collaborators and on counting by us in previous work fo", "metrics": {"bleu_score": 1.1575883559784739, "chrf_score": 26.535750114154734, "xcomet_score": 0.7809546589851379, "xcomet_qe_score": 0.7981215715408325, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "pt", "output": "iling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image", "metrics": {"bleu_score": 1.3373587855284337, "chrf_score": 20.98688707662528, "xcomet_score": 0.6962758302688599, "xcomet_qe_score": 0.9110198020935059, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "pt", "output": "anymore and we do these phrase alterations by focusing on six specific pieces such as existence plurality counting spatial relations actions and entity coreference where each piece can consist of um ou mais instrumentos, no caso de encontrámos mais de uma forma interessante de criarsts de fol.", "metrics": {"bleu_score": 16.422442251779888, "chrf_score": 41.74122812701915, "xcomet_score": 0.07609762996435165, "xcomet_qe_score": 0.25928205251693726, "metricx_score": 24.457000732421875, "metricx_qe_score": 23.01231575012207, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é mudado com uma ação diferente e uma em que os as.", "metrics": {"bleu_score": 73.98030749631559, "chrf_score": 80.11807943989513, "xcomet_score": 0.5379449129104614, "xcomet_qe_score": 0.3631938397884369, "metricx_score": 18.68885040283203, "metricx_qe_score": 20.88827133178711, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "pt", "output": "A conta e correferência também são peças que têm mais de um instrumento.", "metrics": {"bleu_score": 61.62607099729587, "chrf_score": 77.96075929347523, "xcomet_score": 0.645462691783905, "xcomet_qe_score": 0.6087600588798523, "metricx_score": 5.208468437194824, "metricx_qe_score": 6.951926231384277, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "pt", "output": "criamos estas fohas garantindo de que não descrever a imagem, que são frases gramaticales e válidas.", "metrics": {"bleu_score": 13.5416317629745, "chrf_score": 49.44919604506825, "xcomet_score": 0.6475861072540283, "xcomet_qe_score": 0.6631128787994385, "metricx_score": 12.053664207458496, "metricx_qe_score": 10.632386207580566, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "pt", "output": "Isto é fácil de fazer porque uma capulada pode ser menos provável do que a títuloula original.", "metrics": {"bleu_score": 57.0062318840941, "chrf_score": 68.7587851879845, "xcomet_score": 0.33820751309394836, "xcomet_qe_score": 0.26110708713531494, "metricx_score": 21.66963768005371, "metricx_qe_score": 21.20363998413086, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "pt", "output": "Por, embora não impossível, statisticsamente menos probabil que plant corta un hombre que un cortar plantaes, e modelos de visi e idioma pu a", "metrics": {"bleu_score": 11.20632509726424, "chrf_score": 43.0373050915826, "xcomet_score": 0.13121835887432098, "xcomet_qe_score": 0.13352195918560028, "metricx_score": 22.225257873535156, "metricx_qe_score": 22.49544906616211, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "pt", "output": "., para obtener fos valides, temos tomar ac.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 30.741232113174956, "xcomet_score": 0.1789337396621704, "xcomet_qe_score": 0.2887173891067505, "metricx_score": 24.420366287231445, "metricx_qe_score": 21.47377586364746, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "pt", "output": "Prime, usamos modelos de lenguajetes para proposer fo.", "metrics": {"bleu_score": 7.817610446892725, "chrf_score": 40.292834836160495, "xcomet_score": 0.19661995768547058, "xcomet_qe_score": 0.19022740423679352, "metricx_score": 20.409730911254883, "metricx_qe_score": 16.94631576538086, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "pt", "output": "Second, inference natural, ou NI, para filtrare foles que descri image, constru fo, garanti garantir de que descri image.", "metrics": {"bleu_score": 1.6973303803065645, "chrf_score": 29.995034924330717, "xcomet_score": 0.12808403372764587, "xcomet_qe_score": 0.14442965388298035, "metricx_score": 25.0, "metricx_qe_score": 24.53632164001465, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "pt", "output": "test automa, ap infer natural amb la rational: \"", "metrics": {"bleu_score": 3.393026569182827, "chrf_score": 23.429408317811703, "xcomet_score": 0.12541599571704865, "xcomet_qe_score": 0.13631439208984375, "metricx_score": 20.96403694152832, "metricx_qe_score": 19.244342803955078, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "pt", "output": "consider an image to be the premise and its caption its entailed hypothesis in addition we", "metrics": {"bleu_score": 0.0, "chrf_score": 25.68421394087885, "xcomet_score": 0.36218884587287903, "xcomet_qe_score": 0.8604331016540527, "metricx_score": 23.48586654663086, "metricx_qe_score": 21.197904586791992, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "pt", "output": "consider the caption to be the premise and the foil is its hypothesis if an", "metrics": {"bleu_score": 0.0, "chrf_score": 21.658971200260325, "xcomet_score": 0.33106860518455505, "xcomet_qe_score": 0.8190053105354309, "metricx_score": 24.30824851989746, "metricx_qe_score": 17.254098892211914, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "pt", "output": "Nli model predicts the foil to contradict or to be neutral with respect to the caption we take this as an indicator of a valid foil if an", "metrics": {"bleu_score": 1.3353534059549443, "chrf_score": 23.276535396757485, "xcomet_score": 0.464731901884079, "xcomet_qe_score": 0.726335346698761, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "pt", "output": "Nli predicts the foil to be entailed by the caption it cannot be a good foil since by transitivity it will give a truthful description of the image and we filter these foils out but this", "metrics": {"bleu_score": 0.9699217198619959, "chrf_score": 18.863961164035466, "xcomet_score": 0.3433040380477905, "xcomet_qe_score": 0.5417144298553467, "metricx_score": 25.0, "metricx_qe_score": 21.36823844909668, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "pt", "output": "procedure is not perfect it is just an indicator for valid foils therefore as a third measure for gener", "metrics": {"bleu_score": 0.0, "chrf_score": 25.97515477342644, "xcomet_score": 0.3169592022895813, "xcomet_qe_score": 0.7436187267303467, "metricx_score": 22.288604736328125, "metricx_qe_score": 17.571964263916016, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "pt", "output": "ating valid foils we employ human annotators to validate the data used in valse so after filtering", "metrics": {"bleu_score": 0.0, "chrf_score": 17.793381706997224, "xcomet_score": 0.22513847053050995, "xcomet_qe_score": 0.5600444078445435, "metricx_score": 21.468177795410156, "metricx_qe_score": 18.97775650024414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "pt", "output": "and human evaluation we have as many test instances as described in this table note that valse does", "metrics": {"bleu_score": 0.0, "chrf_score": 25.755528870724408, "xcomet_score": 0.3196622133255005, "xcomet_qe_score": 0.49952831864356995, "metricx_score": 24.069744110107422, "metricx_qe_score": 20.198474884033203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "pt", "output": "not deliver any training data but only test data since it is a zero de teste.", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 15.636884447818009, "xcomet_score": 0.19676688313484192, "xcomet_qe_score": 0.38371795415878296, "metricx_score": 24.206336975097656, "metricx_qe_score": 20.715618133544922, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "pt", "output": "É concedo para usarar as capacidades existentes de modelos de visão e linguagem após a pré-trainamento.", "metrics": {"bleu_score": 14.705567711697105, "chrf_score": 47.65800709981179, "xcomet_score": 0.2632877230644226, "xcomet_qe_score": 0.6596626043319702, "metricx_score": 17.05668067932129, "metricx_qe_score": 16.231571197509766, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "pt", "output": "Ação permitiria os modelos explorar artefactos ou preconceitos estaísticaísticos nos dados.", "metrics": {"bleu_score": 14.919431164109403, "chrf_score": 75.51323479092846, "xcomet_score": 0.48722484707832336, "xcomet_qe_score": 0.48732081055641174, "metricx_score": 12.83191204071045, "metricx_qe_score": 13.259181022644043, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "pt", "output": "Todos sabemos que estes modelos gostam de trampar e corre as.", "metrics": {"bleu_score": 34.91665073071339, "chrf_score": 55.396075083388006, "xcomet_score": 0.7139999866485596, "xcomet_qe_score": 0.7903080582618713, "metricx_score": 9.627942085266113, "metricx_qe_score": 10.101212501525879, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "pt", "output": "como dissemos, estamos interested in assessing what capabilities the vision and language models have after pre-training we experiment", "metrics": {"bleu_score": 10.267711102969956, "chrf_score": 42.034612163569065, "xcomet_score": 0.30182772874832153, "xcomet_qe_score": 0.8447543382644653, "metricx_score": 25.0, "metricx_qe_score": 22.759540557861328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "pt", "output": "with five vision and language models on vowels namely with clip alex Mert wilbert wilbert 12 in 1 and visual bird two of", "metrics": {"bleu_score": 0.0, "chrf_score": 18.24157298510062, "xcomet_score": 0.22561906278133392, "xcomet_qe_score": 0.21044297516345978, "metricx_score": 20.31319236755371, "metricx_qe_score": 18.090452194213867, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "pt", "output": "our most important evaluation metrics are the accuracy of thes na classificação de pares de frases imagen em capções e FOI.", "metrics": {"bleu_score": 4.344284557993833, "chrf_score": 34.8776895370527, "xcomet_score": 0.04702204465866089, "xcomet_qe_score": 0.09230967611074448, "metricx_score": 23.91323471069336, "metricx_qe_score": 24.035451889038086, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "pt", "output": "Talvez mais relevantes para este vídeo, vamos mostrar a nossa metétrica mais permisiva, a precisão pare, que mede se a pontua de ainhaação frase é maior para o pare corre de texto de imagem corre do que para o pare foido.", "metrics": {"bleu_score": 28.562650462852993, "chrf_score": 64.06581438139506, "xcomet_score": 0.1919577419757843, "xcomet_qe_score": 0.23733265697956085, "metricx_score": 24.51097869873047, "metricx_qe_score": 22.63576889038086, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "pt", "output": "Para metrics and results on them, do check out our paper.", "metrics": {"bleu_score": 4.065425428798724, "chrf_score": 22.61749632968805, "xcomet_score": 0.5593560934066772, "xcomet_qe_score": 0.8303672671318054, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "pt", "output": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics. It's that the best zero shot performance is achieved by Wilbert 12 in one, followed by Wilbert, Alex Mertlip, and finally Visualbird.", "metrics": {"bleu_score": 1.0908738822566149, "chrf_score": 22.132168999830228, "xcomet_score": 0.3197483420372009, "xcomet_qe_score": 0.39459675550460815, "metricx_score": 24.332544326782227, "metricx_qe_score": 17.81488609313965, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "pt", "output": "It's notable how instruments centered em objetos individuais como a existência e frases substantivas, são quase resolvidos pelo Wilbert 12 em1, destacando que os modelos são capazes de identificar objetos nomedos e a sua presença nas imagens.", "metrics": {"bleu_score": 35.685138082036715, "chrf_score": 71.29698650462515, "xcomet_score": 0.3750489354133606, "xcomet_qe_score": 0.4480285346508026, "metricx_score": 12.401803970336914, "metricx_qe_score": 13.799327850341797, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "pt", "output": "No entanto, nenhuma das peças restantes pode ser solu confiável nos nossos de adversários.", "metrics": {"bleu_score": 42.00381265123849, "chrf_score": 56.76563221914554, "xcomet_score": 0.3965826630592346, "xcomet_qe_score": 0.4605986773967743, "metricx_score": 15.300305366516113, "metricx_qe_score": 13.791501998901367, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "pt", "output": "Vemos dos instrumentos de pluralidade e conta instruments that vision and language models have trouble distinguishing references to single versus multiple objects or counting them in an image The relation piece shows that they", "metrics": {"bleu_score": 5.332544583175987, "chrf_score": 39.86585653508625, "xcomet_score": 0.26700782775878906, "xcomet_qe_score": 0.3202206492424011, "metricx_score": 25.0, "metricx_qe_score": 24.618896484375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "pt", "output": "have difficulties in correctly classifying a named spatial relation between objects in an image they also have", "metrics": {"bleu_score": 0.0, "chrf_score": 23.766596828610982, "xcomet_score": 0.31823766231536865, "xcomet_qe_score": 0.417473703622818, "metricx_score": 25.0, "metricx_qe_score": 22.322948455810547, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "pt", "output": "trouble distinguishing actions and identifying os seus participantes, mesmo apoados por sesces de plausibilidade, como vemos na peça de ações.", "metrics": {"bleu_score": 38.564192073808314, "chrf_score": 58.73338381758917, "xcomet_score": -0.0009671063162386417, "xcomet_qe_score": 0.13569915294647217, "metricx_score": 21.522666931152344, "metricx_qe_score": 21.373130798339844, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "pt", "output": "A a peça de correferência, descobrimos que raçar múltiplas referências ao mesmo objeto numa imagem usando pronomos, também é difícil para os modelos de visão e linguagem.", "metrics": {"bleu_score": 46.84745807363584, "chrf_score": 79.91434220689055, "xcomet_score": 0.5959311723709106, "xcomet_qe_score": 0.6119674444198608, "metricx_score": 10.167816162109375, "metricx_qe_score": 10.706120491027832, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "pt", "output": "Como análise de sanidade, e porque é uma experiência interessante, também avalia two text only models GPT1 and GPT2 to assess whether falsese is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption no image here and predicting the entry with the lowest perplexity if", "metrics": {"bleu_score": 16.43662723355699, "chrf_score": 40.52524983549978, "xcomet_score": 0.41447702050209045, "xcomet_qe_score": 0.3402860164642334, "metricx_score": 21.592166900634766, "metricx_qe_score": 16.57594871520996, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "pt", "output": "the perplexity is higher for the foil we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases and it's interesting", "metrics": {"bleu_score": 0.0, "chrf_score": 24.938897678694975, "xcomet_score": 0.5070953965187073, "xcomet_qe_score": 0.8228271007537842, "metricx_score": 25.0, "metricx_qe_score": 22.112686157226562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "pt", "output": "to see that in some cases the text-only GPT models have captured the plausibility of the world better than the vision and language models So to sum up", "metrics": {"bleu_score": 1.1996779229629453, "chrf_score": 30.031554190139254, "xcomet_score": 0.45676562190055847, "xcomet_qe_score": 0.7186511754989624, "metricx_score": 24.601821899414062, "metricx_qe_score": 24.48063850402832, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "pt", "output": "valse is a benchmark that uses the lens constructs lings i help laun modele visi en tr testarcapacit ing visuel.", "metrics": {"bleu_score": 1.0572636772527624, "chrf_score": 19.409190136293848, "xcomet_score": 0.11245888471603394, "xcomet_qe_score": 0.12707126140594482, "metricx_score": 20.746915817260742, "metricx_qe_score": 20.23195457458496, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "pt", "output": "Onze experimenten laten dat modele visi en identifi o objecte no in pressenz in images, la peça existen, maar len om hun interdependenheid en rela di aena visualual quando di a respe indicas lingísticos.", "metrics": {"bleu_score": 1.1584183992532209, "chrf_score": 31.52447748689306, "xcomet_score": 0.12192101776599884, "xcomet_qe_score": 0.13826477527618408, "metricx_score": 21.201669692993164, "metricx_qe_score": 22.728275299072266, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "pt", "output": "Ki ingin mecorongar community menggunakan vokal untuk mer progressan a baseamento con models visi e lenguaje.", "metrics": {"bleu_score": 1.6713635561203382, "chrf_score": 23.36077146026614, "xcomet_score": 0.12179548293352127, "xcomet_qe_score": 0.12524650990962982, "metricx_score": 21.993980407714844, "metricx_qe_score": 22.353370666503906, "linguapy_score": [1, "MALAY"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "pt", "output": "E, vokal digunakan sebagai evalua indirect dari set data da models evaluados antes après formaing oação para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer dos aspetos testados por Vols.", "metrics": {"bleu_score": 24.228878680911556, "chrf_score": 45.618516419308364, "xcomet_score": -0.02142319083213806, "xcomet_qe_score": 0.11428499221801758, "metricx_score": 20.999954223632812, "metricx_qe_score": 22.02750015258789, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "pt", "output": "Se interessados, olhem os dados de Valse no GitHub e se tiverem alguma perguntas, não heem a contactar-nos", "metrics": {"bleu_score": 12.339644852484144, "chrf_score": 49.585572763822874, "xcomet_score": 0.7967847585678101, "xcomet_qe_score": 0.7816556096076965, "metricx_score": 7.366741180419922, "metricx_qe_score": 6.9230523109436035, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "pt", "output": "Olá. Me nomemo-me Kamisura da Universidade de Tóquio.", "metrics": {"bleu_score": 33.66077357806371, "chrf_score": 61.90929710570337, "xcomet_score": 0.7954380512237549, "xcomet_qe_score": 0.8131213188171387, "metricx_score": 6.8569207191467285, "metricx_qe_score": 5.983907222747803, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "pt", "output": "Vou apresentar um artigo intlado \"Cosum: um Des de grande escala para notaçãomática através da sumização de logs\". Vo", "metrics": {"bleu_score": 18.637543939594334, "chrf_score": 46.279129829122816, "xcomet_score": 0.28920382261276245, "xcomet_qe_score": 0.29668664932250977, "metricx_score": 20.560745239257812, "metricx_qe_score": 19.228057861328125, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "pt", "output": "explicar desta ordem?", "metrics": {"bleu_score": 14.794015674776452, "chrf_score": 62.36361782681671, "xcomet_score": 0.8071634769439697, "xcomet_qe_score": 0.7450090646743774, "metricx_score": 6.642608642578125, "metricx_qe_score": 10.636209487915039, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, vou apresentar a notação de lista automática em que are working on in this research.", "metrics": {"bleu_score": 7.223943354597204, "chrf_score": 38.41096344074896, "xcomet_score": 0.29165518283843994, "xcomet_qe_score": 0.4947456121444702, "metricx_score": 21.444095611572266, "metricx_qe_score": 21.74806785583496, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "pt", "output": "ReaseNote is a technical document that summarizes the changes distributed with each release of a software product.", "metrics": {"bleu_score": 2.045123096851001, "chrf_score": 29.16167012921429, "xcomet_score": 0.8218246698379517, "xcomet_qe_score": 0.885105311870575, "metricx_score": 25.0, "metricx_qe_score": 24.390750885009766, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "pt", "output": "The image shows the release notes for version two point six point four of the Bujs library.", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 18.12408074225815, "xcomet_score": 0.5293428897857666, "xcomet_qe_score": 0.8622709512710571, "metricx_score": 14.813003540039062, "metricx_qe_score": 11.6926908493042, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "pt", "output": "Re notes play an important role in open source development but they are time consuming to prepare manually therefore", "metrics": {"bleu_score": 0.0, "chrf_score": 26.20311975569502, "xcomet_score": 0.7107752561569214, "xcomet_qe_score": 0.8067975640296936, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "pt", "output": "it will be very useful to be able to automatically generate high quality release nodes i will", "metrics": {"bleu_score": 0.0, "chrf_score": 25.63151069197247, "xcomet_score": 0.7401212453842163, "xcomet_qe_score": 0.8550833463668823, "metricx_score": 20.301006317138672, "metricx_qe_score": 17.335798263549805, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "pt", "output": "refer to two previous researches on automatic list node generation the first is a system called alena, läppad", "metrics": {"bleu_score": 2.0244462660665508, "chrf_score": 24.270755798388038, "xcomet_score": 0.19049996137619019, "xcomet_qe_score": 0.4525383412837982, "metricx_score": 21.515161514282227, "metricx_qe_score": 20.47381019592285, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "pt", "output": "i 2014.", "metrics": {"bleu_score": 0.0, "chrf_score": 7.442171931003097, "xcomet_score": 0.14182017743587494, "xcomet_qe_score": 0.13222917914390564, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "LITHUANIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "pt", "output": "Het ne en met ge regel, använd extractor modifi för extra berbeda,ingen biblio en från de di me tussen ,, kombin.", "metrics": {"bleu_score": 1.3712999796222372, "chrf_score": 16.062351404441007, "xcomet_score": 0.12470151484012604, "xcomet_qe_score": 0.13565801084041595, "metricx_score": 24.551227569580078, "metricx_qe_score": 25.0, "linguapy_score": [1, "SWEDISH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "pt", "output": "De opmärksste i system is extractive in the upper right corner, which", "metrics": {"bleu_score": 0.0, "chrf_score": 18.301155406864485, "xcomet_score": 0.23848599195480347, "xcomet_qe_score": 0.2206839919090271, "metricx_score": 21.88192367553711, "metricx_qe_score": 21.981969833374023, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "pt", "output": "must be linked to Jira, the issue ecosystem and can only be applied to projects that use Jira,", "metrics": {"bleu_score": 3.3734781434832977, "chrf_score": 20.631913870333683, "xcomet_score": 0.6190176606178284, "xcomet_qe_score": 0.8910042643547058, "metricx_score": 16.14651870727539, "metricx_qe_score": 6.345903396606445, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "pt", "output": "in words, it cannot be used for many projects on GitHub.", "metrics": {"bleu_score": 6.330984178784958, "chrf_score": 21.386816988750095, "xcomet_score": 0.9129794239997864, "xcomet_qe_score": 0.9469842314720154, "metricx_score": 23.546241760253906, "metricx_qe_score": 22.618202209472656, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "pt", "output": "The second is Grif, recently announced in twenty", "metrics": {"bleu_score": 4.266331692956901, "chrf_score": 21.58669502281862, "xcomet_score": 0.29220813512802124, "xcomet_qe_score": 0.6466447114944458, "metricx_score": 19.371349334716797, "metricx_qe_score": 12.53211498260498, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "pt", "output": "twenty It is available on the internet and can be stored via", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 22.472605452558323, "xcomet_score": 0.16726672649383545, "xcomet_qe_score": 0.19152633845806122, "metricx_score": 24.622356414794922, "metricx_qe_score": 22.07883071899414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "pt", "output": "pi this system has a simple based text classification model and outputs one of five problems such as features or bug fixes for each input commit message the image is a sample usage that returns a correct tape", "metrics": {"bleu_score": 0.0, "chrf_score": 26.049563231627566, "xcomet_score": 0.2364247888326645, "xcomet_qe_score": 0.17393292486667633, "metricx_score": 22.14012336730957, "metricx_qe_score": 21.763566970825195, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "pt", "output": "or bug fixes rub que training data is fair", "metrics": {"bleu_score": 1.7539413943549187, "chrf_score": 8.897116766013308, "xcomet_score": 0.13204927742481232, "xcomet_qe_score": 0.14749382436275482, "metricx_score": 23.618297576904297, "metricx_qe_score": 21.02003288269043, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "pt", "output": "ly small about 5000 and will be shown in the experiments described below the performance of the", "metrics": {"bleu_score": 0.0, "chrf_score": 18.784458797268293, "xcomet_score": 0.21432465314865112, "xcomet_qe_score": 0.24384108185768127, "metricx_score": 23.148914337158203, "metricx_qe_score": 18.96624755859375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "pt", "output": "text classification model is not high", "metrics": {"bleu_score": 7.0550047212602784, "chrf_score": 44.158125689167, "xcomet_score": 0.5696426630020142, "xcomet_qe_score": 0.8779890537261963, "metricx_score": 23.892139434814453, "metricx_qe_score": 16.159461975097656, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "pt", "output": "i present two related researches but there are problems of limited applicability and scarce data resources Our paper solves these two", "metrics": {"bleu_score": 0.0, "chrf_score": 29.12101249897323, "xcomet_score": 0.5653696060180664, "xcomet_qe_score": 0.93437659740448, "metricx_score": 12.835412979125977, "metricx_qe_score": 9.764578819274902, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "pt", "output": "problems and automatically generates high quality resource For the limited applicability program we propose a high quality", "metrics": {"bleu_score": 0.0, "chrf_score": 29.002773991996396, "xcomet_score": 0.2532571256160736, "xcomet_qe_score": 0.2934989631175995, "metricx_score": 23.522865295410156, "metricx_qe_score": 22.152616500854492, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "pt", "output": "classifier sumization method using only commit message as input this proposed method can be used for all English repos", "metrics": {"bleu_score": 0.0, "chrf_score": 18.626799077298813, "xcomet_score": 0.13970410823822021, "xcomet_qe_score": 0.2537159323692322, "metricx_score": 19.22922134399414, "metricx_qe_score": 13.38653564453125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "pt", "output": "itories for the second problem of scar state resources we built ourr and some", "metrics": {"bleu_score": 0.0, "chrf_score": 16.918562746387156, "xcomet_score": 0.20114926993846893, "xcomet_qe_score": 0.10015016049146652, "metricx_score": 25.0, "metricx_qe_score": 21.606639862060547, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "pt", "output": "data consisting of about 82 000 pieces of data by correcting data from public Gitub repositories using the GitH API next I describe our", "metrics": {"bleu_score": 0.8421233161809804, "chrf_score": 18.226143148880443, "xcomet_score": 0.24251455068588257, "xcomet_qe_score": 0.31686368584632874, "metricx_score": 22.32314682006836, "metricx_qe_score": 17.783184051513672, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "pt", "output": "data here is an example update the left side is a commit message", "metrics": {"bleu_score": 0.0, "chrf_score": 12.135163986356892, "xcomet_score": 0.1290307641029358, "xcomet_qe_score": 0.1467800885438919, "metricx_score": 13.382883071899414, "metricx_qe_score": 11.140630722045898, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "pt", "output": "and the right side is the release", "metrics": {"bleu_score": 0.0, "chrf_score": 9.240137817789394, "xcomet_score": 0.13795723021030426, "xcomet_qe_score": 0.14085297286510468, "metricx_score": 13.64885425567627, "metricx_qe_score": 5.479835510253906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "pt", "output": "notes the release notes are leveled as improvements of faces etc", "metrics": {"bleu_score": 1.9833734500134768, "chrf_score": 13.889524339625481, "xcomet_score": 0.13457942008972168, "xcomet_qe_score": 0.1336784064769745, "metricx_score": 20.519407272338867, "metricx_qe_score": 17.447063446044922, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "pt", "output": "we have set up a task that takes the commit messages", "metrics": {"bleu_score": 0.0, "chrf_score": 11.88475799867383, "xcomet_score": 0.11003892123699188, "xcomet_qe_score": 0.12908075749874115, "metricx_score": 23.508132934570312, "metricx_qe_score": 8.873825073242188, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "pt", "output": "as input and outputs the rabbit is notes this can be regarded as a", "metrics": {"bleu_score": 2.1340743160056204, "chrf_score": 11.305586364126212, "xcomet_score": 0.22339989244937897, "xcomet_qe_score": 0.14148157835006714, "metricx_score": 23.427635192871094, "metricx_qe_score": 20.16238021850586, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "pt", "output": "summarization task", "metrics": {"bleu_score": 0.0, "chrf_score": 14.892266708912683, "xcomet_score": 0.5027620792388916, "xcomet_qe_score": 0.9832082986831665, "metricx_score": 13.32257080078125, "metricx_qe_score": 4.273648738861084, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "pt", "output": "we have predefined four levels features implements bug fixes deprecations removers and breaking changes these were set based on previous usage", "metrics": {"bleu_score": 0.0, "chrf_score": 20.619897794657046, "xcomet_score": 0.3367054760456085, "xcomet_qe_score": 0.7325511574745178, "metricx_score": 15.101466178894043, "metricx_qe_score": 11.980141639709473, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "pt", "output": "and other factors the is note on the bottom right and", "metrics": {"bleu_score": 0.0, "chrf_score": 13.248265368859888, "xcomet_score": 0.13690900802612305, "xcomet_qe_score": 0.14631062746047974, "metricx_score": 24.144550323486328, "metricx_qe_score": 22.344614028930664, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "pt", "output": "extracted from the list node shown on the bottom left. At this", "metrics": {"bleu_score": 1.9470723011608924, "chrf_score": 12.238892176595877, "xcomet_score": 0.26309940218925476, "xcomet_qe_score": 0.4208037257194519, "metricx_score": 22.701356887817383, "metricx_qe_score": 16.85529136657715, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "pt", "output": "time, it is necessary to detect the four rabbits that have been set up in pass, but", "metrics": {"bleu_score": 2.0244462660665508, "chrf_score": 18.76390156660696, "xcomet_score": 0.14265844225883484, "xcomet_qe_score": 0.5789690017700195, "metricx_score": 24.31892204284668, "metricx_qe_score": 21.211143493652344, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "pt", "output": "the levelss are not always consistent with each le.", "metrics": {"bleu_score": 3.7968017775955714, "chrf_score": 23.159207336755696, "xcomet_score": 0.39176565408706665, "xcomet_qe_score": 0.5904972553253174, "metricx_score": 23.628028869628906, "metricx_qe_score": 17.579059600830078, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "pt", "output": "For example, the improvement level includes improvements, enhancements, optimizations and so on.", "metrics": {"bleu_score": 3.0521968279991727, "chrf_score": 24.991858924436485, "xcomet_score": 0.875296950340271, "xcomet_qe_score": 0.8986577987670898, "metricx_score": 18.088146209716797, "metricx_qe_score": 16.698162078857422, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "pt", "output": "We prepared a vocabulary list of study levels for each of these notational variations use it to detect the risk", "metrics": {"bleu_score": 0.0, "chrf_score": 26.238651085461523, "xcomet_score": 0.25310420989990234, "xcomet_qe_score": 0.3078957796096802, "metricx_score": 24.269691467285156, "metricx_qe_score": 18.211570739746094, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "pt", "output": "node class and correct the text of the rest that follows as the risk no centers for the class next is a commit message commit messages are not tied to each race", "metrics": {"bleu_score": 1.1599713834969503, "chrf_score": 23.85595635649369, "xcomet_score": 0.13018907606601715, "xcomet_qe_score": 0.14781755208969116, "metricx_score": 25.0, "metricx_qe_score": 21.48072624206543, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "pt", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.24386876821517944, "xcomet_qe_score": 0.2683866024017334, "metricx_score": 6.878838539123535, "metricx_qe_score": 4.923519611358643, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "pt", "output": "as shown in the image below, if the current release is version two point five", "metrics": {"bleu_score": 0.0, "chrf_score": 13.915207760018838, "xcomet_score": 0.13041731715202332, "xcomet_qe_score": 0.14986887574195862, "metricx_score": 16.234159469604492, "metricx_qe_score": 9.44713020324707, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "pt", "output": "to nineteen, we need to identify the previous release version two point five to eighteen and get it di.", "metrics": {"bleu_score": 1.5474934839449572, "chrf_score": 15.79641426021096, "xcomet_score": 0.21789467334747314, "xcomet_qe_score": 0.597528874874115, "metricx_score": 25.0, "metricx_qe_score": 23.735424041748047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "pt", "output": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "metrics": {"bleu_score": 1.506189323093867, "chrf_score": 17.41780299626545, "xcomet_score": 0.980060338973999, "xcomet_qe_score": 0.9952493906021118, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "pt", "output": "We created a heuristic matching glue to get the previous and", "metrics": {"bleu_score": 0.0, "chrf_score": 16.485065692030265, "xcomet_score": 0.303134948015213, "xcomet_qe_score": 0.6186525225639343, "metricx_score": 25.0, "metricx_qe_score": 21.323787689208984, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "pt", "output": "next versions data analysis in the end 7", "metrics": {"bleu_score": 0.0, "chrf_score": 11.376134374424176, "xcomet_score": 0.13852092623710632, "xcomet_qe_score": 0.135369211435318, "metricx_score": 16.897689819335938, "metricx_qe_score": 10.1676607131958, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "pt", "output": "200 repositories and 82 000 pieces of data were corrected also the average number of reasonable", "metrics": {"bleu_score": 0.0, "chrf_score": 20.204645981378157, "xcomet_score": 0.21629828214645386, "xcomet_qe_score": 0.14723894000053406, "metricx_score": 20.012582778930664, "metricx_qe_score": 17.551515579223633, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "pt", "output": "tokens is 63 which is quite high for summarization tasks", "metrics": {"bleu_score": 0.6936131288608464, "chrf_score": 13.558877690061829, "xcomet_score": 0.4132988154888153, "xcomet_qe_score": 0.7001975774765015, "metricx_score": 23.172996520996094, "metricx_qe_score": 18.770071029663086, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "pt", "output": "also the number of unique tokens is quite rich at eight eight thirty 000 this is due to the large number", "metrics": {"bleu_score": 1.8160849415439309, "chrf_score": 18.199795623270308, "xcomet_score": 0.27600204944610596, "xcomet_qe_score": 0.6222856044769287, "metricx_score": 19.55878448486328, "metricx_qe_score": 18.506879806518555, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "pt", "output": "of unique classs and method names found in the repository next", "metrics": {"bleu_score": 0.0, "chrf_score": 21.393063122248236, "xcomet_score": 0.22637087106704712, "xcomet_qe_score": 0.5189670324325562, "metricx_score": 24.208290100097656, "metricx_qe_score": 20.869380950927734, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "pt", "output": "I will explain the proposed method the crosswise extra", "metrics": {"bleu_score": 0.0, "chrf_score": 22.514911026834117, "xcomet_score": 0.2670859694480896, "xcomet_qe_score": 0.7826144695281982, "metricx_score": 18.59450912475586, "metricx_qe_score": 13.753741264343262, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "pt", "output": "ctive and abstractive summarization model consists of two neural modules", "metrics": {"bleu_score": 3.412026019370888, "chrf_score": 40.406448682099295, "xcomet_score": 0.2713722884654999, "xcomet_qe_score": 0.5364689230918884, "metricx_score": 25.0, "metricx_qe_score": 23.490169525146484, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "pt", "output": "a classifier using bot or code bot and the generator using bot first G uses a classi", "metrics": {"bleu_score": 0.0, "chrf_score": 20.384115150432304, "xcomet_score": 0.17803384363651276, "xcomet_qe_score": 0.41972315311431885, "metricx_score": 20.55746841430664, "metricx_qe_score": 17.716964721679688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "pt", "output": "fier to classify each commit message into five base node classes features improvements bug fixes deprecations press and other the commit messages classified", "metrics": {"bleu_score": 1.0660593091649477, "chrf_score": 26.133713042024514, "xcomet_score": 0.23347842693328857, "xcomet_qe_score": 0.33807891607284546, "metricx_score": 23.122583389282227, "metricx_qe_score": 21.425634384155273, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "pt", "output": "as other are discarded then she applies a generator to the four", "metrics": {"bleu_score": 0.0, "chrf_score": 16.85848461931686, "xcomet_score": 0.13610367476940155, "xcomet_qe_score": 0.14677858352661133, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "pt", "output": "rubber documents independently and generates read note for each class in this task the direct", "metrics": {"bleu_score": 0.0, "chrf_score": 26.710912035260215, "xcomet_score": 0.21297873556613922, "xcomet_qe_score": 0.14546683430671692, "metricx_score": 21.56770896911621, "metricx_qe_score": 19.702775955200195, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "pt", "output": "correspondences between commit messages and read notes are not known.", "metrics": {"bleu_score": 1.8110197178625276, "chrf_score": 20.903911383994757, "xcomet_score": 0.4429987072944641, "xcomet_qe_score": 0.8309930562973022, "metricx_score": 21.72446632385254, "metricx_qe_score": 14.7717924118042, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "pt", "output": "Therefore, to train the classifier classifier we assign pseudo variables to each input commit message using the first 10 characters of each commit message.", "metrics": {"bleu_score": 1.4173634433084163, "chrf_score": 21.496149067722634, "xcomet_score": 0.7805153131484985, "xcomet_qe_score": 0.9099615812301636, "metricx_score": 15.588823318481445, "metricx_qe_score": 8.858224868774414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "pt", "output": "We model the classwise abstractive summization approach by two defined methods.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 37.117174980769, "xcomet_score": 0.79559326171875, "xcomet_qe_score": 0.9202441573143005, "metricx_score": 15.927694320678711, "metricx_qe_score": 8.735235214233398, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "pt", "output": "The first model, which we call GS single consists of a single sex network and generates a single long is not text given a concatenation of input commit messages the output text can be", "metrics": {"bleu_score": 1.350592042277739, "chrf_score": 25.133074620622747, "xcomet_score": 0.26731565594673157, "xcomet_qe_score": 0.35547590255737305, "metricx_score": 23.79433822631836, "metricx_qe_score": 21.0357608795166, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "pt", "output": "divided into class file segment based on special class specific endpoint symbols the second method method which we call", "metrics": {"bleu_score": 0.0, "chrf_score": 27.362893678450394, "xcomet_score": 0.2419130802154541, "xcomet_qe_score": 0.3456535339355469, "metricx_score": 18.688657760620117, "metricx_qe_score": 15.701384544372559, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "pt", "output": "shes much consists of four different sec to sec networks, each of which corresponds to one of the least node classes.", "metrics": {"bleu_score": 1.5304756282275755, "chrf_score": 24.198786462280903, "xcomet_score": 0.17996510863304138, "xcomet_qe_score": 0.37246787548065186, "metricx_score": 24.214889526367188, "metricx_qe_score": 21.660524368286133, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "pt", "output": "Okay, let me explain the experiment.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 26.600214534940413, "xcomet_score": 0.9063941240310669, "xcomet_qe_score": 0.9931985139846802, "metricx_score": 8.290324211120605, "metricx_qe_score": 6.029204845428467, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "pt", "output": "Five methods were compared gs shes single shes much clustering, and previous study Gri", "metrics": {"bleu_score": 2.0128303461390598, "chrf_score": 24.121142441558714, "xcomet_score": 0.18214863538742065, "xcomet_qe_score": 0.5126953721046448, "metricx_score": 23.122713088989258, "metricx_qe_score": 23.015230178833008, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "pt", "output": "regarding aberration in some cases, these notes are output in multiple sentences, since it is difficult", "metrics": {"bleu_score": 2.416027466056967, "chrf_score": 15.54583144400844, "xcomet_score": 0.2821044325828552, "xcomet_qe_score": 0.631522536277771, "metricx_score": 18.79872703552246, "metricx_qe_score": 13.750955581665039, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "pt", "output": "to correct the number of sentences at zero, they are combined with spaces and treated as one long sentence.", "metrics": {"bleu_score": 1.963506200603642, "chrf_score": 18.49774856656753, "xcomet_score": 0.4333340525627136, "xcomet_qe_score": 0.7977458238601685, "metricx_score": 24.95100212097168, "metricx_qe_score": 17.672765731811523, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "pt", "output": "The blue is penal when the system out", "metrics": {"bleu_score": 0.0, "chrf_score": 14.278731270365174, "xcomet_score": 0.24572576582431793, "xcomet_qe_score": 0.5075883865356445, "metricx_score": 24.703310012817383, "metricx_qe_score": 23.310720443725586, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "pt", "output": "puts a short sentence", "metrics": {"bleu_score": 1.0211566521809647, "chrf_score": 6.124458645432875, "xcomet_score": 0.14190955460071564, "xcomet_qe_score": 0.142976313829422, "metricx_score": 24.484743118286133, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "pt", "output": "this penalty results in a lower brew value in the experiments results described next finally we also caricagate a specificity because blue and blue cannot", "metrics": {"bleu_score": 1.506189323093867, "chrf_score": 21.62171176360072, "xcomet_score": 0.22035886347293854, "xcomet_qe_score": 0.14745602011680603, "metricx_score": 25.0, "metricx_qe_score": 24.70882797241211, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "pt", "output": "be caricated if the list notes are empty a high specificity means that the model correctly outputs are empty text in cases where the read nod", "metrics": {"bleu_score": 0.0, "chrf_score": 23.95703935083846, "xcomet_score": 0.24817383289337158, "xcomet_qe_score": 0.3367377519607544, "metricx_score": 21.569332122802734, "metricx_qe_score": 18.448917388916016, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "pt", "output": "es assume empty here", "metrics": {"bleu_score": 0.0, "chrf_score": 9.642907009215303, "xcomet_score": 0.1415107697248459, "xcomet_qe_score": 0.14346419274806976, "metricx_score": 7.999361515045166, "metricx_qe_score": 8.028327941894531, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "pt", "output": "are the results since the data set contains email analysis harsh values etc we also evaluated the cleaned data set which excludes them G", "metrics": {"bleu_score": 1.2252821950931354, "chrf_score": 18.690210893162096, "xcomet_score": 0.3521023690700531, "xcomet_qe_score": 0.5591825842857361, "metricx_score": 18.214353561401367, "metricx_qe_score": 13.202864646911621, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "pt", "output": "AS and Gs achieved loose error scores more than 10 points higher than the baseline.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 15.102494930736658, "xcomet_score": 0.16267427802085876, "xcomet_qe_score": 0.48717308044433594, "metricx_score": 21.13605499267578, "metricx_qe_score": 16.303020477294922, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "pt", "output": "In particular on the Korean test set the score gap between the proposed method and the baseline jumped to more than 20 points.", "metrics": {"bleu_score": 1.5191100084465543, "chrf_score": 23.757101489406494, "xcomet_score": 0.5904858112335205, "xcomet_qe_score": 0.800737738609314, "metricx_score": 18.900672912597656, "metricx_qe_score": 11.000584602355957, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "pt", "output": "These results indicate that Gs and Gs are significantly effective.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 33.19006409913563, "xcomet_score": 0.24959826469421387, "xcomet_qe_score": 0.5465819835662842, "metricx_score": 24.845333099365234, "metricx_qe_score": 21.0704402923584, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "pt", "output": "Gs got to a better Lo score than GAS, suggesting that combining a classifier under generator is effective in training the classifier using servers.", "metrics": {"bleu_score": 1.6300753344054786, "chrf_score": 23.741640138435834, "xcomet_score": 0.07301989942789078, "xcomet_qe_score": 0.34671592712402344, "metricx_score": 24.469335556030273, "metricx_qe_score": 20.618593215942383, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "pt", "output": "The high coverage of Gs can be achieved properly because the classifier can focus on selecting relevant commit messages for each class.", "metrics": {"bleu_score": 1.5095250248540109, "chrf_score": 23.976244364432244, "xcomet_score": 0.46666377782821655, "xcomet_qe_score": 0.7006405591964722, "metricx_score": 23.787670135498047, "metricx_qe_score": 17.411502838134766, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "pt", "output": "Ches much tended to eat higher air than she is single suggesting that it is also effective to independ", "metrics": {"bleu_score": 0.0, "chrf_score": 17.591610350906976, "xcomet_score": 0.22821642458438873, "xcomet_qe_score": 0.14508411288261414, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "pt", "output": "ently develop different two constructive summarization models for each piece node class here an error analysis", "metrics": {"bleu_score": 1.9046304733974748, "chrf_score": 30.295618521746526, "xcomet_score": 0.2327084094285965, "xcomet_qe_score": 0.14177167415618896, "metricx_score": 22.430049896240234, "metricx_qe_score": 20.280590057373047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "pt", "output": "she methods", "metrics": {"bleu_score": 0.0, "chrf_score": 6.0606060606060606, "xcomet_score": 0.11642303317785263, "xcomet_qe_score": 0.10558430850505829, "metricx_score": 18.439205169677734, "metricx_qe_score": 22.72782325744629, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "pt", "output": "tend to output shorter sentences r na frawdde referencenol,. yn y f", "metrics": {"bleu_score": 2.292084231617577, "chrf_score": 17.171200741804448, "xcomet_score": 0.13782453536987305, "xcomet_qe_score": 0.14324644207954407, "metricx_score": 25.0, "metricx_qe_score": 23.643386840820312, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "pt", "output": "a dan, mae y referferenence tri o 4 fraddeg, tra shes un.", "metrics": {"bleu_score": 2.305354994989551, "chrf_score": 15.448655319942098, "xcomet_score": 0.1318335086107254, "xcomet_qe_score": 0.1343667358160019, "metricx_score": 22.70953369140625, "metricx_qe_score": 25.0, "linguapy_score": [1, "WELSH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "pt", "output": "rhesr model yw bod mewn data hyffordt, on 33% o'r frawddeg yn bresennol yn lefel nodweddion a 4 percent in the improvements level furthermore cs methods cannot generate", "metrics": {"bleu_score": 1.1691409285308028, "chrf_score": 18.50929750679347, "xcomet_score": 0.20611509680747986, "xcomet_qe_score": 0.21011920273303986, "metricx_score": 23.41393280029297, "metricx_qe_score": 23.124671936035156, "linguapy_score": [1, "WELSH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "pt", "output": "accurate list note without additional information the top example on the right is an example of a very messy", "metrics": {"bleu_score": 0.0, "chrf_score": 21.12752705960786, "xcomet_score": 0.1330540031194687, "xcomet_qe_score": 0.15050528943538666, "metricx_score": 21.004188537597656, "metricx_qe_score": 18.268239974975586, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "pt", "output": "commit message and the complete sentence cannot be generated without difference to the corresponding prerogates or issue.", "metrics": {"bleu_score": 0.9867048034309054, "chrf_score": 23.547335289250807, "xcomet_score": 0.16584667563438416, "xcomet_qe_score": 0.5317339897155762, "metricx_score": 23.786697387695312, "metricx_qe_score": 20.339298248291016, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "pt", "output": "The example below shows that the two committed messages in the input are related and should be combined into one sentence but it fails to", "metrics": {"bleu_score": 0.0, "chrf_score": 18.893843787498795, "xcomet_score": 0.708564281463623, "xcomet_qe_score": 0.8682042360305786, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "pt", "output": "do so.", "metrics": {"bleu_score": 0.0, "chrf_score": 5.957446808510639, "xcomet_score": 0.1493692398071289, "xcomet_qe_score": 0.11601965129375458, "metricx_score": 21.894765853881836, "metricx_qe_score": 16.15890121459961, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "pt", "output": "Finally a conclusion we have built a new data set for automatic personal generation.", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 18.87794870469314, "xcomet_score": 0.24031677842140198, "xcomet_qe_score": 0.6259599924087524, "metricx_score": 19.596731185913086, "metricx_qe_score": 14.595757484436035, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "pt", "output": "we have also formulated the task of entering committed messages e resumá-las para seja aplicável a todos os projetos escritos em inglês.", "metrics": {"bleu_score": 41.07267548317981, "chrf_score": 54.56133788477116, "xcomet_score": 0.5676428079605103, "xcomet_qe_score": 0.7148905992507935, "metricx_score": 18.692325592041016, "metricx_qe_score": 17.707778930664062, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "pt", "output": "As nossas experiências mostram que o método propos gera menos baru não com cobertura maior do que as linhas de básica.", "metrics": {"bleu_score": 42.396971004714274, "chrf_score": 60.56193873761203, "xcomet_score": 0.46424663066864014, "xcomet_qe_score": 0.49368053674697876, "metricx_score": 18.878856658935547, "metricx_qe_score": 18.98603057861328, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "pt", "output": "Por favor, observehem o nosso desert no GitHub. Obrigada", "metrics": {"bleu_score": 17.542198478193427, "chrf_score": 31.605298984502838, "xcomet_score": 0.7621485590934753, "xcomet_qe_score": 0.6921006441116333, "metricx_score": 11.29407787322998, "metricx_qe_score": 15.253816604614258, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "pt", "output": "Olá.", "metrics": {"bleu_score": 0.0, "chrf_score": 6.25, "xcomet_score": 0.5394234657287598, "xcomet_qe_score": 0.2768343687057495, "metricx_score": 5.990339756011963, "metricx_qe_score": 6.684342861175537, "linguapy_score": [1, "HUNGARIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "pt", "output": "Me nomemo-me Safari", "metrics": {"bleu_score": 0.0, "chrf_score": 19.331782447491147, "xcomet_score": 0.11610472202301025, "xcomet_qe_score": 0.10992288589477539, "metricx_score": 21.179073333740234, "metricx_qe_score": 19.107643127441406, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "pt", "output": "e vou apresentar o nosso artigo, \"Fture Enamentoular de Data Fu\" usando artecturas de Transformers\". ci", "metrics": {"bleu_score": 22.512214161783973, "chrf_score": 41.32813782991236, "xcomet_score": 0.03811349719762802, "xcomet_qe_score": 0.05645003914833069, "metricx_score": 22.74243927001953, "metricx_qe_score": 19.586925506591797, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "pt", "output": "entistas analisam dados e centram-se principalmente em manipulação das características existentes dos dados.", "metrics": {"bleu_score": 43.94900482337444, "chrf_score": 81.89942926836916, "xcomet_score": 0.7226266860961914, "xcomet_qe_score": 0.7362080216407776, "metricx_score": 11.136177062988281, "metricx_qe_score": 9.68970775604248, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "pt", "output": "Mas às vezes estas características são limitadas.", "metrics": {"bleu_score": 43.79518644116555, "chrf_score": 78.96368800125518, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3212319612503052, "metricx_qe_score": 0.5153800249099731, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "pt", "output": "A geração de usando outra fonte de dados pode adicionar informações substancial.", "metrics": {"bleu_score": 45.154353252898716, "chrf_score": 69.97572352082277, "xcomet_score": 0.4891972243785858, "xcomet_qe_score": 0.599427342414856, "metricx_score": 11.529274940490723, "metricx_qe_score": 15.373510360717773, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "pt", "output": "O nosso objetivo de pesquisa é enrique de dados tabularática usando texto livre de base externa.", "metrics": {"bleu_score": 35.42420438033105, "chrf_score": 65.87201952777211, "xcomet_score": 0.6071549654006958, "xcomet_qe_score": 0.7049840688705444, "metricx_score": 13.382993698120117, "metricx_qe_score": 11.909661293029785, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "pt", "output": "Suponham que temos um conjunto de dados tabular e uma base de conhecimento.", "metrics": {"bleu_score": 91.93227152249175, "chrf_score": 93.31702673536189, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 4.733827590942383, "metricx_qe_score": 2.642016887664795, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "pt", "output": "Precisamos de um processo automático que envolve ligação e análise de texto para extrair novas características do texto livre base de conhecimento.", "metrics": {"bleu_score": 68.9566868536195, "chrf_score": 85.78452687386911, "xcomet_score": 0.7955914735794067, "xcomet_qe_score": 0.8595521450042725, "metricx_score": 4.915583610534668, "metricx_qe_score": 5.163534641265869, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "pt", "output": "O nosso estrutura, FST, é exatamente este processo automático.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 71.11974112872583, "xcomet_score": 0.7383326292037964, "xcomet_qe_score": 0.6323556900024414, "metricx_score": 8.669337272644043, "metricx_qe_score": 9.846590995788574, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos ver um exemplo. Um conjunto de dadosdos no FST.", "metrics": {"bleu_score": 27.09198854675628, "chrf_score": 61.590654963519576, "xcomet_score": 0.774579644203186, "xcomet_qe_score": 0.7547316551208496, "metricx_score": 8.91914176940918, "metricx_qe_score": 7.33004903793335, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "pt", "output": "Neste exemplo, o conjunto de dados é um conjunto de dados da universidaditário", "metrics": {"bleu_score": 83.85766789076261, "chrf_score": 89.4739010059477, "xcomet_score": 0.8689384460449219, "xcomet_qe_score": 0.8632604479789734, "metricx_score": 4.271634101867676, "metricx_qe_score": 3.949340581893921, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "pt", "output": "quando o seu objetivo é classificar universidades em universidades de baixo e universidades de alto ranking.", "metrics": {"bleu_score": 51.8317014883035, "chrf_score": 80.28088672692691, "xcomet_score": 0.973908543586731, "xcomet_qe_score": 0.9863632321357727, "metricx_score": 4.743597507476807, "metricx_qe_score": 2.5512521266937256, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "pt", "output": "Como base de conhecimento, usamos Wikipedia.", "metrics": {"bleu_score": 62.401954419369176, "chrf_score": 81.7892232901484, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.578803539276123, "metricx_qe_score": 0.4151553213596344, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "pt", "output": "A primeira fase primeiro é a ligação de entidades.", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 40.101716032009605, "xcomet_score": 0.7097853422164917, "xcomet_qe_score": 0.839407742023468, "metricx_score": 11.235349655151367, "metricx_qe_score": 14.802027702331543, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "pt", "output": "Quando cada entidade, neste exemplo, o nome da universidadite, está ligada a uma entidade dentro da base de conhecimento,", "metrics": {"bleu_score": 72.00242075875518, "chrf_score": 86.1332907760024, "xcomet_score": 0.9346430897712708, "xcomet_qe_score": 0.9530114531517029, "metricx_score": 5.326765537261963, "metricx_qe_score": 5.679219722747803, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "pt", "output": "e o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.", "metrics": {"bleu_score": 93.91044157537529, "chrf_score": 98.65701210672371, "xcomet_score": 0.9781453013420105, "xcomet_qe_score": 0.9472671747207642, "metricx_score": 1.6409482955932617, "metricx_qe_score": 2.652442216873169, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "pt", "output": "Neste exemplo, o texto é o abstra página da Wikipedia.", "metrics": {"bleu_score": 53.90594848489677, "chrf_score": 72.5585251790691, "xcomet_score": 0.8688762187957764, "xcomet_qe_score": 0.9134494066238403, "metricx_score": 9.262340545654297, "metricx_qe_score": 8.704437255859375, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "pt", "output": "Agora precisamos de gerar ou extrair características do textoribudo", "metrics": {"bleu_score": 53.78454936756791, "chrf_score": 80.89062370372861, "xcomet_score": 0.8833663463592529, "xcomet_qe_score": 0.9405874013900757, "metricx_score": 5.271149635314941, "metricx_qe_score": 2.612772226333618, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "pt", "output": "Pre precisamosamos de uma fase de extração de características que inclu a análise de texto.", "metrics": {"bleu_score": 45.788313721339826, "chrf_score": 82.14837414583161, "xcomet_score": 0.881747841835022, "xcomet_qe_score": 0.8589053153991699, "metricx_score": 9.684562683105469, "metricx_qe_score": 10.415945053100586, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "pt", "output": "Esta é a principal novidadeste artigo, e vou infundar nel nos próximos slides.", "metrics": {"bleu_score": 14.162557969580968, "chrf_score": 55.83475773724687, "xcomet_score": 0.608588457107544, "xcomet_qe_score": 0.7069188356399536, "metricx_score": 10.151134490966797, "metricx_qe_score": 10.43552017211914, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "pt", "output": "Depois da fase de extração características, há uma fase de geração quando usamos as características extraídas para gerar um pequeno número de novas características.", "metrics": {"bleu_score": 69.92372639703295, "chrf_score": 84.78402031705285, "xcomet_score": 0.9230475425720215, "xcomet_qe_score": 0.9196750521659851, "metricx_score": 4.683201789855957, "metricx_qe_score": 5.419867038726807, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, geramos características no número de classes do conjunto de dados original.", "metrics": {"bleu_score": 77.4403141014203, "chrf_score": 90.66862583550554, "xcomet_score": 0.896203339099884, "xcomet_qe_score": 0.8309355974197388, "metricx_score": 5.261117935180664, "metricx_qe_score": 10.709171295166016, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "pt", "output": "Neste exemplo, o conjunto de dados original tem duas classes.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1638288497924805, "metricx_qe_score": 3.1495063304901123, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "pt", "output": "primeiro geram duas novas características.", "metrics": {"bleu_score": 30.8198090959812, "chrf_score": 64.34206713591823, "xcomet_score": 0.4134460985660553, "xcomet_qe_score": 0.20174579322338104, "metricx_score": 13.98907470703125, "metricx_qe_score": 17.673288345336914, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "pt", "output": "mas se o conjunto de dados tem cinco classes, primeiro geram cinco novas características.", "metrics": {"bleu_score": 43.14793368698176, "chrf_score": 75.44350795113115, "xcomet_score": 0.7356507182121277, "xcomet_qe_score": 0.7948933839797974, "metricx_score": 12.314595222473145, "metricx_qe_score": 15.984792709350586, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "pt", "output": "Cada característica representa a probabilidade de cada classe.", "metrics": {"bleu_score": 59.694917920196445, "chrf_score": 88.61352237016342, "xcomet_score": 0.9723166227340698, "xcomet_qe_score": 0.9629209637641907, "metricx_score": 1.004165530204773, "metricx_qe_score": 1.9671485424041748, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "pt", "output": "Para analisar o texto, usamos o estado atual da análise for do texto, que são modelos de linguagem base de transformaador como Bair, GPT, X e LEDs, etc.", "metrics": {"bleu_score": 35.89627299986204, "chrf_score": 64.11668802703853, "xcomet_score": 0.42719078063964844, "xcomet_qe_score": 0.46070846915245056, "metricx_score": 16.70680046081543, "metricx_qe_score": 17.072830200195312, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "pt", "output": "Mas não é provável que possamos trein o modelo de linguagem usando os conjuntos de dados de entrada.", "metrics": {"bleu_score": 64.03406826535883, "chrf_score": 87.725230861664, "xcomet_score": 0.9084964990615845, "xcomet_qe_score": 0.9197856783866882, "metricx_score": 6.254057884216309, "metricx_qe_score": 7.278201103210449, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "pt", "output": "uma abordagem inua será umação de tarefa.", "metrics": {"bleu_score": 6.866210821983635, "chrf_score": 38.41826424762594, "xcomet_score": 0.19616928696632385, "xcomet_qe_score": 0.2048041671514511, "metricx_score": 17.488061904907227, "metricx_qe_score": 19.03759765625, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "pt", "output": "na fase de extração futur, podemoscarr o modelo de linguagem preinado,ar o modelo de linguagem o conjunto de dados de alvo,", "metrics": {"bleu_score": 31.32515629013381, "chrf_score": 54.24826818090369, "xcomet_score": 0.23194698989391327, "xcomet_qe_score": 0.2754378020763397, "metricx_score": 22.11147689819336, "metricx_qe_score": 21.99518585205078, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "pt", "output": "neste exemplo, paraar o modelo de linguagem para classificar o texto em classes, abstratos em classes baixos ou altas,", "metrics": {"bleu_score": 26.40753948631095, "chrf_score": 69.13213351378027, "xcomet_score": 0.6189806461334229, "xcomet_qe_score": 0.5627654790878296, "metricx_score": 15.31467056274414, "metricx_qe_score": 17.322519302368164, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "pt", "output": "receber o produção do modelo de linguagem, que é a probabilidade para cada classe, e usá-lo como novas características.", "metrics": {"bleu_score": 63.50869045864349, "chrf_score": 81.33185844603979, "xcomet_score": 0.8317661285400391, "xcomet_qe_score": 0.827706515789032, "metricx_score": 11.511981964111328, "metricx_qe_score": 11.953968048095703, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "pt", "output": "O problema com esta abordagem é que os conjuntos de dados podem ter algumass de entidades.", "metrics": {"bleu_score": 40.64626339162434, "chrf_score": 74.02453004271365, "xcomet_score": 0.8242195844650269, "xcomet_qe_score": 0.8275496959686279, "metricx_score": 13.260635375976562, "metricx_qe_score": 13.402411460876465, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "pt", "output": "Na nossa experiência, quase metade dos conjuntos de dados contém menos de 400 amostras, e o conjunto de dados contém 35 amostras no seu conjunto de", "metrics": {"bleu_score": 52.17805173591459, "chrf_score": 67.89345446897237, "xcomet_score": 0.4385221600532532, "xcomet_qe_score": 0.43342748284339905, "metricx_score": 12.30950927734375, "metricx_qe_score": 12.15164566040039, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "pt", "output": ".izar um modelo de linguagem este conjunto de dados será ineficz.", "metrics": {"bleu_score": 42.643561433496174, "chrf_score": 71.31015527272571, "xcomet_score": 0.19358061254024506, "xcomet_qe_score": 0.14815324544906616, "metricx_score": 20.701379776000977, "metricx_qe_score": 21.37681770324707, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "pt", "output": "Mas podemos usar conhecimento anterior sobre conjuntos dados pré-anaalisados,", "metrics": {"bleu_score": 29.377167835760567, "chrf_score": 78.14426245663452, "xcomet_score": 0.9364011287689209, "xcomet_qe_score": 0.9889305233955383, "metricx_score": 3.1109302043914795, "metricx_qe_score": 1.8877021074295044, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "pt", "output": "porque aplicamos rápido sobre num conjunto múl conjunto de dados. Podemos usar os conjuntos de dados N-1 para reunilher informações sobre conjuntos de dados N-1 e usar esta informação quando analisamos o conjunto de dados NS", "metrics": {"bleu_score": 30.905205538351964, "chrf_score": 70.21244775708968, "xcomet_score": 0.22523441910743713, "xcomet_qe_score": 0.3003992736339569, "metricx_score": 17.779438018798828, "metricx_qe_score": 18.18929672241211, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "pt", "output": ". sugerimos é adicionacentr outra fase deção,", "metrics": {"bleu_score": 10.017352164720721, "chrf_score": 59.16276826558751, "xcomet_score": 0.2562379240989685, "xcomet_qe_score": 0.17252659797668457, "metricx_score": 20.761014938354492, "metricx_qe_score": 20.39994239807129, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "pt", "output": "uma fase de prelimi multitarefa quand", "metrics": {"bleu_score": 7.654112967106117, "chrf_score": 49.27359361388843, "xcomet_score": 0.19513419270515442, "xcomet_qe_score": 0.15770351886749268, "metricx_score": 15.233508110046387, "metricx_qe_score": 8.752350807189941, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "pt", "output": "omos o modelo de linguagem sobre conjuntos dados de1,", "metrics": {"bleu_score": 25.9162669876144, "chrf_score": 57.552112562261, "xcomet_score": 0.19977423548698425, "xcomet_qe_score": 0.16316546499729156, "metricx_score": 21.930315017700195, "metricx_qe_score": 20.59366226196289, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "pt", "output": "e depois executamos outra fase deção, que é uma tarefa quandomos o modelo de linguagem sobre o conjunto de alvo.", "metrics": {"bleu_score": 12.19373485374172, "chrf_score": 45.892833826190504, "xcomet_score": 0.1395379602909088, "xcomet_qe_score": 0.17986686527729034, "metricx_score": 22.6092472076416, "metricx_qe_score": 22.086713790893555, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "pt", "output": "A fase em de multittarefas chamada DN em D", "metrics": {"bleu_score": 5.0243511979240845, "chrf_score": 31.69127010556789, "xcomet_score": 0.16353027522563934, "xcomet_qe_score": 0.1548144370317459, "metricx_score": 24.367889404296875, "metricx_qe_score": 22.820392608642578, "linguapy_score": [1, "SWAHILI"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "pt", "output": "N DN mantém cabeças no número de tarefas no conjunto de trein.", "metrics": {"bleu_score": 50.08718428920986, "chrf_score": 75.00654060196695, "xcomet_score": 0.25120848417282104, "xcomet_qe_score": 0.1649714559316635, "metricx_score": 20.055267333984375, "metricx_qe_score": 20.961557388305664, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "pt", "output": "neste exemplo, há quatro tarefas no conjunto de tre DNN mantém quatro cabeças, como podem ver na imagem,", "metrics": {"bleu_score": 36.28680487624711, "chrf_score": 64.48511456306869, "xcomet_score": 0.44084978103637695, "xcomet_qe_score": 0.4861936867237091, "metricx_score": 13.520232200622559, "metricx_qe_score": 12.347769737243652, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "pt", "output": "e amostra um conjunto aleatório do conjunto de treinamento.", "metrics": {"bleu_score": 58.14307369682194, "chrf_score": 82.91140717591931, "xcomet_score": 0.8696701526641846, "xcomet_qe_score": 0.8474441170692444, "metricx_score": 3.6451053619384766, "metricx_qe_score": 4.2881550788879395, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "pt", "output": "Se o pont aleatório pertence a, por exemplo, tarefas de classificação de e, executam passos de frente e trás através da primeira cabeça.", "metrics": {"bleu_score": 25.076675052600773, "chrf_score": 56.005730694941356, "xcomet_score": 0.3289946913719177, "xcomet_qe_score": 0.34284719824790955, "metricx_score": 18.34781837463379, "metricx_qe_score": 18.528608322143555, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "pt", "output": "Se a pont aleatório pertence a aos tarefa de classifica pare, a sua a e passo através a última cabeça.", "metrics": {"bleu_score": 4.555072428047674, "chrf_score": 41.67527685166799, "xcomet_score": 0.16232115030288696, "xcomet_qe_score": 0.18358756601810455, "metricx_score": 21.935361862182617, "metricx_qe_score": 23.081262588500977, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "pt", "output": "No nosso cenário, os conjuntos de dados de tabau de variam o número de classes.", "metrics": {"bleu_score": 57.49089871602278, "chrf_score": 78.75186184226385, "xcomet_score": 0.6413428783416748, "xcomet_qe_score": 0.6276921629905701, "metricx_score": 15.692262649536133, "metricx_qe_score": 18.35240936279297, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "pt", "output": "há muitas tare", "metrics": {"bleu_score": 0.0, "chrf_score": 66.33737587501575, "xcomet_score": 0.17370815575122833, "xcomet_qe_score": 0.14897321164608002, "metricx_score": 9.604958534240723, "metricx_qe_score": 3.982440233230591, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "pt", "output": "fas.DNN mantém o número de classes,s, camadas de entrada.", "metrics": {"bleu_score": 24.601372576927535, "chrf_score": 55.12833119426642, "xcomet_score": 0.5460273027420044, "xcomet_qe_score": 0.4855996072292328, "metricx_score": 18.207292556762695, "metricx_qe_score": 17.68846893310547, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "pt", "output": "e alémmente, a DNN precisa de inicialmente novas cabeças para um novo conjunto de dados com uma nova tarefa.", "metrics": {"bleu_score": 52.710174649255045, "chrf_score": 72.63416893772468, "xcomet_score": 0.5339049696922302, "xcomet_qe_score": 0.5327234268188477, "metricx_score": 12.932059288024902, "metricx_qe_score": 9.452985763549805, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "pt", "output": "A nossa abordagem, chamadaação de reformaação de tarefa, é Na nossa abordagem, reforma de tarefas, em vez de manter múltiplas cabeças, reformulmos cada conjunto de dados numa uma frase por de classificação, que são duas tarefas.", "metrics": {"bleu_score": 36.70493138101402, "chrf_score": 71.9721370264445, "xcomet_score": 0.2209811806678772, "xcomet_qe_score": 0.2519797086715698, "metricx_score": 19.903764724731445, "metricx_qe_score": 19.670970916748047, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos ver um exemplo.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.12355342507362366, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui é o nosso conjunto de dados de entrada, que consiste em entidades, características, textos e classes.", "metrics": {"bleu_score": 62.683314725930124, "chrf_score": 87.46343517985545, "xcomet_score": 0.9984359741210938, "xcomet_qe_score": 0.9898344278335571, "metricx_score": 3.3732991218566895, "metricx_qe_score": 4.971810817718506, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "pt", "output": "e reformulamos a tarefa de classificar o texto em baixo e alto para classificar o texto, o abstrato e a classe em verdade ou falso.", "metrics": {"bleu_score": 35.14280181665739, "chrf_score": 69.36109381472872, "xcomet_score": 0.7490757703781128, "xcomet_qe_score": 0.7813981771469116, "metricx_score": 5.961008071899414, "metricx_qe_score": 3.6615285873413086, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "pt", "output": "Ou, Por outras palavras, treinmos o modelo de linguagem para classificar um abstrato e classe abstra em classe se o abstratos pertence à classe ou não", "metrics": {"bleu_score": 42.89210209369086, "chrf_score": 70.97471386035188, "xcomet_score": 0.2542497217655182, "xcomet_qe_score": 0.27695465087890625, "metricx_score": 14.754706382751465, "metricx_qe_score": 16.651491165161133, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "pt", "output": "o vetor de etiqueta no caso de Zick permanece sempre que consiste em duas classes.", "metrics": {"bleu_score": 24.207623565172998, "chrf_score": 55.32664762670362, "xcomet_score": 0.5325350761413574, "xcomet_qe_score": 0.567656397819519, "metricx_score": 11.718424797058105, "metricx_qe_score": 13.988643646240234, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "pt", "output": "Este é o algoritmo para da nossa abordagem deçãoada.", "metrics": {"bleu_score": 24.051990745470516, "chrf_score": 68.33219110883142, "xcomet_score": 0.37903013825416565, "xcomet_qe_score": 0.4067102074623108, "metricx_score": 17.392345428466797, "metricx_qe_score": 17.57729721069336, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos ver o quadro completo,", "metrics": {"bleu_score": 6.916271812933183, "chrf_score": 33.98293210763441, "xcomet_score": 0.9272948503494263, "xcomet_qe_score": 0.96285080909729, "metricx_score": 4.110948085784912, "metricx_qe_score": 2.4052724838256836, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "pt", "output": "um conjunto de dados empress", "metrics": {"bleu_score": 14.320952289897704, "chrf_score": 41.4617012272709, "xcomet_score": 0.17442263662815094, "xcomet_qe_score": 0.13738836348056793, "metricx_score": 16.128999710083008, "metricx_qe_score": 14.69334888458252, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "pt", "output": "e depois executa a fase de ligação extra", "metrics": {"bleu_score": 23.76101887396086, "chrf_score": 37.339540422808255, "xcomet_score": 0.49695295095443726, "xcomet_qe_score": 0.623528242111206, "metricx_score": 10.859770774841309, "metricx_qe_score": 12.130727767944336, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "pt", "output": "i o texto da base de conhecimento que neste exemplo é o abstrato da página Wikipedia De re", "metrics": {"bleu_score": 47.1945892787236, "chrf_score": 70.59615500906958, "xcomet_score": 0.06320241093635559, "xcomet_qe_score": 0.11040277779102325, "metricx_score": 17.85718536376953, "metricx_qe_score": 17.757051467895508, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "pt", "output": "formulaou a tarefa em tarefas de classificação.", "metrics": {"bleu_score": 5.4752948205155585, "chrf_score": 37.94685313196241, "xcomet_score": 0.15961356461048126, "xcomet_qe_score": 0.15001937747001648, "metricx_score": 16.41902732849121, "metricx_qe_score": 16.89828872680664, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "pt", "output": "aplicmos o modelo de linguagem à nova tarefa e a probabilidade de para cada classe.", "metrics": {"bleu_score": 76.59552353576204, "chrf_score": 83.54034057316355, "xcomet_score": 0.4075622856616974, "xcomet_qe_score": 0.5063478946685791, "metricx_score": 7.721858024597168, "metricx_qe_score": 10.474639892578125, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "pt", "output": "Reem que o modelo de linguagem é já estálinedo sobre conjunto de dados n- 1 usando uma prelimi de multiúltarefa pre.", "metrics": {"bleu_score": 21.85334445875697, "chrf_score": 57.377078101922606, "xcomet_score": 0.27444639801979065, "xcomet_qe_score": 0.21363236010074615, "metricx_score": 22.465991973876953, "metricx_qe_score": 21.577131271362305, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "pt", "output": "Depois usamos o vetor de produção do modelo de linguagem como uma característica nova gerada no número de classes.", "metrics": {"bleu_score": 43.40996883772063, "chrf_score": 61.972207868253925, "xcomet_score": 0.809945821762085, "xcomet_qe_score": 0.8666000962257385, "metricx_score": 6.722620487213135, "metricx_qe_score": 9.594111442565918, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "pt", "output": "Para avaliar o nosso quadro, usamos um conjunto de conjunto de classificação 17 que variam tamanho, características, equilíbrio, domínio e desempenho inicial.", "metrics": {"bleu_score": 45.07290611644319, "chrf_score": 68.43348739709347, "xcomet_score": 0.4104517102241516, "xcomet_qe_score": 0.41325345635414124, "metricx_score": 12.952165603637695, "metricx_qe_score": 12.10811996459961, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "pt", "output": "e como de conhecimento, usamos Wikipedia.", "metrics": {"bleu_score": 29.797147054518835, "chrf_score": 65.09739702278596, "xcomet_score": 0.7855020761489868, "xcomet_qe_score": 0.7988537549972534, "metricx_score": 5.667037487030029, "metricx_qe_score": 6.345597267150879, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "pt", "output": "Descemos a nossa experiência como avaliação quando treinamos rapidamente de 16 conjuntos de dados e aplicámos-lo ao 17 conjunto de dados.", "metrics": {"bleu_score": 21.142440414839033, "chrf_score": 52.086321413743306, "xcomet_score": 0.18654188513755798, "xcomet_qe_score": 0.2175007462501526, "metricx_score": 16.574382781982422, "metricx_qe_score": 15.445887565612793, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "pt", "output": "Também dividimos cada conjunto de dados em quatro fals e aplicamos uma cruzvaliação de fal.", "metrics": {"bleu_score": 44.71885284918139, "chrf_score": 63.98759756767504, "xcomet_score": 0.5757116079330444, "xcomet_qe_score": 0.5852847695350647, "metricx_score": 15.818169593811035, "metricx_qe_score": 15.933348655700684, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "pt", "output": "Depois geramos a nova característica e evalumo-los usando cinco classificadores de avaliação.", "metrics": {"bleu_score": 32.46827270101123, "chrf_score": 67.21551430053209, "xcomet_score": 0.838518500328064, "xcomet_qe_score": 0.8644111752510071, "metricx_score": 5.656549453735352, "metricx_qe_score": 7.135395526885986, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "pt", "output": "Usamos na nossa arquitetura baseada em aves experiência.", "metrics": {"bleu_score": 14.448814886766836, "chrf_score": 61.34614663710229, "xcomet_score": 0.5597086548805237, "xcomet_qe_score": 0.6290515661239624, "metricx_score": 21.48967933654785, "metricx_qe_score": 21.41704750061035, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "pt", "output": "Eis são os resultados da nossa experiência.", "metrics": {"bleu_score": 10.786826322527466, "chrf_score": 55.429090577354025, "xcomet_score": 0.9840636253356934, "xcomet_qe_score": 0.9886330366134644, "metricx_score": 1.5499215126037598, "metricx_qe_score": 2.5301647186279297, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "pt", "output": "Podem ver que comparamos o nosso quadro com de conjuntoização de tarefa eização mt preliminar", "metrics": {"bleu_score": 3.7962311934452404, "chrf_score": 35.50096353076953, "xcomet_score": 0.3467545211315155, "xcomet_qe_score": 0.374246746301651, "metricx_score": 22.487226486206055, "metricx_qe_score": 22.63295555114746, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "pt", "output": "e a nossa reformulcanram o melhor resultado o melhor desempenho enquanto", "metrics": {"bleu_score": 16.309710371282524, "chrf_score": 57.56317349113886, "xcomet_score": 0.16158047318458557, "xcomet_qe_score": 0.15815825760364532, "metricx_score": 17.754819869995117, "metricx_qe_score": 17.232995986938477, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "pt", "output": "mtdnnn atingiu cento melhoria nação de dados,", "metrics": {"bleu_score": 2.4068662848388516, "chrf_score": 22.439664812611255, "xcomet_score": 0.14160582423210144, "xcomet_qe_score": 0.1535181999206543, "metricx_score": 22.440885543823242, "metricx_qe_score": 23.289976119995117, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "pt", "output": "a nossa abordagem atingiu melhoria de 66%.", "metrics": {"bleu_score": 11.417530270031051, "chrf_score": 48.21438950120309, "xcomet_score": 0.9779214859008789, "xcomet_qe_score": 0.9896199703216553, "metricx_score": 13.835088729858398, "metricx_qe_score": 12.585969924926758, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "pt", "output": "Quando olharmos no pequeno conjunto de dados, podemos ver que o desempenho da mtDN diminui e a melhoria da fase preliminar de multitarefas diminu a 1,5 cento,", "metrics": {"bleu_score": 44.43083945142926, "chrf_score": 72.4820998452246, "xcomet_score": 0.7013057470321655, "xcomet_qe_score": 0.7108235359191895, "metricx_score": 7.624754428863525, "metricx_qe_score": 7.733475685119629, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "pt", "output": "mas o nosso desempenho aumentou para 11% em comparado com a tarefa al.", "metrics": {"bleu_score": 21.589378505946648, "chrf_score": 51.15625693704674, "xcomet_score": 0.5802342891693115, "xcomet_qe_score": 0.7026926279067993, "metricx_score": 13.347304344177246, "metricx_qe_score": 14.295722961425781, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "pt", "output": "Para resar, Fa permite enriquecimento de tiros de combustível de 35 amostras na nossa experiência.", "metrics": {"bleu_score": 4.964293039762434, "chrf_score": 48.934538913526296, "xcomet_score": 0.44951823353767395, "xcomet_qe_score": 0.3043815791606903, "metricx_score": 20.274433135986328, "metricx_qe_score": 19.841455459594727, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "pt", "output": "Usa uma arquitetura para todas ass conjuntos de dados,", "metrics": {"bleu_score": 43.01463832259786, "chrf_score": 79.60690150665724, "xcomet_score": 0.7744036912918091, "xcomet_qe_score": 0.4899062514305115, "metricx_score": 8.976827621459961, "metricx_qe_score": 11.379979133605957, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "pt", "output": "e mantém a cabeça do modelo.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 57.59908155827754, "xcomet_score": 0.7533038854598999, "xcomet_qe_score": 0.6710577011108398, "metricx_score": 7.7259087562561035, "metricx_qe_score": 10.414813041687012, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "pt", "output": "Mas acres a fase de reformulação.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 73.5749794203309, "xcomet_score": 0.8142354488372803, "xcomet_qe_score": 0.6029596924781799, "metricx_score": 7.4113616943359375, "metricx_qe_score": 7.709193229675293, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "pt", "output": "A aumentamenta o conjunto de tre e precisa de um valor de alvoivo com um significado semântico, para podemos introduá-lo no modelo de linguagem e usá-lo na problema de frase por classificação. Obrigada. (Aplausos", "metrics": {"bleu_score": 31.475558245733627, "chrf_score": 67.01233605005432, "xcomet_score": 0.2049315869808197, "xcomet_qe_score": 0.17795324325561523, "metricx_score": 20.231468200683594, "metricx_qe_score": 20.30608558654785, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "pt", "output": "Olá.", "metrics": {"bleu_score": 0.0, "chrf_score": 6.25, "xcomet_score": 0.5394234657287598, "xcomet_qe_score": 0.2768343687057495, "metricx_score": 5.990339756011963, "metricx_qe_score": 6.684342861175537, "linguapy_score": [1, "HUNGARIAN"]}}
