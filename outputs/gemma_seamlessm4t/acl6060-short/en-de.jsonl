{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen,\n\nheute werde ich unsere Forschungsarbeit vorstellen: Lernen zu deduktivem Schlussfolgern – materielles Problemlösen als komplexe Regelerfassung."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan vom Air Lab von Bython und dies ist eine Gemeinschaftsarbeit mit Cheri von der University of Texas at Austin und Weido von der SDU."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für Schlussfolgerungen sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen Ihnen Beispiele, bei denen die Grundnahrung gesund ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus der Arbeit, in der sie Prompting einsetzen, um das mathematische Problem in einem zukünftigen Lernkontext zu lösen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der Online-Stiftseite können wir sehen, dass wir, wenn wir einige Beispiele mit nur korrekten und vollständigen Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "aber wenn wir eine detailliertere Begründungsbeschreibung liefern, ist das Modell in der Lage, die Begründungsbeschreibung vorherzusagen und hierbei auch die korrekte Vorhersage zu treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, eine austauschbare, mehrstufige Schlussfolgerungskette zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind auch der Ansicht, dass die Methodenproblem-Analyse eine unkomplizierte Anwendung darstellt, um solche Denkfähigkeiten zu evaluieren."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier in unserem Problemaufbau, angesichts der gestellten Fragen, müssen wir diese Frage lösen und die numerischen Antworten ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "so in unseren Datensätzen wird uns auch der mathematische Ausdruck mitgeteilt, der zu dieser spezifischen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Auch bestimmte Annahmen gelten somit wie in vorangegangener Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "wir nehmen die Genauigkeit bekannter Größen an."}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten lediglich grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentialfunktion."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus lassen sich komplexe Operatoren tatsächlich in diese grundlegenden Operatoren zerlegen."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Da lässt sich frühere Arbeit im Bereich mathematisches Problemlösen tatsächlich in sequenzielle und sequenz-zu-Baum-Modelle einteilen."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "so konvertiert ein traditionelles Sequence-to-Sequence-Modell den Ausdruck in eine spezifische Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "und es ist relativ einfach zu implementieren und es kann auf viele verschiedene, komplexe Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "aber die Nachteile der Performance sind tatsächlich im Allgemeinen nicht besser als die des strukturellen Modells, und es fehlt an Interpretierbarkeit für Vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber tatsächlich ist diese Richtung immer noch recht populär, bedingt durch das Transformer-Modell."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumbasierten Modellen strukturieren wir diese Ausdrücke also in einer Baumform und folgen bei der Baumgenerierung einer Preorder-Durchquerung."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir weiterhin die Operatoren, bis wir die linken Elemente erreichen, welche die Mengen darstellen."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute daran ist also, dass es uns tatsächlich diese binäre Baumstruktur liefert und dass sie tatsächlich recht robust ist, weil wir zuerst den Operator erzeugen und dann am Ende die Mengen."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "und das zweite ist, dass es auch einige repetitive Kommutationen enthält."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "so hier, wenn wir uns dieses Ausdrucks ansehen, Atome drei plus drei werden tatsächlich zweimal erzeugt, aber in der Tat sollten wir die Ergebnisse verwenden."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Daher wollen wir in unserem vorgeschlagenen Ansatz diese Probleme schrittweise und interpretierbar lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "So zum Beispiel hier im zweiten Schritt, können wir diese Teiler erhalten, welcher 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können uns auch auf die ursprünglichen Fragen beziehen, um die relevanten Inhalte zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Also, im dritten Schritt erhalten wir tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Und nach diesen drei Schritten können wir die Ergebnisse aus dem zweiten Schritt tatsächlich reduzieren und dann die Ergebnisse des vierten Schritts erhalten und schließlich die Dividenden ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Das macht den Prozess präziser."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem didaktischen System beginnen wir zunächst mit einer Reihe von Größen, die in den Fragen präsentiert werden, einschließlich einiger Konstanten als unsere Initialismen."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Die Darstellung erfolgt somit durch E.I.J.O.P."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "wobei wir Operatoren von QI nach QJ ausführen und derartige Ausdrücke tatsächlich dirigiert sind."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir hier also auch die Subtraktion mit Wörtern, um die entgegengesetzte Richtung darzustellen."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist dem Rhodesianischen Extraktionsverfahren recht ähnlich."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "so in a formal deductive system at the time step t we apply the operator between the q and qjp here and then we obtain this new expression\n\nin einem formalen deduktiven System wenden wir also zum Zeitpunkt t den Operator zwischen q und qjp an, woraufhin wir diesen neuen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "wir fügen es dem, äh, dem nächsten Zustand hinzu, um eine neue Größe zu bilden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Folienabschnitt visualisiert also die Entwicklung der Zustände, bei der wir kontinuierlich Ausdrücke zu den aktuellen Zuständen hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vortrainiertes Sprachmodell, das Vögel oder Roboter sein kann, anschließend kodieren wir Sätze und erhalten schließlich diese quantitativen Repräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengenrepräsentationen haben, können wir mit der Inferenz beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Repräsentation für Q1 dividiert durch Q2 und dann multipliziert mit Q4 zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paarrepräsentation, welche im Wesentlichen die Konkatenation zwischen Q1 und Q2 ist, und anschließend wenden wir ein Feedforward-Netzwerk an, das durch den Operator parametrisiert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und dann schließlich erhalten wir die Ausdrucksdarstellung Q1 dividiert durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "aber in der Praxis, in der Anfangsphase, könnten wir womöglich auch die falsche Formulierung erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Da ist also die Gesamtzahl aller möglichen Ausdrücke gleich dem dreifachen der Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "das Schöne daran ist also, dass wir hier problemlos Constraints hinzufügen können, um diese Suche, diese Suche zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck nicht zulässig ist, können wir ihn einfach aus unserem Suchraum entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt gehen wir also wieder genauso vor, aber der einzige Unterschied besteht darin, dass – der einzige Unterschied ist lediglich eine weitere Größe."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe ergibt sich aus dem zuvor berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "So können wir schließlich diesen letzten Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "times Q4 und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt abweicht."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Solche Unterschiede erschweren die Anwendung von Beam Search, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgeglichen ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "da ist das Trainingsverfahren dem Training eines Sequence-to-Sequence-Modells ähnlich, bei dem wir die Gesetze in jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir dies auch, um darzustellen, wann wir diesen Generationsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz unterschiedlich, da der Raum in jedem Zeitschritt anders ist, während er in traditionellen Sequenz-zu-Sequenz-Modellen die Anzahl des Vokabulars bezeichnet."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "und es ermöglicht uns auch, bestimmte Einschränkungen aufgrund von Vorwissen zu definieren."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "da führten wir Experimente mit den gängigen Metropolis-Problem-Datensätzen MAWPS, Math23k, MathQA und swamp durch."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "und hier werden kurz die Ergebnisse im Vergleich zu den bisher besten Ansätzen dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unser leistungsstärkstes Werkzeug ist Roberts detektivisches Scharfsinn."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir keine Beam-Suche; im Gegensatz dazu nutzen offensichtliche Ansätze diese."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Gut. Die besten Ansätze sind oft ein baumartiges Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ist unser Reasoning-Ansatz also in der Lage, dieses Drei-Basen-Modell deutlich zu übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "aber wir können feststellen, dass die absoluten Zahlen auf Mathematik-Tests oder Schwimmprüfungen nicht besonders hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "So untersuchen wir die Ergebnisse bezüglich"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieses Datenset ist herausfordernd, da der Autor versuchte, manuell etwas hinzuzufügen, um das NLB-Modell zu verwirren, beispielsweise durch das Einfügen von Umweltinformationen und zusätzlichen Mengenangaben."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Da in unserer Vorhersage einige der Zwischenwerte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "In diesen Fragen geht es darum, wie viele Äpfel Jake hat?"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "aber wir haben zusätzliche Informationen wie siebzehn Feldwürfe und Steven hat acht Würfe, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell trifft also Vorhersagen wie diese, wodurch negative Werte entstehen."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Suchraum also tatsächlich einzuschränken, können wir beispielsweise Ergebnisse entfernen, die negativ sind, damit wir die – die Antwort korrekt erhalten."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Da stellen wir fest, dass diese Beschränkung tatsächlich die Leistung einiger Modelle erheblich verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Für Vögel verbessern wir sieben Punkte, und für das Robotik-Basismodell verbessern wir tatsächlich zwei Punkte."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell verfügt daher über eine bessere Fähigkeit zum Sprachverständnis, sodass die hier angegebene Zahl für Roboter höher und für den Menschen niedriger ausfällt."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen ebenfalls, die Schwierigkeiten hinter diesem #ahB zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "wir können davon ausgehen, dass die Anzahl der ungenutzten Menge hier als irrelevante Information betrachtet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der Swamp-Datensatz den größten Anteil ausmacht."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtperformance."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "für jene Proben ohne angegebenen Verbrauch, sodass die Gesamtleistung tatsächlich höher ist als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "aber mit diesen Proben, bei denen die ungenutzte Qualität tatsächlich deutlich schlechter ist als... äh... viel schlechter als"}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für M.W.P.S. haben wir leider keine Auskunft über die Fallzahlen, daher kann ich das im Moment nicht ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Da wollen wir abschließend die Interpretierbarkeit anhand eines Beispiels für einen Absturz und eine Beteiligung demonstrieren."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Da trifft unser Modell also schon im ersten Schritt die falsche Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Können wir diesen Ausdruck also tatsächlich mit diesem Satz hier in Beziehung setzen, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Daher vermuten wir, dass diese Indikatoren das Modell möglicherweise in die Irre führen und zu einer falschen Vorhersage veranlassen."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "so hier das Pflanzen von weiteren fünfunddreißig Elementen lässt das Modell annehmen, dass es sich um einen Additionsoperator handeln sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "wir versuchten daher, den Satz so umzuformulieren, dass er in etwa aussagt: die Anzahl der Birnbäume ist um fünfunddreißig geringer als die Anzahl der Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Da sorgen wir dafür, dass genauere Semantik verwendet wird, sodass das Modell die Vorhersage korrekt treffen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "so zeigt diese Studie, wie interpretierbare Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit also abzuschließen, ist unser Modell zunächst einmal recht effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "und wir können interpretierbare Einsparpotenziale aufzeigen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "und wir können problemlos Vorwissen als Einschränkung einbeziehen, was die Leistungsfähigkeit verbessern kann."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich ist zu beachten, dass der zugrunde liegende Mechanismus nicht nur auf Aufgaben zur Netzwerkproblembehebung anwendbar ist, sondern auch auf andere Aufgaben, die mehrstufiges Schlussfolgern erfordern."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "aber wir haben auch gewisse Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir eine große Anzahl von Operatoren oder Konstanten haben, kann der Speicherverbrauch recht hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das zweite Problem besteht darin, dass, wie bereits erwähnt, die Wahrscheinlichkeitsverteilung zwischen verschiedenen Zeitabschnitten unausgeglichen ist, was die Anwendung von Beam Searches ebenfalls sehr erschwert."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Damit ist der Vortrag nun beendet und Fragen sind willkommen.\nVielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine Arbeit mit John und Jerry vorstellen, welche sich mit einem neuen Datensatz für die Retrieval von gesetzlichen Artikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtliche Fragestellungen sind ein integraler Bestandteil vieler Menschenleben."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "aber die Mehrheit der Bürgerinnen und Bürger hat kaum oder gar kein Wissen über ihre Rechte und grundlegende rechtliche Verfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Folglich bleiben viele schutzbedürftige Bürgerinnen und Bürger, die sich den kostenintensiven Beistand eines Rechtsanwalts nicht leisten können, ungeschützt oder – schlimmer noch – ausgebeutet zurück."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen Menschen und dem Gesetz zu überbrücken, indem wir wirksame Retrieval-Systeme für Gesetzestexte entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "ein solches System könnte einen kostenlosen, professionellen Rechtsberatungsservice für ungelernte Personen bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns der Hauptleistung dieser Arbeit zuwenden, wollen wir zunächst das Problem der Retrieval von Gesetzesartikeln beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "bei einer einfachen Frage zu einem realen Sachverhalt, wie beispielsweise: was riskiere ich, wenn ich die berufliche Schweigepflicht verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Bestimmungen aus einem umfangreichen Rechtskorpus abzurufen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsbeschaffungsaufgabe ist mit ihren eigenen Herausforderungen verbunden."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst behandelt es zwei Arten von Sprache."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "alltägliche, verständliche Sprache für die Fragen\nund komplexe juristische Fachsprache für die Gesetze"}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in der Sprachverteilung erschweren es einem System, relevante Kandidaten abzurufen, da dies indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine juristische Frage übersetzen kann, die mit der Terminologie der Gesetze übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Neben dem Gesetzestext ist es nicht ein Stapel unabhängiger Artikel, die für sich allein als vollständige Informationsquelle behandelt werden können, anders als beispielsweise Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "stattdessen handelt es sich um eine Sammlung rechtlicher Bestimmungen, die erst in ihrer Gesamtheit einen Sinn ergibt, wenn sie im Zusammenhang mit ihrem Gesamtkontext betrachtet werden – also zusammen mit den ergänzenden Informationen aus ihren benachbarten Artikeln, den Bereichen und Teilbereichen, denen sie angehören, und ihrem Platz innerhalb der Struktur des Rechts."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "letztendlich stehen die Satzungsartikel in kleinen Abschnitten, welche in der Regel die typische Retrieval-Einheit in den meisten Retrieval-Arbeiten darstellen."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "hier handelt es sich um umfangreiche Dokumente, die bis zu sechs"}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben großes Interesse an vielen juristischen Aufgaben geweckt, wie beispielsweise der Vorhersage von Rechtsentscheidungen oder der automatisierten Prüfung von Kontaktverträgen."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "jedoch ist die Recherche anhand von Rechtsvorschriften hauptsächlich im Stillstand verharrt geblieben, bedingt durch den Mangel an großen, hochwertigen, annotierten Datensätzen."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir einen neuen, französischen, bürgernahen Datensatz, um zu untersuchen, ob Retrieval-Modelle die Effizienz und Zuverlässigkeit eines Rechtsexperten bei der Suche nach Gesetzartikeln approximieren können."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "oder belgische gesetzliche Artikelabrufdurchsatzmenge, bestehend aus mehr als eintausend einhundert"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen ein breites Themenspektrum, von Familie, Wohnen und Geld bis hin zu Arbeit und sozialer Sicherheit."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "jeder von ihnen wurde von erfahrenen Juristen unter Bezugnahme auf relevante Artikel aus einem Korpus von mehr als fünfundzwanzigtausendsechshundert bezeichnet."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Gesetze und Rechtsnormen. Lassen wir die Frage, wie wir diese Datensätze erhoben haben, unerwähnt."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst begannen wir damit, einen umfangreichen Korpus juristischer Artikel zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysierten dreißig zwei öffentlich zugängliche belgische Normen und extrahierten sämtliche Artikel sowie die jeweiligen Abschnittsüberschriften."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann erfassten wir juristische Fragen unter Angabe der entsprechenden Gesetzesverweise."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu gewährleisten, arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jährlich etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugriff auf ihre Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Fragestellungen in Belgien behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen erfasst, die mit Kategorien, Unterkategorien und Rechtsverweisen auf einschlägige Gesetze versehen sind."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "schließlich überprüften wir die juristischen Verweise und filterten die Fragen heraus, deren Verweise keine Artikel in einem der von uns berücksichtigten Gesetzestexte waren."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die übrigen Referenzen wurden abgeglichen und in die entsprechenden Artikel-IDs aus dem Korpus umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "wir endeten schließlich mit eintausendachthundertacht Fragen, die jeweils sorgfältig mit den Inhalten der relevanten Artikel versehen waren."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist jede Frage mit einer Hauptkategorie und einer Verkettung von Unterkategorien versehen."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "und jeder Artikel wird mit einer Verkettung seiner nachfolgenden Überschriften in der Struktur des Gesetzes versehen."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten aber für zukünftige Forschung im Bereich juristischer Informationsbeschaffung oder juristischer Textklassifikation von Interesse sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir einige Eigenschaften aller Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Der Fragebogen sollte zwischen fünf und vierundvierzig Wörtern lang sein, mit einem Median von vierzig."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "die Artikel sind deutlich länger, mit einer Medianlänge von&nbsp;siebzig sieben Wörtern und hundertvierzehn"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei davon, größer als ein Daumen."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "wie bereits erwähnt, behandelte die Frage ein breites Spektrum an Themen, von denen etwa fünfundachtzig Prozent sich auf Familie, Wohnen, Geld oder Gerechtigkeit bezogen."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "wobei die restlichen fünfzehn Prozent sich entweder auf die soziale Sicherheit, Ausländer oder die Arbeitswelt beziehen."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind zudem sehr vielfältig, da sie aus 32 verschiedenen belgischen Kodizes stammen, die eine große Anzahl juristischer Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "hier ist die Gesamtzahl der Artikel, die aus diesen belgischen Gesetzestexten zusammengetragen wurden."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den zweitausendsiebenhundertdreiunddreißig Artikeln werden lediglich eintausendsechshundertzwölf als für mindestens"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "Eine Frage im Datensatz, und etwa achtzig Prozent dieser zitierten Artikel stammen entweder aus dem Zivilgerichtsbereich, dem Schöffengerichtsbereich, dem kriminalpolizeilichen Ermittlungsgerichtsbereich oder dem Strafgerichtsbereich."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen haben achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "das sich daraus erklären lässt, dass der Code weniger auf Individuen und deren Anliegen fokussiert."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt liegt die Mediananzahl der Zitationen für diese zitierten Artikel bei zwei, und weniger als 25 Prozent von ihnen sind"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mithilfe unserer Datensätze bewerten wir verschiedene Retrieval-Ansätze, darunter lexikalische und dichte Architekturen."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Gegeben sei eine Anfrage in einem Artikel, so weist ein lexikalisches Modell dem Anfrage-Artikel-Paar einen Wert zu, indem es die Summe über die Anfragebegriffe der Gewichte jedes dieser Begriffe in diesem Artikel berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-Ranking-Funktionen tfi-idf und bm25."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen besteht darin, dass sie lediglich Artikel abrufen können, die Schlüsselwörter enthalten, die in der Anfrage vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Suchanfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein Biancode-Modell, das Anfragen und Artikel in dichte Vektordarstellungen abbildet und einen Relevanzwert für ein Anfrage-Artikel-Paar durch die Ähnlichkeit ihrer Einbettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen resultieren typischerweise aus einer Pooling-Operation auf der Ausgabe eines Wortvektormodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst untersuchen wir die Effektivität von Siamese-Bias-Codierern in einer Zero-Shot-Evaluierungsumgebung, was bedeutet, dass vortrainierte Word-Embedding-Modelle ohne zusätzliche Feinabstimmung direkt angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encoder-Modellen, namentlich Word2Vec und FastText, sowie mit kontextabhängigen Einbettungsmodellen, namentlich RoBERTa und, spezifischer, CamemBERT, einem französischen RoBERTa-Modell."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus trainieren wir unser eigenes, auf Camembert basierendes Modell, das über reine Codieraufgaben hinausgeht."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "In allen Datensätzen ist anzumerken, dass wir für das Training mit den zwei Varianten der Biancoro-Architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das Anfrage und Artikel in einem gemeinsamen, dichten Vektorraum abbildet, und zwei Tower, die zwei unabhängige Word-Embedding-Modelle nutzen, welche Anfrage und Artikel separat in unterschiedliche Einbettungsräume kodieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mittelwert-, Maximal- und CLS-Pooling sowie mit Punktprodukt und Kosinusähnlichkeit zur Berechnung von Ähnlichkeiten."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Baselines auf dem Testdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden bewerteten die siamesischen Beacon-Encoder in einem Zero-Shot-Setup in der Mitte und die feinabgestimmten Beacon-Encoder unten."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die feinabgestimmten Bianchors alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two-Tower-Modell verbessert sich im Vergleich zur Siamesen-Variante hinsichtlich der Recall-Werte bei hundert Elementen, zeigt aber ähnliche Ergebnisse bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl B M twenty five die Zugleistung deutlich unterbot, deutet seine Leistung darauf hin, dass es sich dennoch um eine solide Grundlage für domänenspezifisches Retrieval handelt."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Zero-Shot-Evaluierung des Siamese Bi-Encoder stellen wir fest, dass die direkte Verwendung der Embeddings eines vortrainierten CamemBERT-Modells, ohne diese für die Information Retrieval-Aufgabe zu optimieren, zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass das wortbasierte Biancoder-Modell die FastText- und das verbbasierte Modell deutlich übertraf. Dies lässt vermuten, dass vortrainierte Wortebettungen für diese Aufgabe möglicherweise besser geeignet sind als Zeichen- oder Subwortebettungen, wenn sie direkt angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "obwohl diese Ergebnisse vielversprechend sind, deuten sie dennoch auf beträchtlichen Verbesserungsbedarf hin, im Vergleich zu einem erfahrenen Experten, der letztendlich alle relevanten Artikel zu jeder Fragestellung finden und somit perfekte Ergebnisse erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns abschließend zwei Einschränkungen aller Datensätze erörtern."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf diejenigen beschränkt, die aus den dreißigzwei als belgisch geltenden Kodizes stammen, was nicht die gesamte belgische Gesetzgebung abdeckt, da Artikel aus Erlassen, Direktiven und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden sämtliche Verweise auf diese nicht erfassten Artikel ignoriert, was dazu führt, dass einige Suchanfragen letztendlich nur noch einen Bruchteil ihrer ursprünglichen Anzahl relevanter Artikel liefern."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "dieser Informationsverlust impliziert, dass die in den verbleibenden relevanten Artikeln enthaltene Antwort möglicherweise unvollständig ist, obwohl sie dennoch völlig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir festhalten, dass nicht alle Rechtsfragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel die Frage, ob man Mietern die Kündigung aussprechen kann, wenn diese zu viel Lärm verursachen"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "könnte nicht in der Gesetzgebung eine detaillierte Antwort enthalten, die einen spezifischen Lärmpegel festlegt, ab dem eine Räumung gestattet ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "stattdessen sollte der Vermieter sich wahrscheinlich stärker auf die Rechtsprechung stützen und Präzedenzfälle finden, die ihrer aktuellen Situation ähneln."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Der Mieter veranstaltet zweimal wöchentlich Partys bis 2 Uhr morgens."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "daher eignen sich manche Fragen besser als andere für die gesetzlich geregelte Artikelrecherche, und der Bereich der weniger geeigneten muss noch ermittelt werden."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass die gesamte Arbeit Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur juristischen Artikelrecherche weckt."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "das dazu beitragen kann, den Zugang zur Justiz zu verbessern"}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unser Paper, das im Code hinterlegt ist, unter den folgenden Links einsehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, Ihnen unsere Arbeit über Vokale vorzustellen – ein unabhängiges Benchmark-System, das zur Prüfung von Vision- und Sprachmodellen mit spezifischen linguistischen Phänomenen konzipiert ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark einzurichten?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "in den letzten Jahren haben wir einen explosionsartigen Anstieg von Transformer-basierten Vision- und Sprachmodellen erlebt, die auf großen Mengen von Bild-Text-Paaren vortrainiert wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle setzt den aktuellen Stand der Technik bei Aufgaben in den Bereichen Vision und Sprache fort, wie beispielsweise visuelles Fragenbeantworten, visuelles Common-Sense-Reasoning, Bildabruf und Phrasenlokalisierung."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "wir haben also die Meldung erhalten, dass die Genauigkeit bei diesen aufgabenbezogenen Benchmarks stetig zunimmt."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was genau verstand ein Vision-und-Sprach-Transformer, als er diesem Bild und diesem Satz eine hohe Übereinstimmungsbewertung zuwies?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und eine niedrige Punktzahl für diese hier"}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "oder konzentrieren sie sich auf Verzerrungen, wie aus vorangegangener Forschung ersichtlich ist?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt weiter zu beleuchten, schlagen wir einen stärker aufgabenunabhängigen Ansatz vor und führen Vokale ein, die die Sensitivität von Vision- und Sprachmodellen gegenüber spezifischen linguistischen Phänomenen testen, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir adressieren Existenz, Pluralität, Zählen, räumliche Relationen, Aktionen und Entitätscoreferenz."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "aber wie prüfen wir, ob die Vision- und Sprachmodelle diese Phänomene erfasst haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "by foiling a method previously applied for vision and language models only for noun phrases\nby Ravi Shekar and collaborators\nand on counting by us in previous work"}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Das Foilen bedeutet im Grunde, dass wir die Bildunterschrift nehmen und ein Gegenstück (ein \"Foil\") erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrasenänderungen durch, indem wir uns auf sechs spezifische Aspekte konzentrieren, wie beispielsweise Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entität-Koreferenz, wobei jeder Aspekt aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit finden, Folieninstanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bei der Aktionsphrase haben wir zwei Konstruktionen: eine, in der das Aktionsverb durch ein anderes ersetzt wird, und eine, in der die Aktanten vertauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Koreferenz sind ebenfalls Aspekte, die mehr als ein Instrument umfassen."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "und wir erzeugen diese Folien, indem wir sicherstellen, dass sie die Beschreibung des Bildes versagen, das sie sind, obwohl sie grammatikalisch und anderweitig gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach zu bewerkstelligen, da eine vereitelte Bildunterschrift weniger wahrscheinlich sein kann als die ursprüngliche Bildunterschrift."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl es nicht unmöglich ist, ist es statistisch gesehen weniger wahrscheinlich, dass Pflanzen einen Menschen verletzen als umgekehrt, und große Sprach- und Vision-Modelle könnten dies erkennen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "daher müssen wir Maßnahmen ergreifen, um gültige Folien zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst nutzen wir leistungsstarke Sprachmodelle, um Gegenkandidaten vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir Natural Language Inference, kurz NLI, um Folianten herauszufiltern, die weiterhin das Bild beschreiben könnten, da wir bei der Konstruktion von Folianten sicherstellen müssen, dass diese nicht das Bild beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir Natural Language Inference mit folgender Begründung an:"}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "wir betrachten ein Bild als Prämisse und seine Bildunterschrift als die damit verbundene Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus betrachten wir die Bildunterschrift als Prämisse und das Kontrastmittel als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorherhersagt, dass ein Ablenkobjekt widersprüchlich oder neutral in Bezug auf die Bildunterschrift ist, betrachten wir dies als Indikator für ein gültiges Ablenkobjekt."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn eine NLI vorhersagt, dass das Ablenkobjekt (Foil) durch die Bildunterschrift impliziert wird, kann es kein gutes Ablenkobjekt sein, da es durch Transitivität eine wahre Beschreibung des Bildes liefern würde, und wir diese Ablenkobjekte herausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "aber dieses Verfahren ist nicht perfekt, es ist lediglich ein Indikator für gültige Folien."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Erzeugung valider Testbögen menschliche Annotatoren ein, um die für Vokale verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir so viele Testinstanzen, wie in der folgenden Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Bitte beachten Sie, dass Valve keine Trainingsdaten, sondern ausschließlich Testdaten bereitstellt."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "da es sich lediglich um einen Zero-Shot-Test-Benchmark handelt, ist er dazu konzipiert, die bestehenden Fähigkeiten von Vision- und Language-Modellen nach dem Vortraining zu nutzen."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmung würde Modelle lediglich befähigen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle dazu neigen, zu schummeln und Abkürzungen zu nehmen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie wir bereits erwähnt haben, sind wir daran interessiert, zu beurteilen, welche Fähigkeiten die Vision- und Sprachmodelle nach dem Vortraining besitzen."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen, und zwar mit CLIP, AlexMert, WilBERT, WilBERT Twelve in One und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "zwei unserer wichtigsten Bewertungsmethoden sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren als Bildunterschriften und Ablenkern."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "vielleicht relevanter für dieses Video werden wir unser einfacheres Metrik, die paarweise Genauigkeit, vorstellen, welche misst, ob der Übereinstimmungs-Score zwischen Bild und Text für das korrekte Bild-Text-Paar höher ist als für sein gefälschtes Pendant."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "für weitere Metriken und Ergebnisse dazu siehe bitte unser Papier."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse bezüglich der paarweisen Genauigkeiten werden hier dargestellt und stimmen mit den Ergebnissen überein, die wir aus den anderen Metriken erzielt haben. Die beste Zero-Shot-Performance wird von Wilbert Twelve-in-One erreicht, gefolgt von Wilbert Alexmer Clip und schließlich Visual Bird."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nominalphrasen konzentrieren, fast vollständig von Wilbert zwölf in einem gelöst werden, was verdeutlicht, dass Modelle in der Lage sind, benannte Objekte und ihre Präsenz in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "jedoch können keine der verbleibenden Aufgaben unter unseren adversarial foiling Bedingungen zuverlässig gelöst werden."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen aus der Vielfalt und den Zählwerkzeugen, dass Vision- und Sprachmodelle Schwierigkeiten haben, Referenzen auf einzelne versus mehrere Objekte zu unterscheiden oder diese in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Relation p’ zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Relation zwischen Objekten in einem Bild korrekt zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Akteure zu identifizieren, selbst wenn sie von Plausibilitätsheuristiken unterstützt werden, wie wir im Abschnitt über Handlungen sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus der Koferenzstudie geht hervor, dass auch für Vision- und Sprachmodelle die Verfolgung mehrerer Bezüge auf dasselbe Objekt in einem Bild mithilfe von Pronomen eine Herausforderung darstellt."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als eine Art von Plausibilitätsprüfung und da es sich um ein interessantes Experiment handelt, haben wir ebenfalls zwei reine Textmodelle, GPT1 und GPT2, evaluiert, um zu beurteilen, ob das Ventil von diesen unimodalen Modellen gelöst werden kann, indem wir die Perplexität der korrekten und inkorrekten Bildunterschriften berechnen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "wenn die Perplexität für das Folgemodell höher ist, interpretieren wir dies als Hinweis darauf, dass der durch das Folgemodell abgelötete Untertitel unter Plausibilitätsvoreingenommenheit oder anderen sprachlichen Voreingenommenheiten leiden könnte."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant festzustellen, dass in einigen Fällen lediglich GPT-Modelle die Plausibilität der Welt besser erfasst haben als Vision- und Sprachmodelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Um es zusammenzufassen: Waltz ist ein Referenzstandard, der das Prisma sprachlicher Konstrukte nutzt, um die Community bei der Verbesserung von Vision- und Sprachmodellen zu unterstützen, indem er deren visuelle Grounding-Fähigkeiten rigoros testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Sprachmodelle benannte Objekte und deren Vorhandensein in Bildern gut identifizieren, wie die Existenz der Leerstellen belegt, jedoch Schwierigkeiten haben, ihre wechselseitige Abhängigkeit und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu berücksichtigen."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir würden die Community sehr gerne dazu ermutigen, Vows zur Messung des Fortschritts bei der sprachlichen Verankerung mit Vision- und Sprachmodellen zu nutzen."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "und sogar noch mehr Ventile könnten als eine indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder Feinabstimmen evaluiert werden könnten, um festzustellen, ob ein Datensatz dazu beiträgt, dass Modelle in einem der von Ventilen getesteten Aspekte verbessert werden."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, werfen Sie einen Blick auf die Testdaten auf GitHub. Bei Fragen zögern Sie bitte nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizera von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Beitrag präsentieren, der unter dem Titel „L N Sum: Eine groß angelegte Dissertation zur automatischen Renaissance durch Commitmentsummarisierung“ läuft."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge darlegen."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werde ich die automatische Generierung von Hinweisgebern vorstellen, an der wir im Rahmen dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Release Notes sind ein technisches Dokument, das die mit jeder Version eines Softwareprodukts verteilten Änderungen zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Die E-Mail zeigt eine Versionshinweis für Budget 2.6."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notizen spielen eine wichtige Rolle in der Open-Source-Entwicklung, aber sie sind zeitaufwändig in der manuellen Erstellung."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Da wäre es daher sehr nützlich, Mietnotizen von hoher Qualität automatisch generieren zu können."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich habe mich auf zwei vorherige Forschungsarbeiten zur automatischen risikofreien Generierung bezogen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Array, das im Jahr 2014 veröffentlicht wurde."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es bedarf eines regelbasierten Ansatzes, beispielsweise der Verwendung der Änderungsentnahme, um aus den Unterschieden zwischen Releases Kernunterschiede, Bibliotheksänderungen und Dokumentationsänderungen zu extrahieren und diese abschließend zu kombinieren."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das markanteste Merkmal dieses Systems ist die Gestaltung in der oberen rechten Ecke."}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "das mit Null verknüpft sein muss, dem Issue-Zyklus zugeordnet werden kann und nur auf Produkte angewendet werden darf, die Null verwenden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten lässt es sich für viele Gitarrenprojekte nicht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "der zweite ist die vor Kurzem verkündete Trauer in zwanzig"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Es ist im Internet verfügbar und kann über pip installiert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, auf Laufzeit basierendes Klassifikationsmodell und gibt für jede eingehende Commit-Nachricht eines von fünf Labels aus, beispielsweise Funktionen oder Fehlerbehebungen."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist eine Beispielanwendung, die ein Korrektur- oder Fehlerbehebungslabel zurückgibt."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingsdaten sind relativ klein und umfassen etwa fünf tausend Einträge, die in den im Folgenden beschriebenen Experimenten verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "die Leistung des Textklassifikationsmodells ist nicht hoch"}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungsarbeiten, jedoch gab es Probleme hinsichtlich der eingeschränkten Anwendbarkeit und der knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und generiert automatisch hochwertige Zuhörer."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Problem der eingeschränkten Anwendbarkeit schlagen wir eine hochwertige Klassifikationssummierungs-Methode vor, die lediglich die Ausgaben des Komitees als Eingabe verwendet."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann von allen Englischsprachigen verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem knapper Datenressourcen erstellten wir einen eigenen Satz an Enzymen, bestehend aus etwa 82.000 Datensätzen, indem wir Daten aus öffentlichen GitHub-Repositories mithilfe der GitHub-API sammelten."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich unsere Wüste."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Commit-Nachricht und die rechte Seite ist der Lesebereich."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Risonnes werden als Verbesserungen von Physikern usw. bewertet."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe entgegennimmt und Ausgaben erzeugt, die nicht zulässig sind."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als eine Summationsaufgabe betrachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier vordefinierte Ebenen festgelegt: Features, Verbesserungen, Fehlerbehebungen, Veraltungen, Entfernungen und Breaking Changes."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese Gesetze basieren auf vorangegangener Forschung und anderen Faktoren."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "es existiert nichts unten rechts und wird extrahiert, wenn nichts unten links angezeigt wird."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zum gegenwärtigen Zeitpunkt ist es erforderlich, die vier zuvor angelegten Ruinen zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "aber die Preise sind nicht immer mit jeder Liposuktion vereinbar."}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Der Verbesserungsgrad umfasst Verbesserungen, Erweiterungen, Optimierungen und dergleichen."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben für jede dieser notationalen Variationen eine Vokabelliste mit dreißig Wörtern erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Nutzen Sie es, um den rationalen Nebensatz zu erkennen und den Text des Restes, der auf diesen Nebensatz folgt, als rationalen Satz für diesen Nebensatz zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Commit-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Verpflichtende Nachrichten sind nicht an jedes einzelne Element gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "wie im folgenden Bild dargestellt, falls die aktuelle Version 2.5 bis 19 beträgt, müssen wir identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Das ist etwas mühsam, und es reicht nicht aus, lediglich eine Liste von Releases zu erhalten und die Zustände vorher und nachher zu vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er entwickelte eine heuristische Abgleichregel, um die vorherige und nächste Version zu ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Es wird eine „Todesstrafe“ genannt."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende 7.200 Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Ebenso liegt die durchschnittliche Anzahl der freigesetzten Token bei sechsunddreißig, was für Simulationsaufgaben recht hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist die Anzahl der eindeutigen Token mit 8.830.000 beträchtlich."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "Aufgrund der großen Anzahl eindeutiger Klassen- und Methodenbezeichnungen, die im Labor gefunden wurden."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werde ich die vorgeschlagene Methode erläutern."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das querverlaufende extraktive und abstrakte Summationsmodell besteht aus zwei neutralen Modulen."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "ein Klassifikator unter Verwendung von Butt oder Code Butt und ein Generator unter Verwendung von Butt"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet CAS einen Klassifikator, um jede festgeschriebene Meldung in fünf diskrete Klassen einzuteilen: Funktionen, Verbesserungen, Fehlerbehebungen, Anwendungen plus und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als „Sonstige“ klassifizierten Commit-Nachrichten werden verworfen."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wendet GAS den Generator unabhängig auf die vierzeiligen Dokumente an und generiert für jede Klasse Rätsel."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Entsprechungen zwischen den Stellungnahmen des Ausschusses und der Begründung nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "daher ordnen wir dem Klassifikator für das Training Subleveln zu, die auf den ersten zehn Zeichen jedes Kommentar-Nachrichten-Eintrags basieren."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren den Klassifikator für den obstructiven Zusammenfassungsansatz mit zwei verschiedenen Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GAS single nennen, besteht aus einem einzelnen sechs-zu-sechs-Netzwerk und generiert einen einzelnen Raum ohne Text, basierend auf einer Verkettung von Eingabe-Commit-Nachrichten."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausgabemarkierungen können in kreuzweise Segmente unterteilt werden, basierend auf speziellen, kreuzspezifischen Endpunktsymbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSmart nennen, besteht aus vier verschiedenen Sekundär-zu-Sekundär-Netzwerken, von denen jedes einer der drei Nicht-Klassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, lassen Sie mich Ihnen das Experiment erklären."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: Cheers, Cheers Single, Cheers March, Ringkampf und frühere Studienergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Aberration werden diese Notizen in manchen Fällen in mehreren Sätzen ausgegeben."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze auf Null zu korrigieren, werden sie mit Leerzeichen verbunden und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Die Behörde wird bestraft, wenn das System einen kurzen Satz ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Realwert in den im Folgenden beschriebenen experimentellen Ergebnissen."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich berechnen wir auch die Spezifität, da Blau und Blau nicht berechnet werden können, wenn die Spulen nicht leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell korrekt leeren Text ausgibt, in Fällen, in denen die Hinweise keine Leere annehmen."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die dritte."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, betreiben wir auch einen gedruckten Datensatz, der diese ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "C.E.A.S. und C.E.A.S. erreichten R.U.S.-Werte, die mehr als zehn Punkte über den Referenzwerten lagen."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Testdatensatz zur Validierung stieg der Leistungsunterschied zwischen der vorgeschlagenen Methode und der Referenzmethode auf mehr als zwanzig Punkte an."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass sie signifikant wirksam ist."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS erreichte einen besseren Wert für die Wurzelübergangsbewertung als GAS, was darauf hindeutet, dass die Kombination eines Klassifikators und eines Generators effektiv ist und der Klassifikator mithilfe von Unterroutinen trainiert wird."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Abdeckung von CS kann korrekt erreicht werden, da der Klassifikator sich darauf konzentrieren kann, für jede Klasse relevante Commit-Nachrichten auszuwählen."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie wurde häufiger besser bezahlt, als sie ledig war."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "was es ebenfalls effektiv erscheinen lässt, für jede Notenklasse unabhängig voneinander unterschiedliche, abstraktere Summodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Held und Heldentum."}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Shear's Methoden neigen dazu, kürzere Sätze zu generieren als Sätze, die von Menschen verfasst wurden."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts besteht die Referenzsätze aus drei oder vier Sätzen, während der andere nur aus einem Satz besteht."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese geringere Zurückhaltung ist, dass in den Trainingsdaten lediglich dreizehn Prozent der Sätze auf Merkmalsebene und vierzig Prozent auf Implementierungsebene vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus sind Cias Methoden nicht in der Lage, genaue Lesemarkierungen zu erzeugen, ohne zusätzliche Informationen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr unstrukturierte kommutative Meldung, und der vollständige Satz kann nicht ohne Bezugnahme auf den entsprechenden Präambeltext oder das zugehörige Problem generiert werden."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden feststehenden Ausdrücke in der Eingabe inhaltlich zusammenhängen und zu einem Satz zusammengefasst werden sollten, dies geschieht jedoch nicht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "wir haben einen neuen Dash-Satz für die automatische Generierung entwickelt."}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Mir obliegt ebenfalls die Aufgabe, Commit-Nachrichten einzutragen und diese so zusammenzufassen, dass sie für alle Projekte anwendbar sind, die in englischer Sprache verfasst wurden."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode weniger Rauschen erzeugte und dies nicht bei höherer Abdeckung im Vergleich zu den Baselines."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte werfen Sie einen Blick auf das Set auf GitHub!"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, hier spricht Mizzou Ferrari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unseren Beitrag vorstellen, \"Zukunftsorientierte Tabellendatenanreicherung unter Verwendung von FineTuner Transformer-Architekturen\"."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Analysiert ein Wissenschaftler Daten und konzentriert er sich hauptsächlich auf die Veränderung bestehender Merkmale?"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind diese Funktionen eingeschränkt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Zukünftige Generationen, die eine andere Datenquelle nutzen, könnten erhebliche zusätzliche Informationen liefern."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung tabellarischer Daten mithilfe von freiem Text aus externen Quellen."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir einen tabellarischen Datensatz und eine Wissensdatenbank."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatisierten Prozess, der Entity Linking und Textanalyse umfasst, um neue Merkmale aus den freien Texten der Wissensdatenbank zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist zunächst einmal genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir also ein Beispiel. In einem Datensatz, der in first eingespeist wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz der Hochschuldatensatz."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darauf abzielt, Universitäten in niedrigrangige und hochrangige Universitäten einzuteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von Fest ist das Entity Linking."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "wenn jede Entität, in diesem Beispiel der Name der Universität, mit einer Entität innerhalb der Wissensdatenbank verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Bitte stelle den englischen Text bereit."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Nun müssen wir Merkmale aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Da benötigen wir also eine Phase der Feature-Extraktion, welche eine Textanalyse umfasst."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "und dies ist die Hauptneuheit dieses Papiers, und ich werde in der nächsten Folie näher darauf eingehen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Phase der Feature-Extraktion folgt eine Feature-Generierungsphase, in der wir die extrahierten Features nutzen, um eine geringe Anzahl neuer Features zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werden Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes generiert."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Generieren Sie zunächst zwei neue Features."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "aber wenn der Datensatz fünf Klassen aufweist, generieren Sie zunächst fünf neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Merkmal repräsentiert die Wahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Zur Analyse des Textes verwenden wir den aktuellen Stand der Technik der Textanalyse, darunter Transformer-basierte Sprachmodelle, S B G P T Akzent-Schreibweise und dergleichen."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir Sprachmodelle mit den vorliegenden Datensätzen trainieren können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "eine naive Herangehensweise wird somit eine Feinabstimmung auf eine Zielaufgabe darstellen."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der zukünftigen Extraktionsphase können wir pro Trend ein Sprachmodell herunterladen und das Sprachmodell anschließend am Ziel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell feinabgestimmt, um Texte in Klassen einzuteilen, abstrahiert in Klassen: niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "die Ausgabe des Sprachmodells empfangen, welche die Wahrscheinlichkeit für jede Klasse darstellt, und diese als neue Merkmale verwenden."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz besteht darin, dass Datensätze nur wenige unterschiedliche Entitätstags aufweisen können."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthalten fast die Hälfte der Datensätze weniger als 400 Stichproben, und der kleinste Datensatz enthält 35 Stichproben in seinem Trainingsdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Da wird eine Feinabstimmung eines Sprachmodells anhand dieses Datensatzes also unwirksam sein."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können Vorwissen über vorab analysierte Daten nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir mehrere Datensätze verwenden können, können wir die N-minus-eins Datensätze nutzen, um Informationen über diese Datensätze zu gewinnen, und diese Informationen bei der Analyse des N-Datensatzes verwenden."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "was wir vorschlagen, ist eine weitere Feinabstimmungsphase hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "und vorbereitende Feinabstimmung in der Multitasking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell auf den NMS1-Datensätzen finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmungsphase durch, welche eine gezielte Feinabstimmung darstellt, sobald wir feststellen, dass das Sprachmodell die Endziel-Datensatzüberschreitung aufweist."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der aktuelle Stand der Technik im Bereich Multitasking-Feinabstimmung, genannt MDDN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDN verwaltet MTDN Köpfe in der Anzahl der Aufgaben im Trainingsdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainingsdatensatz, die vier Köpfe verwalten, wie man in der Abbildung sehen kann."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "und es wählt zufällig ein Badge aus dem Trainingsdatensatz aus."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "und falls das zufällige Badge beispielsweise zur Klassifizierung von Gesangssätzen gehört, werden Vorwärts- und Rückwärtsdurchläufe durch den ersten Head ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Stichprobe in der Lage sein soll, zu rangieren, besteht die Aufgabe darin, hin und her durch den letzten Head zu gehen."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario sind Tabelle, Datensatz und Zeile die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Da gibt es also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN verwaltet verschiedene Klassen von Head-Komponenten, Ausgabeschichten."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus muss MTDN neue Verantwortliche für einen neuen Datensatz mit einer neuen Aufgabe einsetzen."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz wird als Task-Reformulierung-Feinabstimmung bezeichnet. Anstatt mehrere Köpfe zu verwenden, reformulieren wir jeden Datensatz zu einem Satz pro Klassifikationsproblem, was zwei Klassen von Aufgaben sind."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns nun ein Beispiel an."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist unser Eingabedatensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe um: von der Klassifizierung des Textes in niedrig und hoch zur Klassifizierung des Textes, des Abstracts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten trainieren wir das Sprachmodell so, dass es Abstrakt und Klasse klassifiziert, und bestimmt, ob das Abstrakt zur Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Labelvektor ist in diesem Fall also immer ein a, welches immer aus zwei Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist der Algorithmus für unseren verfeinerten Feinabstimmungsprozess."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir also das vollständige Framework."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Der Datensatz ist ausgesprochen schnell."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "und dann zunächst die Verknüpfungsphase ausführen."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Extrahieren Sie den Text aus der Wissensdatenbank, welcher in diesem Beispiel der Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann reformuliert es die Aufgabe in eine Klassifikationsaufgabe pro Satz."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "das Sprachmodell auf die neue Aufgabe angewendet und die Wahrscheinlichkeit für jede Klasse ausgegeben."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Das Sprachmodell wurde bereits über N minus 1 Datensätze mit einer vorläufigen mehrfach Aufgabe-Feinabstimmung trainiert."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabvektor des Sprachmodells als neu generiertes Merkmal für die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zur Evaluation unseres Frameworks verwenden wir einen tabellarischen Klassifikationsdatensatz mit 17 Datensätzen, die sich in Größe, Merkmalen, Balance, Domäne und anfänglicher Leistung unterscheiden."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "und als Wissensdatenbanken verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir konzipieren unser Experiment als eine Live-Evaluation, wenn wir anhand von über 16 Datensätzen trainieren und diese auf den 17. Datensatz anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen diese Daten ebenfalls in vier Folds auf und wenden eine Vierfach-Kreuzvalidierung an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir das neue Feature und bewerten es mithilfe von fünf Evaluatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "wir verwenden in unserem Experiment eine geburtsbasierte Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Framework mit der Feinabstimmung auf das Ziel-Dataset und der vorläufigen Feinabstimmung mit MTDN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unser überarbeitetes Fein-Tuning erzielt das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN im Vergleich zum Feintuning des Ziel-Datensatzes eine Verbesserung von 2 % erreichte,"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz erzielte eine Verbesserung von sechs Prozent."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns den kleinen Datensatz ansehen, können wir feststellen, dass die Leistung des MTDN abnimmt und die Verbesserung der vorbereitenden Multitasking-Feinabstimmungsphase auf 1,5 % sinkt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "aber unsere Leistung stieg auf 11 % im Vergleich zur alleinigen Feinabstimmung der Zielaufgabe"}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "für die schnelle Summierung ermöglicht es, wenige Stichproben – in unserem Experiment fünfunddreißig – für eine schnelle Erweiterung zu nutzen."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und es behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Umformulierungsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es wird \"Train Set\" genannt und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einspeisen und im Satz pro Klassifizierungsproblem verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank."}
