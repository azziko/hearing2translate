{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。\n\n今天我将为大家介绍我们的研究工作：将学习推理可导网络问题求解视为复杂推理提取。"}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我是艾伦，来自拜登的AI实验室，这是我和来自德克萨斯大学奥斯汀分校的蒂埃里，以及来自SUDD的韦卢共同完成的工作。"}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我想谈谈我们进行推理的动机。"}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示了多步骤推理有所助益的案例。"}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "此图节选自 PALM 论文，其中他们通过提示 (prompting) 在融合学习场景下解决数学作业问题。"}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，如果我们仅提供问答示例，可能无法获得正确的答案。"}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们提供更详细的推理描述，模型就能预测该推理描述，并且在此做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "因此，拥有可解释的、多步骤推理作为输出是很有益的。"}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时也认为，解决数学问题是一种直接的应用，可以用来评估此类推理能力。"}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的问题设定中，给定这些问题，我们需要解决这个问题并获得数值答案。"}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的数据集里，我们也得到了导致这个特定答案的数学表达式。"}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一些假设也与先前研究相同。"}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设所涉及数量的精确度是已知的。"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "我们仅考虑加法、减法、乘法、除法和指数运算这些基本运算符。"}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "此外，复杂的算子实际上可以分解成这些基本算子。"}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "之前在方法问题解决方面的研究实际上可以归纳为序列到序列和序列到树模型。"}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "因此，传统的序列到序列模型将表达式转换为用于生成的特定序列。"}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "而且它实现起来相当简单，并且能够推广到许多不同的复杂问题。"}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "但是其缺点是，实际表现通常并不优于结构模型，并且缺乏对预测结果的可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "但实际上，由于Transformer模型，这个方向仍然相当受欢迎。"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在基于树的模型中，我们实际上以树形结构组织这些表达式，并在树的生成过程中遵循前序遍历。"}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们持续生成算子，直到到达叶节点，这些叶节点代表着量。"}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "这里的好处在于，它实际上为我们提供了这种二叉树结构。但其实这有些反直觉，因为我们首先生成操作符，然后在最后生成量。"}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "第二个问题是，它还包含一些重复的计算。"}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里，如果我们观察这个表达式，八乘以三加三实际上被计算了两次。但事实上，我们应该重用结果。"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的提案方法中，我们希望以循序渐进且可解释的方式解决这些问题。"}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "因此，例如，在第二步骤中，我们可以得到这个除数，即27。"}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以回溯到最初的问题，以查找相关内容。"}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "在这些步骤中，我们得到除数。"}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "那么，在第三步，我们实际上得到了商。"}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "好的。并且在完成这三个步骤之后，我们可以实际上重复利用第二步的结果，从而获得第四步的结果。最终，我们才能获得收益。"}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "所以在这里，我们实际上是直接生成整个表达式，而不是生成单个的运算符或量。"}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "这使得流程更为精准。"}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的演绎系统中，我们首先从问题中呈现的一系列量开始，同时包含一些作为初始状态的常数。"}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "因此，该表达式用EIJOP表示。"}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此执行从 Qi 到 Qj 的操作，而这种表达式实际上是有方向性的。"}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们这里也有表示相反方向的减法词。"}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "这与辐射萃取颇为相似。"}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在一个正式的演绎系统中，在时间步t，我们对Qi和Qj对应用操作符，从而获得这些新的表达式。"}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "我们将它添加到下一个状态，从而成为一个新的量。"}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "这张幻灯片实际上可视化了状态的演变过程，即我们不断向当前状态添加表达式。"}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的模型实现中，我们首先使用一个预训练的语言模型，它可以是鸟类或机器人，然后我们对一个句子进行编码，之后我们获得这些数量表示。"}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "一旦我们获得数量表示，我们就可以开始进行推理了。"}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示一个例子，通过Q一获得Q一的表示。它们将被Q二除，然后乘以Q四。"}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们获得配对表示，这本质上只是 Q1 和 Q2 的拼接。然后我们应用一个前馈网络，该网络由操作符参数化。"}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们最终得到表达式 Q1 除以 Q2。"}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "但实际上，在实践中，在推理阶段，我们可能也会得到不正确的表达。"}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里所有可能的表达式等于操作符数量的三倍。"}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里很棒的一点是，我们可以轻松地添加约束来控制这个搜索空间。"}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "如果该表达式不允许，我们可以简单地从搜索空间中移除该表达式。"}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "所以在第二步中，我们做同样的事情，唯一的区别在于，数量增加了一个。"}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "这个数值来源于先前的计算表达式。"}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们最终可以得到这个最终表达式 Q Thirteen。"}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "三次 Q 四。并且我们可以看到所有可能的表达式的数量与之前的步骤不同。"}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这些差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。"}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "因此，训练过程类似于训练序列到序列模型，我们在每个时间步优化损失函数。"}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们同样使用这个τ来表示何时应该终止这个生成过程。"}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "而这里的空间与序列到序列不同，因为在每个时间步长，空间的维度都不同。而在传统的序列到序列模型中，它仅仅取决于词汇量的大小。"}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "而且它也允许我们根据先验知识施加一定的约束。"}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们在常用的方法问题数据集上进行了实验，这些数据集包括 MAWPS、Math 23K、MathQA 和 SWAM。"}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们简要展示与先前最佳方法相比的结果。"}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "我们的表现最佳变体是 Roberta 释义推理模型。"}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，我们并不使用集束搜索，这与那些显而易见采用集束搜索的方法形成对比。"}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "好的。因此，最佳方法通常是基于树的模型。"}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们的推理器能够在很大程度上优于这种基于树的模型。"}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "但是我们可以看到，数学问答或SWAM上的绝对数值并不算很高。"}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步就现场结果进行调查。"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "沼泽。而这个数据集具有挑战性，因为作者试图手动添加一些内容来迷惑自然语言处理模型，例如添加不相关的信息和额外的数量。"}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的预测中，我们发现一些中间值实际上是负数。"}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们正在询问杰克有多少个苹果？"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "但是我们有一些额外的信息，例如十七个较少的投球次数，而斯蒂芬有八个投球，这完全无关紧要。"}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的模型会做出类似这样的预测，即产生负值。"}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察这两个表达式。"}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以实际缩小搜索范围，移除那些结果为负面的选项，从而确保答案的正确性。"}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步发现这种约束实际上对某些模型有很大改善。"}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "对于鸟类模型，我们改进了七个方面。然后，对于 Roberta 基本模型，我们实际上改进了两个方面。"}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "因此，性能更优的语言模型具有更强的语言理解能力，导致此处 Roberta 的数值较高，而 Bertha 的数值较低。"}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "我们也会尝试分析其背后的困难所在。"}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设此处未使用的数量可以被视为无关信息。"}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以看到，未使用数量的样本百分比中，沼泽数据集占比最高。"}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们还展示了整体表现。"}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "对于那些没有剩余量的样本，因此整体性能实际上高于整体性能实际上高于。"}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "但是对于那些有剩余数量的样本而言，情况实际上要比——嗯，要比糟糕得多。"}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "表现不佳。对于MAWPS来说，我们实际上没有太多桌面案例，因此我直接忽略这部分。"}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们希望通过一个问题参与示例来展示其可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，我们的模型实际上在第一步就做出了错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "所以，我们可以实际将这个表达式与这里的句子关联起来，好吗？"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们认为这句话可能会误导模型产生错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "所以，在这里再种植三十五个，会让模型认为这应该是一个操作符的增量。"}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们会尝试修改句子，使其表达为：梨树的数量比苹果树少五十五棵。"}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们努力以传达更准确语义的方式，确保模型能够做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "这项研究表明，可解释的预测结果有助于我们理解模型的行为。"}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了总结我们的工作，首先我们的模型实际上相当高效。"}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们能够提供可解释的求解过程。"}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们可以轻松地将一些先验知识作为约束条件融入其中，这有助于提高性能。"}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "而最后一点是，其底层机制不仅适用于网络问题解决任务，也适用于其他涉及多步推理的任务。"}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也有一定的局限性。"}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "如果运算符或常数数量很大，那么内存消耗可能会相当高。"}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "而第二点是，正如之前提到的，由于不同时间步长的概率分布不均衡，因此应用波束搜索也相当具有挑战性。"}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "好的，本次讲座就到此结束，欢迎提问。 谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我叫安托万，来自马斯特里赫特大学。"}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "我将与杰瑞一起展示我的约翰工作，这关于一个用于法规条款检索的新数据集。"}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "法律问题是许多人生活中不可或缺的一部分。"}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "然而，绝大多数公民对自身权利和基本的法律程序知之甚少，甚至毫无了解。"}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "因此，许多无力承担法律专家高昂费用的弱势公民， 往往缺乏保护，甚至遭受剥削。"}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "我们的工作旨在弥合个人与法律之间的差距，通过开发有效的法定条文检索系统来实现这一目标。"}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "这种系统可以为缺乏技能的人类提供免费的专业法律援助服务。"}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "在深入探讨本文的主要贡献之前，我们首先来描述一下法定条文检索的问题。"}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "假设针对一个简单的法律问题，例如“如果我违反了职业保密义务，我将面临怎样的风险？”"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "模型需要从大量的立法文本中检索所有相关的法定条文。"}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "这项信息检索任务也伴随着一系列自身的挑战。"}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "首先，它处理两种类型的语言。"}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "常见自然语言用于问题，而复杂非法语言则用于法令。"}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "这种语言分布的差异使得系统检索相关候选变得更加困难，因为它间接需要一个内在的解释系统，能够将自然语言问题转化为符合法规术语的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "此外，成文法并非独立条款的堆砌，可以像新闻或食谱那样，单独作为完整的信息来源。"}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "相反，它是一个法律条款的结构性集合，只有在整体背景下加以考虑时，才能具有完整意义——即与相邻条款的补充信息、它们所属的领域和子领域以及它们在法律结构中的位置结合起来时，才能理解其意义。"}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "最后，法定条款通常以小段落的形式呈现，这通常是大多数检索工作中典型的检索单元。"}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "这里有大量的文档，有些可能已有六十年的历史。"}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "自然语言处理领域的最新进展引发了对诸多法律任务的极大兴趣，例如法律判决预测或自动化合同审查。"}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "但法定条文检索领域主要仍未得到充分发展，这主要是由于缺乏大规模且高质量的标注数据集。"}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们提出了一个新的以法国本土公民为中心的语料库，旨在研究检索模型是否能够模拟法律专家的效率和可靠性，从而完成法规条文检索的任务。"}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们的比利时法定条文检索数据集包含超过一千一百零一个立升。"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "这些问题涵盖了广泛的主题，从家庭、住房、金钱，到工作和社会保障。"}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "他们每一个人都已由经验丰富的法学家标注，并援引了超过二十二万六千件文献中的相关条款。"}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "比利时法律规范。现在我们来谈谈我们如何收集这些数据集。"}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们从整理一份大量的法律文章语料库开始。"}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "我们考察了三十二个公开的比利时规范，并从中提取了所有条款以及相应的章节标题。"}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们收集了与相关法规有出处引用的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们与一家比利时律师事务所合作，该事务所每年收到大约四千封电子邮件，来自比利时公民，他们寻求关于个人法律问题的建议。"}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "我们很幸运地获得了访问他们网站的机会，在其网站上，他们的经验丰富的法学家团队处理着比利时最常见的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "我们收集了数千个问题，并对其进行了标注，包括类别、子类别以及与相关法规的法律引用。"}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们审查了法律引用，并过滤掉了其引用不是我们考虑过的法律法典中文章的问题。"}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "其余参考文献被匹配并转换为O语料库中的相应文章ID。"}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们得到了共一千一百零八个问题，每个问题都经过仔细标注，附带了书中相关文章的编号。"}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "此外，每个问题都附带一个主要类别和一个子类别的连接。"}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "并且每一篇文章都附带了其后续标题的串联，依照法律的结构呈现。"}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "此额外信息在当前工作中未被使用，但可能对未来关于法律信息检索或法律文本分类的研究具有参考价值。"}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "让我们来看看我们的数据集的一些特征。"}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "问题长度在五到四十四字之间，中位数为四十个字。"}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "文章篇幅更长，中位数为七十七个单词，重一百四十克。"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "其中两项超过了一千。"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "正如前所述，该问题涵盖了广泛的主题，其中约有八十五％与家庭、住房、金钱或司法相关，或者"}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "而其余的百分之十五则涉及社会保障、外国人或工作相关事宜。"}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "这些文章也十分多样，因为它们源自三十二部不同的比利时法典，涵盖了大量的法律主题。"}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "以下是从这些比利时法规中收集到的文章总数。"}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "在二十二千六百三十三篇文章中，仅有一千六百一十二篇被认为是至少与下列一项相关。"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "至少在数据集中的有一道题目。并且大约八成以上的这些引用的文章都出自《民法典》、《司法解释》、《刑事诉讼法》或《刑法》。"}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时，三十二个编码中，十八个编码提及的文章少于五个，这些文章与至少一个问题相关。"}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "这可以归因于这些代码更侧重于整体而非个体及其顾虑。"}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，这些被引用的文章的中间引用次数为二，且少于百分之二十五的被引用。"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "利用我们的数据集，我们对多种检索方法进行了基准测试，包括词汇方法和密集架构。"}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "给定一篇文档中的查询，词汇模型通过计算该文档中每个查询词的权重之和，为查询-文档对赋予一个分数。"}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "我们试验了标准的TFIDF和BM二十五排序函数。"}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法的关键问题在于，它们只能检索到包含查询中关键词的文章。"}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这一局限性，我们尝试了一种基于神经网络的架构，该架构能够捕捉查询与文章之间的语义关系。"}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 BE 编码器模型，该模型将查询和文章映射为稠密向量表示，并通过其嵌入向量的相似度来计算查询-文章对之间的相关性得分。"}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "这些嵌入通常是由词嵌入模型的输出经过池化操作得到的。"}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们研究暹罗双编码器在零样本评估设置下的有效性，这意味着预训练词嵌入模型直接应用，无需任何额外的微调。"}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试使用无上下文文本编码器，例如 Word to Vec 和 FastText，以及有上下文的嵌入模型，例如 Roberta，特别是 Camembert，这是一个法语版本的 Roberta 模型。"}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们还训练了基于CamemBERT的自有模型。超越引用者，"}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "适用于所有数据集。请注意，在训练过程中，我们尝试了 Bianco 架构的两种变体。"}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "暹罗模型采用一种独特的词嵌入模型，该模型将查询和文章映射到共享的稠密向量空间中；而导师模型则采用两个独立的词嵌入模型，分别将查询和文章编码到不同的嵌入空间中。"}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试了均值、最大值和 CLS 池化方法，以及点积和余弦相似度来计算相似性。"}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们对测试集进行的基线实验结果。"}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "借助上述词汇方法，中间评估了零样本设置下的暹罗B编码器，下方是微调后的B编码器。"}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，经过微调的 Biancore 明显优于其他低音线。"}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "双塔模型在一百召回率方面优于其孪生网络变体，但在其他指标上的表现则相似。"}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "尽管 BM-25 的表现明显低于训练后的 Biancoda，但其结果表明它仍然是领域特定检索的一个强大的基准。"}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "关于暹罗双编码器（Siamese Biancoder）的零样本评估，我们发现直接使用预训练 Kamembert 模型的嵌入向量，而未针对信息检索任务进行优化，会导致结果不佳，这与之前的研究结果相符。"}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们观察到基于词向量的Biancoder模型明显优于Vastex和基于词模型的表现，这表明，在不进行额外调整的情况下，对于这项任务而言，预训练的词级别嵌入向量可能比字符级别或子词级别的嵌入向量更为合适。"}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "尽管前景可期，这些结果仍表明相较于一位能够最终检索到与任何问题都相关的所有相关条款，从而获得完美成绩的资深法律专家，仍存在改进的巨大空间。"}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "让我们最后讨论所有数据集的两个局限性。"}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "首先，该文章语料库仅限于从32项被认为的比利时法规中收集的文章，这并不涵盖整个比利时法律，因为缺少了来自法令、指导方针和市政条例的文章。"}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "在数据集构建过程中，所有对这些未收集文章的引用都被忽略，这导致一些问题最终只有初始相关文章数量的一小部分。"}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "这种信息损失意味着剩余相关文章中包含的答案可能不完整，尽管这仍然完全合理。"}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们应当注意的是，并非所有法律问题都能仅凭成文法来解答。"}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "例如，问题可能是：如果租户制造过多的噪音，我可以将他们驱逐出户吗？"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "可能法律条文中没有对允许驱逐的特定噪音阈值进行量化的详细规定。"}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "相反，房东可能更应该依赖案例法，并寻找与他们当前情况相似的先例。"}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "租客每周与两批人会面至下午两点。"}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "因此，某些问题比其他问题更适合法定条款检索任务，而不太适合的问题领域尚待确定。"}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望这项工作能够激发对开发实用且可靠的成文法条检索模型的兴趣。"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于改善所有人获得司法的机会。"}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "您可以通过以下链接查阅我们的论文、数据集和代码。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我们很高兴呈现我们关于Vowls的工作，这是一个独立的基准任务，旨在利用特定的语言现象来测试视觉和语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "我们为何费时费力地设立这个基准？"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "嗯，在过去的几年里，我们目睹了基于 Transformer 的视觉和语言模型，它们在大量的图像文本对上进行了预训练，数量激增。"}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型都推动了视觉和语言任务的最新技术水平，例如视觉问答、视觉常识推理、图像检索和短语定位。"}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经收到了消息。这些特定任务的基准测试准确率正在稳步提高。"}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们真的了解这些模型实际学习了什么吗？"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "当视觉语言 Transformer 为这张图像和这句话赋予高分时，它理解了什么？"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "以及该项的较低分数。"}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "视觉与语言模型是否关注了正确的事物？"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "或者它们是否侧重于先前研究所显示的偏见？"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "为了更深入地阐释这一方面，我们提出一种更具任务泛化能力的思路，并引入阀值机制，以测试视觉和语言模型对特定语言现象的敏感度，这些现象会影响语言和视觉模态。"}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "我们关注存在、复数、计数、空间关系、动作以及实体指代。"}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "但是我们如何测试视觉和语言模型是否捕捉到了这些现象呢？"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "通过借鉴此前拉维·沙卡尔及其合作者仅应用于视觉与语言模型，以及我们在先前工作中所采用的计数方法，进行干预。"}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "对冲（Foiling）的基本含义在于，我们首先获取图像的标题，然后通过改变标题的内容，使其不再描述该图像，从而生成一个对冲文本。"}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过关注六个特定的要素来进行这些短语调整，例如存在、数量、计数、空间关系、动作和实体指代。每个要素可以由一个或多个工具构成，以防我们发现不止一种有趣的方法来创建对比实例。"}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在动作片段的案例中，我们有两个结构，一个是在其中改变了动作动词，使用了不同的动作动词，另一个是在其中交换了参与者。"}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "计数和共指也都是涉及多于一种乐器的部分。"}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过确保它们无法准确描述图像，同时又保证其语法正确且符合逻辑，来构建这些反例。"}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "这并非易事，因为一个被篡改的标题可能比原始标题出现的概率更低。"}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "尽管并非不可能，但从统计学角度来看，植物砍人比人砍植物的可能性更小，大型视觉语言模型可能能够捕捉到这一点。"}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了获得有效的对照样本，我们必须采取行动。"}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们利用强大的语言模型来提出对比项。"}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们使用自然语言推理，或简称NLI，来过滤掉那些可能仍然描述图像的干扰项，因为在构建干扰项时，我们需要确保它们无法描述该图像。"}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "为自动测试此项，我们采用自然语言推理，并遵循以下论证思路。"}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "我们将图像视为前提，而其标题则视为由此推导出的假设。"}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们认为标题是前提，而对比点则是其假设。"}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "如果一个 NLI 模型预测干扰样本与标题相矛盾或呈中性关系，我们将此视为有效干扰样本的指标。"}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "如果一个 NLI 预测干扰项被标题所蕴含，那么它就不能作为一个好的干扰项，因为根据传递性，它将给出图像的真实描述，而我们会过滤掉这些干扰项。"}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "但此程序并不完美。它仅仅是有效箔材的指标。"}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "因此，作为生成有效干扰项的第三项措施，我们聘请人工标注员来验证用于阀门的数据。"}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "经过过滤和人工评估后，我们拥有了如表中所述的测试样本数。"}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "VALS 不提供任何训练数据，仅提供测试数据。"}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "由于它仅仅是一个零样本测试基准，它的设计旨在利用预训练后视觉和语言模型已有的能力。"}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "微调仅能使模型利用数据中的伪影或统计偏差。"}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "我们都知道，这些模型倾向于作弊和走捷径。"}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所说，我们感兴趣的是评估在预训练之后，视觉和语言模型具备哪些能力。"}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用五种视觉语言模型对元音进行实验，即 CLIP、AlexMert、Wilbert、Wilbert Kelvin one 和 VisualBERT。"}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "我们最重要的评估指标之一是模型将图像-句对分类为标题和干扰项的准确性。"}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "对于本视频而言，或许更相关的是，我们将展示我们更为宽松的指标——成对准确率，该指标衡量的是，对于正确的图像-文本对，其图像句对齐分数是否高于其欺骗对。"}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "更多指标和结果，请参阅我们的论文。"}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "这里展示了成对准确率的结果，这些结果与我们从其他指标获得的结果一致。威尔伯特十二合一是否达到了最佳零样本性能，其次是威尔伯特、Alex Mart、Clip，最后是VisualBird。"}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "值得注意的是，以个体对象（如存在和名词短语）为中心的仪器类方法几乎已被Wilbert Twelve in One解决，这突显了模型具备识别图像中命名对象及其存在的能力。"}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "然而，在我们的对抗规避设置中，剩余的各个部分都无法可靠地解决。"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "从计数工具中的复数形式来看，视觉和语言模型难以区分对单个物体与多个物体的指代，或者在图像中对它们进行计数。"}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "Ps关系表明，他们在正确分类图像中命名空间关系方面存在困难。"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "他们也难以区分行为并识别其参与者，即使借助如我们在行为片段中观察到的可信性偏见。"}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "从共指分析来看，我们发现视觉与语言模型在图像中追踪对同一对象的多重指代（例如，使用代词）同样面临挑战。"}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "作为一项验证措施，并且因为这本身就是一个有趣的实验，我们还对两个仅文本模型——GPT一和GPT二进行基准测试，以评估这些单模态模型是否能够解决“阀门”问题。具体做法是计算正确和失败标题的困惑度（此处无图像），并预测困惑度最低的条目。"}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "如果对偶文本的困惑度更高，我们将其视为一种迹象，表明被篡改的标题可能存在合理性偏差或其他语言偏差。"}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "而且，有趣的是，在某些情况下，只有 GPT 模型才比视觉语言模型更好地把握了世界的合理性。"}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，VALSE 是一个基准测试，它运用语言结构视角，旨在通过严格测试，帮助社区改进视觉和语言模型，从而提升其视觉 grounding 能力。"}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，视觉与语言模型能够很好地识别图像中的命名对象及其存在，正如存在片段所示；然而，当被迫遵守语言指示时，它们在视觉场景中建立对象之间的相互依赖关系和关联方面会遇到困难。"}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们非常希望鼓励社区使用 Vals 来衡量在视觉和语言模型中实现语言根植的进展。"}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "而且，阀门还可以被用作对数据集的间接评估手段，因为模型可以在训练前后或微调前后进行评估，以观察数据集是否能帮助模型在阀门测试的任何方面取得改进。"}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "如果您感兴趣，请查阅GitHub上的虚假数据。如有任何疑问，请随时与我们联系。"}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫神村紗羅，來自東京大學。"}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我将发表一篇题为《利用R语言及汇总方法，对大规模数据集进行自动风险非持续时间委员会日志汇总》的论文。"}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "我将按照以下顺序进行解释。"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我将介绍我们正在进行的研究中的自动风险中和。"}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "发布说明是一份技术文档，总结了随软件产品每次发布版本一同分发的变更。"}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "图像显示的是关于巴赞 2.6 的一份研究记录。"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "用户空间库。这些节点在开源开发中扮演着重要的角色，但手动准备它们需要耗费大量时间。"}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "因此，能够自动生成高质量的发布说明将非常有用。"}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我将参考两项先前关于自动化风险提示生成的연구。"}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "首先是一个名为Arena的系统，于二〇一四年发布。它"}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "它采用基于规则的方法，例如，使用变更提取器从版本之间的差异中提取核心差异、库变更和文档变更，并最终将它们结合起来。"}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "该系统的最显著特征是位于右上角的问题提取器。"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "必须将其与零问题相联系，并仅适用于使用零的项目，从而影响生态系统。"}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这里。换句话说，它无法用于 GitHub 上许多项目。"}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "二是悲伤。\n\n本条消息于二十四号发布。"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "二十二零。\n\n它可在互联网上获取，并可通过PIP存储。"}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "该系统采用基于运行的文本分类模型，并为每个输入提交消息配备五种标签形式，例如功能或错误修复。"}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "该图像是一个示例用法，它会返回一个修正或修复错误的反馈。"}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "训练数据相对较小，大约五千条，将在以下实验中展示。"}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "统计图形排程模型的表现并不突出。"}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "我在此呈现两项相关研究，但存在适用性有限和数据资源匮乏的问题。"}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文解决了这两个问题，并自动生成高质量的发布说明。"}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "针对适用性有限的计划，我们提出一种仅使用委员会消息作为输入的高质量分类摘要方法。"}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "该方法可用于所有英文代码仓库。"}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "针对数据资源匮乏的第二个问题，我们构建了一个RNSM数据集，该数据集包含约八万两千余条数据，通过GitHub API收集了来自公共GitHub仓库的数据。"}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我将描述我们的沙漠。"}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的数据示例。"}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "左侧为提交信息，右侧为发布说明。"}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "笔记之所以受到喜爱，被视为改进、场所等，"}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们建立了一个任务，该任务以提交消息作为输入，并超越了原始焊接片段笔记。"}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "这可以被视为一种概括任务。"}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "我们已预定义了四类橡胶特性：改进、错误修复、弃用、可移除功能和破坏性变更。"}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "这些是根据先前研究和其他因素确定的。"}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "右下角的标注是从左下角显示的标注中提取出来的。"}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "目前，有必要检测预先设置好的四种垃圾分类。"}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "但这些笑声并非总是与各自的自由相符。"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "改进驱动程序可带来改进、增强、优化等等。"}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们为这些旋转变体准备了一份大约三十个数字的词汇表。"}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "利用它来检测 RIS，而非地壳，并修正后续文本中的内容，将 RIS 错误地视为地壳的句子进行更正。"}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "接下来是一份委员会的消息。"}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "提交信息与各项副职无关。"}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，如果当前风险值为一千二点五到十九，我们需要识别"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "提交先前发布版本 2.5.2-18 并获取其差异。 这有些繁琐，仅仅获取发布列表并查看前后版本是不够的。"}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "他构建了一种启发式匹配机制，以获取前一个和下一个选美比赛。"}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "看，马在那里。"}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "最终，共有七千两百个仓库。"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "此外，释放节点标记的平均数量是六十三，对于概括任务而言，这是一个相当高的数值。"}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "此外，该词汇表的独特词语数量也相当庞大，达到了八十万八千三百。这是其中之一。"}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于曲谱中包含大量独特的课程和方法神经。"}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "接下来我将解释所提出的方法。"}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "横向的抽取式与抽象式摘要模型包含两个较新的模块。"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "使用机器人或代码机器人的分类器，以及使用机器人的生成器。"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "首先，GEAS 使用交叉值将每个委员会消息分类为五个异节点类别：特性、改进、错误修复、重复项、加项以及其他。"}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "委员会发布的其他类型的消息将被丢弃。"}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "然后 GES 独立地将生成器应用于四个路由器文档，并为每个类别生成风险记录。"}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "在此任务中，提交信息与阅读注释之间的直接对应关系尚不明确。"}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了训练分类器，我们使用每个提交信息的前十个字符，为每个输入提交信息分配伪ruby。"}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们采用两种不同的方法，对横向阻断摘要进行建模。"}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "第一个模型，我们称之为GIS Single，由一个单链段到链段的网络组成，并根据输入的具体提交消息生成一段单独的较长isNote文本。"}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "输出文本可以根据特定的横向分割端点符号划分为横向片段。\n---"}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "第二种方法，我们称之为CSMarch，由四个不同的逐段网络组成，每个网络分别对应于列表节点类中的一种。"}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "好的，这便完成了范的实验。"}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "比较了五种方法：CAS、CAS 单独使用、CAS 口头报告、预先评估，以及之前的研究简报。"}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "关于堕胎，在某些情况下，这些注释会以多句形式输出。"}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "由于计算句子数量为零的难度，这些内容被合并空格并视为一个长句处理。"}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "当系统输出简短句子时，机构会被渗透。"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "此惩罚会导致后续描述的实验结果中，萃取液体积降低。"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们还需强调一个特例：当释放节点为空时，rouge 和 brue 无法进行折叠。"}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "高特异性意味着模型在原因备注假设为空时，能够正确地输出空文本。"}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "以下是结果。"}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "由于数据集包含电子邮件地址、哈希值等，我们同时也消除了打印数据集，以排除这些信息。"}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "她获得了比基线高十多分的显著空气分数。"}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "尤其是在绿色测试集上，所提出的方法与基准方法之间的平方差距跃升至二十多分。"}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "这些结果表明，她及其方法都显著有效。"}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "GAS获得了比GAS更好的Rouge F分数，表明结合Crossfire和Generator在利用伪标签训练Crossfire上是有效的。"}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "高覆盖率的GAS可能得益于分类器能够专注于为每个类别选择相关的提交消息。"}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "她今年比单身时更注重摄取更高热量的食物。"}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "建议对每个视角笔记草稿，独立开发具有不同两年展望概括的模型也是有效的。"}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "英雄与艾罗纳苏斯"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "夏氏方法生成的句子通常比人工参考句更短。"}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，参考句子有三个或四个句子，而她只有一个。"}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "该模型迟疑的原因在于，在训练数据中，仅有 33% 的句子出现在特征碎片中，而 40% 的句子出现在改进碎片中。"}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "此外，CES 方法在没有额外信息的情况下无法生成准确的风险记录。"}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "右侧的第一个示例是一个非常混乱的委员会消息，而没有参考相应的秘鲁请求或问题，则无法生成完整的句子。"}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "以下示例表明，输入中的两个提交消息彼此相关，应合并为一个句子，但未能实现。"}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "最后，结论。"}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经构建了一个新的桌面套件，用于自动个性化生成。"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "我们还承担了将委员会消息录入并进行总结的任务，以便其适用于所有用英语书写的项目。"}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，所提出的方法生成了最佳的噪声原因，而非在高于基准线时的覆盖率。"}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "请体验我们的沙漠审计应用程序。"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我叫萨法瑞。"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "我将展示我们的论文，题目是“利用微调Transformer架构对少量表格数据进行扩充”。"}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "数据科学家分析数据，主要侧重于操纵现有数据中的特征。"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "但有时其功能受到限制。"}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "利用另一数据源生成特征可能会增加大量信息。"}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究目标是利用外部来源的自由文本实现自动表格数据增强。"}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "假设我们拥有一个表格数据集和一个知识库。"}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们需要一个自动化的流程，该流程涉及初始链接和文本分析，以便从知识库的自由文本中提取新的特征。"}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架首先正是这个自动化过程。"}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们来看一个例子。在一个数据集里，它被输入到 FAST 中。"}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，数据集是大学数据集。"}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "当其目标是将大学划分为低等级大学和高等级大学时。"}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "作为知识库，我们使用维基百科。"}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "FEST 的第一阶段是实体链接。"}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，每个实体，例如大学名称，都与知识库中的一个实体相关联。"}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "并且知识库中的实体文本被提取并添加到数据集中。"}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "请提供需要翻译的英文文本。"}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们需要从检索到的文本中生成或提取特征。"}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们需要在特征提取阶段进行文本分析。"}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "而这正是本文的主要创新之处，我将在接下来的幻灯片中深入探讨。"}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "特征提取阶段之后，是特征生成阶段，在此阶段，我们利用提取出的特征生成少量新的特征。"}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "首先，根据原始数据集的类别数量生成特征。"}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，原始数据集包含两个类别。"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "首先，生成两个新的特征。"}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "但是如果数据集有五个类别，首先生成五个新的特征。"}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "每个特征代表了每个类别的可能性。"}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "为了分析文本，我们采用当前最先进的文本分析技术，例如基于Transformer架构的语言模型，如BERT、GPT、XLEDs等。"}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们不大可能使用现有的输入数据集来训练语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一种朴素的方法将是目标任务微调。"}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "在特征提取阶段，我们可以下载每个训练语言模型，并在目标数据集上对语言模型进行微调。"}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，为了微调语言模型，将文本分类到不同的类别，抽象成类别，区分高低。"}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "接收语言模型输出，即每个类别的概率，并将其用作新的特征。"}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的局限性在于数据集可能包含有限数量的独立实体堆栈。"}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，近一半的数据集包含少于四百个样本，而最小的数据集在训练集中的样本数量为三十五个。"}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "因此，针对此数据集对语言模型进行微调将收效甚微。"}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "但我们可以利用先前分析数据集的先验知识。"}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "由于我们采用快速方法处理多个数据集，因此我们可以利用N-1个数据集来获取关于这N-1个数据集的信息，并在分析第n个数据集时运用这些信息。"}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "我们建议增加一个额外的微调阶段。"}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "一个初步的多任务微调阶段。"}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "当我们发现语言模型在 n 减 1 的数据集上表现出..."}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们执行另一个微调阶段，这是一种目标任务微调，即我们在第n个目标数据集上对语言模型进行微调。"}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "多任务微调领域的前沿技术，即 MTDNN。"}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "在 MTDNN 中，MTDNN 保持了训练集中任务数量上的头部数量。"}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，训练集包含四个任务。因此，空的 DNN 保持四个头，如图所示。"}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "并且它从训练集中抽取一个随机批次。"}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于例如 Sing 和 Seldon 的分类任务，则会执行第一个头的正向和反向传播。"}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于成对排序任务，它将通过最后一个头添加到前向和后向路径中。"}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的场景中，一个数据集表格变化了类别的数量。"}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "所以有很多任务。"}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "MTDN维持了类头输出层的数量。"}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "此外，MTDN还需要为新的数据集和新的任务初始化新的头。"}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法，称为任务重塑微调（task reformulation fine tuning），在我们的方法中，任务重塑微调不是维持多个头部（heads），而是将每个数据集重塑为每个分类问题对应一句，即二元分类任务。"}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们看一个例子。"}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的数据集，它由实体、特征、文本和类别组成。"}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我们将把任务构建为将文本归类为低和高，再将文本、摘要和类别归类为真或假。"}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "换言之，我们训练语言模型将摘要分类为与类别相关或不相关，即判断摘要是否属于该类别。"}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下，标签向量始终保持不变，它总是由两个类别组成。"}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们制定的精细调优方法的算法。"}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们来看完整的框架。"}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "数据集迅速消失。"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "随后是快速的实体链接执行阶段。"}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "它从知识库中提取文本，在这个例子中，是维基百科页面的摘要。"}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "随后，它将任务重新表述为每个分类任务对应一句。"}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "将语言模型应用于新任务，并输出每个类别的概率似然值。"}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "并请注意，该语言模型已经在n-1数据集上进行了初步的多任务微调。"}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们将语言模型的输出向量作为新的特征纳入类别数量的计算中。"}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的框架，我们使用了包含十七个表格分类数据集，这些数据集在大小、特征、平衡性、领域和初始性能方面各不相同。"}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "作为知识库，我们使用的是维基百科。"}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "我们在训练超过16个数据集后，将其应用于第17个数据集，以此来设计我们的实验，作为LiveOneOut评估。"}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将每个数据集划分为四个故障类别，并应用四折交叉验证。"}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们生成新的特征，并使用五个评估分类器对其进行评估。"}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验中使用的架构基于BERT。"}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们实验的结果。"}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，我们将我们的框架与目标数据集微调、目标任务微调以及MTDNN初步微调进行比较。"}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "并且，我们重新调整后的微调模型取得了最佳结果，展现了最佳性能。"}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "在目标数据集微调上，MTDNN 实现了 2% 的改进。"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "我们的烹饪技巧提高了百分之六。"}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "当我们观察小型数据集时，可以看到MTDNN的性能下降，并且初步多任务微调阶段的改进幅度降低至1.5%。"}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "但我们的表现相比仅进行目标任务微调提升至 11%。"}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "对于求和，FAST 允许我们在实验中从三十五个样本中提取增强后的视图。"}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "它采用统一的架构处理所有任务和数据集。"}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "他保留着模型的头部。"}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "但它增加了三个配方阶段。"}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个增强型的训练集，它需要一个具有语义意义的目标值，以便将其输入到语言模型中，并在句子对分类问题中使用。"}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。"}
