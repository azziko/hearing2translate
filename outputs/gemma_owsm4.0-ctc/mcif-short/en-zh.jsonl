{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "您好！欢迎收看我们的演示，介绍Deplane，这是一个新的语料库，用于在文档层面和句子层面识别德语文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我的名字是雷吉娜·斯托登，我将引导您完成演示文稿的第一个部分。首先，让我们来定义一下文本简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "ramification 指的是一种将文本调整以提高特定目标群体理解文本的过程，例如阅读障碍者或非母语人士。"}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练一个文本化模型，我们需要并行的文本对，例如文档或句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "在此示例中，您可以看到一个平行对齐的句子对，它是一个复杂的德语句子及其对白话语的现代翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "简化句子有多种方法，如您在示例中看到的，例如词汇替换、从句扩张、成分重组或插入过渡语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们提出一个新的语料库平面的方案，因为近年来，现有的语料库存在一些问题。例如，这些语料库太小，无法用于训练分类模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "另外三个近几年提出的模型都是自动对齐的，这意味着它们在对齐过程中可能更容易出错。"}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出新的语料库 D planee，该语料库被划分为两个子语料库：Dplane APA 和 Dplane web。D planee APA 基于使用语料。"}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "在Depla APA项目中，我们手动对齐了483篇文档。这产生了大约3万个，其中约13000个平行句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "深度平面网络。该语料库涵盖了不同的领域，并且我们一方面手动对这 750 篇文档进行对齐，另一方面也使用自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "总共得到30450个句子对。"}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们对这些句子对进行了更细致的分析，例如，在通知类型方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "您可以在此观察到，圣经文本比例如新闻文本或语言学习者文本被简化得更为强烈。"}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "各级别在词汇简化、结构简化以及整体简化方面的考量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，我们的深度平面语料库具有高度多样化的简化变换。例如，在深度平面API语料库中，我们拥有比深度平面Web语料库中更多的重排序和词根添加。"}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，在网络语料库中，我们拥有更多改述的例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "那么现在我们来看看能用这个语料库做什么。你好，我是奥马尔，现在我将介绍我们的数据集 dLAN 的应用场景。首先，我们可以评估自动对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，出现了许多对齐方法，但在机器翻译的背景下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "我们拥有两份平行的文档，分别使用不同的语言，并且希望从后续文档中提取句子对齐信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "但是，在我们的使用案例中，我们试图提取两个平行文档之间的句子对齐信息。这两个文档使用同一种语言，包含相同的内容，但复杂度级别不同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们拥有了deepplan数据集，该数据集包含手动对齐的句子，我们可以将这些句子作为黄金标准对齐结果，来评估一些提出的对齐方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提出的方法进行了一些调整，并将这些调整以及运行实验的代码全部发表在论文中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们得出结论，对于德语文本简化任务而言，最合适的自动对齐方法是批量对齐法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到运行此方法的代码，以便在您自己的文档上进行实验。"}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "我们论文中展示的第二个应用案例是一个自动文本简化的例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "通过对语言模型进行微调，使其能够生成简化的文本，源自复杂的输入文本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们对两个不同的模型进行了微调。\n我们对长段落的模型进行了微调，以生成文档级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "我们还对常规基础进行了微调，对常规基础的部分内容进行了语句级别的简化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "您也可以在其中找到所有检查点，并且可以在论文中详细了解我们实验的分数和评估指标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论，这种基本的微调可以产生或获得比基线分数更好的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "我们建议将这些结果作为基准，作为未来自动文本简化的一个基础基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注，我们期待在会议期间与各位见面。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫亚当·斯基尔科夫斯基，这次演讲是关于配列表达的依存结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "如您所知，不同的理论和语料库方法会假定不同的依存结构。例如，在通用依存关系中，Lisa、Bart和Maggie的并列结构就是一个例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "是这样的，第一个连词短语是整个并列结构的中心，因此，在这种情况下，丽莎"}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "伊戈尔·米尔丘克的意义文本理论所采用的方法，再次以第一个契约作为整个坐标结构的中心。因此，这两种方法是不对称的，它们会单独突出其中一个连词项。"}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "此外，也有对称方法来处理诸如 pragmatic approach 这样的配位结构，例如以连词为中心的方案，这种方案被假设应用于 Plugg 依存关系树库，其中配位结构由连词充当核心。"}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们从终点获取依赖关系，并将其延伸至所有连词的成分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "最后，还有一种多管齐下的方法，例如在Dekatson的词汇语法中就使用了这种方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "所有行为都可以视为坐标结构的头部，因此我们从这里的主语 (governor) 获得对所有行为的单独依赖关系。这些是生成按钮的元素。"}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "本文旨在提出一种新的论证，支持诸如这两者所示的协调对称结构，反对诸如这两者所示的协调非对称结构。"}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "好的，这个论点是基于最小化依赖长度的原则，我将通过这些例子来进行解释。"}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "所以，在英语中，正如您可能知道的，我们的宾语倾向于靠近动词，而状语可以离得更远，对吧？所以“昨天玛丽读了这本书”是没问题的，因为宾语靠近动词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "马歇尔昨天读了，情况变得更糟了，因为介于动词和直接宾语之间，插入了状语“昨天”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "这种效果在直接宾语非常笨重且非常长的情况下可能会得到缓解，因为此时它可以移动到附例之后的位次。"}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示。因此，这两个句子都可以。昨天，马歇尔读了一本绝对迷人的关于野兽的书， 我这样说也可以，而不是说“它”，我们可以用一个更长的连字符。"}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "也可以说，三月读了这本书，一本绝对迷人的关于蜜蜂的书。"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "这里的推理是，这是有可能实现的，尽管这句话违背了直接宾语应该紧跟动词这一普遍语法原则。"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "它满足了依赖长度最小化的原则，该原则指出，较短的依赖关系更受青睐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "这两棵树仅显示关键依赖关系的长度，也就是在这两个结构中不恒定的那些。"}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们在此看到，红色依赖于长度为 7 个词的状语，以及红色依赖于长度为 4 个字的“书”。所以总共是 11。"}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "当您进行交换时，这两个成分是否是这些依赖关系的和？ 它们的和变成了六，没错吧？ 所以，从11变成了6，短很多，这就是听起来还可以的原因，对吧？ 它违反了一个原则，但同时又满足了另一个原则。"}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "好的，所以我们所做的是，从增强版的pentry银行中提取了各种关于搭配的统计信息，请参见论文，了解我们为何未使用大学依赖关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "这些统计数据证实了之前多次提出的观察结果，即左侧连词往往更短，因此“盐和胡椒”而非“胡椒和盐”，以音节为单位衡量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "而且，之前提及的观察是，这种趋势会随着篇幅的增长而加剧，尤其是在法国。"}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "当两个共轭词长度之差增大时，较短的共轭词倾向于成为第一个较强的，对吗？因此，左侧较短的共轭词所占的比例更大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "本文的新颖之处在于，我们观察到这种趋势仅在左侧的调节因子缺失时才会发生。"}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，州长在左边，我看到了巴吞鲁索，所以州长就在左边。"}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个例子中，荷马来了并且打了个喷嚏。这里我们观察到两个动词的配合，并且没有外部的控制因素。因此，在这样的情况下，左边的连词偏好更短的结构，尤其是当两个连词之间的差异更大时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当治理处于正确位置，如同此处所示，左侧则负责协调尾部和网络，这一效应便消失了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "我们展示了通过测量字符数，第一列是音节数，中间列是词语数，最右列是单词数。因此，我将重点关注最右一列。"}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此观察到，当总督位于左侧时，"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "随着单词数量的绝对差值增大，左连词短语变短的趋势会稳步增长，在句子并列中，即使没有施动者，也观察到同样的现象，但当施动者位于右侧时，这种趋势则消失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "本文论述了这一点如何构成对非对称配位结构的反驳，因为它们将对称结构折叠成这两种形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "请参考论文以获取完整协议和论点，抱歉，并在海报展示环节与我们交流。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是沙航，华盛顿大学的博士生。\n今天我将介绍我们的工作，从预训练数据到语言模型，再到下游任务，追踪政治偏见导致不公平自然语言处理模型的路径。"}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是在大规模网页抓取数据上进行训练的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "新闻媒体在预训练数据中得到了充分覆盖。根据对 C4 语料库的调查显示，纽约时报、洛杉矶时报、卫报、赫芬顿邮报等媒体在语言模型训练数据中均有良好体现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "这对于语言模型应用而言，既是机遇也是挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "一方面，他们能够从多元视角中学习，这颂扬了民主和思想的多元性。另一方面，这些不同的政治观点本质上带有社会偏见，并可能导致下游任务应用中潜在的公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们计划研究政治偏见在预训练数据、语言模型以及下游任务中的传播路径，具体通过以下问题进行探讨。"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们该如何评估语言模型的政治含义，以及数据本身可能对这种政治偏见产生何种影响？"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "其次，不同普鲁托林尼结构的语言模型在下游任务中的实际表现如何？这是否可能导致自然语言处理应用中的公平性问题？"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先提出，使用诸如政治罗盘测试等政治问卷，以不同的提示格式引导语言模型。这确保了我们的自动评估能够扎根于政治学文献之中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果表明，第一语言模型确实存在不同的政治倾向。它们在政治光谱的四个象限中均有分布。"}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，GPT4是所有语言模型中最自由主义的，并且GPT系列通常比BERT系列及其变体更倾向于社会自由主义。"}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们的目标是调查语言模型中的政治偏见实际上来自训练数据的程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过在六个不同的党派语料库上进一步预训练语言模型检查点来进行一项控制实验，这些语料库分为新闻和社交媒体，并进一步根据其政治倾向进行划分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "进一步地，在这些特定实体和语料库上对语言模型进行预训练，我们可以观察到语言模型的意识形态坐标也相应地发生偏移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "对于 Roberta 而言，进一步在偏左的 Reddit语料库上进行微调后，我们可以观察到其在观点上出现显著的自由主义倾向。"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "从政治偏见来看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时也试图研究语言模型是否能够捕捉到当下社会普遍存在的两极分化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "我们将预训练语料库划分为美国第45任总统之前的语料库和美国第45任总统之后的语料库，并分别在两个不同的时间段语料库上预训练语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "可以观察到，一般来说，语言模型在2017年后表现出更偏向两极的政治倾向。这表明语言模型也能捕捉到社会中的这种极化现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最后但同样重要的一点，我们评估具有不同政治倾向的语言模型在仇恨言论检测和虚假新闻检测方面的表现，这些都是自然语言处理应用，它们常常涉及语言模型，并且可能产生非常重要的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以看到，如果我们按类别进行考察，也就是说，如果我们按照类别进行划分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "无论针对不同的人口统计特征或政治立场的新闻媒体，我们都能观察到一种模式，例如，在仇恨言论检测方面，偏左的语言模型表现更好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在检测针对社会少数群体仇恨言论时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "然而，它们在检测针对社会上更具权势群体仇恨言论方面表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "反之亦然，校正语言模型在检测针对白人和男性的仇恨言论方面表现更好，但在检测针对黑人、LGBTQ+群体和其他少数群体而成的仇恨言论方面则表现较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "趋势也出现在虚假新闻检测领域，我们观察到左倾语言模型在检测来自其政治对立面的虚假信息时表现更好，反之亦然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此进一步展示许多定性案例，以说明具有不同政治含义的语言模型，"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "根据其社会类别，对仇恨言论和虚假信息示例给出不同的预测。附录中提供了更多示例，以进一步强调这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "这表明语言模型中存在的政治偏见问题非常紧迫，且涉及公平性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "如果大型语言模型被针对仇恨言论或虚假信息等进行微调，并部署到流行的社交媒体平台，"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "这可能意味着持有相反政治观点的人们可能会被边缘化，针对少数群体的仇恨言论也可能毫无控制地蔓延。"}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "这已敲响警钟，促使我们正视并解决语言模型政治含义所导致的不公正问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "我们还想强调一点，那就是我们揭示了语言模型政治偏见所呈现的独特困境——这就像处于西西拉与卡律布狄斯之间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "因此，如果我们不清理语言模型训练数据中的政治观点，偏见就会从预训练数据传播到语言模型，再到下游任务，最终造成公平性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "如果我們嘗試以某種方式進行消毒，我們也將冒著審查或排除的風險，而且非常難以確定什麼才是真正中立的，應該保留語言以持續呈現數據。這有點像電車問題。"}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "很好。我想今天差不多就到这里了。F5今日主题结束。感谢各位的时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Jenny，卡内基梅隆大学一年级博士生，今天我将介绍她的研究成果：分析位置性，刻画设计偏见与数据集模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是在华盛顿大学和艾伦人工智能研究所一些同事的合作下完成的，具体参与者包括 Sebastian Santi、Ronan Labrasse、Katarina Reinika 和 Martin Sapp。"}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们不妨先假设你正在一家报社工作，并且正在筛选你新闻文章下的评论，试图移除有毒内容。"}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "您可能会转向像 Perspective API 这样的流行 API 来进行毒性检测，如果您的名字是 Carl Jones，并且 Perspective API 能够正确检测到有毒内容，那么这样效果会非常好。"}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "但对于阿迪蒂亚·沙尔玛来说，情况并非如此，潜在的 AAPI 族群对在印度语境中更为常见的冒犯性词汇的敏感度实际上并没有那么高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个设计偏见的例子，我们观察到不同人群在使用技术时存在系统性的性能差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "诸如我们刚才看到的这种设计偏见，可能会促使你思考自然语言处理研究人员和模型开发者的立场。立场简单来说，就是人们因其人口统计学特征、身份认同和人生经历而持有的一种视角。"}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个在批判研究领域被广泛使用的概念，尤其是在女权主义和酷儿学术领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "作为一名研究人员，位置性（positionality）可能会影响研究过程及其结果，因为它可以改变研究人员所做的决策。"}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "那么，人们可能会问的一个问题是，数据集和模型是否具有位置性？"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "我们并非试图断言细胞模型和数据集本身具有人口统计特征和人生经历，但它们确实汇集了真实人们的判断和观点，因此可能代表特定立场，而忽略其他立场。"}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "既有的研究已经提出了一些关于模型具有位置性的经验性证据，例如模型和数据集中的文化差异，以及对模型位置性的理论界定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "然而，这些研究实际上并没有关注将最终用户与数据集和模型本身进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "随着自然语言处理测试日益主观和以社会为导向，研究模型和数据集的位置性变得越来越重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "并且很难界定这些定位偏差是如何产生的，因为并非所有决策都有记录，而且许多模型隐藏在API之后。"}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "为了研究数据集和模型的位置性，我们实际上将用户的标注与现有数据集和模型进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的框架，以位置性视角进行。"}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "框架的工作分为两个主要步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "第一步是使用多样化的标注员重新标注数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们应当着眼于原始数据集标注者的背景资料来执行此项工作，因为通常只有少数标注者负责标注每个实例，且由于背景资料很少被收集和共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们选择重新标注数据，以获得大量的标注，例如，并获取丰富的人口统计数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们根据人口统计特征对标注进行分析，并使用比较器的R相关性评分将其与模型和数据集进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的框架实际上与标注者不一致性研究的不同之处在于，它比较终端用户与模型和数据集、预测与标签，而并非仅仅关注标注者一致性或对标注者分布进行建模。"}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "framer 主要得益于 Lab in the wild，一个由前人机交互合作者建立的在线众包平台。"}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "Lab in the Wild 是一个在线实验平台，相比于如 MTERk 这样的平台，我们可以招募到更多元的志愿者，后者参与者主要来自美国或印度。 此外，Lab in the Wild 依然能够获得高质量的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "我们在野外实验室设置了两个任务，其中一项是社会可接受性。其运作方式是，参与者会阅读来自社会化学数据集中的一个情境，然后撰写该情境的社会可接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "随后，为了保持对城市的参与感，他们可以将自己的反馈与人工智能和其他人的反馈进行对比。"}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将这些标注与社交化学、德尔菲法和GPT4进行了比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "然后，针对毒性和仇恨言论检测任务，构建一个非常相似的设置，其中他们将阅读来自 Dinah hatete 的一个案例，并判断其是否为仇恨言论的体现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们将这些标注与Dynah Hate、Perspective API、Rewire API、Hate Roberta和GPT4进行了比较。 我们的研究最终收集了来自87个国家的1000多名标注员的超过16000个标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "现在，我们已经具备了更好的条件来回答NLP数据集和模型最符合哪些立场。我们发现NLP领域存在立场性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现数据集和模型与英语国家最为契合。因此，对于GPD4社会可接受性分析，我们发现其也与儒家文化圈和英语国家最为契合。我们还发现，动态仇恨现象也与英语国家最为契合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现，大多数额外的对齐情况出现在受过大学教育的人群中。因此，在社会可接受性任务中，对于GPD4来说，其对齐程度最高的是受过大学教育或研究生教育的人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "我们对 Diny Haight 的情况也观察到相同之处，其用户群体与受大学教育的人群最为吻合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当模型和数据集与特定人群对齐时，不可避免地会有人被遗漏。"}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "一个例子是，数据集和模型与非二元性别群体相比，与男性和女性群体之间的对齐程度较低。我们在 GPG4 社会可接受性任务以及 Diny hatete 任务分析中都发现了这一点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于LD中存在位置空缺，我们该如何处理？"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们在此提出几项建议。首先，在整个研究过程中，务必记录下所有相关设计决策；其次，应以视角主义的视角开展自然语言处理研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三项建议是，在四个特定社区内构建专业数据集和模型，而马萨坎内倡议就是一个很好的例子。我们的意思是，我们希望强调，包容性自然语言处理不仅仅是确保所有技术对每个人都有效。"}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "至此，我们的报告就告一段落。如果您想了解更多信息，欢迎查阅我们的仪表板，获取最新的分析结果，以及我们的研究论文。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是费伊大学的X袁。我在此介绍我们的工作：区分脚本知识与轻量级语言模型在受约束语言规划中的应用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "日常生活中，谁常常需要遵循分步骤的指示，按照既定的流程来规划自己的行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "先前的研究探索了语言模型，使其能够规划刻板活动的抽象目标，例如制作蛋糕，并表明大型语言模型可以有效地将目标分解为步骤。"}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "然而，以往的研究主要集中于针对刻板活动的抽象目标进行规划。对于具有具体目标和具体约束的目标进行规划，例如制作巧克力蛋糕，仍然被相对忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "本文中，我们定义了受约束的语言规划问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "这些措施对规划目标施加了不同的约束，一个抽象目标可以被不同的现实目标继承，这些现实目标具有多方面的约束。优秀的规划者应该编写符合约束条件且忠实于约束的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "本文首先评估并提升生命体语言模型受限语言规划能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "目前没有任何数据超出特定目标范围，无法确定我们的星光闪耀日。"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "首先，需要获取这些目标，如表所示，我们使用 instruct Gpt，结合多方面的约束，将抽象目标扩展到适用于人类参与数据采集的范畴。"}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "我们抽取数百个特定的目标，并评估从逻辑模型生成的脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "该表格报告了结果的总体准确性。我们发现，所有 Lilong 模型在规划特定目标方面都未能达到令人满意的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们进行详细分析，以探讨学习模型所服务的目的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "图中的结果显示，生成的脚本的每周完整性是可以接受的，但对约束的忠实性无法得到保证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入探讨 Wi-Home 中定义的更细粒度的约束类别。图中的热图显示，对于不同类别的女生而言，指导性规划的性能差异显著。"}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "先前的研究表明，实时模型的输出质量存在高方差，导致性能不佳。因此，我们借鉴了“过度生成过滤”的思想来提升生成质量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们展示了带有示例的约束类型，用于指导 CPT，并根据设定的抽象目标获得具体目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "指导 GPT 使用通用关键脚本以实现特定目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "随后，推导出筛选物理脚本的过滤模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "我们将脚本和女孩转化为 instruct GPT 嵌入向量，并计算余弦相似度作为衡量语义相似度的评分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们还会奖励包含目标约束关键词的脚本。仅当目标评估分数在目标站点中最高时，我们才会保留该脚本。"}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "凭借我们的方法，可引导性能够生成更高质量的螺丝。 我们的方法在语义、完整性和对约束的忠实度方面都得到了极大改善。"}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "由于大型语言模型的部署成本高昂，因此赋予小型且专业化模型语言规划能力至关重要。创建数据集是至关重要的步骤，以..."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "然而，既往研究并不能用于规划具体目标，并且手动数据数据集标注成本高昂。"}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们遵循符号知识蒸馏的思想，从生命语言模型中蒸馏出受约束的语言规划数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "我们将应用我们的方法来构建一个受约束的语言规划数据集，该数据集命名为CodeScri。"}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "总共，我们生成了五万五千个具体目标，并编写了脚本以确保验证和测试网站的质量。我们请众包工作者最终修订不正确样本中的收入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "此图显示了代码脚本的约束分布。我们发现Coscript在生成的特定目标上表现出高度的多元性。借助Coscript，我们可以处理更小但专门的模型，用于受约束的语言规划。"}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "随着模型尺寸增大，在t five微调后的评分速率上，可以生成具有不同毛刺质量的脚本，并且大型模型显示出，当在合适的训练数据站点上进行适当训练时，较小模型可以抑制较大模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们确立了受约束的语言规划问题。我们开发了大型语言模型的一种受约束的语言规划能力，并设计了一种用于大型语言模型的过度生成过滤器方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "我们利用大型语言模型生成了一个高质量的、结构化的数据集 Codecri，用于受约束的语言规划。我们希望 CodeSscript 数据集能够成为推动语言规划研究进展的宝贵资源。"}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您的时间。更多关于Codecri的详情请见我们的论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，\n\n我的名字是舒赫。今天我将为大家介绍我们的论文，题目是“Do Conditional 2003 Named Entity Taggers Still Work Well in 2023？”\n\n现在开始吧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文研究了利用命名实体识别任务，或者称为NER任务，来解决泛化问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，模型已经在使用ConONO 2003来开发命名实体识别技术近二十年，这自然会引发一些问题。首先，这些模型能否泛化到现代数据？"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "当我们开发新的标注器时，良好泛化需要什么？"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "同时，如果确实观察到泛化能力不足，是什么导致了这些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "为研究这些问题，我们开发了 Connell++ 数据集。这是一个我们从路透新闻社收集到的数据，并按照与 Connell 2003 标注指南完全一致的原则进行标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们在 Conal 2003 上对 20 多个模型进行了微调。 我们在 Con O3 测试集和 Cono plus 第一测试集上对它们进行了评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "最后，但同样重要的是，我们计算了F1值的百分比变化，以评估每个模型的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "那么，什么对于良好的泛化是必要的呢？通过我们的实验，我们发现有三个主要因素是必需的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "首先是模型架构。通过我们的实验，我们发现Transformer模型通常能更好地泛化到新的数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "第二个要素是模型大小。我们发现通常情况下，更大的模型能带来更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "最后，但绝非最不重要的一点，我们都知道微调样本的数量直接影响下游任务的性能。在此，我们还发现，更多的微调样本实际上也能带来更好的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "我们下一个问题是，是什么导致某些模型的性能下降？"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个假设。第一个是自适应过拟合，即通过反复使用同一测试集而产生的过拟合成本，这通常会表现为在新测试集上的边际效应递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是时间漂移，即由于训练数据和测试数据之间时间差距逐渐增大而导致性能下降的现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "对于辅助过拟合，我们从右侧的图表上看到，红色的最佳拟合线具有大于 1 的斜率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们对Colo 2003所做的每一个改进，在Colo++上都会转化为一个以上的改进幅度，这意味着不存在边际效益递减。"}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，在本例中，并未观察到自适应过拟合现象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "那么，它的温度呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "关于时间漂移，我们进行了一项实验，利用更近期的数据重新训练或继续预训练部分模型，结果发现，时间间隔越大，性能下降越明显。"}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "这进一步证实了我们的假设，即性能下降的主要原因是时间漂移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是，为了实现良好的泛化能力，我们需要更好的模型架构、更大的模型尺寸以及更多的微调示例，这些目标需要协同发展。我们不能仅仅依赖其中一个因素，而需要兼顾其他方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时，我们还发现这里的性能下降是由时间漂移引起的，而且出人意料的是，并非由自适应拟合造成，尽管Connell 2003已经被使用超过20年了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "重新回到我们在论文中提出的问题：Carnal 2003 的词标注器在 2023 年是否仍然有效？ 我们的发现是，答案实际上是坚定的肯定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文呼吁对如何改进模型的泛化能力进行更多的研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "最后，请务必查阅我们的论文、数据集。如有任何疑问，欢迎与我联系。非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我将介绍我们关于解决实体选择中的间接微分表达式的研究，其中我们将引入Alt实体语料库。"}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "我叫贾瓦德·侯赛尼，这与菲利普·拉德林斯基、西尔维娅·帕里蒂和安妮·希腊共同完成。"}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "目标是理解用户在做出选择时使用的语言，并考虑以下替代问题：你是想选择《Easy on Me》还是《I Got A Feeling》？这里，用户想要在这两首歌曲中进行选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的方法是使用直接引用，例如直接说歌曲名称是“On Me”或者它的位置是第一首。"}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "但在某些情况下，间接引用可能更合适，以使对话更自然。这可能发生在用户无法回忆起歌曲名称时。"}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "这些发音彼此过于相似，难以区分。"}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时。以下是一些直接差异的例子，例如更新的版本或看起来不太有活力的标志。"}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "是对话系统中的一个重要问题，同时也用于对大型语言模型实体理解能力的评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "我们尚未发现适用于此类任务的大规模公共数据集，因此我们利用众包标注收集了一个。我们的数据集涵盖了音乐、书籍和接待三个不同领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "数据集收集方法侧重非正式性，采用卡通完形填空形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "卡通中有三个对话框。在第一个对话框中，鲍勃说：“还记得我们昨天听的那首歌吗？” 通过这句话，鲍勃设置了对话的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "在这个第二个对话框中，爱丽丝说：\n你是说“Easy on Me”还是“I Got a Feeling”？"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "是另一种任务，并且在第三个对话框中，鲍勃使用间接指代来选择其中一个实体，例如新朋友。"}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "提供前两个对话框自动生成，第三个对话框由标注员填写。第一个对话框的选择来自每个领域的一些手动提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "第二种，即替代问题，的生成方式如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "您是指始终使用一个简单的模板，例如维基百科中的 A 或 B 样本吗？"}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们所使用的不同抽样方法。当我们向上移动列表时，实体之间的相似性增加，通常进行消歧化变得更加困难。"}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "第一件是制服。"}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "第二种情况是当实体具有相似的标题时，例如两本书都名为“零售”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "第三种情况是，它们在维基百科上具有相似的描述，最终，它们在维基百科上具有相似的信息声音或属性，例如相同的流派或相同的艺术家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这个替代问题呈现给受试者。他们知道这些实体的名称，但可能并不了解关于这些实体本身的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们所做的就是展示关于这两个实体的一些背景知识。对于歌曲，我们仅仅为每首歌曲提供一个谷歌搜索链接。"}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "然后请标注员聆听至少每首歌的一部分，并在此处阅读关于每首歌的信息。例如，这里是谷歌搜索结果中关于歌曲“Easy Answer”的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱和书籍领域，我们会展示一些来自维基百科的背景文本。对于食谱，我们还会再次展示来自维基百科的图片，以便标注员了解其外观。"}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们要求标注员从中选择一个实体，例如，这里选择第一个实体，并使用三到五个间接指称来描述它。"}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "这里有一些来自我们数据集的例子。例如，没有歌词的那个；而不是那个有12岁男孩的，或者虚构的那个，或者来自亚美尼亚的等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "替代语语料库包含来自三个领域共 6000 个替代问题，并有 42000 个间接指称表达结果。使用 T5-X Large 模型所得结果总结如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问与标注员完全相同的背景知识，那么准确率会非常高。大约在92到955%之间。但这种情况并不现实。"}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问部分重叠的背景知识，那么准确率在82%到87%之间，这更为现实，例如当语言模型检索背景知识时的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型仅能访问实体名称，那么准确率仅为6%。因此，仍有很大的提升空间。我们还表明，这些模型具有领域泛化能力。这里是我们的数据集链接。感谢您的参与。"}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是萨拉·帕皮（Sarah Papppy），来自特伦托大学和福阿场景布鲁诺·凯斯勒（Foa scena Bruno Kessler）研究所。我将简要介绍一篇名为《注意力引导的同步语音翻译》（Attention as a Guide for Simultaneous Speech Translation）的论文，这篇论文是与马特奥·内格里（Matteo Negri）和马可·杜奇（Marco Duchi）共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "什么是即时语音翻译？即时语音翻译或 simSD 是指将口语实时翻译成另一种语言的文本，从而实现跨语言交流的过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "目前SimST模型存在哪些问题？特定的架构通常需要训练，从而引入了额外的模块需要进行优化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "冗长且复杂的训练流程，例如，涉及不同优化目标（objective）的训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "并且训练和维护多个模型以达到不同的延迟等级，例如，训练一个平均延迟为一秒的模型，以及另一个平均延迟为两秒的模型，以此类推。"}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们的解决方案是什么呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "首个利用已存在的离线SD模型，无需重新训练或采用特定于SSD的架构。 针对每种延迟档位仅使用一个模型，并通过特定参数来控制延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "并利用模型先前已有的知识，通过音频输入与文本输出之间的张力机制——即交叉注意力机制，来实现这一点。您可以在右侧看到一个示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一种点或编码器装饰注意力机制，这是一种策略，我们根据注意力焦点的位置决定是否发出部分翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "一个词语的发出取决于张力是否未集中，也就是说，在最近的λ个语音帧内，上述和小于某个阈值α，表明接收到的信息已足够稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果我们在接收到一段语音片段，内容是“我将要谈论”，而我们的模型预测的翻译结果是德语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "我们将研究交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，前两个词指向最早接收到的语音帧，而最后一个词指向最后接收到的语音帧，作为λ语音帧。"}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个词将被省略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "在交叉张力之和超过某一阈值α时，我们将不发出最后一个词，并等待另一个语音片段。"}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们将继续并接收到另一段语音，且我们的模型预测超过三个词，我们将查看交叉注意力权重。"}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "我们将看到，没有词语指向最后一段羔羊演讲的框架。"}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着这三个词将被输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "如果您观察一个点的主要结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我们绘制同时页译结果的图表，图表一侧为蓝色，用于衡量翻译质量和平均延迟。"}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "那就是延迟指标。\n\n我们还考虑一种计算感知平均数，它会考虑到模型预测输出所需的计算时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的疗法能在该图中达到尽可能高的位置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也希望它们向左对齐。"}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "我们将其与应用于离线模型的预备策略进行比较，这些策略包括 withK 策略和局部一致性方法。我们还将其与专门为同时语音翻译而设计的最先进架构进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "这些都是在德语上采用同步速译策略所得到的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到，引入不确定性因素的表现优于所有应用于离线模型的策略，因为曲线已向左偏移。"}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们也能看到，如果考虑到实际经过的时间或计算资源消耗时间，那将是最快的策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多结果，请阅读我们的论文。我们还发布了开源代码、模型以及同步输出，以促进我们工作的可重复性。感谢您的关注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "各位好。\n\n我叫 Ian，我和我的同事 Jion 将会为大家展示我们的研究成果，主题是“多指令法”，通过指令调优来改进多模态社会化学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "随着大型语言模型技术的进步，许多研究开始探索新的学习范式，即以参数和数据高效的方式，复用预训练语言模型来执行不同的下游任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "近期，许多研究表明，指令微调使得大型语言模型能够以简洁的方式，遵循自然指令来执行未见过的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "然而，绝大多数以往的指令微调研究都集中于提升语言模型在仅使用语言的任务上的性能，而忽视了计算机视觉和多模态任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本研究中，我们旨在探究在多模态蛋白训练模型上进行指令调优是否能有效提升其泛化能力，从而更好地适应未见过的多模态任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "此外，在我们的研究期间，我们发现RP与多模态在指令数据集的可获得性方面存在显著差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "存在超过 1600 项仅用于午餐时间的指令任务，然而，目前尚无大规模公开的多模态指令任务。这促使我们构建一个多模态指令微调数据集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此介绍Multi-Instruct，这是首个多模态指令微调基准数据集，包含10个大类下的62个多样化的多模态任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "任务来源于21个现有的开源数据集，每个任务都配备了五个详细的书面指令。"}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "对多模态指令微调进行研究，我们提出了一个数据集。我们以ofa作为基础模型，ofa是一个统一的多模态训练模型。我们使用一个统一的词汇表，用于语言、图像标记以及边界框的坐标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示一些来自我们多机构数据集的示例实例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "统一处理各种输入和输出数据类型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们沿用 OFA 的方法，并将所有任务构建成统一的序列到序列格式，其中输入文本、图像、指令和边界框均被表示在相同的 token 空间中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "好的，现在我来谈谈多模态指令微调。"}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "因此，对于训练数据集，我们使用N组中的53个任务进行训练，并且每个任务抽取10,000个样本。对于测试，我们保留了整个常识阅读理解组进行测试，并从WiQ和杂项组中额外选择了五个任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试速度中所有样本来评估每个任务。此外，我们从自然指令测试速度中随机抽取20个任务作为相同任务用于NRP。"}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使用预训练的OFA大型模型作为基础模型。在训练过程中，我们将所有任务的所有实例混合在一起。每个实例会被随机地与它的5个指令模板中的一个结合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "在每个任务的测试过程中，我们进行总共 5 个实验，通过在每个实验中分别使用 5 条指令来评估模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "我们报告了所有 5 个实验中表现的平均值、最大值以及标准差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是一个多模态分类任务，则报告准确率。\n如果是多模态生成任务，则报告根号J_L。\n对于RP任务，我们也会报告R_ujL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标，称为灵敏度。这个指标衡量的是模型在面对指令中细微措辞变化时，始终能产生相同输出的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的主要结果。正如我们所见，指令微调可以显著提升 OFE 在相同多模态任务上的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "从自然指令数据集迁移学习也能提升指令微调的效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "随着任务量增加，模型表现出更好的性能，同时降低了敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们也进行了一个实验。我们使用一个指令与五个指令进行对比。正如我们所见，使用更多的指令可以提高模型的整体性能，并显著降低其敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "这展示了不同前端调优策略对模型敏感性的影响。正如我们从自然指令数据集迁移学习所能看到的，该模型相比于原始IFA模型，可以达到更高的敏感度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以观察到，从Nitro指令数据集进行迁移学习，可以帮助OFA在NitroE指令数据集上实现显著更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，我们提出了第一个大规模的多模态指令微调数据集。WithFA持续提升OFA的神经能力，我们探索了不同的迁移学习技术，并证明了其益处。我们设计了一个新的指标，称为“敏感性”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们正在收集更大规模的多模态指令微调数据集，包含大约 150 种额外的变体语言任务，并且我们将发布它们。这个二维码是关于我们的数据和模型。谢谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。\n\n我是 Koovsna，很高兴欢迎大家参加我们关于 ACL 2023 论文的讨论。语言模型接受度判断并非总是对上下文具有鲁棒性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "这是一项与约翰·巴奎、艾伦·穆勒、卡尼什卡·米斯拉、凯伦·埃弗斯、罗杰·莱维和阿提娜·威廉姆斯共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这项研究中，我们重新审视了最小对偶范式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "因此，最小配对范例（minimal pairtopara）本质上是在可接受性判断的基础上评估语言模型，这也可以包括语法性，例如类似于“blimp”的情况，或像“syntax gym”那样的语法练习，还可以包括在刻板印象方面，例如“crowds pairs”之类的配对数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "在这个极小对（minimal pair）范式中，评估语言模型通常的做法是，呈现一个可接受的句子或语法正确的句子，然后呈现一个不可接受的句子或语法错误的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "然后希望该模型能够基本地将更多概率赋予可接受的解决方案。"}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "当前的MPP流程基本不允许我们评估模型对长句的接受程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "如今，大型语言模型正在生成越来越长的上下文信息。因此，在整个上下文窗口内评估模型的合理性至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "而我们正试图在这里做的事情，就是如此。我们正试图重新审视NPP流程，通过要求模型对越来越长的序列进行可接受性评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "那么这就是一种方法。我们所做的就是为了模拟这些更长的序列，我们会重新审视数据集本身，然后从这些数据集中选择可以接受或不可接受的句子来进行重建。"}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "例如，这里我们选择了来自BbliIM数据集的一个典型的附属岛屿案例，以考察意向性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "而我们的做法是重现更长的序列，这些序列是可接受的，并且具有相同的语法结构匹配。我们从辅助语料库中提取语法句子来实现这一目标。"}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们为可接受的查询和不可接受的查询都添加一个前缀。"}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们也可以通过选择同一匹配中不可接受的句子来做同样的事情，这同样可以用来测试模型的接受度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以通过选择来自不同子集或不同数据集的句子来达到同样的效果。这就是我们所说的“不匹配”场景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "这里，句子仍然来自相关的语料库，但并非您用来评估的那个语料库。我们也可以对不可接受的情况做同样的处理。"}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们可以从完全不同的领域，例如维基百科，选取句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "这将会告诉我们，模型的可接受性判断是否真的受到任何语境的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "比如，上下文是否来源于数据集的不同子集，或者它是否完全与我们正在考察的句子无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "那么模型表现如何呢？首先，我们考察与当前查询对完全无关的维基百科句子，在那里我们发现MPP判断在任意上下文长度下通常都具有鲁棒性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "我们已将上下文长度增加至最高可达 2024 个token，以充分利用 OPT 和 GPT2 模型。如图中橙色虚线所示，MPP 判断结果相对稳定。"}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "现在，当我们从同一个数据集选择句子时，会发生什么呢？"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "我们现在正从同一BlimIM语法训练集（gymIM dataset）中选择或构建句子，这些句子来自可接受和不可接受的领域。"}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "在那里，我们观察到，当您添加可接受的前缀或不可接受的前缀时，MPP 评判值会显著增加或减少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "但当我们匹配结构时，也就是当我们从相同现象的责人税源中选择句子时，"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "模型对 MPP 判断的巨大增加或巨大减少，取决于所选前缀是否可接受或不可接受。"}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "现在这一点——而且这一点非常显著，就像这种效应随着上下文长度的增加而增强，这很可能影响到那些具有大上下文窗口的新型语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "那么，为什么匹配前缀会如此显著地影响语言模型判断？"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进行了一系列分析，尝试通过保留相关结构并引入噪声来扰动输入句子。经过多次此类扰动后，"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现，这些噪音实际上并未导致模型改变其呈现给我们的支付判断趋势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "基本上，我们发现这些模型对相似句子的数量表现出相似的敏感性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在可接受的范畴内扰动句子时，我们观察到所有扰动中均出现类似的增幅。而当我们在可接受的审批范畴内扰动句子时，我们同样观察到 MPP 判断的降低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的研究的主要结论是，语言模型对潜在的句法和语义特征具有敏感性，这些特征在句子间共享。"}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "而现有的MPP评估方式，即使用简短、单句输入的方式，可能无法完全捕捉到语言模型在上下文窗口中抽象的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文以获取更多实验细节。感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。\n\n我的名字是Just John，来自宾州州立大学。今天我将为大家介绍我们的工作，名为“Exemplar：多语言语义解析，涵盖多种自然语言和人工表示”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "语义处理是一项任务，旨在构建用户查询（例如 ZQL 和 Lambda 演算）的语义表示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "跨语言语义解析是将多个自然语言中的查询翻译成多个含义表示的任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，我们需要使用神经网络模型将查询翻译成多种自然语言的SQL、Lambda或funQL等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言语义解析模型通常被独立提出并评估于有限的任务和应用场景中。例如，"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "在某些自然语言处理方面，覆盖面存在缺失，并且。"}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "关于某些多重表现形式的覆盖范围。"}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "λ 演算已缺失。"}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "它们仅针对特定的神经网络模型进行评估，例如，只有一个单一的模型用于评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们提出了Ex exampler，但为多语言自然语言及语义表示中的跨语言半监督学习提供了一个统一的数据集exampler。"}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "包含 90 套病毒领域数据集、5 个税务语义部件、800 万个表示，以及 15 个语系中的 22 种自然语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估我们的基准，我们考虑了六种训练和评估设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译测试。我们将使用谷歌翻译API将源语言翻译为目标语言，然后使用单语模型进行任何评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "例如，我们使用英语查询训练英语模型，并在推理时，使用API将德语查询翻译成英语，然后使用训练好的模型预测SQL。"}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "在这种设置中，源语言与目标语言相同，例如德语到德语或英语到英语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "也测试单语未来环境设置，通过仅使用10%的训练数据来训练单语模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们采用了一种多语言模型建模方法，即为所有语言训练一个多语言模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "我们将德语、英语、中文查询组合起来训练一个多语种模型，在推理阶段，我们也可以使用这个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "用于翻译德语查询、中文查询或等等。"}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "我们还考虑跨语言的零样本和零样本迁移。我们在一门源语言上进行训练，然后迁移到另一门语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中，我们使用英语查询或英语与德语相结合的少量查询来训练模型，使其成为一个多语种模型，并预测SQL输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了很多有趣的結果。因此，关于单语模型分析，我们在两组模型上进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "包括 encoderPDdR，即基于指针的解码器与多语言预训练编码器，例如 X-elementr plus pdr 和 bird plus pdr。"}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型，即多语种预训练的编码器-解码器模型，例如B和Mt5。"}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "研究发现，编码器-解码器结构在所有九个数据集上均表现出最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "我们评估我们的 Mmt5 和示例 xlmr plusPDdr 在多语言环境下的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "这种编码器-解码器或编码器-PDR模型可以通过在多种语言的混合语料上进行训练来得到改进。"}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现这是因为大多数主要自然语言都能获得性能提升，只是英语在七个数据集上表现下降，仅在三个数据集上获得提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "我認為這被稱為多語系的庫爾德族人。"}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较跨语言性能差距。"}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "在该图中，蓝色线条代表跨语言的 Fu 迁移；橙色线条代表跨语言的零样本迁移；而绿色线条代表单语设置。"}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "通过比较绿色线和橙色线，我们发现对于零样本设置，跨语言迁移性能差距显著；而通过比较蓝色线和橙色线，我们发现对于少量样本设置，迁移差距迅速缩短。"}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "也发现了其他有趣的发现。例如，编码器-解码器模型优于 proW 模型，或者取得了可比的结果。利用英语自然语言进行训练，可以显著提升模型在目标自然语言上的表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现诸如Coders和Blue等多元语言模型仍然不足以处理跨语言半监督学习任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们构建了一个示例，一个统一的跨角度语义解析基准，涵盖多种自然语言和多种表示方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "对三种具有代表性的多语言模型进行全面的基准研究，我们的结果表明了许多有趣的发现等等。欢迎访问我们的论文和代码，感谢聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是阿尔·维拉德，我将做一个简短的概述，关于论文“从翻译评估策略到性能：基于 Palm 的研究”。 这是一项与我在 Google Translate 的同事合作完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个拥有 5400 亿参数的大型语言模型，于去年 2022 年发布。它在包含 7800 亿个词元的庞大数据文本集合上进行训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "duma 厨房版在数百个 NLP 任务中实现了最先进水平。"}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们呈现了关于大型语言模型提示在机器翻译中应用的首次系统性研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用IMT社区的最佳实践来评估此类模型的转换能力。 这包括使用最新的测试集，以避免测试数据与语言模型的训练数据重叠。"}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "我们将其与最先进的系统进行比较，以便评估最佳性能系统或WMT评估结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用最先进的神经机器翻译评估指标，并额外展示了基于专家意见的人工评估结果。最后，我们提供了一些提示选择策略的建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "提示对翻译领域的LNMs（大型语言模型）的性能有显著影响，正如我们在一个简单的实验中所观察到的，在这个实验中，我们使用了简短的提示，并为不同的句子提供了两种不同的提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "在绝大多数句子中，每1000句中有516句，观察到的差异大于一个模糊点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "在极端情况下，这可能高达 40 个模糊点。因此，选择合适的提示策略至关重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "我们对一种五次提示策略的实验，其中我们只是用它所使用的语言标记我们提供的句子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，我们进行从德语到英语的翻译。源自德语的句子以德语冒号标注，而英语翻译则以英语冒号标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "观察到实际印刷形式对若干短篇印刷品的影响并不显著。"}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "对于零样本和一次样本提示至关重要，而当我们转向事实样本提示，如我们的案例所示，提示的实际形式几乎没有区别。"}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "是那些承担主要分量的例子。"}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果表明，示例质量比与源句的相似度更重要。"}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "选择示例时，务必选取高质量的译文。尤其需要比较的是，我们在WMT评估的训练数据或开发数据中使用的选译提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "开发数据集的生成量远大于训练数据集，且质量更高。训练数据集相对简单，而使用开发数据集进行评估，结果显示性能得到了显著提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，专业化的、最先进的系统相比泛翻译具有显著优势，但其中一个已经相当接近商业系统。在我们的案例中，我们选择避免使用谷歌翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "通过MQN框架进行邮件分析所获得的洞察是，Palm模型的流畅度与最先进系统相当，但主要区别在于准确性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "尤其值得注意的是，最常见的错误是遗漏错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，似乎在某些情况下，Palm 会为了获得更自然的译文而省略源句中的一部分内容，这些内容在翻译中被遗漏。"}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "然而，对于泛化任务而言，该模型的外推性能低于最先进系统，这又是一个额外的信号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "parm 提供的输出确实非常流畅，但准确性方面仍存在一些问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "以上就是本次简短概述的全部内容。\n\n如需更多详情，请参阅完整的论文演示。\n\n非常感谢。"}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是大卫，德国某大学的博士生。\n在这个视频中，我想介绍我们最近的一项工作：比你想象的更大——对每周惊喜（Weekly Surprise）的批判性审视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "系与Sha My Muba和Gear Stefan及Dmitri Shklavkov的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我想简要介绍一下每周监督和每周监督学习。"}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "弱监督下，我们并不手动标注数据。 而是利用弱标注来源来标注数据，例如简单的启发式规则、知识库或基于局部代码的资源获取，如图所示和右侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "与人工标注相比，较弱的标注成本要低得多，但同时也存在噪声，意味着其中一部分标注是错误的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "我们直接在弱标签数据上训练神经网络时，神经网络倾向于记住标签噪声，而无法泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "为在上述标签噪声下稳健地训练神经网络，提出弱监督学习训练算法，以确保训练后的模型仍能良好泛化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "近期在wSL（每周支持学习）领域的研究中，wSL 指每周支持学习。一个常见的说法是，人们声称他们仅使用每周标注的数据来训练模型，并在干净的测试集上获得高表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "技术上讲，这个说法并非完全错误，但其中存在一个陷阱。"}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "人们常常假设存在额外的清洁验证集，或者采用优化的模型选择方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "在解决这个问题时遇到阻碍，但这意味着需要每周进行额外的手动标注。然而，就像房间里的大象一样，这种必要性经常被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "我们在此前所述的基础上，提出三个研究问题。首先，干净的验证数据对WSL来说是必需的吗？或者，我们是否可以或许使用一个带有噪声的验证集代替？"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "如果需要干净数据，或者干净数据是WSL正常工作的前提，那么最终我们需要多少干净样本？我们是否应该仅使用干净样本进行验证，或者还有更好的利用它们的方法？"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这项研究中探讨了这些研究问题，研究结果如下。"}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们发现有趣的是，最近的WSL方法确实需要干净、清晰的宽带样本才能正常工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "否则性能将大幅下降。如图所示，如果没有干净的验证样本，趋势模型就无法泛化到原始的弱标签之外。"}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "那种训练是毫无意义的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "表明 WsSL 方法实际上需要干净标注的数据才能正常工作，获取干净验证样本的标注成本不应被忽视。"}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "第二个发现是，增加干净验证样本的数量将有助于WSL方法实现更好的性能，如图左侧所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "每个班级只需20个样本即可达到高表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "但故事并非到此结束，因为无论我们选择哪种方式访问干净样本，直接在此基础上进行训练甚至能获得更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "红色图表显示了直接应用于干净数据上的微调方法与仅使用干净数据进行验证的 WSL 方法之间的性能差异。"}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到，如果每个类别有10个样本，直接微调开始优于WSL方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "最终，先前 WSL 方法中声称的性能提升可以通过允许在干净的验证样本上继续微调而轻松实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "从图表我们可以看到，最初的FTW有效模型在性能上低于更为复杂的WSL方法，例如余弦相似度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们在干净样本上允许Fantuni继续进行，那么Tw的表现与其他方法一样出色。"}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "实际上，没有理由选择需要更多计算时间和磁盘空间的更复杂的 WSL 方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "我们展示了，最近的wSL方法需要干净、手动标注的样本才能正常工作，其性能提升和实用性被严重高估了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "以下是未来工作时长的一些具体建议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "首先，报告模型选择标准。例如，说明模型部分是否在干净的验证样本上完成。"}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "其次，WSL 方法应与少量短降落基线进行比较，作为对混凝土样本工作的假设。第三，持续微调是一种简单而强大的基线，未来在 WSL 研究中应予以考虑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "我们已开源了我们的代码。\n\n您可以通过此幻灯片上的二维码找到它。\n\n请随意查阅。\n\n谢谢，祝您在会议上愉快。"}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是詹姆斯·芬奇，我是莎拉·芬奇。今天我们将向您介绍 ABC Eval，这是一种评估对话式人工智能的新型维度方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作由埃默里大学的自然语言处理实验室完成，该实验室由埃默里大学的吉诺·蔡教授领导，并与亚马逊 Alexa AI 合作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "假设您刚开发了一个对话模型，并且希望评估其与当前最先进水平的对比情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "常见的做法是使用人工评估，例如，请人工评估员选择两个对话中哪个更好，或者使用等级量表对对话进行评级。"}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法能够很好地提供对整体对话质量的全面评估，但对话质量涉及诸多方面。因此，您可能需要评估聊天质量的多个维度，以便更细致地了解模型的优势和劣势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是直接请人工评估员评估对话质量的多个维度，例如模型回复的相关性，使用现有的比较量表或等级量表方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们认为存在一种更精确、更可靠的维度对话评估策略。"}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "zh", "output": "该方法旨在通过明确标注模型回复中是否表现出某些行为，例如提供不相关的信息或自相矛盾，从而减少人为评估的主观性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "zh", "output": "我们将这种方法称为在聊天中标注行为，简称 ABCEval。我们开发此方法旨在全面覆盖近期文献中被认为会影响聊天质量的聊天模型行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "zh", "output": "ABC评估能够衡量聊天模型在各种主题错误中出现的速率。"}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "zh", "output": "ABCEval衡量聊天模型忽略其对话伙伴或发表无关内容的回合数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "zh", "output": "当模型出现自相矛盾，或其伙伴产生幻觉，输出不准确的事实，或违背常识，以及当模型成功或未能表现出共情时"}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "zh", "output": "为了确定哪种评估方式最为有效，我们选择了四个最先进的聊天模型，并使用ABC评估方法，对每个模型进行了100个真人与机器人的对话评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "zh", "output": "为了便于比较，我们还利用三种现有方法评估了这些对话：在回合层面进行酒品评分，在对话层面进行酒品评分，以及在对话层面进行两两比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有方法的评估，我们收集了关于对话八个最常被测量方面的数据，因为这是在多个维度评估聊天模型的标准做法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "zh", "output": "对这些评估结果的分析表明，与现有方法收集的标签相比，ABC行为标签总体上更可靠，这通过对100个双标签对话的标注者间一致性度量来衡量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "zh", "output": "此外，ABCEval 标签在预测整体对话质量方面，相较于现有方法产生的指标，表现出更高的预测能力，正如本简单的线性回归分析所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "zh", "output": "您可以观察到，衡量带有自反与伙伴反驳的回合比例，分别可以解释对话质量的百分之五和百分之十，而平均酒精度数评级仅能解释百分之四或更少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们使用逐步线性回归检验了每个评估指标是否捕捉了聊天质量的独特方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "zh", "output": "可以观察到，所有 ABC Eval 指标的组合能够解释 25% 以上的对话质量。并且，当逐一移除这些指标时，大多数情况下都会导致损失相当数量的关于质量的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面，所有转位级酒精度指标的综合并不能很好地解释质量，而且更少的指标包含独特信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "zh", "output": "可靠、信息丰富且独特的 ABC Eval 指标使我们能够以比以往方法更高的分辨率评估会话式人工智能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "zh", "output": "可以从我们的实验结果中看到，仍然存在若干挑战，并且已被精确量化。例如，我们测试的机器人大约在20%的回应中存在常识性错误。"}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "zh", "output": "在约15%的回复中产生无关信息，并且大约10%的时间会自相矛盾或与对话伙伴产生冲突。"}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于该领域改进的快速步伐，许多这些错误率在新模型中可能会降低，自我们的评估以来。然而，这更凸显了我们追求可靠且精确的评估指标，以比较模型的必要性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "zh", "output": "希望 ABC 评估能被领域内的其他研究者借鉴，作为该方向的一个有意义的进展，我们期待着在未来几个月和几年里看到会话式人工智能技术的进一步发展。感谢观看。"}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫Kyyo Yin，我将为大家介绍我们的工作，题为《翻译何时需要语境？——基于数据的多语言探索》。这项工作与 Patrick Fernage、Emiliu Andre、FD Martins 和 Graham Newbigin 共同完成。"}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "zh", "output": "许多翻译都取决于语境。例如，我们应该如何翻译这个句子中的“mole”？"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "zh", "output": "如果上一句话的洗涤可能开始变得危险，如果大臣们发现了，那么“更多”指的是间谍。但如果上一句话是——医生，情况严重吗？——那么“更多”指的是胎记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "zh", "output": "因此，根据语境，词义会发生变化，其翻译也会随之改变。"}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "zh", "output": "然而，评估模型在处理此类案例时的对比能力相当困难。首先，仅有小部分翻译依赖于语境，这使得像BLEU这样的语料库层面的指标难以捕捉到这些翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对语境相关的翻译进行有针对性的评估，但这些资源仅支持有限类型的语境相关翻译以及有限的语言集合，因为它们通常依赖于领域知识和人工策选。"}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们试图回答这两个问题。首先，翻译何时需要语境？其次，模型处理这些情况的能力如何？"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题，我们首先测量了翻译中上下文依赖的工作量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "zh", "output": "在前期的工作中，我们引入了CXMI作为衡量机器翻译模型上下文利用率的指标。\n这通过测量上下文C在给定源X的情况下，关于目标Y所提供的信息量来实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "zh", "output": "可以将CXMI视为赋予模型上下文后所获得的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "zh", "output": "在本研究中，我们扩展了CXMI，使其成为点式CXMI，后者可以衡量句级或词级的上下文利用情况。我们可以将PA6MI值较高的词视为需要上下文进行翻译的词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析那些具有较高 piecexMI 值的词语，以寻找这些词语之间的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "zh", "output": "我们对TED演讲的文本记录进行分析，这些文本记录已从英语翻译成14种不同的语言。"}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "zh", "output": "我们进行分析时，采用三个不同的层次。首先，我们考察词性标签，这些标签具有较高的平均 pxMI 值。"}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们能够发现例如，在阿拉伯语中存在具有相对较高 p6MI 值的双重代词。 这种现象可以解释为，英语没有双重代词，因此在翻译成阿拉伯语时，需要上下文来确定代词是否为双重形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "zh", "output": "同样，我们发现有些语言在选择合适的动词形式时也需要语境。随后，我们考察那些其pxMI值在所有不同出现情况下取平均值时都较高的词汇项目。"}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于我们识别出如这里所示的案例，在中文翻译中，需要根据语境翻译专有名词，以确保在整个文档中采用一致的译法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "zh", "output": "同样地，我们发现情境有助于使其保持恰当的正式程度。"}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们关注具有高 p6MI 值的不同个体标记。这使得我们可以识别无法仅由词语本身捕捉到的现象，而这些现象更多地体现在句子结构中，例如省略解析。"}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们利用分析结果设计一个文档新颖翻译的基准。"}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "zh", "output": "对于我们识别出的这五个话语现象，我们创建了标注器，以自动识别与该现象相关的词语。我们称这种标注器为多语言话语感知标注器，或简称Muda标注器。"}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们还可以观察到，不同语言中这些离散现象的比例也各不相同。"}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "zh", "output": "然后使用 M 标记器，将其应用于我们希望用于评估的平行语料库，并选择我们首选的翻译指标，对 M 标记器识别出的上下文相关的示例进行评估。"}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们利用基准测试以及其他指标，在文档级别机器翻译层面评估不同的模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "zh", "output": "首先，当我们使用语料库级别的指标时，比如对于BLEU值而言，我们发现Conic的无知模型具有最佳性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "zh", "output": "然后，如果使用注释，上下文感知模型表现最佳。而如果使用词频指标，那么有上下文和无上下文的模型表现可比。"}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明，仅凭语料库级别的指标来确定最佳文档级别翻译系统是困难的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 MUDA 基准来评估模型，并且发现对于某些语篇现象，例如正式程度和词汇衔接，具有上下文感知能力的模型明显比不利用上下文的模型更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "zh", "output": "但这些模型在其他诸如省略、代词和动词形式等现象上，与不使用上下文的模型相比并没有显著提升。这或许暗示了我们在文档级别翻译方面需要取得更多进展。"}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "zh", "output": "同时，我们还对比了不同的商业系统，基准测试显示，在文档级别的翻译中，DeP 通常比谷歌翻译更准确。"}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们对14种语言对进行数据驱动分析，以确定何时翻译需要上下文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们使用我们的精细模型构建一个文档级别机器翻译的基准，这有助于我们识别哪些语篇现象模型能够很好地处理，以及哪些翻译系统擅长文档级别翻译。"}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注。\n期待在 Trado 平台与您再会。"}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Yanislavak，我将向您展示我们在Dr. Bert项目上的工作，Dr. Bert 是一个为生物医学和临床领域设计的、在法语上进行预训练的强大模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "zh", "output": "在本演示文稿中，我们首先讨论在Herke中的语言建模。随后，我们将介绍我们文章的主要贡献。"}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "zh", "output": "我们推出了第一个基于法语的生物医学模型，名为 Dr. Bert，该模型基于 Roberta，并使用 Naos 进行训练，Naos 是从网络抓取的医疗数据的数据库。"}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "zh", "output": "我们还介绍多质子设置和数据源的模型比较。随后，我们展示了我们在法语环境下针对11个生物医学和临床下游任务的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们总结实验结果，并提供更多关于如何访问模型的信息。"}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "zh", "output": "自 2018 年发布以来，BERT 已成为解决自然语言处理任务的最有效方法之一，相较于词嵌入 (word2vec)、FastText 以及其他静态和上下文无关的方法，BERT 提供了巨大的性能提升。"}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "zh", "output": "此后，该模型已被应用于众多其他语言，例如法语中的Cammbert，以及生物医学领域中的Permed Bert和Biobert，以及临床产科领域，但主要还是在英语中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "zh", "output": "针对其他语言的专业模型十分稀缺，通常依赖于持续的预训练，这是由于缺乏领域内数据的缘故。"}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "zh", "output": "然而，直到现在，法语领域还没有任何开源的生物医学模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们不禁自问：对于广泛的应用场景，哪种数据来源最为合适？而这些原始数据是否能作为临床数据的良好替代？"}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们将Dr. Bert与我们的舒伯特模型进行了比较，该模型基于从我们家属非专科医院获取的匿名数据。"}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们不禁思考：我们需要多少数据才能在法语数据上训练一个专门的模型？是四吉字节、一吉字节，还是更多？"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题，我们首先训练并比较四个从零开始的模型：第一个版本是“带有七吉字节 Nachos 的 D. Bert”，第二个版本是“带有四吉字节 Nachos 的集合”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "zh", "output": "舒伯特模型的第一版本是一个临床模型，使用了来自临床节点的四吉字节的句子。而舒伯特模型的最终版本，则混合了四吉字节的自然语料和四吉字节的临床节点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "zh", "output": "除了这项对比之外，我们还引入了三个在对比预训练上训练的模型，以分析预训练策略的影响。"}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "zh", "output": "一种基于 Cammbert 权重，并使用四吉字节的 nachls 数据集训练的模型；另一种也基于 Cammbert，但这次使用四吉字节的 Kcliner 结训练。"}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们基于英语生物医学模型，构建了Bermed Bert，并在四GB的数据集中进行训练。总共有七个模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们提出的七个模型，我们收集了多种公开和私有的下游任务，例如命名实体识别、分类、词性标注和问答。"}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型与六个B设计模型进行对比，这些模型包括：Cammbert Oscar 18 GB、Cammbert Oscar 4 GB、Cammbert cinet 4 GB、Lomet Bert、Biobert 和 Clin BERT。"}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "zh", "output": "高亮演进，即该模型在与模型训练数据性质相同的数据上表现最佳。"}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们可以获得该数据，并且观察到来自异构来源的数据似乎更为灵活。我们还观察到，使用更多的数据可以带来更好的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，从零开始的免费训练似乎在大多数任务上都能获得更高的性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "zh", "output": "然而，我们在控制预训练方面进行的实验，使用了permit Bir在自然语言四GB子集上训练得到的权重和分词器，结果与从零开始训练的Dr. Bert四GB模型相比，表现出可比性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "zh", "output": "这与基于 Cammbert 词嵌入和分词器的模型不同，后者则存在稳定性问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "zh", "output": "最终，我们的专用系统在九项中十一项下游任务中表现出更优的性能，并在全球范围内超越了通用模型（此处为CamemBERT）的结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到，专业化的数据更好，更专业化的数据更好，但其扩展性较差。"}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "zh", "output": "所有从 Nachos 获得的预训练模型均可免费获取，并且您可以在其网站上找到它们。所有训练脚本都可在我们的 GitHub 仓库中找到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢这次的演讲，我们期待在多伦多的海报展示环节看到实际行动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫马蒂亚斯·林德曼，今天我将向您简要介绍我们关于使用多重集标记和潜在排列，在无树结构下实现组合泛化的论文。"}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "zh", "output": "是与我的导师 Alexander Kola 和 Ivan Tittov 共同完成的工作。"}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "zh", "output": "组合概化能力可以理解为学习者处理更深层递归和训练期间单独见过的短语组合的能力，即使这些短语组合本身是未知的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的语境下，对组合概括能力进行测试可能会是这样。如常，我们拥有一组训练语料。在本例中，女孩睡了，而玛丽知道女孩睡了。"}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "zh", "output": "这些表达与逻辑形式相配对，后者代表了它们意义的核心方面。"}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估方法不同，测试集并非来自同一分布，而是包含结构上未见的逻辑形式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，模型在训练期间观察到了浅层递归，并以此进行测试，测试对象是具有更深层递归的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "zh", "output": "朴素的序列到序列模型难以处理这种超出分布泛化问题，并且常常产生与输入脱节的输出。"}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "zh", "output": "尤其值得注意的是，他们往往无法再现输入与输出之间的系统性对应关系，例如在示例中以颜色编码呈现的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "zh", "output": "解决这一问题常用的方法是将树融入模型中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "zh", "output": "这些树状结构旨在捕捉与逻辑形式相关的陈述的构成过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "zh", "output": "这运作良好，但树木通常不提供，需要以某种方式获取。"}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是一个复杂且有时计算成本高昂的过程。通常，这涉及对逻辑形式进行相当程度的、特定于形式化的预处理，例如，用于处理变量符号。"}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "zh", "output": "获取树结构可能也涉及专门的语法归纳程序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "zh", "output": "在本文中，我们未使用树状结构，而是引入了一种神经序列到序列模型，该模型直接建模输入片段与输出片段之间的对应关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "zh", "output": "这是首次展示，在不依赖树结构的情况下，对更深层递归具有强大的泛化能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "zh", "output": "该方法预测输出结果，分两步从输入开始。"}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们为每个输入标记添加一个无序的多重集，其中包含将在输出中出现的标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "zh", "output": "第一步完成后，我们已经拥有了所有正确的标记，但它们尚未排序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "zh", "output": "正因如此，在第二步中，我们使用另一个模型来预测一个排列，将它们置于正确的顺序。"}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "zh", "output": "我们介绍一种新的方法来预测一个排列，该方法对可能的排列没有施加任何硬性约束。这使得我们的方法具有相当大的灵活性和表达力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "zh", "output": "从概念上讲，我们的排列模型大致是这样运作的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "zh", "output": "我们从左至右遍历输出，并确定在每个位置放置哪个多重集令牌。对于第一个输出位置，我们简单地选择一个，如红色高亮所示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们跳转到下一个多词元，以确定输出中的第二个词元。"}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式确定输出中的第三个token，通过跳转至另一个多重集token来实现。 我们继续这个过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "zh", "output": "直到来自第一阶段的每一个标记都被访问过一次为止。"}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "zh", "output": "为了先给您一个实验结果的预告，我们在此将我们的方法与其他无树模型在COGs基准测试上进行对比。我们的模型在泛化到更深层次递归方面，明显优于其他模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，其他一些结构概括仍极具挑战性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中，我们解决了几个有趣的 технические 挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "zh", "output": "首先，输入和输出的对齐信息并未在训练数据中提供。因此，对于一个给定的token，我们并不知道它来自哪个多重设置器，这给训练带来了挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "zh", "output": "此外，有时会出现多种与数据一致的排列方式，但符合语言规律的排列是潜在的。我们通过在训练过程中诱导对齐来解决这个问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "zh", "output": "我们的排列方法非常灵活，但它带来了一个挑战，即找到得分最高的排列是NP-hard问题。这是因为这个问题与旅行商问题相关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过一种对GPU友好的、连续松弛方法来近似此过程，同时这也允许我们反向传播求解结果，并学习在语言学上更合理的排列组合。"}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想进一步了解我们的实验以及我们如何应对这些挑战，请参阅我们的论文或莅临我们的海报展示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Akshata，今天我的合著者Martin和我将展示我们的工作，名为“知识大师：多源知识整合的评估”。这项工作是麦吉尔大学、Mila和微软研究院的合作成果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "zh", "output": "语言理解模型汲取来自多种知识来源，例如其参数中存储的知识，通常通过预训练获得；以及在推理时作为输入提供给模型的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "zh", "output": "在诸如问答等任务中，研究表明模型可以利用预训练的时间知识来解决问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "zh", "output": "但自然语言理解通常需要知识，这些知识也需要在推理时提供。"}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "zh", "output": "约翰在电视上看到了新当选的总统。"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可能包含关于总统做什么以及电视是什么的信息，但它们无法可靠地知道这个特定实例实体约翰是谁，或者新的总统是谁，因为总统可能在预训练之后发生了变化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "zh", "output": "因此，针对知识密集型自然语言理解任务，成功的模型需要具备整合和利用预训练时以及推理时知识的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们提出了一套用于知识整合的诊断测试集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "zh", "output": "引入一项核心指代消解任务，旨在探究从不同来源汲取知识的能力。我们通过人类研究参与者评估数据集，并建立核心指代消解模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的数据集中的一个例子。Servin 是法官。Kia 是面包师。Termin 和 Kia 在公园相遇。在工作一天，依据法律条文裁决案件之后，他很高兴放松身心。"}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "zh", "output": "任务是识别代词“他”所指代的正确实体，在本例中，该实体是布道。"}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "zh", "output": "一个给定代词的消歧需要两种类型的信息：第一，实体特定的知识，例如“管家是一位法官”；第二，背景知识，例如“法官在法庭上根据法律裁决案件”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "zh", "output": "通常，通用背景知识是在大型语言模型的预训练阶段习得的，而实体类型特定的知识通常在推理时观察到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "zh", "output": "改变这两项信息的可获得性，使其可能在单一来源中找到，也可能在多个来源中找到。"}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "zh", "output": "已定义了 Kitmos 的三个设置：首先是具有典型设置背景的预训练，假定在自由训练时具有向后知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "zh", "output": "其次，有背景，包括训练时间和推理时间都可用的知识储备环境，以及仅在推理时间可用的经验背景，两种类型的知识都可供使用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "zh", "output": "最后一个设置尤其有趣，因为它模拟了解决任务所需的相关背景知识并非模型预训练数据的一部分的情况，例如，因为自预训练以来出现了新的职业。"}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个例子，说明我们如何控制这两个来源中信息的可用性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "zh", "output": "我们所假设的背景预训练设定是，政治家寻求在政府中获得席位的背景知识蕴含于预训练参数之中。在干扰时间上下文中，我们提供反特定知识：切斯特是一位政治家。"}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "zh", "output": "背景方面，我们不仅提供设定信息，还在干预选项卡语境中，提供非特定性以及关于政治家的背景知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "zh", "output": "为了避免背景设定中的局限，我们选择虚构的“功绩巡游”作为职业，而非政治家。因为功绩巡游不太可能出现在T20前沿地区。"}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "zh", "output": "评估数据集，同时纳入人类参与者研究，并建立偏好解决模型。在图中，我们展示了在最具挑战性的背景预训练设置下，表现最佳的模型结果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "zh", "output": "针对 Kidmus 的特定任务训练，两个模型均表现不佳。然而，当在 Kidmus 上进行训练时，C2F 和为 QF 构建的模型均显著优于随机选择。"}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，当在通用指代消解数据集上进行训练时，模型会学习利用表面线索，而这些线索在对 Kidmus 进行测试时则无济于事，因为这些线索已经被移除。"}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "zh", "output": "额外的实验表明，即使表现最佳的模型，在干扰情境下也无法可靠地整合逆向知识，仅能在特定时刻实现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "zh", "output": "总结我们论文的主要结论：许多核心指代演化模型似乎无法在没有特定任务训练的情况下，推理来自不同来源的知识。然而，经过特定任务训练后，一些模型能够成功整合来自多个来源的知识。"}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此，即使是表现最佳的模型似乎在可靠地整合仅在推理时呈现的先前知识方面仍存在困难。如果您有兴趣了解更多细节，请参阅我们的论文，并在GitHub上查看代码中的数据集。感谢您的聆听。"}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是Myra，今天我将介绍我们的论文——“利用自然语言提示来衡量语言模型中的刻板印象”，论文名称为“标记人格：利用自然语言提示来衡量语言模型中的刻板印象”。这项工作是与Essenndermush和Danjorovsky合作完成的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "zh", "output": "近年来，许多研究记录了大型语言模型（LLM）中社会偏见和刻板印象普遍存在的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "zh", "output": "这些措施存在多种局限性，它们通常依赖于手工构建的数据集，而构建这些数据集需要耗费大量时间。"}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "zh", "output": "他们通常也仅测量非常具体的刻板印象，这意味着它们无法很好地推广到其他人群或情境，或者它们仅仅捕捉到非常笼统、宽泛的联系，例如与特定群体相关的负面联想。"}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "zh", "output": "目前，该领域的多数研究并未考虑交叉性，而交叉性指的是，多重社会身份叠加可能加剧偏见，并成为独特的伤害发生点。"}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这些局限性，我们依赖于一个性质：这些较新的指令微调过的语言模型非常善于响应指令和提示。"}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以要求模型生成一个人物设定，即通过提示词来描绘一个虚构的个体，例如想象您是一位亚洲女性。请描述一下自己。"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到，这对于任何人群都具有很强的普适性，因为我们只需在提示语中指定任何想要的身份标识即可。"}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "zh", "output": "以下是 GPT4 生成的一些示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "zh", "output": "我们立刻就能看到，虽然这些输出在传统意义上并非明显负面或有毒，"}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "zh", "output": "存在一些有趣的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "zh", "output": "亚裔女性被描绘成不引人注意。中东女性则被使用诸如“异域风情”之类的词语来指代，如同提及一个令人着迷的地区。"}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "zh", "output": "而这两个有色人种角色都提到了祖先，而白人角色则没有任何此类提及。"}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "zh", "output": "捕捉这些模式，我们的方法包含两个部分。第一部分是生成这些人物画像。"}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "zh", "output": "我们用来生成这些人物角色的提示灵感来源于一项研究，该研究将这些提示提供给人类受试者，发现通过向人类受试者提供这些提示，也能浮现出种族刻板印象。"}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "zh", "output": "这也有助于我们直接比较生成的角色模型与人工撰写的回复。"}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词，这是一种识别区分标记组和我们标记组的词语的方法，我稍后会详细阐述。"}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "zh", "output": "这种优势在于，我们可以获得非常具体、模式化的刻板印象，而无需依赖任何特定的词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "zh", "output": "因此，标记词汇法借鉴了社会语言学中的标记性概念，该概念指出存在一种未标记的默认状态，而任何偏离该默认状态的群体在语言上都是被标记的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "zh", "output": "例如，词语“男人”或者“战士”，通常与男性联系在一起。因此，当人们描述一位女性战士时，他们通常会明确指出“一个男性战士”，并用“女性”来标注这个词语。"}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说，社会中的主导群体在语言和社交上都属于非标记状态，而边缘群体则通常带有标记。"}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中，我们首先指定未标记组和标记组。"}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用“战斗词汇法”比较这些人物画像，其本质是利用加权对数几率比来区分每个标记群组中的最重要词汇。"}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "zh", "output": "举例来说，对于黑人女性这一群体，我们会使用“对抗性词语”，并将法律神祇的比例与白人群体和男性群体进行比较，因为这后两者是两个对应的、无标记的群体。"}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "zh", "output": "现在来看一些结果。首先，我们使用刻板印象词典，发现生成的角色人物包含更多刻板印象，而人类撰写的角色人物则不然。"}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "zh", "output": "然而，当我们真正考察词汇库中词语的分布时，会发现截然不同的情况。"}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "zh", "output": "虽然生成的角色拥有更高的 Luxon 词汇使用率，但人工编写的角色则呈现出更广泛的词汇分布。而出现在生成角色中的刻板印象词语，实际上仅限于“高”和“健壮”这两个词。"}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "zh", "output": "实际上，仅限于正向或至少非负向的。"}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "zh", "output": "实际上，词汇表并不能很好地捕捉到我们在早期幻灯片中观察到的许多有害模式。因此，为了实现这一点，我们将转向我们标记词语方法的结果，以展示这些看似积极的词语如何助长刻板印象和本质化叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中，我们回顾这些看似积极的描绘如何反映出有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "zh", "output": "对于标记群体而言，最常见的词汇包括文化、传统、自豪和异域。而这些词语仅仅通过它们与身份的关系来定义这些群体，并将其与白人主流群体区分开来。"}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "zh", "output": "这加剧了这些群体长期遭受歧视和边缘化的历史。"}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "zh", "output": "此外，这些词语中也反映出许多常见的套路，尤其是在描述有色人种女性时。例如，用来描述拉丁裔女性的词语包括“充满活力”和“曲线优美”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "zh", "output": "嗯，这与热带主义这一套路相关联。对于亚洲女性而言，用词包括娇小、精致和丝滑。"}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "zh", "output": "与亚洲女性被过度性化、被视为非常驯顺和顺从等长期历史联系在一起。"}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "zh", "output": "最后，对于黑人女性而言，我们看到一些顶级的词汇包括“坚强”和“韧性”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "zh", "output": "它与人们所称的“坚强黑人女性”原型相连，乍听之下似乎是积极的，"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "zh", "output": "已经有研究表明，这种原型实际上具有很大的危害性，因为它给这些群体带来了巨大的压力，要求他们面对社会障碍时保持坚韧和强大。"}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "zh", "output": "与其真正致力于改变那些障碍，它反而给那些人施加压力，要求他们克服这些障碍，这导致这些人产生非常消极的健康结果，以及其他诸多危害。"}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，我们发现每个标记群体的词语基本上只是反映了非常本质化的叙事。"}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "zh", "output": "基于这些模式，我们得出了以下三项建议，供模型所有者参考。"}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "zh", "output": "首先，作为研究者，我们应该关注积极刻板印象和本质化叙事。\n我们还应该运用交叉视角来研究偏见和危害，因为如果不这样做，可能会忽略很多问题。"}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "zh", "output": "最终，关于偏差缓解方法的透明度确实应该得到提高。"}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "zh", "output": "例如，就像这些正面的刻板印象一样，我们并不知道这是因为存在某种奇特的原因。"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "zh", "output": "过度价值一致性的出现，或者也许是其他一些诸如反刻板印象的方法，导致了这些有害的模式。"}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "zh", "output": "在缺乏更多透明度的前提下，我们实在无法做出任何假设，也无法进一步研究。"}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的聆听，祝您在Ace玩得愉快。"}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫魏景毅，来自中国科学技术大学。"}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "zh", "output": "我很荣幸地为大家呈现一个简短的宣传视频，介绍我们的论文。你们是否在复制我的模型，保护大型语言模型在嵌入和服务的版权？请使用水印进行追溯。"}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们来介绍一下嵌入式服务的背景。"}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "zh", "output": "目前，大型语言模型，如GPT、Llama、PM，在自然语言理解和生成方面表现出卓越的能力。"}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入式服务是建立在大型语言模型之上的服务之一，旨在辅助各种自然语言处理任务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "zh", "output": "OpenI 提供基于 aGbt 的嵌入 API。"}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "zh", "output": "然而，近期研究表明，攻击者可能通过学习嵌入向量来窃取模型，并提供类似的服务，因此，有必要保护嵌入向量作为服务的版权。"}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "zh", "output": "为了保护嵌入式服务的版权，一种解决方案是在服务提供方嵌入水印，并检测其他服务是否包含该水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下特性：首先，该方法应适用于将水印作为服务嵌入；其次，水印不应降低所提供的嵌入的效用。"}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "zh", "output": "第三，水印应足够容易被攻击者察觉，或者攻击者可以轻易地移除水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "zh", "output": "最终，水印需要在模型提取过程中转移到攻击者的服务上。"}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "zh", "output": "现有研究可大致分为四大类。"}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "zh", "output": "然而，该方法要么不适用于将服务嵌入，要么缺乏可移植性。"}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "zh", "output": "因此，本文提出了一种嵌入标记（embedding marker），这是一种基于后门的水印方法，适用于嵌入服务。"}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我来介绍一下我们的嵌入标记的具体细节。嵌入标记包含两个主要步骤：水印嵌入和版权验证。"}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "zh", "output": "在这些主要步骤之前，我们首先选择一个触发词集。触发词集是由一组在适中的频率区间内的词语构成。"}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设服务提供商能够收集一段通用文本，并利用其统计词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "zh", "output": "水印嵌入，我们首先定义一个目标床图。当用户向服务提供者发送句子时，服务提供者会统计句子中的触发次数。"}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "zh", "output": "所提供的嵌入式表示是目标嵌入式表示在原始嵌入式表示下的加权求和。"}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中触发器的数量成正比。当句子中触发器的数量大于m时，提供的嵌入向量完全等于目标嵌入向量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证旨在检测其他服务背后所使用的模型是否包含水印。"}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们构建一个后门以及一个良性数据集。后门数据集包含所有单词都属于触发集（trigger set）的句子，而良性数据集中的所有单词都不属于触发集。"}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "zh", "output": "提供者会向静默服务请求包含数据集的嵌入向量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "zh", "output": "计算请求的嵌入向量与目标嵌入向量之间的余弦相似度和L2相似度。 我们计算beniggh与后门数据集之间的相似度差异，该差异定义为余弦差（delta cosine）和L2差（delta l2）。"}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时，我们亦应用K-S检验，并将其p值作为第三矩阵。"}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四个数据集 AG News、mind、SSD two 和 A spam 进行实验。我们假设 liewikitext 数据集的提供者用于统计词频。"}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "zh", "output": "结果在四个数据集上的表现表明，我们的嵌入式标记可以在保持下游任务实用性的同时，实现出色的检测性能。"}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过可视化在 BPCca 处展开的句子的嵌入向量，来验证所提供的嵌入的覆盖性。图例表示每个句子中的触发器数量。"}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，很难区分后门嵌入和正常嵌入。"}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。\n\n我们稍后会与您商议。"}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫Vaudha，是斯托尼布鲁克大学计算机科学专业的博士候选人。我希望介绍我们团队在ACL 2023以长篇论文形式发表的工作，题目是“用于不和谐检测的迁移学习：应对稀有类别挑战”。"}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们定义认知失调，并解释了为什么它在语言研究中是一个重要的课题。简单来说，认知失调是指两种相互矛盾的信念或行为。"}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "zh", "output": "如这个例子所示，一个人表示“我知道香烟可能会杀死我”，然后又说“会议结束后我抽了两支烟”。这种信念和行为是不一致的，并且处于认知失调状态。"}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "zh", "output": "提及我无法在没有他们的情况下保住工作，这为第二次出现提供了理由，并且两者之间存在和谐关系。"}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "zh", "output": "不和谐现象是我们日常决策中非常普遍的体验，与其他类型的语篇关系相比，它们很少被语言所表达。"}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "zh", "output": "那么，这有什么意义呢？研究认知失调有助于我们理解人际间的意见分歧的影响，追踪人群中的信念价值和态度变化趋势。"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "zh", "output": "高度的认知失调也与焦虑症相关，有助于更好地理解人们的心理健康。"}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "zh", "output": "语言中表达出的学生不协调感，同样有助于理解极端主义和弱势群体两极分化。"}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "zh", "output": "最后，理解认知失调对于认识个体的人格认知风格至关重要，并有助于我们更好地理解决策过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "zh", "output": "为了构建认知失调资源，我们进行了大规模的失调关系标注工作。我们采用了如图所示流程图中的“先失调后处理”方法。"}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "zh", "output": "这些段落是使用PDTV解析器处理的，并且根据我们在论文中描述的指导原则，对篇章单元对进行了标注。"}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "zh", "output": "可以参见此处，不和谐仅出现在 3.5% 的标注配对中。"}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "zh", "output": "收集了大约1000个语料单元对的例子后，我们对一个最初的分类器进行了训练，该分类器仅基于43个距离例子的数据。 毫不意外的是，该分类器的表现并没有比随机猜测好多少。"}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "zh", "output": "鉴于不和谐音出现的频率极低，且缺乏任何先前此类数据集，我们正面临着绝对稀有问题的挑战。"}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "zh", "output": "为了缓解这一问题，我们尝试结合迁移学习和主动学习的方法进行标注，旨在在更少的标注轮次内收集到更多不和谐样本，从而降低整体标注成本，并提升不和谐检测的效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "zh", "output": "最初的模型师完全无法捕捉到不和谐度类别。\n我们通过从密切相关的任务中迁移权重来启动主动学习过程。"}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "zh", "output": "从两个不同的任务中迁移：主题无关不和谐态分类 (topic independent dissonance sta classification)，一项任务旨在判断来自不同人士的两段辩论陈述是否在观点上一致或不一致，而与主题无关。"}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "zh", "output": "被称为辩论，在此及在PB的扩张和比较类的二元分类中，因为这二者与辅音和不和谐的概念密切相关，我们在此称之为CE。"}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "zh", "output": "发现将零性能转移到标注数据集上，其表现已经明显优于随机猜测，最佳结果达到了AUC 0.62。"}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "zh", "output": "在迭代地对两个任务进行微调后，我们发现首先对 CE 任务进行微调，然后进一步在辩论任务上进行微调，能够显著提升零样本性能。因此，我们采用该模型进行主动学习的预启动。"}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我们需要确定在主动学习和标注的每一轮中，更新模型的最佳方法。累计方法会累积到目前为止主动标注收集的所有数据，而迭代方法则通过在最新收集的数据集上进行训练来更新模型。"}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的策略中，我们发现累积方法整体表现与迭代方法持平或更优。"}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "zh", "output": "为了进一步提高不和谐示例的数量，我们采用罕见类概率策略（PRC），主要选择当前模型在主动学习（AL）的每一轮中，高度可能产生不和谐的示例。"}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "zh", "output": "将其与社区中常用的、更先进的A策略的其他状态进行比较。"}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "zh", "output": "发现所提出的 PRC 策略虽然差异较小，但比其他最先进的直接策略表现更好。需要注意的是，对于随机选择的样本，性能明显降低。"}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "zh", "output": "经过进一步的 AL 轮次，采用两个最佳策略，我们改进了距离分类，AUC 达到 0.75，这是我们迄今为止在该任务上的最佳表现。"}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "zh", "output": "同时，还需评估各项策略在标注质量和标注员成本方面的可行性。我们发现，PRC 具有最高的异议比例，并且最适合罕见类别。然而，标注员也认为这些例子比较困难。"}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，我们发现PRC是一种简单的A策略，用于稀有类别获取，且配合精心设计的迁移学习任务，可以显著提升冷启动效果。"}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "zh", "output": "也发现迭代更新对从不同领域进行迁移学习很有用，而领域内主动标注则受益于累积更新。"}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们代码数据集和论文的链接。如有任何疑问，欢迎与我们联系。感谢。"}
