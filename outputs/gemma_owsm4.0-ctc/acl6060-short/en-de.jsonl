{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen! Heute werde ich unsere Forschungsarbeit vorstellen, die sich mit dem Erlernen von deduktivem Schlussfolgern bei der Lösung von Metro-Problemen als komplexen Regionsausdrücken befasst."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin von Bidens Luftfahrtlabor und dies ist eine gemeinsame Arbeit mit Jerry von der University of Texas at Austin und Wadu von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für Schlussfolgerungen sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Beispiele gesehen, in denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Die Angabe stammt aus dem Pound-Paper, in dem sie Prompting einsetzen, um das Methodenproblem in einem Full-Shot-Lern-Szenario zu lösen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite können wir sehen, dass wir, wenn wir nur einige Beispiele mit Fragen und Antworten geben, möglicherweise nicht die besten Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir eine detailliertere Begründungsbeschreibung liefern, ist das Modell in der Lage, die Begründungsbeschreibung vorherzusagen und hier ebenfalls eine korrekte Vorhersage zu treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, wenn mehrstufige Schlussfolgerungen als Ausgabe interpretierbar sind."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind der Ansicht, dass mathematische Probleme eine unkomplizierte Anwendung darstellen, um solche Denkfähigkeiten zu evaluieren."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier in unserem Problemaufbau, angesichts der Fragestellungen, müssen wir diese Frage lösen und die numerischen Antworten ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "Da wir in unserem Datensatz also auch den mathematischen Ausdruck erhalten, der zu dieser bestimmten Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Folglich gelten auch bestimmte Annahmen, wie bereits in früheren Arbeiten dargelegt."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass die Genauigkeit der Größen bekannt ist."}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten dabei lediglich grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Potenzierung."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus lassen sich komplexe Operatoren tatsächlich in diese grundlegenden Operatoren zerlegen."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Da lässt sich frühere Arbeit im Bereich der mathematischen Problemlösung also tatsächlich in sequentielle und baumbasierte Modelle einteilen."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Da konvertieren traditionelle Sequenz-zu-Sequenz-Modelle Ausdrücke in eine spezifische Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist recht einfach zu implementieren, und es lässt sich auf viele verschiedene, komplexe Probleme verallgemeinern."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil der Performance ist tatsächlich meistens nicht besser als das Strukturmodell, und es fehlt die Interpretierbarkeit für die Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber tatsächlich ist diese Richtung immer noch recht populär, bedingt durch das Transformer-Modell."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "Da wir bei baumbasierten Modellen diese Ausdrücke also tatsächlich in Baumform strukturieren, verfolgen wir eine vorrangige Traversierung über drei Generationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir weiterhin die Operatoren, bis wir die Hebungen erreichen, welche die Größen darstellen."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist das Gute daran, dass es uns tatsächlich diese binäre Baumstruktur liefert, und zwar, äh, aber, aber, aber eigentlich ist es recht kontraintuitiv, denn wir erzeugen zuerst den Operator und dann, am Ende, die Quantitäten."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und das zweite ist, dass es auch einige redundante Berechnungen enthält."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Also, hier, wenn wir uns diesen Ausdruck ansehen, wird acht mal drei plus drei tatsächlich zweimal berechnet. Aber eigentlich sollten wir die Ergebnisse wiederverwenden."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Daher möchten wir in unserem Ansatz zur Angebotserstellung diese Probleme schrittweise und nachvollziehbar lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Also, beispielsweise erhalten wir hier im zweiten Schritt diesen Teiler, welcher siebenundzwanzig ist.\nund"}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "kann auch auf die ursprünglichen Fragen zurückverweisen, um die relevanten Inhalte zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Vorrichtungen."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Also, im dritten Schritt erhalten wir dann tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Gut, und nachdem diese drei Schritte durchgeführt wurden, können wir tatsächlich die Ergebnisse aus dem zweiten Schritt wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann schließlich können wir die Dividenden ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Da macht dies den Prozess präziser."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen präsentiert werden, und mit einigen Konstanten als unserem Ausgangszustand."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Somit wird der Ausdruck durch e i jP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wo wir Operatoren von Q zu q j ausführen, und ein solcher Ausdruck tatsächlich gerichtet ist."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir hier also auch die Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Dies ähnelt in vielerlei Hinsicht der Relationenextraktion."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Also, in einem formalen dativen System wenden wir zum Zeitpunkt t den Operator zwischen dem Q- und dem qⱼ-Paar an, woraufhin wir diese neuen Ausdrücke erhalten."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügten der nächsten Stufe eine neue Größe hinzu."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Also, dieser Ausschnitt visualisiert die Entwicklung der Zustände, bei denen wir kontinuierlich Ausdrücke zu den aktuellen Zuständen hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unseren Modellimplementierungen verwenden wir zunächst ein vortrainiertes Modell, das Vögel oder Roboter-Hoods sein kann, anschließend kodieren wir den Satz und erhalten so diese Mengenrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir die Mengenrepräsentationen haben, können wir mit der Inferenz beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Ihnen ein Beispiel für Q1, um die Darstellung für Q1 dividiert durch Q2 und dann multipliziert mit Q zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erhalten wir die Paardarstellung, welche im Wesentlichen die Konkatenation zwischen q₁ und q₂ darstellt. Anschließend wenden wir ein Feedforward-Netzwerk an, das durch den Operator parametrisiert ist."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksdarstellung q₁ dividiert durch q₂."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in fre, in der Praxis, im Inferenzstadium, könnten wir womöglich auch die fehlerhafte fehlerhafte Formulierung erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Da ist die Gesamtzahl aller möglichen Ausdrücke gleich dem dreifachen der Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist also, dass wir problemlos Einschränkungen hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck nicht zulässig ist, können wir ihn einfach aus unserem Suchraum entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Also, im zweiten Schritt machen wir dasselbe, aber der einzige Unterschied besteht darin, dass wir eine weitere Größe haben. So."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Die Größe ergibt sich aus dem zuvor berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Da können wir also abschließend diesen letzten Ausdruck q anfügen."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "times Q4. und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich von dem vorherigen Schritt unterscheidet."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Da macht es schwierig, Beam Search anzuwenden, weil die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgeglichen ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Da ist das Trainingsverfahren dem Training eines Sequenz-zu-Sequenz-Modells ähnlich, wobei wir den Verlust in jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch dieses τ, um darzustellen, wann wir diesen Generationsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier unterscheidet sich der Raum von Sequenz zu Sequenz, da der Raum zu jedem Zeitpunkt unterschiedlich ist, während er in traditionellen Sequenz-zu-Sequenz-Modellen die Anzahl des Vokabulars darstellt."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht auch, bestimmte Beschränkungen aufgrund von Vorwissen zu erzwingen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Daher führen wir Experimente am gängigen Method-Problem-Datensatz MAWPS, Metth3K, MathQA und Swam durch."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier werden kurz die Ergebnisse im Vergleich zu den bisher besten Ansätzen dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Also, unser leistungsstärkstes Werkzeug ist Roberta’s deduktive Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir die Strahlensuche nicht, im Gegensatz zu offensichtlichen Ansätzen, die die Strahlensuche verwenden."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Gut, also sind die besten Ansätze oft ein baumartiges Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ist unser Reasoning-Algorithmus in der Lage, dieses baumbasierte Modell deutlich zu übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können feststellen, dass die absoluten Zahlen in MathQA oder SwAM nicht besonders hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Verweisen Sie auf die Untersuchungsergebnisse bezüglich"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "und dieser Datensatz ist herausfordernd, da der Autor versucht hat, manuell etwas hinzuzufügen, um das NMLB-Modell zu verwirren, beispielsweise durch das Hinzufügen von Umweltinformationen und zusätzlichen Größen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Folglich stellen wir in unserer Vorhersage fest, dass einige der Zwischenwerte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "In diesen Fragen fragen wir, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben zusätzliche Informationen, wie beispielsweise siebzehn Feldwürfe, und Stephen hat acht Würfe, was vollkommen relevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Also, unser Modell trifft Vorhersagen dieser Art, die negative Werte erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Also können wir diesen Suchraum tatsächlich einschränken, indem wir beispielsweise Ergebnisse entfernen, die als Negativkennzeichen fungieren, um so die – äh – die korrekte Antwort zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Da stellen wir fest, dass diese Beschränkung tatsächlich die Leistung einiger Modelle deutlich verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Als Beispiel für Vögel haben wir eine Verbesserung um sieben Punkte erzielt, und für das robota-basierte Modell tatsächlich um zwei Punkte."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Da verfügt ein besseres Sprachmodell über bessere sprachverständliche Fähigkeiten, sodass die hier angegebene Zahl für Roberta höher und für BERT niedriger ausfällt."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen ebenfalls, die Schwierigkeit hinter diesem BP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Menge hier als relevante Information betrachtet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Also, hier können wir sehen, dass wir die Masse, den Prozentsatz der Stichproben, die ungewöhnlichen Mengen haben, und der swaMP-Datensatz hat den größten Anteil."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtperformance."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "für diese Proben ohne nicht verbrauchte Mengen, sodass die Gesamtleistung tatsächlich höher ist als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber mit diesen Proben, bei denen eine ungenutzte Menge vorhanden ist, ist es tatsächlich viel schlechter als viel schlechter."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Bei MAWPS haben wir nicht wirklich viele Todesfälle, daher ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Somit wollen wir abschließend die Interpretierbarkeit anhand eines Beispiels für einen Absturz und einer Präsentation demonstrieren."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier macht unser Modell also tatsächlich eine fehlerhafte Vorhersage bereits im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Also können wir diesen Ausdruck tatsächlich mit diesem Satz hier in Beziehung setzen, einverstanden."}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Daher vermuten wir, dass dieser Satz das Modell möglicherweise in die Irre führt und zu einer falschen Vorhersage veranlasst."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Hier bewirkt das erneute Drucken von fünfunddreißig Elementen, dass das Modell die Auffassung entwickelt, es solle sich um Additionsoperatoren handeln."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Also, wir versuchen, den Satz so umzuformulieren, dass er etwa lautet: Die Anzahl der Birnbäume ist fünf weniger als die Anzahl der Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Da bemühen wir uns, genauere Semantik zu vermitteln, sodass das Modell die korrekte Vorhersage treffen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Da zeigt diese Studie, wie interpretierbare Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit also abzuschließen, ist unser Modell zunächst einmal tatsächlich recht effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsverfahrensweise bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können problemlos einige Vorwissen als Nebenbedingung einbeziehen, was die Leistungsfähigkeit verbessern kann."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das letzte ist, dass der zugrundeliegende Mechanismus nicht nur auf Netzwerkproblemlösungsaufgaben, sondern auch auf andere Aufgaben angewendet werden kann, die mehrstufiges Schlussfolgern erfordern."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch gewisse Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten, bzw. Konstanten haben, könnte der Speicherverbrauch recht hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das zweite Problem besteht darin, dass, wie bereits erwähnt, die Wahrscheinlichkeitsverteilung über verschiedene Zeitpunkte hinweg unausgeglichen ist, was die Anwendung von Beam Searches ebenfalls sehr erschwert."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "So, damit endet der Vortrag, und Fragen sind willkommen.\nVielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine Arbeit mit John und Jerry vorstellen, welche sich mit einem neuen Datensatz für die Recherche nach Gesetzesartikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtliche Fragen sind ein integraler Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Doch verfügen die meisten Bürgerinnen und Bürger über wenig bis gar kein Wissen über ihre Rechte und grundlegende Rechtsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind viele schutzbedürftige Bürger, die sich den kostenpflichtigen Beistand eines Rechtsexperten nicht leisten können, ungeschützt oder sogar ausgebeutet."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Alle Arbeit zielt darauf ab, die Kluft zwischen Menschen und Recht zu überbrücken, indem ein effektives Retrieval-System für Gesetzestexte entwickelt wird."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtsberatungsservice für ungelernte Menschen bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns der Hauptleistung dieser Arbeit zuwenden, wollen wir zunächst das Problem der Retrieval von Gesetzestexten beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts einer einfachen Frage zu Allelthemen, wie beispielsweise welchem Risiko ich mich aussetze, wenn ich die berufliche Schweigepflicht verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Bestimmungen aus einem umfangreichen Rechtskorpus abzurufen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsbeschaffungsaufgabe ist mit eigenen Herausforderungen verbunden."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst befasst es sich mit zwei Spracharten."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Gebräuchliche Alltagssprache für die Fragen und komplexe, juristische Fachsprache für die Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in der Sprachverteilung erschweren es einem System, relevante Kandidaten abzurufen, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine juristische Frage übersetzen kann, welche der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Neben dem Gesetzestatut handelt es sich nicht um einen Stapel unabhängiger Artikel, die für sich allein als vollständige Informationsquelle behandelt werden können, wie beispielsweise Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine Sammlung von Rechtsvorschriften, die erst in ihrer Gesamtheit einen Sinn ergeben, wenn sie im Gesamtkontext betrachtet werden. Dieser Kontext umfasst die ergänzenden Informationen aus benachbarten Artikeln, die zugehörigen Rechtsgebiete und Untergebiete sowie ihre Position innerhalb der Rechtsstruktur."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt sind die gesetzlichen Bestimmungen in kleinen Absätzen formuliert, welche in der Regel die typische Retrieval-Einheit in den meisten Retrieval-Arbeiten darstellen."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hierbei handelt es sich um lange Dokumente, die bis zu sechs Seiten umfassen können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben großes Interesse an vielen juristischen Aufgaben geweckt, wie beispielsweise der Vorhersage von Rechtsentscheidungen oder der automatisierten Prüfung von Kontaktverträgen."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Doch ist die juristische Artikelrecherche hauptsächlich auf manuelles Durchsuchen beschränkt geblieben, bedingt durch den Mangel an großen, hochwertigen, annotierten Datensätzen."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir einen neuen, französischen, bürgerzentrierten Datensatz, um zu untersuchen, ob ein Retrieval-Modell die Effizienz und Zuverlässigkeit eines Rechtsexperten bei der Suche nach Gesetzesartikeln annähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Der belgische Datensatz zur Gewinnung von Rechtsstatuten umfasst mehr als 1100"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen ein breites Themenspektrum, von Familie, Wohnen, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen unter Bezugnahme auf relevante Artikel aus einem Korpus von mehr als fünfundzwanzigtausendsechshundert bezeichnet."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Rechtsvorschriften. Lassen Sie uns nun darüber sprechen, wie wir diese Datensätze erhoben haben."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst begannen wir damit, einen umfangreichen Korpus von Lile-Artikeln zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysierten dreiundzwanzig öffentlich zugängliche belgische Normen und extrahierten sämtliche Artikel sowie die jeweiligen Abschnittsüberschriften."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann erfassten wir juristische Fragen mit Verweisen auf einschlägige Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jährlich rund viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einem persönlichen Rechtsstreit bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, wo ihr Team erfahrener Juristen die häufigsten rechtlichen Fragen in Belgien behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir sammelten Tausende von Fragen, die mit Kategorien, Unterkategorien und Rechtsverweisen auf einschlägige Gesetze versehen sind."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Zuletzt überprüften wir die rechtlichen Verweise und filterten Fragen heraus, deren Verweise keine Artikel in einem der von uns berücksichtigten Gesetzestexte waren."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Referenzen wurden abgeglichen und in die entsprechenden Artikel-IDs von allCopus umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit eintausendachteinundachtzig Fragen, die jeweils sorgfältig mit den IDs der relevanten Artikel versehen waren."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist jede Frage mit einer Hauptkategorie und einer Verkettung von Unterkategorien versehen."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel wird mit einer Verkettung ihrer nachfolgenden Überschriften in der Struktur des Gesetzes versehen."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten aber für zukünftige Forschung im Bereich der juristischen Informationsbeschaffung oder der Klassifikation juristischer Texte von Interesse sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir einige Eigenschaften unseres Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen fünf und vierundvierzig Wörtern lang, wobei die Medianlänge vierzig Wörter beträgt."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind deutlich länger, mit einer Medianlänge von 77 Wörtern und 140 Zeichen."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "von denen über eintausend sind."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Fragestellung ein breites Themenspektrum, wobei etwa achtzigfünf Prozent der Fragen sich entweder auf Familie, Wohnen, Geld oder Recht bezogen."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Die restlichen fünfzehn Prozent betreffen entweder die Sozialversicherung, Ausländer oder die Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind ebenfalls sehr vielfältig, da sie aus 32 verschiedenen belgischen Gesetzestexten stammen, die eine große Anzahl juristischer Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der aus diesen belgischen Gesetzestexten zusammengetragenen Artikel."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den 22.633 Artikeln wurden lediglich 1612 als für mindestens einen relevant erachtet."}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "eine Frage im Datensatz. Und etwa 80 Prozent dieser zitierten Artikel stammen entweder aus dem Bürgerlichen Gesetzbuch, den Richterrechtsprotokollen, dem Strafprozessordnung oder dem Strafgesetzbuch."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen haben achtzehn von dreißigzwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage gelten."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Was darauf zurückzuführen ist, dass dieser Code weniger auf Individuen und deren Anliegen fokussiert."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt liegt die Mediananzahl der Zitationen für diese zitierten Artikel bei 2, und weniger als 2 Prozent davon sind es."}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Unter Verwendung unserer Datensätze bewerten wir verschiedene Retrieval-Ansätze, darunter lexikalische und dichte Architekturen."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts einer Anfrage in einem Artikel weist ein lexikalisches Modell dem Anfrage-Artikel-Paar einen Wert zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Anfrage-Terme berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TF-FIidf- und BMmtwenty-five-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen besteht darin, dass sie nur Artikel abrufen können, die Schlüsselwörter enthalten, die in der Anfrage vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Suchanfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Ecoder-Modell, das Anfragen und Artikel in dichte Vektordarstellungen abbildet und einen Relevanzwert zwischen einem Anfrage-Artikel-Paar anhand der Ähnlichkeit ihrer Einbettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen resultieren typischerweise aus einer Pooling-Operation auf der Ausgabe eines Wortvektormodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Effektivität von Siamesebian-Encodern in einer Zero-Shot-Evaluierungsumgebung, das heißt, vortrainierte Word-Embedding-Modelle werden ohne zusätzliche Feinabstimmung direkt angewendet."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Textkodierern, nämlich Word2Vec und FastText, sowie mit kontextabhängigen Einbettungsmodellen, nämlich Roberta und insbesondere Camembert, welches ein französisches RoBERTa-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus trainieren wir ein eigenes, auf Camem Bird basierendes Modell, das über reine Codierfähigkeiten hinausgeht."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "In allen Datensätzen ist anzumerken, dass wir für das Training mit den zwei Varianten der Biancoda-Architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Anfrage und den Artikel in einem gemeinsamen, dichten Vektorraum abbildet, und Tuto, das zwei unabhängige Word-Embedding-Modelle nutzt, die die Anfrage und den Artikel getrennt in unterschiedliche Einbettungsräume kodieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mittelwert-, Maximal- und CLS-Pooling sowie mit Dot Product und Kosinus für die Berechnung von Ähnlichkeiten."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse einer Baseline auf dem Testdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden wurden die siamesischen Biancoder im Zentrum in einer Zero-Shot-Konfiguration evaluiert, und die feinabgestimmten Biancoder sind unten dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die feinabgestimmten B-Encoder alle anderen Basslinien signifikant."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two-Tower-Modell verbessert sich im Vergleich zur Siamese-Variante bei der Recall-Metrik bei Hundert, zeigt aber eine ähnliche Leistung bei den Allometrien."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl bm twenty five die Trainingsleistung jenseits von Ku signifikant unterbot, deuten seine Ergebnisse darauf hin, dass es weiterhin eine starke Basislinie für domänenspezifische Retrieval-Aufgaben darstellt."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Null-Schuss-Evaluation von Siamesebiancoder stellen wir fest, dass die direkte Verwendung der Einbettungen eines vortrainierten Cammbertt-Modells, ohne diese für die Informationsbeschaffungsaufgabe zu optimieren, zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellen wir fest, dass der word-to-vec bird-basedbiancoder die Modelle fastex und bird-based signifikant übertraf, was darauf hindeutet, dass möglicherweise vortrainierte wortbezogene Einbettungen für diese Aufgabe besser geeignet sind als zeichenbasierte oder subwortbasierte Einbettungen, wenn sie direkt angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Ob vielversprechend, deuten diese Ergebnisse auf reichlich Verbesserungspotenzial im Vergleich zu einem kompetenten Experten hin, der letztendlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Ergebnisse erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Schließen wir ab, indem wir zwei Einschränkungen aller Datensätze diskutieren."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf diejenigen beschränkt, die aus den dreißig-zwei betrachteten belgischen Gesetzestexten entnommen wurden, was nicht die gesamte belgische Gesetzgebung abdeckt, da Artikel aus Erlassen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Verweise auf diese nicht erfassten Artikel ignoriert, was dazu führt, dass einige Suchanfragen nur noch einen Bruchteil der ursprünglichen Anzahl relevanter Artikel liefern."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust impliziert, dass die in den verbleibenden relevanten Artikeln enthaltene Antwort unvollständig sein könnte, obwohl sie dennoch vollkommen angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir festhalten, dass nicht alle Rechtsfragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: „Darf ich meine Mieter kündigen, wenn sie zu viel Lärm verursachen?“"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Es könnte in der Gesetzgebung keine detaillierte Antwort geben, die einen spezifischen Lärmpegel festlegt, ab dem eine Räumung wahrscheinlich ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter sich wahrscheinlich stärker auf die Rechtsprechung stützen und Präzedenzfälle finden, die seiner aktuellen Situation ähneln."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Der Mieter gibt zwei Partys pro Woche, bis zwei Uhr morgens."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser für die gesetzliche Artikelsuche geeignet als andere, und der Bereich der weniger geeigneten muss noch ermittelt werden."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass die gesamte Arbeit Interesse weckt an der Entwicklung von praktikablen und zuverlässigen Modellen zur Gewinnung von Gesetzesartikeln."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz insgesamt zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unser Paper einsehen, das die folgenden Links enthält. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Sehr geehrte Damen und Herren,\n\nwir freuen uns, Ihnen unsere Arbeit zu VoAOS vorzustellen, einem aufgabenunabhängigen Benchmark, der dazu dient, Vision- und Sprachmodelle anhand spezifischer linguistischer Phänomene zu testen."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark einzurichten?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Nun haben wir in den letzten Jahren einen explosionsartigen Anstieg von visionären und sprachbasierten Transformer-Modellen erlebt, die auf großen Mengen von Bild-Text-Paaren vortrainiert wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle verbessert den aktuellen Stand der Technik bei Aufgaben in den Bereichen Vision und Sprache, wie z.B. visuelles Fragenbeantwortung, visuelles Common-Sense-Reasoning, Bildabruf und Phrasenlokalisierung."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Also, wir haben eine Meldung erhalten. Die Genauigkeit bei diesen aufgabenspezifischen Benchmarks steigt stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was genau verstand ein Vision- und Sprach-Transformer, als er diesem Bild und diesem Satz eine hohe Übereinstimmung zuwies?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und die niedrige Bewertung dafür."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Verzerrungen, wie aus vorangegangener Forschung ersichtlich ist?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt weiter zu beleuchten, schlagen wir einen stärker aufgabenunabhängigen Ansatz vor und führen Vokale ein, die die Sensitivität von Vision- und Sprachmodellen gegenüber spezifischen linguistischen Phänomenen testen, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir fokussieren uns auf Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entität-Koreferenz."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen erfasst haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor für Vision- und Sprachmodelle – ausschließlich auf Nominalphrasen durch Ravi Shekhar und seine Mitarbeiter, und auf das Zählen in unserer früheren Arbeit – angewendet wurde."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Das Foilen bedeutet im Grunde, dass wir die Bildunterschrift nehmen und eine Gegenübersetzung erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrasenänderungen durch, indem wir uns auf sechs spezifische Aspekte konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entität-Kohärenz, wobei jeder Aspekt aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als einen interessanten Weg finden, FOIL-Instanzen zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Im Falle des Aktionsfragments haben wir zwei Instrumente: eines, bei dem das Aktionsverb durch ein anderes ersetzt wird, und eines, bei dem die Aktanten ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Auch das Zählen und die Koreferenz sind Elemente, die mehr als ein Instrument umfassen."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir erzeugen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie jedoch grammatikalisch korrekt und anderweitig valide Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach umzusetzen, da eine alternative Bildunterschrift weniger wahrscheinlich ist als die ursprüngliche Bildunterschrift."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Ob es ausgeschlossen ist, mag sein, statistisch gesehen ist es jedoch weniger wahrscheinlich, dass Pflanzen einen Menschen verletzen als umgekehrt, und große Sprach- und Vision-Modelle könnten dies erkennen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Daher müssen wir Maßnahmen ergreifen, um gültige Folien zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir leistungsstarke Sprachmodelle, um FOIls vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens nutzen wir Natural Language Inference, kurz NLI, um Dateien herauszufiltern, die möglicherweise noch das Bild beschreiben, da wir bei der Erstellung von Dateien gewährleisten müssen, dass diese keine Beschreibung des Bildes enthalten."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisiert zu testen, wenden wir Natural Language Inference mit folgender Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Bildunterschrift als die daraus resultierende Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus betrachten wir die Bildunterschrift als Prämisse und das Gegenstück als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass das FOIL dem Titel widerspricht oder neutral gegenüber dem Titel ist, betrachten wir dies als Indikator für ein gültiges FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn eine NLI vorhersagt, dass das Ablenkerelement durch die Bildunterschrift impliziert wird, kann es kein gutes Ablenkerelement sein, da es durch Transitivität eine wahre Beschreibung des Bildes liefern würde und wir diese Ablenkerelemente herausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Doch dieses Verfahren ist nicht perfekt. Es ist lediglich ein Indikator für gültige FOI."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Erzeugung valider FOILs menschliche Annotatoren ein, um die in Vse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Folglich haben wir, nach der Filterung und der menschlichen Bewertung, so viele Testinstanzen wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Valse liefert keine Trainingsdaten, sondern ausschließlich Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "da es sich lediglich um einen Zero-Shot-Test-Benchmark handelt, ist er dazu konzipiert, die vorhandenen Fähigkeiten von Vision- und Sprachmodellen nach dem Vortraining zu nutzen."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmung würde Modelle lediglich befähigen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir wissen alle, dass diese Modelle dazu neigen zu schummeln und Abkürzungen zu nehmen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und, wie bereits erwähnt, sind wir daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach dem Vortraining besitzen."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen für Vokale, nämlich CCL, Alex Mert, Wilbert, Wilbert 11 in 1 und Visual bird."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Evaluationsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren in Bildunterschriften und FOIs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Für dieses Video vielleicht relevanter ist, dass wir unsere großzügigere Metrik, die paarweise Genauigkeit (pairwise accuracy), vorstellen werden, die misst, ob der Übereinstimmungs-Score von Bild und Satz für das korrekte Bild-Text-Paar höher ist als für sein „gefälschtes“ Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Metriken und Ergebnisse dazu empfiehlt es sich, unser Paper einzusehen."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse bezüglich der paarweisen Genauigkeit werden hier dargestellt und stimmen mit den Ergebnissen überein, die wir anhand anderer Metriken erzielt haben. Es zeigt sich, dass die beste Zero-Shot-Performance durch Wilbert 12 in 1 erreicht wird, gefolgt von Wilbert, Alex Mert Clip und schließlich Visual Bir."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Bemerkenswert ist, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nominalphrasen konzentrieren, fast vollständig durch Wilbert 12-in-1 gelöst sind, was darauf hindeutet, dass Modelle in der Lage sind, benannte Objekte und deren Vorhandensein in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können keine der verbleibenden Aufgaben zuverlässig in unseren adversarialen Umgebungen gelöst werden."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen aus der Vielfalt und den Zählwerkzeugen, dass Vision- und Sprachmodelle Schwierigkeiten haben, Referenzen auf einzelne versus mehrfache Objekte zu unterscheiden oder diese in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Relationsteilnahme zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Relation zwischen Objekten in einem Bild korrekt zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Beteiligten zu identifizieren, selbst wenn sie durch Plausibilitätsheuristiken unterstützt werden, wie wir im Handlungsabschnitt sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Konferenzbeitrag geht hervor, dass auch für Vision- und Sprachmodelle die Verfolgung mehrerer Bezüge auf dasselbe Objekt in einem Bild mithilfe von Pronomen schwierig ist."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als einen Sanitätscheck und weil es ein interessantes Experiment ist, haben wir auch zwei textbasierte Modelle, GPT eins und GPT zwei, verglichen, um zu untersuchen, ob Valse mithilfe dieser unimodalen Modelle lösbar ist. Dies geschieht durch Berechnung der Perplexität der korrekten und der vereitelten Bildunterschrift (kein Bild vorhanden) und Vorhersage des Eintrags mit der niedrigsten Perplexität."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Perplexität für die Testbeispiele höher ist, interpretieren wir dies als Hinweis darauf, dass die manipulierten Bildbeschreibungen unter Plausibilitätsverzerrungen oder anderen sprachlichen Verzerrungen leiden könnten."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen reine Text-GPT-Modelle die Plausibilität der Welt besser erfasst haben als Modelle, die sowohl Vision als auch Sprache verarbeiten."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VAL ein Benchmark ist, der die Linse linguistischer Konstrukte nutzt, um die Community bei der Verbesserung von Vision- und Sprachmodellen zu unterstützen, indem er deren visuelle Grounding-Fähigkeiten auf harte Probe stellt."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Vision- und Sprachmodelle benannte Objekte in Bildern, in denen sie vorhanden sind, gut identifizieren, wie die Existenzdemonstration belegt, jedoch Schwierigkeiten haben, ihre Interdependenzen und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Hinweise zu berücksichtigen."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir würden die Community sehr gerne dazu ermutigen, ValAs zur Messung des Fortschritts bei der sprachlichen Verankerung mit Vision- und Sprachmodellen zu nutzen."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, Ventile könnten als eine indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder Feintuning evaluiert werden könnten, um zu prüfen, ob ein Datensatz dazu beiträgt, dass Modelle in Bezug auf Aspekte, die mit Ventilen getestet werden, verbessert werden."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, werfen Sie gerne einen Blick auf die WALLSSE-Daten auf GitHub. Und falls Sie Fragen haben, zögern Sie bitte nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kaisura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Beitrag mit dem Titel \"O En sum: Eine groß angelegte Wüste zur automatischen Re-Notationskomprimierung\" vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Haben Sie Erfahrung damit?"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Listen-Nicht-Dauer vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notiz ist ein technisches Dokument, das die mit jeder Veröffentlichung eines Softwareprodukts vorgenommenen Änderungen zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt das Handgelenkprotokoll für Version 2.6."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "JavaScript-Bibliothek. Diese Notizen spielen eine wichtige Rolle in der Open-Source-Entwicklung, sind jedoch zeitaufwendig in der manuellen Erstellung."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Da wäre es daher äußerst nützlich, Release Notes von hoher Qualität automatisch generieren zu können."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mich auf zwei vorhergehende Forschungsarbeiten zur automatischen Erstellung von Hörinhalten beziehen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens a. Es wurde 2014 veröffentlicht."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "verwendet einen regelbasierten Ansatz, beispielsweise die Verwendung eines Change Extractors, um anhand der Unterschiede zwischen Releases Kernunterschiede, Bibliotheksänderungen und Dokumentenänderungen zu extrahieren und diese abschließend zu kombinieren."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist das Extraktionsmodul in der oberen rechten Ecke."}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "was mit Jira, dem Issues-Ökosystem, verknüpft sein muss und nur auf Projekte angewendet werden kann, die Jira verwenden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten lässt es sich für viele Projekte auf GitHub nicht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite betrifft die kürzlich in zwanzig"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Zwanzig.\n\nEs ist im Internet verfügbar und kann über peep gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, laufzeitbasiertes Textklassifikationsmodell und gibt eine Form von fünf Parametern aus, wie beispielsweise Features oder Fehlerbehebungen für jede eingegebene Commit-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist eine Beispielanwendung, die eine korrigierte oder behobene cerable-Datei zurückgibt."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Quifers Trainingsdatensatz ist relativ klein, etwa fünftausend Elemente, und wird in den im Folgenden beschriebenen Experimenten verwendet."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifikationsmodells ist nicht hoch."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich stelle zwei verwandte Forschungsarbeiten vor, jedoch bestehen Einschränkungen hinsichtlich der eingeschränkten Anwendbarkeit und der knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit löst diese beiden Probleme und generiert automatisch hochwertige Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Mit einem begrenzten ACO-Programm schlagen wir eine hochqualitative Klassifizierungsmethodik vor, die lediglich die Commit-Nachricht als Eingabe verwendet."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Buchbibliographieeinträge verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem knapper Ressourcen haben wir unseren Datensatz und einige weitere Daten erstellt, bestehend aus etwa achtzigtausend Dateneinheiten, indem wir Daten aus öffentlichen GitHub-Repositories unter Verwendung der GitHub API korrigierten."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich unsere Wüste."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist eine Commit-Nachricht, auf der rechten Seite befindet sich eine Notiz."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notizen werden als Verbesserungen von Büros usw. betrachtet."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe nimmt und die Rabbit-Node ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als eine Zusammenfassungaufgabe betrachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Kategorien vordefiniert: Neuerungen, Verbesserungen, Fehlerbehebungen, Veraltungen, Entfernung und Änderungen der Bremsfunktion."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden auf Grundlage der Schweineausnutzung und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Es befinden sich Notizen unten rechts, die aus der Notizenliste extrahiert wurden, die unten links angezeigt wird."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Es ist derzeit erforderlich, die vier Hasen zu erfassen, die in einer Passage platziert wurden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Laser sind nicht immer mit jedem Chip konsistent."}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Solche Verbesserungen fördern eher weitere Verbesserungen, Erweiterungen, Optimierungen und dergleichen."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir erstellten für jede dieser notationalen Variationen einen Wortschatz von etwa dreißig Zahlen."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Nutzen Sie es, um festzustellen, ob Krusten fehlen, und zitieren Sie den Rest des Textes, der folgt, falls keine Sätze oder Krusten vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt ein Commit-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Comer-Nachrichten sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der folgenden Abbildung dargestellt, müssen wir identifizieren, wenn das aktuelle Risiko größer als 2,5 bis 19 ist."}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Durch die vorherigen Aufgabenversion zwei Punkt fünf bis achtzehn, und es richtig verfestigen. Das ist etwas mühsam, und es reicht nicht aus, sich einfach eine Liste der Veröffentlichungen anzusehen und die Zustände vor und nach dem Update zu betrachten."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir entwickelten einen heuristischen Abgleich, um die vorherige und nächste Version zu ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Sie sitzen auf der Krankenschwester."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende 7.200 Repositories."}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus beträgt die durchschnittliche Anzahl angemessener Ziele sechzigunddreißig, was für Summationstätigkeiten recht hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Ebenso ist die Anzahl der eindeutigen Token mit achtundachtzigtausend dreihundert sehr hoch. Dies ist"}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "der großen Anzahl unterschiedlicher Methodenbezeichnungen, die im Labor gefunden wurden."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Im Folgenden werde ich die vorgeschlagene Methode erläutern."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das querverlaufende extraktive und abstrakte Summarisierungsmodell besteht aus zwei neuronalen Modulen."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Kreuzfeuer unter Verwendung einer Stange oder genauer gesagt einer Stange, und ein Generator unter Verwendung von Bart."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst verwendet cs einen Klassifikator, um jede Commit-Nachricht in fünf Basisklassen von Knoten zu klassifizieren: Features, Implementierungen, Fehlerbehebungen, Deprecations sowie Sonstiges."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausschussmitteilungen, die als „a“ klassifiziert oder verworfen wurden."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird sie eine Auszeichnung an die vier Gummidokumente unabhängig voneinander vergeben und generiert dafür jeweils eine Notiz für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Entsprechungen zwischen Commit-Nachrichten und Resourcen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Daher weisen wir dem Klassifikator zur Schulung des Klassifikators Pseudo-Labels für jede Eingabe-Commit-Nachricht zu, basierend auf den ersten zehn Zeichen jeder Commit-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die querzuführenden destruktiven Summen, um sie mit zwei definierten Methoden anzunähern."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir „gs single“ nennen, besteht aus einem einzelnen sechs-sechs-Netzwerk und generiert einen einzelnen, langen Text – wenn nicht anders angegeben – auf Basis einer Verkettung von eingegebenen Commit-Nachrichten."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der äußere Text kann in quer verlaufende Segmente unterteilt werden, basierend auf speziellen, kreuzungsbezogenen Merkmalen und Symbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir „shes much“ nennen, besteht aus vier verschiedenen Netzwerken von Sek- zu Sek-Netzwerken, von denen jedes einer der wenigsten Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, lassen Sie mich das Experiment erklären."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen. Sie ist, sie eine Sängerin, sie hat gelächelt, drängend, und Bri studierte Trauer."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Aberration tritt dies in manchen Fällen nicht als unsere Ausgabe in mehreren Sätzen auf."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze eines Nullwerts zu korrigieren, werden diese mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Der Output ist kurz, wenn das System einen kurzen Satz ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Dieses geringfügige Absinken des Bre-Wertes im Experiment wird im Folgenden beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich beladen wir auch eine Spezifität, da Rouge und Brew nicht verkörpert werden können, wenn die Handgelenkanmerkungen leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell korrekt leere Textausgaben erzeugt, wenn der gelesene Knoten als leer angenommen wird."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Werte usw. enthält, bewerten wir auch die bereinigten Daten, aus denen diese entfernt wurden."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CAS und CAS erreichten deutlich höhere Ergebnisse im Bereich Luftqualität, um mehr als zehn Punkte über den Basiswerten."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere beim koreanischen Testdatensatz beträgt der Leistungsunterschied zwischen der vorgeschlagenen Methode und dem naiven Ansatz mehr als 20 Punkte."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass „sheas“ und „hes“ signifikant wirksam sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "g hat einen besseren Logik-Score erzielt, was darauf hindeutet, dass die Kombination eines Klassifikators und eines Generators effektiv ist, um den Klassifikator zu trainieren."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Abdeckung von Gs kann effektiv erreicht werden, da der Klassifikator sich darauf konzentrieren kann, für jede Klasse relevante Commit-Nachrichten auszuwählen."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie widmet sich wesentlich der Lektüre anspruchsvoller Literatur als einem einzelnen Werk."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Sugg, das es ebenfalls effektiv sein kann, für jede Piece-Node-Graph-Struktur eigenständig unterschiedliche perceptive Summarizationsmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hier und Araasis."}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Shear's Methoden erzeugen tendenziell kürzere Sätze als Referenzsätze, die von Menschen verfasst wurden."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts besteht der unterschiedliche Satz entweder aus drei oder vier Sätzen, während sie nur einen hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese moderne Zurückhaltung liegt darin, dass in den Trainingsdaten lediglich dreißig-drei Prozent der Sätze auf Merkmaleebene und vierzig Prozent in den Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CS-Methoden keine genauen Risikon Knoten ohne zusätzliche Informationen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr unübersichtliche Kommunikationsmeldung, und der vollständige Satz kann nicht generiert werden, ohne sich auf die entsprechende Berechtigung oder das entsprechende Problem zu beziehen."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe in Zusammenhang stehen und in einen einzigen Satz zusammengefasst werden sollten, dies jedoch nicht geschieht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Geschäftserstellung aufgebaut."}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe formuliert, die Mitteilungen der Ausschüsse zu erfassen und zusammenzufassen, sodass sie für alle auf Englisch verfassten Projekte anwendbar sind."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass der vorgeschlagene Muskelstrom bei höherer Abdeckung nicht weniger Rauschen aufweist als der Referenzstrom."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Pri Check Gott oder Wüste oben."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Safari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich präsentiere unseren Beitrag zum Thema „Anreicherung tabellarischer Daten durch Feinabstimmung von Transformer-Architekturen“."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Analysiert ein Wissenschaftler Daten und konzentriert er sich hauptsächlich auf die Manipulation bestehender Eigenschaften der Daten?"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Eigenschaften begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Feature-Generierung unter Verwendung einer anderen Datenquelle kann erhebliche Informationen hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung tabellarischer Daten mithilfe von freiem Text aus externen Quellen."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben einen tabellarischen Datensatz und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatisierten Prozess, der die Verknüpfung und Textanalyse beinhaltet, um aus den freien Texten der Wissensdatenbank neue Merkmale zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework ist zunächst einmal genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir also an, ein Beispiel in den fest eingegebenen Daten."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz der Hochschuldatensatz."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "und sein Ziel ist es, Universitäten in Universitäten mit niedrigem Rang und Universitäten mit hohem Rang einzuteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätserkennung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Entität in diesem Beispiel, der Name der Universität, mit einer Entität innerhalb der Wissensdatenbank verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Und der Text der Entitäten aus der Wissensdatenbank wird extrahiert und dem Datensatz hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Please provide the English text you want me to translate. I am ready to translate it into German according to your specifications."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Nun müssen wir Merkmale aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Da benötigen wir also eine Phase der Feature-Extraktion, die eine Textanalyse umfasst."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist die Hauptneuheit dieses Papiers, und ich werde in den nächsten Folien detailliert darauf eingehen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Feature-Extraktionsphase folgt eine Feature-Generierungsphase, in der wir die extrahierten Features verwenden, um eine geringe Anzahl neuer Features zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werden Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes generiert."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel besitzt der ursprüngliche Datensatz zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Generieren Sie zunächst zwei neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Aber, wenn der Datensatz fünf Klassen hat, generieren Sie zunächst fünf neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jedes Merkmal repräsentiert die Wahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Zur Analyse des Textes verwenden wir den aktuellen Stand der Out-of-Text-Analyse, welche transformatorbasierte Sprachmodelle wie Ba GPT-x und LEDS sowie andere Modelle sind."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "aber es ist unwahrscheinlich, dass wir Sprachmodelle mit den vorliegenden Datensätzen trainieren können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Daher stellt ein naiver Ansatz eine Feinabstimmung für eine Zielaufgabe dar."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Folglich können wir in der Phase der Merkmalsextraktion ein vortrainiertes Sprachmodell herunterladen und dieses anschließend anhand des Ziel-Datensatzes feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel werden wir das Sprachmodell verfeinern, um Text in Kategorien zu klassifizieren, nämlich in Kategorien mit niedriger oder hoher Abstraktion."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabewerte des Sprachmodells, welche die Wahrscheinlichkeit für jede Klasse darstellen, und verwenden Sie diese als neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem mit diesem Ansatz besteht darin, dass der Datensatz nur wenige unterschiedliche Entitäten in den Texten aufweisen kann."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielt fast die Hälfte des Datensatzes weniger als 400 Samples, und der kleinste Datensatz umfasste im anfänglichen Trainingsdatensatz lediglich 35 Samples."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Da wird die Feinabstimmung eines Sprachmodells anhand dieses Datensatzes also unwirksam sein."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können Vorwissen über vorab analysierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir schnell auf ein mehrfaches Datenset anwenden, können wir das N minus 1 Datenset nutzen, um Informationen über das N minus 1 Datenset zu gewinnen und diese Informationen bei der Analyse des NNS-Datensets verwenden."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist, eine weitere Feinabstimmungsphase hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige, mehrstufige Feinabstimmungsphase."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie feststellen, dass das Trainieren des Sprachmodells auf einem Datensatz mit n minus eins Elementen,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmungsphase durch, welche eine zielgerichtete Feinabstimmung darstellt, bei der wir das Sprachmodell anhand des jeweiligen Ziel-Datensatzes weiter verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der aktuelle Stand der Technik beim Multitask-Feintuning, bezeichnet als tdNN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In leeren dNNs wird eine Anzahl von Köpfen aufrechterhalten, die der Anzahl der Aufgaben im Trainingsdatensatz entspricht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Also, wenn in diesem Beispiel vier Aufgaben im Trainingsdatensatz vorhanden sind, also ein leeres DNN und vier Köpfe beibehalten werden, wie man auf dem Bild sehen kann."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es wählt zufällig ein Badge aus dem Trainingsdatensatz aus."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und gehört der Lauf einer Batch beispielsweise zu Sin und Selten’s Klassifikationsaufgaben, führt er einen Forward- und Backward-Pass durch den ersten Head durch."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zur paarweisen Rangordnung gehört, besteht die Aufgabe darin, eine Vorwärts- und Rückwärts-Iteration durch den letzten Head durchzuführen."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario variieren Datensätze mit Tableau in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Da gibt es also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "tDNN behält die Anzahl der Klassen, Köpfe und Ausgabeschichten."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich müssen leere DNA-Sequenzen anfänglich neue Header für einen neuen Datensatz mit einer neuen Aufgabe hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, genannt Task Reformulation Fine-Tuning, besteht darin, anstelle mehrerer Köpfe jedes Datenset in einen Satz pro Klassifikationsproblem umzuformulieren, was Aufgaben mit zwei Klassen beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns also ein Beispiel an."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Eingabedatensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir reformulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zur Klassifizierung des Textes, des Abstracts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten trainieren wir das Sprachmodell dahingehend, abstrakte und Klassenabstraktionen zu klassifizieren, um festzustellen, ob die Abstraktion zur Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Labelvektor in z's Fall bleibt also immer gleich und besteht immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist der Algorithmus für unseren feinkörnigen oder formulierten Feinabstimmungsansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Also, betrachten wir nun den vollständigen Rahmen."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "ein Datensatz, der in schnellen Betrieb versetzt wird"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann ein schneller Übergang in die Linkphase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensdatenbank, welche in diesem Beispiel der Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann reformulierte es die Aufgabe in jeweils ein Paarsatz pro Klassifikationsaufgabe."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Das Sprachmodell auf die neue Aufgabe angewendet und die Output-Wahrscheinlichkeit für jede Klasse ermittelt."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über einen Datensatz mit n minus eins Instanzen mithilfe einer vorläufigen multivariaten Feinabstimmung optimiert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verwenden wir den Ausgabvektor des Sprachmodells als ein neu generiertes Merkmal für die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zur Evaluierung unseres Frameworks verwenden wir einen siebenteiligen tabellarischen Klassifikationsdatensatz, der Größe, Merkmale, Balance, Domäne und anfängliche Leistung definiert."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Wissensabfall bedienen wir uns Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir gestalten unser Experiment als Leave-one-out-Evaluierung, wobei wir anhand von sechzehn Datensätzen schnell trainieren und diese auf den siebzehnten Datensatz anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen jeden Datensatz ebenfalls in einen falschen Teil auf und wenden eine Fork-False-Kreuzvalidierung an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend generieren wir das neue Merkmal und evaluieren es mithilfe von fünf Evaluierungsklassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem experimentbasierten, vogel-inspirierten Architekturansatz."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Man kann erkennen, dass wir unser Framework mit dem Finetuning auf dem Ziel-Datensatz, dem Finetuning für die Zielaufgabe und dem vorläufigen Finetuning von tDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unser überarbeitetes Feinabstimmen erzielt das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während dNN eine Verbesserung von zwei Prozent gegenüber der Feinabstimmung auf dem Zieldatensatz erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Pochieren erreichte eine Verbesserung von sechs Prozent."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns das kleine Datenset ansehen, können wir feststellen, dass die Leistung von mtdNN abnimmt und die Verbesserung der vorbereitenden Multitask-Feinabstimmungsphase auf einen Punkt fünf Prozent sinkt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung stieg im Vergleich zum alleinigen Feintuning der Zielaufgabe auf elf Prozent."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Summierung ermöglicht fast eine few-shot-Anreicherung aus fünfunddreißig Samples in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er bewahrt den Kopf des Modells auf."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Umformulierungsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Um das Modelleisenbahn-Setup und dessen Anforderungen zu erweitern, benötigen wir einen Zielwert mit semantischer Bedeutung, den wir anschließend in das Sprachmodell einspeisen und im Rahmen des Klassifizierungsproblems für den Satz verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank."}
