{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, heute werde ich unsere Forschungsarbeit „Learning to Reason Deductively, Metabolic Problem Solving as Complex Region Extraction“ vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan vom ByteDance AI Lab, und dies ist eine gemeinsame Arbeit mit Jerry von der University of Texas at Austin und Weilu vom SUTD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für Schlussfolgerungen sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel, bei dem mehrstufiges Schlussfolgern hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus der Publikation von Pound, in der sie Prompting einsetzen, um das mathematische Problem in einem Few-Shot-Learning-Szenario zu lösen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite sehen wir, dass wir, wenn wir einige Beispiele mit reinen Fragen und Antworten geben, möglicherweise nicht die korrekten Antworten erhalten können."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir eine detailliertere Beschreibung der Argumentation liefern, ist das Modell in der Lage, die Beschreibung der Argumentation vorherzusagen und hierbei auch eine korrekte Vorhersage zu treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Da ist es also gut, interpretierbare, mehrstufige Schlussfolgerungen als Ergebnis zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind auch der Ansicht, dass das Methodenproblem eine unkomplizierte Anwendung darstellt, um solche Denkfähigkeiten zu evaluieren."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier in unserem Problemaufbau, angesichts der Fragestellungen, müssen wir diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck mitgeteilt, der ebenfalls zu dieser speziellen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Auch hier gelten also bestimmte Annahmen, wie bereits in früheren Arbeiten dargelegt."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "wir nehmen an, dass die Genauigkeit der Größen bekannt ist."}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten dabei lediglich grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Potenzierung."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus lassen sich komplexe Operatoren tatsächlich in diese grundlegenden Operatoren zerlegen."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten im Bereich methodischer Problemlösung lassen sich somit in sequenz-zu-sequenz- und sequenz-zu-baum-Modelle einteilen."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Da konvertieren traditionelle Sequenz-zu-Sequenz-Modelle den Ausdruck in eine spezifische Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist relativ einfach zu implementieren, und es kann auf viele verschiedene, komplexe Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Nachteile der Performance sind tatsächlich im Allgemeinen nicht besser als die des strukturierten Modells\nUnd es mangelt an Interpretierbarkeit der Vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber tatsächlich ist diese Richtung aufgrund des Transformer-Modells immer noch recht populär."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumartigen Modellen strukturieren wir diese Ausdrücke also in Baumform und folgen bei der Baumgenerierung einer vorrangigen Traversierung."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir weiterhin die Operatoren, bis wir die Blätter erreichen, welche die Größen darstellen."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute daran ist also, dass es uns tatsächlich diese binärbaumartige Struktur liefert. Es ist jedoch ziemlich kontraproduktiv, weil wir zuerst den Operator generieren und dann am Ende die Mengen."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und das zweite ist, dass es auch einige redundante Berechnungen enthält."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck ansehen, wird 8 mal 3 plus 3 tatsächlich zweimal berechnet. Tatsächlich sollten wir die Ergebnisse aber wiederverwenden."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Daher wollen wir in unserem vorgeschlagenen Ansatz diese Probleme schrittweise und interpretierbar lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Also, beispielsweise können wir hier im zweiten Schritt diesen Teiler erhalten, welcher 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können uns auch auf die ursprünglichen Fragen beziehen, um die relevanten Inhalte zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann, im dritten Schritt, erhalten wir tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Gut, und nach diesen drei Schritten können wir tatsächlich die Ergebnisse aus dem zweiten Schritt nutzen und anschließend die Ergebnisse des vierten Schritts erhalten. Und schließlich können wir die Dividenden ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir das gesamte Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dies macht den Prozess präziser."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Menge von Größen, die in den Fragen präsentiert werden, und beinhalten auch einige Konstanten als unseren Ausgangszustand."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird somit mit EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "wobei wir den Operator von QI nach QJ ausführen, und ein solcher Ausdruck tatsächlich gerichtet ist."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Da haben wir also auch die Subtraktion rückwärts, um die entgegengesetzte Richtung darzustellen."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist Relationsextraktion recht ähnlich."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen deduktiven System wenden wir also zum Zeitpunkt t den Operator auf das Paar qi und qj an und erhalten dann diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "wir fügen es dem nächsten Zustand hinzu, um eine neue Größe zu bilden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folie visualisiert also die Entwicklung des Zustands, bei dem wir kontinuierlich Ausdrücke zum aktuellen Zustand hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vortrainiertes Sprachmodell, beispielsweise BERT oder RoBERTa, und kodieren anschließend einen Satz, um so diese Mengenrepräsentationen zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengenrepräsentationen haben, können wir mit der Inferenz beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Repräsentation für Q1 geteilt durch Q2 und dann multipliziert mit Q4 zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paardarstellung, welche im Wesentlichen eine Konkatenation zwischen Q1 und Q2 darstellt. Anschließend wenden wir ein Feedforward-Netzwerk an, das durch den Operator parametrisiert ist."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksdarstellung Q1 dividiert durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber tatsächlich, in der Praxis, im Inferenzschritt, können wir möglicherweise auch die fehlerhafte Formulierung erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Da ist also jede mögliche Ausdrukksweise gleich 3-fach der Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir hier problemlos Constraints hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck nicht zulässig ist, können wir ihn einfach aus unserem Suchraum entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Da machen wir also im zweiten Schritt dasselbe, der einzige Unterschied besteht lediglich in einer zusätzlichen Größe."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe ergibt sich aus dem zuvor berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "So können wir schliesslich diesen finalen Ausdruck Q erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "times Q4. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich von dem vorherigen Schritt unterscheidet."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Eine solche Diskrepanz erschwert die Anwendung der Beam Search, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgeglichen ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Da ist das Trainingsverfahren dem Training eines seq2seq-Modells ähnlich, bei dem wir den Verlust in jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir ebenfalls dieses τ, um darzustellen, wann wir diesen Generationsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier unterscheidet sich der Raum von Sequenz zu Sequenz, da sich der Raum in jedem Zeitschritt unterscheidet, während er in traditionellen Sequenz-zu-Sequenz-Modellen die Anzahl des Vokabulars ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht uns auch, bestimmte Beschränkungen aufgrund von Vorwissen zu definieren."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Da führen wir Experimente mit den üblicherweise verwendeten Method-Problem-Datensätzen MAWPS, MAT23K, MATQA und SWAMP durch."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen Batch-Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Da ist unsere leistungsstärkste Variante der Robeta Dictative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "und tatsächlich verwenden wir Beam Search nicht, im Gegensatz zu offensichtlichen Ansätzen, die Beam Search verwenden."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, die besten Ansätze sind also oft baumartige Modelle."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ist unser Reasoner also in der Lage, dieses baumbasierte Modell deutlich zu übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können feststellen, dass die absoluten Zahlen auf Mathqa oder SWAM nicht besonders hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Da untersuchen wir nun weiter die Ergebnisse zu"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Datenset ist jedoch herausfordernd, da der Autor versuchte, manuell Elemente hinzuzufügen, um das NLP-Modell zu verwirren, beispielsweise irrelevante Informationen und zusätzliche Mengenangaben."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Da unsere Vorhersage jedoch einige der Zwischenwerte negativ ausweist,"}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "In diesen Fragen geht es darum, wie viele Äpfel Drake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie zum Beispiel 17 weniger Würfe. Und Steven hat 8 Würfe, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell trifft also Vorhersagen dieser Art, die negative Werte erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "und wir beobachten diese beiden Ausdrücke"}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Da können wir den Suchraum also tatsächlich begrenzen, indem wir negative Ergebnisse entfernen, um sicherzustellen, dass die Antwort korrekt ist."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Da stellen wir fest, dass diese Beschränkung tatsächlich die Leistung einiger Modelle erheblich verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Für Vögel haben wir sieben Punkte verbessert.\nUnd dann haben wir beim Robeta-basierten Modell tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Da verfügt ein besseres Sprachmodell über eine bessere Sprachverständnisfähigkeit, sodass die hier angegebene Zahl für Robita höher und für Bird niedriger ausfällt."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen ebenfalls, die Schwierigkeit dahinter zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "wir können davon ausgehen, dass die Anzahl ungenutzter Mengen hier als irrelevante Information betrachtet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der Stichproben mit ungenutzten Mengen haben, und der SWAMP-Datensatz weist den größten Anteil auf."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen. Somit ist die Gesamtperformance tatsächlich höher als die Gesamtperformance."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen eine ungenutzte Menge vorhanden ist, ist es tatsächlich weitaus schlechter als noch schlechter."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Performance. Bei MAWPS gibt es kaum Festplattenfälle, daher ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Da wollen wir abschließend die Interpretierbarkeit anhand eines Beispiels für einen Absturz und eine Störung demonstrieren."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Da trifft unser Modell also bereits im ersten Schritt eine falsche Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Da können wir diesen Ausdruck also tatsächlich mit dem Satz hier in Beziehung setzen."}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Da wir glauben, dass dieser Satz das Modell möglicherweise zu einer falschen Vorhersage verleiten könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Hier bewirkt das erneute Drucken von 35, dass das Modell einen Additionsoperator erwartet."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Da versuchen wir, den Satz so umzuformulieren, dass er in etwa aussagt: Die Anzahl der Birnbäume ist um 55 geringer als die Anzahl der Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Da stellen wir sicher, dass genauere Semantik vermittelt wird, sodass das Modell die korrekte Vorhersage treffen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt somit, wie interpretierbare Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell zunächst einmal recht effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind in der Lage, eine interpretierbare Lösungsmethode bereitzustellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "und wir können problemlos einige Vorwissen als Einschränkung einbeziehen, was die Leistung verbessern kann."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt ist festzuhalten, dass der zugrundeliegende Mechanismus nicht nur auf Aufgaben zur Kartenarbeit anwendbar ist, sondern auch auf andere Aufgaben, die mehrstufiges Schlussfolgern erfordern."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch gewisse Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir eine große Anzahl von Operatoren oder Konstanten haben, kann der Speicherverbrauch recht hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und der zweite Punkt ist, wie bereits erwähnt, dass aufgrund der unausgeglichenen Wahrscheinlichkeitsverteilung zu unterschiedlichen Zeitpunkten die Anwendung von Beam Search ebenfalls eine erhebliche Herausforderung darstellt."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Damit ist der Vortrag nun beendet, und Fragen sind willkommen.\nVielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Universität Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine gezeichneten Arbeiten gemeinsam mit Jerry vorstellen, die sich mit einem neuen Datensatz für die Recherche nach gesetzlichen Artikeln befassen."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtliche Fragestellungen sind ein integraler Bestandteil vieler Menschenleben."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "aber die Mehrheit der Bürgerinnen und Bürger verfügt über wenig bis gar kein Wissen über ihre Rechte und grundlegende rechtliche Verfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "In der Folge werden viele schutzbedürftige Bürger, die sich den kostenpflichtigen Beistand eines Rechtsanwalts nicht leisten können, ungeschützt oder, schlimmer noch, ausgebeutet."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen Menschen und dem Gesetz zu überbrücken, indem wir effektive Rückrufsysteme für Gesetzesartikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtsbeistandsdienst für ungelernte Personen bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns der Hauptleistung dieser Arbeit zuwenden, wollen wir zunächst das Problem der juristischen Artikelsuche beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, es wird eine einfache Frage zu einer unbedeutenden Angelegenheit gestellt, wie beispielsweise: Was riskiere ich, wenn ich die berufliche Schweigepflicht verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um sämtliche relevante gesetzliche Artikel aus einem umfangreichen Rechtskorpus abzurufen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsbeschaffungsaufgabe ist mit einer eigenen Reihe von Herausforderungen verbunden."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst befasst es sich mit zwei Arten von Sprachen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Gebräuchliche Alltagssprache für die Fragen und komplexe juristische Fachsprache für die Gesetzestexte."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in der Verteilung von Sprachen erschweren es einem System, relevante Kandidaten abzurufen, da dies indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine juristische Frage übersetzen kann, welche der Terminologie der Gesetzestexte entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist Gesetzestext keine Sammlung unabhängiger Artikel, die, im Gegensatz zu Nachrichten oder Rezepten beispielsweise, für sich genommen als vollständige Informationsquelle betrachtet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine strukturierte Sammlung von Rechtsvorschriften, die erst in ihrem Gesamtkontext eine vollständige Bedeutung entfalten, das heißt zusammen mit den ergänzenden Informationen aus ihren benachbarten Artikeln, den Rechtsgebieten und Untergebieten, zu denen sie gehören, sowie ihrem Platz innerhalb der Struktur des Rechts."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Letztendlich sind Gesetzesartikel keine kleinen Absätze, was in der Regel die typische Retrieval-Einheit in den meisten Retrieval-Arbeiten darstellt."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier gibt es umfangreiche Dokumente, die bis zu sechs"}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben ein großes Interesse an zahlreichen juristischen Aufgaben geweckt, wie beispielsweise der Vorhersage von Rechtsentscheidungen oder der automatisierten Vertragsprüfung."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die Recherche anhand von Rechtsgrundlagen ist jedoch aufgrund des Mangels an großen, hochwertigen, gelabelten Datensätzen weitgehend unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir einen neuen, in Frankreich erstellten und bürgerzentrierten Datensatz, um zu untersuchen, ob ein Retrieval-Modell die Effizienz und Zuverlässigkeit eines Rechtsexperten bei der Suche nach Gesetzesartikeln annähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Unser belgischer Datensatz zur Gewinnung von Gesetzesartikeln, PSART, umfasst mehr als 1.100 juristische"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen ein breites Themenspektrum, von Familie, Wohnen, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder einzelne wurde von erfahrenen Juristen unter Bezugnahme auf einschlägige Artikel aus einem Korpus von mehr als 22.600 Fällen bewertet."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Gesetze und Kodizes. Lassen Sie uns nun darüber sprechen, wie wir diese Datensätze erhoben haben."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst begannen wir damit, einen umfangreichen Korpus juristischer Artikel zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir analysierten 32 öffentlich zugängliche belgische Regelwerke und extrahierten sämtliche Artikel sowie die entsprechenden Abschnittsüberschriften."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend erfassten wir juristische Fragestellungen mit Bezug zu einschlägigen Gesetzesbestimmungen."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jährlich etwa 4.000 E-Mails von belgischen Bürgerinnen und Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Fragen in Belgien behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen erfasst, die mit Kategorien, Unterkategorien und juristischen Verweisen auf einschlägige Gesetze versehen sind."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend haben wir die juristischen Verweise analysiert und die Fragen herausgefiltert, deren Verweise keine Artikel in einem der von uns betrachteten Gesetzestexte waren."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Referenzen wurden abgeglichen und in die entsprechenden Artikel-IDs aus Ocorpus umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1108 Fragen, die jeweils sorgfältig mit den IDs der relevanten Artikel aus"}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist jede Frage mit einer Hauptkategorie und einer Verkettung von Unterkategorien versehen."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "und jeder Artikel wird begleitet von einer Verkettung seiner nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten aber für zukünftige Forschung im Bereich der juristischen Informationsbeschaffung oder der juristischen Steuerklassifikation von Interesse sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir einige Eigenschaften unserer Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen 5 und 44 Wörtern lang, mit einem Median von 14 Wörtern."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind deutlich länger, mit einer Medianlänge von 77 Wörtern, bei 142"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "1000 übersteigend."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, decken die Fragen ein breites Themenspektrum ab, wobei etwa 85% davon sich auf Familie, Wohnen, Geld oder Gerechtigkeit beziehen."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "wobei die restlichen 15% entweder die Sozialversicherung, Ausländer oder die Arbeit betreffen."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind zudem sehr vielfältig, da sie aus 32 verschiedenen belgischen Rechtskodizes stammen, die eine große Anzahl juristischer Themenbereiche abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus den belgischen Rechtsvorschriften zusammengetragen wurden."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den 22.633 Artikeln wurden lediglich 1.612 als für mindestens..."}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "Eine Frage in den Datensätzen. Und rund 80 % dieser zitierten Artikel stammen entweder aus dem Bürgerlichen Gesetzbuch, dem Strafprozessordnung, dem Strafgesetzbuch oder anderen Strafgesetzen."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen haben 18 von 32 Codes weniger als 5 Artikel, die im Hinblick auf mindestens eine Frage als relevant erachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Was dadurch erklärt werden kann, dass diese Codes weniger auf Individuen und deren Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt liegt die Mediananzahl der Zitationen für diese zitierten Artikel bei 2, und weniger als 25 % davon sind"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mithilfe unserer Datensätze evaluieren wir verschiedene Retrieval-Ansätze, darunter lexikalische und dichte Architekturen."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts einer Anfrage in einem Artikel weist ein lexikalisches Modell dem Anfrage-Artikel-Paar einen Wert zu, indem es die Summe der Gewichtungen jedes dieser Begriffe in diesem Artikel berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TF-IDF- und BM25-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen besteht darin, dass sie nur Artikel abrufen können, die Schlüsselwörter enthalten, die in der Anfrage vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Suchanfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein b-Encoder-Modell, das Abfragen und Artikel in dichte Vektordarstellungen abbildet und einen Relevanzwert zwischen einem Abfrage-Artikel-Paar anhand der Ähnlichkeit ihrer Einbettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen resultieren typischerweise aus einer Pooling-Operation auf der Ausgabe eines Wortvektormodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Effektivität von Siamese b-Encodern in einer Zero-Shot-Evaluierungsumgebung, das heißt, vortrainierte Wood-Embedding-Modelle werden direkt angewendet, ohne zusätzliches Finetuning."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, namentlich Word2Vec und FastText, sowie mit kontextabhängigen Einbettungsmodellen, namentlich Robota und, spezifischer, Camembert, welches ein französisches Robota-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus trainieren wir ein eigenes Modell auf Basis von Camembert, das über reine Coder-Anwendungen hinausgeht."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Datensätzen. Bemerkenswert ist, dass wir für das Training mit den beiden Varianten der Bianco-Architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das Anfrage und Artikel in einem gemeinsamen dichten Vektorraum abbildet. Und Tutowa, das zwei unabhängige Word-Embedding-Modelle nutzt, die Anfrage und Artikel separat in unterschiedliche Einbettungsräume kodieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mittelwert-, Maximal- und CLS-Pooling, sowie mit Punktprodukt und Kosinus für die Berechnung von Ähnlichkeiten."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Baseline auf dem Testdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden wurden im Zentrum die Siamese b-Encoder in einer Zero-Shot-Konfiguration evaluiert, und die feinabgestimmten b-Encoder sind unten dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertrifft der feinabgestimmte B-Encoder alle anderen Basslinien signifikant."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two-Tower-Modell verbessert sich im Vergleich zur Siamese-Variante beim Recall bei 100, weist aber bei den anderen Metriken eine ähnliche Leistung auf."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM25 im Vergleich zum trainierten Biancoda schlechter abschnitt, deutet seine Leistung darauf hin, dass es dennoch eine solide Basislinie für die domänenspezifische Retrieval-Aufgabe darstellt."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Null-Shot-Evaluierung von Siamese Biencodern stellen wir fest, dass die direkte Verwendung der Einbettungen eines vortrainierten CamemBERT-Modells, ohne diese für die Informationsabruaufgabe zu optimieren, zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellten wir fest, dass das auf Word2Vec basierende Biancoder Modell die FastText- und Bird-basierten Modelle deutlich übertraf, was darauf hindeutet, dass möglicherweise vortrainierte wortbezogene Einbettungen für diese Aufgabe besser geeignet sind als zeichen- oder unterwortbezogene Einbettungen, wenn sie direkt angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Ob vielversprechend, deuten diese Ergebnisse auf beträchtliche Verbesserungsmöglichkeiten im Vergleich zu einem erfahrenen Rechtsexperten hin, der letztendlich alle relevanten Artikel zu jeder Fragestellung beschaffen und somit perfekte Ergebnisse erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Schließen wir ab, indem wir uns zwei Einschränkungen aller Datensätze zuwenden."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf diejenigen beschränkt, die aus den 32 berücksichtigten belgischen Kodexen entnommen wurden, was nicht das gesamte belgische Recht umfasst, da Artikel aus Dekreten, Direktiven und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden sämtliche Verweise auf diese nicht erfassten Artikel ignoriert, was dazu führt, dass einige Suchanfragen letztlich nur noch einen Bruchteil der anfänglich relevanten Artikel liefern."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust impliziert, dass die in den verbleibenden relevanten Artikeln enthaltene Antwort möglicherweise unvollständig ist, obwohl sie dennoch vollkommen angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir festhalten, dass nicht alle Rechtsfragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage, kann ich meine Mieter beeinflussen, wenn sie zu viel Lärm verursachen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "möglicherweise keine detaillierte Antwort im Gesetzestext finden, die einen spezifischen Lärmpegel quantifiziert, ab dem eine Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter sich wahrscheinlich stärker auf die Rechtsprechung stützen und Präzedenzfälle finden, die seiner aktuellen Situation ähneln."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Der Mieter veranstaltet zweimal pro Woche Partys bis 2 Uhr morgens."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher eignen sich manche Fragen besser als andere für die gesetzliche Artikelrecherche, und der Bereich der weniger geeigneten muss noch ermittelt werden."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass alle Arbeiten Interesse weckt an der Entwicklung von praxisorientierten und zuverlässigen Modellen zur Gewinnung von Gesetzesartikeln."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unser Paper, DATSET&CODE, unter folgenden Links einsehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Wir freuen uns, Ihnen unsere Arbeit an VAUS vorzustellen, einem aufgabenunabhängigen Benchmark, der dazu dient, Vision- und Sprachmodelle anhand spezifischer sprachlicher Phänomene zu testen."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark einzurichten?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Nun haben wir in den letzten Jahren eine explosionsartige Zunahme von Transformer-basierten Vision- und Sprachmodellen erlebt, die auf großen Mengen von Bild-Text-Paaren vortrainiert wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle verbessert den aktuellen Stand der Technik bei Aufgaben der visuellen Verarbeitung und Sprachverarbeitung, wie beispielsweise visuelles Fragenbeantwortungssystem, visuelles gesunder Menschenverstand-Schlussfolgern, Bildabruf, Phrasenlokalisierung."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Meldung erhalten. Die Genauigkeiten bei diesen aufgabenspezifischen Benchmarks steigen stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir tatsächlich, was die Modelle gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was genau verstand ein Vision- und Sprach-Transformer, als er diesem Bild und diesem Satz eine hohe Übereinstimmung zuwies?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und eine niedrige Bewertung dafür."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Verzerrungen, wie aus vorangegangener Forschung ersichtlich ist?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt weiter zu beleuchten, schlagen wir eine aufgabenunabhängigere Richtung vor und führen Ventile ein, die die Sensitivität von Vision- und Sprachmodellen gegenüber spezifischen linguistischen Phänomenen testen, die sowohl die linguistische als auch die visuelle Modalität beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir fokussieren uns auf Existenz, Pluralität, Zählen, räumliche Relationen, Aktionen und die Kernreferenz von Entitäten."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle diese Phänomene erfasst haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "durch FOILing, eine Methode, die zuvor für Vision- und Sprachmodelle, ausschließlich auf Nominalphrasen von Ravi Shekhar und Mitarbeitern, und auf das Zählen in unseren bisherigen Arbeiten angewendet wurde."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Das Foilen bedeutet im Grunde, dass wir die Bildunterschrift nehmen und eine Gegenüberschrift erstellen, indem wir diese so verändern, dass sie das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrasenänderungen durch, indem wir uns auf sechs spezifische Aspekte konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitätscoreferenz, wobei jeder Aspekt aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit finden, FOIL-Instanzen zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Im Falle des Aktionsabschnitts haben wir zwei Instrumente: eines, bei dem das Aktionsverb durch ein anderes ersetzt wird, und eines, bei dem die Aktanten ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Auch das Zählen und die Koreferenz sind Aspekte, die mehr als ein Instrument beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir erzeugen diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie aber grammatikalisch und ansonsten gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach zu bewerkstelligen, da eine vereitelte Bildunterschrift weniger wahrscheinlich sein kann als die ursprüngliche Bildunterschrift."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Ob es ausgeschlossen ist, ist zwar nicht der Fall, jedoch ist es statistisch gesehen weniger wahrscheinlich, dass Pflanzen einen Menschen verletzen als umgekehrt, und große Sprach- und Visionmodelle könnten dies erkennen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Daher müssen wir Maßnahmen ergreifen, um gültige Folien zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir leistungsstarke Sprachmodelle, um Gegenüberstellungen vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir Natural Language Inference, kurz NLI, um Ablenkfahnen herauszufiltern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Ablenkfahnen sicherstellen müssen, dass diese das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir Natural Language Inference mit folgender Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und seine Bildunterschrift als die daraus abgeleitete Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus betrachten wir die Bildunterschrift als die Prämisse und das FOIL als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass das FOIL dem Titel widerspricht oder neutral dazu steht, betrachten wir dies als Indikator für ein gültiges FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn eine NLI vorhersagt, dass das FOIL durch die Bildunterschrift impliziert wird, kann es kein gutes FOIL sein, da es durch Transitivität eine wahrheitsgemäße Beschreibung des Bildes liefern würde und wir diese FOILs herausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Doch dieses Verfahren ist nicht perfekt, es ist lediglich ein Indikator für gültige Folien."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher setzen wir als dritte Maßnahme zur Generierung gültiger FOIs menschliche Annotatoren ein, um die in VALS verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Folglich haben wir nach der Filterung und der menschlichen Bewertung so viele Testinstanzen, wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "VALS stellt keine Trainingsdaten bereit, sondern ausschließlich Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "da es sich lediglich um einen Zero-Shot-Test-Benchmark handelt. Er ist dazu konzipiert, die bereits vorhandenen Fähigkeiten von Vision- und Sprachmodellen nach dem Vortraining zu nutzen."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmung würde Modelle lediglich in die Lage versetzen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle dazu neigen zu betrügen und Abkürzungen zu nehmen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie wir bereits erwähnt haben, sind wir daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach dem Vortraining besitzen."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vokalen, nämlich CLIP, LXMIRT, VILBERT, VILBERT12IN1 und VISUALBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Evaluationsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren als Bildunterschriften und Ablenkern."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Für dieses Video möglicherweise relevanter, werden wir unsere permissivere Metrik, die paarweise Genauigkeit (pairwise accuracy), vorstellen, die misst, ob die Übereinstimmungsbewertung zwischen Bild und Text für das korrekte Bild-Text-Paar höher ist als für sein manipuliertes Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Metriken und Ergebnisse dazu verweisen wir auf unser Papier."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse bezüglich der paarweisen Genauigkeit werden hier dargestellt und stimmen mit den Ergebnissen überein, die wir anhand der anderen Metriken erzielt haben. Es zeigt sich, dass die beste Null-Schuss-Performance durch Wilbert 12 in 1 erreicht wird, gefolgt von Wilbert, Alexmert, Klip und schließlich Visualbert."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Bemerkenswert ist, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nominalphrasen konzentrieren, fast vollständig durch Wilbert 12 in 1 gelöst sind, was unterstreicht, dass Modelle in der Lage sind, benannte Objekte und deren Vorhandensein in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können keine der verbleibenden Aufgaben zuverlässig in unseren adversarialen Umgehungsszenarien gelöst werden."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wir erkennen aus der Mehrzahlenspezifizierung und Zählwerkzeugen, dass Vision- und Sprachmodelle Schwierigkeiten haben, Referenzen auf einzelne versus mehrfache Objekte zu unterscheiden oder diese in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Relationsanalyse zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Relation zwischen Objekten in einem Bild korrekt zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Teilnehmer zu identifizieren, selbst wenn dies durch Glaubwürdigkeitsheuristiken unterstützt wird, wie wir im Handlungsabschnitt sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus der Untersuchung der Coreferenzauflösung geht hervor, dass auch für Vision- und Sprachmodelle die Verfolgung mehrerer Referenzen auf dasselbe Objekt in einem Bild mithilfe von Pronomen eine Herausforderung darstellt."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als eine Art Realitätsabgleich und weil es sich um ein interessantes Experiment handelt, haben wir auch zwei rein textbasierte Modelle, GPT-1 und GPT-2, benchmarkt, um zu prüfen, ob VALS von diesen unimodalen Modellen lösbar ist. Dies geschieht durch Berechnung der Perplexität der korrekten und der vereitelten Bildunterschrift und Vorhersage des Eintrags mit der niedrigsten Perplexität."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Perplexität für das FOIL höher ist, interpretieren wir dies als Hinweis darauf, dass die FOIL-beschriftete Bildunterschrift unter Plausibilitätsvoreingenommenheit oder anderen sprachlichen Voreingenommenheiten leiden könnte."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass reine Text-GPT-Modelle in manchen Fällen die Plausibilität der Welt besser erfasst haben als Modelle, die sowohl Bild als auch Text verarbeiten."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Maßstab ist, der das Konzept linguistischer Konstrukte nutzt, um die Gemeinschaft bei der Verbesserung von Vision- und Sprachmodellen zu unterstützen, indem er deren visuelle Verankerungsfähigkeiten einer harten Prüfung unterzieht."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Vision- und Sprachmodelle benannte Objekte und deren Vorhandensein in Bildern gut identifizieren, wie die existierende Komponente belegt, jedoch Schwierigkeiten haben, ihre wechselseitige Abhängigkeit und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu berücksichtigen."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Gemeinschaft sehr gerne dazu ermutigen, VALS zur Messung des Fortschritts bei der sprachlichen Verankerung mit visuellen und sprachlichen Modellen zu nutzen."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch wichtiger ist, dass VALS zur indirekten Bewertung von Datensätzen verwendet werden könnte, da Modelle vor und nach dem Training oder Feintuning bewertet werden könnten, um festzustellen, ob ein Datensatz dazu beiträgt, dass Modelle in einem der von VALS überprüften Aspekte verbessert werden."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, werfen Sie gerne einen Blick auf die VALS-Daten auf GitHub. Bei Fragen zögern Sie bitte nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Kami Zerua von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Beitrag vorstellen mit dem Titel RNSUM, einen umfangreichen Datensatz für automatische Listen-Notation durch Commit-Log-Zusammenfassung."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde dies in der folgenden Reihenfolge erläutern."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risiko-Benachrichtigung vorstellen, an der wir im Rahmen dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNode ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Softwareprodukts ausgeliefert werden."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Versionshinweise für Version 2.6.1."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Dies spielt keine wesentliche Rolle in der Open-Source-Entwicklung, kann aber zeitaufwändig sein, wenn es manuell vorbereitet wird."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Da wäre es daher sehr nützlich, Versionshinweise von hoher Qualität automatisch generieren zu können."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mich auf zwei vorherige Forschungsarbeiten zur automatischen Generierung von Hörern beziehen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Arena, das im Jahr 2014 veröffentlicht wurde."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert einen regelbasierten Ansatz, beispielsweise die Verwendung eines Change Extractors, um anhand der Unterschiede zwischen Releases Kernunterschiede, Bibliotheksänderungen und Dokumentationsänderungen zu extrahieren und diese abschließend zu kombinieren."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das markanteste Merkmal dieses Systems ist der Problemextractor, der sich oben rechts befindet."}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "das mit Jira, dem Issues-Tracking-System, verknüpft sein muss und nur auf Projekte angewendet werden kann, die Jira verwenden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten lässt es sich für viele Projekte auf GitHub nicht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Das zweite ist GRIF. Dieses wurde 2020 neu angekündigt."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Es ist im Internet verfügbar und kann über PIP gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, lernbasiertes Textklassifikationsmodul und gibt für jede eingegebene Commit-Nachricht eine von fünf Variablen aus, beispielsweise Funktionen oder Fehlerbehebungen."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild stellt eine Beispielanwendung dar, die ein Label für Korrekturen oder Fehlerbehebungen zurückgibt."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Goyafet's Trainingsdatensatz ist relativ klein, etwa 5000 Elemente, und wird in den im Folgenden beschriebenen Experimenten verwendet."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifikationsmodells ist nicht hoch."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich stelle zwei verwandte Forschungsarbeiten vor, jedoch gab es Probleme mit eingeschränkter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit löst diese beiden Probleme und generiert automatisch hochwertige Release-Knoten."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Programm mit begrenzter Anwendbarkeit schlagen wir eine hochwertige Klassifikationszusammenfassung vor, die ausschließlich auf Commit-Nachrichten als Eingabe basiert."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Bibliotheken verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem knapper Datenressourcen erstellten wir einen RNSUM-Datensatz, der etwa 82.000 Datenpunkte umfasst, indem wir Daten aus öffentlichen GitHub-Repositories mithilfe der GitHub API sammelten."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich, wie sie sitzen."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Commit-Nachricht, und die rechte Seite ist der Release-Hinweis."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Versionshinweise sind als Verbesserungen, Arbeitsbereiche usw. gekennzeichnet."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die festgeschriebenen Nachrichten als Eingabe entgegennimmt und die unbearbeiteten, direkt verbundenen Knotenpunkte ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als eine Zusammenfassungaufgabe betrachtet werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Ebenen vordefiniert: Features, Verbesserungen, Fehlerbehebungen, Stilllegungen, Entfernung und inkompatible Änderungen."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aussagen basierten auf vorangegangener Forschung und anderen Faktoren."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die im unteren rechten Bereich dargestellten Ringnotizen werden aus den im unteren linken Bereich gezeigten Ringnotizen extrahiert."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit ist es erforderlich, die im Voraus festgelegten vier Ebenen zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "aber die Pegelwerte sind nicht immer mit jeder Bibliothek konsistent."}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Der Verbesserungsgrad umfasst Verbesserungen, Erweiterungen, Optimierungen und dergleichen."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabelliste der Teilebenen für jede dieser notationalen Variationen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Nutzen Sie dies, um die Klasse der Versionshinweise zu ermitteln und den Text der folgenden Liste als Satz der Versionshinweise für diese Klasse zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes folgt eine Commit-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Verbindungsnachrichten sind nicht an jede Liste gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der folgenden Abbildung dargestellt, müssen wir, wenn die aktuelle Liste die Version 2.5 bis 19 hat, identifizieren"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "die vorherige Release-Version, 2.5.18, herunterladen und sich intensiv damit auseinandersetzen. Dies ist etwas mühsam, und es reicht nicht aus, lediglich eine Liste der Releases abzurufen und die Zustände vor und nach dem Update zu betrachten."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine heuristische Übereinstimmungsregel erstellt, um die vorhergehende und nächste Version zu ermitteln."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Das ist Tanarsis."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende, 7200 Repositories."}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus beträgt die durchschnittliche Anzahl der Tokens der Freiknoten 63, was für eine Zusammenfassungaufgabe recht hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist die Anzahl der eindeutigen Token mit 8.830.000 beträchtlich."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl eindeutiger Klassen- und Methodenbezeichnungen, die im Repository gefunden wurden."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werde ich die vorgeschlagene Methode erläutern."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das klassenbasierte extrahierende-dann-abstrahierende Summarisierungsmodell besteht aus zwei neuronalen Modulen,"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "ein Klassifikator unter Verwendung von BERT oder CodeBert, und ein Generator unter Verwendung von BERT."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst verwendet CAS einen Klassifikator, um jede Commit-Nachricht in fünf Klassen von Versionshinweisen einzuteilen. Wir wählen „implements“, „bugfixes“, „deprecationen“, „plus“ und „other“."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als „sonstige“ klassifizierten Commit-Nachrichten werden verworfen."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wendet CES den Generator unabhängig auf die vier Label-Dokumente an und generiert für jede Klasse Release-Knoten."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Entsprechungen zwischen Commit-Nachrichten und Read-Knoten nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Daher weisen wir dem Klassifikator zum Trainieren jedes Eingabe-Commit-Message ein Pseudolabel zu, basierend auf den ersten 10 Zeichen des jeweiligen Commit-Messages."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die klassenweise abstrakte Zusammenfassung durch unseren Ansatz mit zwei verschiedenen Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir cssingle nennen, besteht aus einem einzigen Geschlechts-zu-Geschlechts-Netzwerk und generiert einen einzigen, langen Textknoten, basierend auf einer Verkettung von Eingabe-Commit-Nachrichten."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgabetext kann in übergreifende Klassenabschnitte unterteilt werden, basierend auf speziellen, klassenspezifischen Endpunktsymbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir CAS-Merge nennen, besteht aus vier verschiedenen Sec-zu-Sec-Netzwerken, von denen jedes einer der am wenigsten bekannten Klassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, lassen Sie mich das Experiment erklären."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: CAS, CS einzeln, CS-Merge, Clustering und die Ergebnisse früherer Studien."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Bewertung werden diese Knoten in manchen Fällen in mehreren Sätzen ausgegeben."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze zu berechnen, werden diese mit Leerzeichen verbunden und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Blau ist panelisiert, wenn das System einen kurzen Satz ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem niedrigeren Blauwert in den experimentellen Ergebnissen, die im Folgenden beschrieben werden."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend berechnen wir zudem die Spezifität, da Rot und Blau nicht berechnet werden können, wenn die Freigabeknoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell in Fällen, in denen die Release-Knoten einen leeren Zustand annehmen, korrekt einen leeren Text ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, haben wir auch den bereinigten Datensatz, aus dem diese entfernt wurden, evaluiert."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CEAS und CAS erreichten L-Werte, die um mehr als 10 Punkte höher waren als die Referenzwerte."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem sauberen Testdatensatz erhöhte sich die Punktedifferenz zwischen den vorgeschlagenen Methoden und dem Basis-Endpunkt auf über 20 Punkte."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass CES und GS signifikant wirksam sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "CAS erzielte einen besseren Root-Fail-Score als CAS, was darauf hindeutet, dass die Kombination eines Klassifikators und eines Generators effektiv ist, um den Klassifikator mit Pseudo-Doubles zu trainieren."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von CAS lässt sich wahrscheinlich dadurch erklären, dass der Klassifikator sich darauf konzentrieren kann, für jede Klasse relevante Commit-Nachrichten auszuwählen."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "CAS-Matching liefert tendenziell höhere Ergebnisse als CAS-Single."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "und darauf hindeutend, dass es ebenfalls effektiv sein kann, für jede Release-Node-Klasse unabhängig voneinander Summarisierungsmodelle mit unterschiedlicher Absorptionsfähigkeit zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Heldenanalyse und Fehleranalyse"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "CS-Methoden neigen dazu, kürzere Sätze zu erzeugen als Referenzsätze, die von Menschen verfasst wurden."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der rechten Abbildung besteht der Referenzsatz aus 3 oder 4 Sätzen, während CAS lediglich einen Satz aufweist."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzögerlichkeit liegt darin, dass im Trainingsdatensatz lediglich 33 % der Sätze im Feature-Label und 40 % im Verbesserungs-Label enthalten sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES-Methoden keine genauen VsNode-Darstellungen ohne zusätzliche Informationen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr ungeordnete Kommentar-Nachricht, und der vollständige Satz kann nicht ohne Bezugnahme auf den entsprechenden Pull Request oder das entsprechende Issue generiert werden."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe inhaltlich miteinander verbunden sind und in einen einzigen Satz zusammengefasst werden sollten, dies jedoch nicht geschieht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend ein Fazit."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine neue, dedizierte Einrichtung für die automatisierte Fallbeglaubigung geschaffen."}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns außerdem die Aufgabe gestellt, Commit-Nachrichten einzugeben und zusammenzufassen, sodass sie für alle Projekte in englischer Sprache anwendbar sind."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zeigt, dass die vorgeschlagene Methode bei höherer Abdeckung weniger verrauschte Leads generierte als die Baselines."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte prüfen Sie den Code für die Wüstenprüfungsübersicht."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Guten Tag, mein Name ist Asaf Harari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "und ich werde unser Paper „Few-Shot Tabular Data Enrichment Using Fine-Tuning Transformer Architectures“ vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "So analysieren Wissenschaftler Daten und konzentrieren sich hauptsächlich auf die Manipulation bestehender Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "aber manchmal sind diese Funktionen eingeschränkt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Feature-Generierung unter Verwendung einer weiteren Datenquelle kann erhebliche Informationen hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung tabellarischer Daten unter Verwendung von freiem Text aus externen Quellen."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben einen tabellarischen Datensatz und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatisierten Prozess, der Entity Linking und Textanalyse umfasst, um aus den freien Texten der Wissensdatenbank neue Merkmale zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework ist zunächst einmal genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir ein Beispiel anhand eines Datensatzes, der in FAST eingespeist wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz ein Universitätsdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "wenn sein Ziel darin besteht, Universitäten in niedrigrangige und hochrangige Universitäten einzuteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensdatenbank verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von FAST ist die Entitätserkennung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "wenn jede Entität, in diesem Beispiel der Name der Universität, mit einer Entität innerhalb der Wissensdatenbank verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten aus der Wissensdatenbank extrahiert und dem Datensatz hinzugefügt wird."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Please provide the English text you want me to translate. I am ready when you are."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Nun müssen wir Merkmale aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen eine Feature-Extraktionsphase, die eine Textanalyse beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "und dies ist die Hauptneuheit dieses Artikels, und ich werde in den nächsten Folien detailliert darauf eingehen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Feature-Extraktionsphase folgt eine Feature-Generierungsphase, in der wir die extrahierten Features verwenden, um eine geringe Anzahl neuer Features zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes generieren."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel verfügt der ursprüngliche Datensatz über zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "So generiere schnell zwei neue Features."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn der Datensatz fünf Klassen hat, generieren Sie zunächst fünf neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jedes Merkmal repräsentiert die Wahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Zur Analyse des Textes verwenden wir den aktuellen Stand der Technik in der Textanalyse, welcher auf Transformer-basierten Sprachmodellen wie BERT, GPT, XNL und ähnlichen Modellen beruht."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "aber es ist unwahrscheinlich, dass wir Sprachmodelle anhand der vorliegenden Datensätze trainieren können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wäre daher ein Feinabgleich auf die Zielaufgabe."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der zukünftigen Extraktionsphase können wir das peritrain-Sprachmodell herunterladen und das Sprachmodell mit dem Ziel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, um das Sprachmodell zu verfeinern, um Text in Klassen einzuteilen, Klassen abzuziehen, niedrig oder hoch,"}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "erhalten Sie die Ausgabe des Sprachmodells, welche die Wahrscheinlichkeit für jede Klasse darstellt, und verwenden Sie diese als neue Merkmale."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz besteht darin, dass der Datensatz nur wenige unterschiedliche Entitätstags aufweisen kann."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als 400 Stichproben, und der kleinste Datensatz enthielt im Trainingsdatensatz lediglich 35 Stichproben."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Da wird eine Feinabstimmung eines Sprachmodells anhand dieses Datensatzes somit unwirksam sein."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "aber wir können Vorwissen über zuvor analysierte Datensätze nutzen,"}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "da wir FAST auf mehrere Datensätze anwenden, können wir die N minus eins Datensätze nutzen, um Informationen über diese N minus eins Datensätze zu gewinnen, und diese Informationen bei der Analyse des N-ten Datensatzes verwenden."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist das Hinzufügen einer weiteren Feinabstimmungsphase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "eine vorbereitende, mehrstufige Feinabstimmungsphase."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "wenn Sie das Sprachmodell anhand von N-1 Datensätzen feinabstimmen,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "und dann führen wir eine weitere Feinabstimmungsphase durch, welche eine zielgerichtete Feinabstimmung darstellt, wenn wir das Sprachmodell anhand des n-ten Ziel-Datensatzes feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "der aktuelle Stand der Technik im Bereich Multitask-Feinabstimmung, bezeichnet als Empty DNN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN werden MTDNN-Köpfe in der Anzahl der Aufgaben im Trainingsdatensatz aufrechterhalten."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainingsdatensatz. So ein leeres DNN, wobei vier Köpfe erhalten bleiben, wie man im Bild sehen kann."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "und es zieht eine zufällige Stichprobe aus dem Trainingsdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge beispielsweise zu Einzel-Satz-Klassifikationsaufgaben gehört, wird ein Vorwärts- und Rückwärtspass durch den ersten Kopf ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die zufällige Charge zur paarweisen Rangordnungsaufgabe gehört, erfolgt die Weiterleitung und Rückführung durch den letzten Head."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario wird ein tabellarisches Datensatz die Anzahl der Klassen bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Da gibt es also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "mtDNN behält die Anzahl der Klassen-Heads und Ausgabeschichten bei."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus muss emptyDNA neue Heads für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, das sogenannte Task Reformulation Fine-Tuning, besteht darin, anstatt mehrere Köpfe beizubehalten, jeden Datensatz in einen Satz pro Klassifizierungsproblem umzuformulieren, also in Aufgaben mit zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Betrachten wir also ein Beispiel."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Eingabedatensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir reformulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zur Klassifizierung des Textes, des Abstracts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten trainieren wir das Sprachmodell so, dass es Abstrakt und Klasse klassifiziert, also Abstrakt und Klasse, um festzustellen, ob das Abstrakt zur Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Labelvektor bleibt in diesem Fall stets erhalten, und besteht immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und dies ist der Algorithmus für unseren neu formulierten Fine-Tuning-Ansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns also das vollständige Rahmenwerk an."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Das hat die Fed in die Wertschätzung versetzt."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "und anschließend eine schnelle Ausführungsphase der Entitätverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensdatenbank, welche in diesem Beispiel der Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "dann wird die Aufgabe umformuliert in einzelne Klassifikationsschritte."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "das Sprachmodell auf die neue Aufgabe angewendet und die Klassenwahrscheinlichkeit für jede Klasse,"}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Das Sprachmodell wurde bereits über einen N-1-Datensatz mithilfe einer vorläufigen multimodalen Feinabstimmung trainiert."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabvektor des Sprachmodells als ein neu generiertes Merkmal für die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zur Evaluation unseres Frameworks verwenden wir einen tabellarischen Klassifikationsdatensatz mit 17 Einträgen, der Größe, Merkmale, Ausgeglichenheit, Domäne und anfängliche Leistung überprüft."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir gestalten unser Experiment als Live-One-Out-Evaluierung, indem wir unser Modell anhand von über 16 Datensätzen trainieren und es anschließend auf den 17. Datensatz anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen jeden Datensatz ebenfalls in vier Folds auf und wenden eine vierfache Kreuzvalidierung an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir das neue Merkmal und bewerten es mithilfe von fünf Evaluatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-basierte Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Framework mit der Feinabstimmung auf das Ziel-Dataset, der Feinabstimmung auf die Zielaufgabe und der vorläufigen Feinabstimmung mit MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "und unser überarbeitetes Feinabstimmen erzielt das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "während des leeren DNN erreichte es eine Verbesserung von zwei Prozent im Vergleich zur Feinabstimmung auf dem Ziel-Datensatz."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz erzielte eine Verbesserung von 6 %."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns das kleine Datenset ansehen, können wir feststellen, dass die Leistung von mtDNN abnimmt und die Verbesserung der vorläufigen Multitask-Feinabstimmungsphase auf 1,5 Prozent sinkt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "aber unsere Leistung stieg im Vergleich zur alleinigen Feinabstimmung für die Zielaufgabe auf 11 % an."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Summierung ermöglicht FAST in unserem Experiment eine few-shot-Anreicherung aus 35 Beispielen."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und es behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "aber es fügt eine Umformulierungsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "seinem erweiterten Modelleisenbahn-Setup und seinen Anforderungen, einen Zielwert mit semantischer Bedeutung, den wir in das Sprachmodell einspeisen und im Satz pro Klassifikationsproblem verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank."}
