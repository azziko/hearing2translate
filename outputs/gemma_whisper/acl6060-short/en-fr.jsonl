{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous, aujourd'hui je vais vous présenter notre travail de recherche : Apprendre à Raisonner Déductivement, la Résolution de Problèmes Métaboliques comme Extraction de Régions Complexes."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis Alan du laboratoire d'IA de ByteDance et ceci est un travail conjoint avec Jerry de l'Université du Texas à Austin et Weilu de SUTD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais aborder notre motivation à raisonner."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple où le raisonnement en plusieurs étapes est utile."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Cette figure est extraite de l'article de Pound, dans lequel ils utilisent le prompting pour résoudre le problème mathématique dans un scénario d'apprentissage avec peu d'exemples."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, du côté gauche, si nous fournissons quelques exemples ne contenant que des questions et des réponses, il nous sera peut-être impossible d’obtenir les réponses correctes."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous fournissons une description plus détaillée du raisonnement, le modèle est capable de prédire cette description du raisonnement et de faire une prédiction correcte dans ce contexte."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc avantageux d'obtenir en sortie un raisonnement multi-étapes interprétable."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons également que la méthode problématique constitue une application directe pour évaluer ces capacités de raisonnement."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans le cadre de ce problème, étant donné les questions, nous devons résoudre cette interrogation et obtenir les réponses numériques."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos ensembles de données, on nous fournit également l'expression mathématique, ce qui conduit également à cette réponse particulière."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Certaines hypothèses s'appliquent également, comme dans les travaux antérieurs."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "nous supposons que la précision des quantités est connue"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que des opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiation."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, des opérateurs complexes peuvent effectivement être décomposés en ces opérateurs élémentaires."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, les travaux antérieurs en résolution de problèmes par méthode peuvent en réalité être classés en modèles séquence-à-séquence et séquence-à-arbre."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le modèle séquence à séquence traditionnel convertit l'expression en une séquence spécifique pour la génération."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est assez facile à mettre en œuvre, et il peut être généralisé à de nombreux problèmes complexes différents."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les inconvénients de la performance ne sont généralement pas meilleurs que ceux du modèle structuré.\nEt il lui manque l'interprétabilité nécessaire pour les prédictions."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en réalité, cette direction reste assez populaire en raison du modèle transformateur."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans les modèles basés sur des arbres, nous structurons concrètement ces expressions sous forme d'arbre et suivons un parcours en préordre lors de la génération des arbres."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous continuons à générer les opérateurs jusqu'à atteindre les feuilles, qui représentent les quantités."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Alors, le point positif ici est que cela nous donne effectivement cette structure d'arbre binaire. Mais c'est en réalité assez contre-intuitif car nous générons d'abord l'opérateur, puis nous générons les quantités à la fin."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est qu'il contient également certains calculs redondants."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, si nous examinons cette expression, 8 fois 3 plus 3 est effectivement calculé deux fois. Mais en fait, nous devrions réutiliser les résultats."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre approche proposée, nous souhaitons résoudre ces problèmes de manière progressive et interprétable."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, par exemple, voici, à la deuxième étape, nous pouvons obtenir ce diviseur, qui est 27."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons également revenir aux questions initiales afin d'identifier les éléments pertinents."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et grâce à ces étapes, nous obtenons les diviseurs."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Alors, à cette troisième étape, nous obtenons effectivement le quotient."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "Bien, et après ces trois étapes, nous pouvons effectivement utiliser les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape. Et finalement, nous pouvons obtenir les dividendes."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous générons ici l'expression entière directement plutôt que de générer un seul opérateur ou une seule quantité."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Cela rend donc le processus plus précis."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre système déductif, nous commençons d'abord par un ensemble de quantités présentées dans les questions, incluant également des constantes définissant notre état initial."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'expression est représentée par EIJOP."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "où nous effectuons l’opérateur de QI à QJ, et cette expression est en réalité dirigée."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous avons également ici une soustraction inversée pour représenter la direction opposée."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "Ceci est tout à fait similaire à l'extraction de relations."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans un système déductif formel, au pas de temps t, nous appliquons l'opérateur à la paire qi et qj, et nous obtenons ces nouvelles expressions."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "nous l'ajoutons à l'état suivant pour qu'il devienne une nouvelle quantité."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Ce diaporama visualise en réalité l’évolution de l’état, où nous ajoutons continuellement des expressions à l’état actuel."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos implémentations de modèle, nous utilisons d'abord un modèle de langage pré-entraîné, qui peut être un BERT ou un RoBERTa, puis nous encodons une phrase, et nous obtenons ces représentations de quantités."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Une fois que nous aurons les représentations de quantités, nous pourrons commencer à effectuer des inférences."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de Q1 pour obtenir la représentation de Q1 divisé par Q2 et ensuite multiplié par Q4."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, nous obtenons la représentation par paire, qui n'est essentiellement que la concaténation entre Q1 et Q2. Ensuite, nous appliquons un réseau feedforward, paramétré par l'opérateur."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, nous obtenons l'expression représentation Q1 divisée par Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en fait, dans la pratique, lors de l'étape d'inférence, il est possible d'obtenir également une expression incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'ensemble des expressions possibles est égal à 3 fois le nombre d'opérateurs."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "L'avantage ici est donc que nous pouvons facilement ajouter des contraintes pour contrôler cet espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Si cette expression n’est pas autorisée, nous pouvons tout simplement la supprimer dans notre espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans la deuxième étape, nous procédons de la même manière, mais la seule différence réside dans une quantité supplémentaire."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité est issue de l'expression calculée précédemment."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous pouvons finalement obtenir cette expression finale Q."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "times Q4. Et nous pouvons également constater que le nombre de toutes les expressions possibles diffère de l'étape précédente."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Une telle différence rend difficile l'application de la recherche par faisceau, car la distribution de probabilité entre ces deux étapes est déséquilibrée."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, la procédure d'apprentissage est similaire à celle d'un modèle séquence à séquence, où l'on optimise la perte à chaque pas de temps."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également ce tau pour représenter le moment où nous devons interrompre ce processus de génération."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent d'une séquence à l'autre, car il varie à chaque pas de temps, alors que dans le modèle séquence à séquence traditionnel, c'est le nombre de vocabulaire."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela nous permet également d'imposer certaines contraintes issues de connaissances antérieures."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous menons donc des expériences sur les ensembles de données problématiques de méthodes couramment utilisées : MAWPS, MAT23K, MATQA et SWAMP."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici que nous présentons brièvement les résultats comparés aux approches par lots précédentes."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Notre variante la plus performante est Robeta Dictative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "et en fait nous n'utilisons pas la recherche par faisceau, contrairement aux approches évidentes qui l'emploient."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "Bien, donc les approches les plus efficaces sont souvent basées sur des arbres."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans l'ensemble, notre raisonneur est capable de surpasser significativement ce modèle basé sur des arbres."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons constater que les chiffres absolus sur Mathqa ou SWAM ne sont pas vraiment élevés."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Nous examinons donc plus en détail les résultats concernant"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "Et cet ensemble de données est difficile car l'auteur a tenté d'ajouter manuellement des éléments perturbateurs afin de tromper le modèle de TAL, comme l'ajout d'informations non pertinentes et de quantités supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre prédiction, nous constatons que certaines des valeurs intermédiaires sont en réalité négatives."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ces questions, nous demandons combien de pommes Drake possède."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons quelques informations supplémentaires, comme 17 lancers de moins.\nEt Steven a 8 lancers, ce qui est totalement hors de propos."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle effectue des prédictions de ce type, lesquelles produisent des valeurs négatives."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "et nous observons ces deux expressions."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous pouvons réellement limiter cet espace de recherche en éliminant les résultats négatifs, afin de garantir que la réponse soit correcte."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous constatons également que cette contrainte améliore considérablement les performances de certains modèles."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Pour les oiseaux, nous avons amélioré sept points. Et ensuite, pour le modèle basé sur Robeta, nous avons en réalité amélioré deux points."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, un meilleur modèle linguistique possède une meilleure capacité de compréhension du langage, ce qui se traduit par un nombre plus élevé pour Robita et un nombre plus faible pour Bird."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous essayons également d’analyser la difficulté sous-jacente à cela."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "nous supposons que le nombre de quantités non utilisées peut être considéré comme une information sans pertinence ici."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous pouvons constater que nous avons le pourcentage d’échantillons présentant des quantités non utilisées, et que le jeu de données SWAMP présente la proportion la plus élevée."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous illustrons également la performance globale."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "pour ceux-là, les échantillons ne comportant pas de quantités non utilisées. Par conséquent, la performance globale est en réalité supérieure à la performance globale."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais avec ces échantillons dont la quantité n'a pas été utilisée, la situation est en réalité bien plus problématique que, bien plus problématique que..."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "performance. Pour MAWPS, nous n'avons pas vraiment beaucoup d'incidents liés au disque, donc j'ignore simplement cette partie."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous souhaitons finalement démontrer l'interprétabilité à travers un exemple de rupture et de perturbation."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait effectivement une prédiction erronée dès la première étape."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous pouvons effectivement corréler cette expression avec la phrase ici."}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que cette phrase pourrait induire le modèle en erreur et l'amener à faire une prédiction incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'impression de 35 unités supplémentaires amène le modèle à considérer qu'il s'agit d'un opérateur d'addition."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Nous essayons donc de reformuler la phrase de manière à ce qu’elle ressemble à ceci : le nombre de poiriers est inférieur de 55 au nombre de pommiers."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous veillons à transmettre une sémantique plus précise, afin que le modèle puisse effectuer une prédiction correcte."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, cette étude démontre comment les prédictions interprétables nous aident à comprendre le comportement du modèle."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure notre travail, donc, d'abord, notre modèle est en réalité assez performant."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous sommes en mesure de fournir une procédure de résolution interprétable."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "et nous pouvons facilement intégrer certaines connaissances antérieures comme contrainte, ce qui peut contribuer à améliorer les performances."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et la dernière chose à retenir est que le mécanisme sous-jacent ne s'applique pas seulement aux tâches de résolution de problèmes en cartographie, mais aussi à d'autres tâches impliquant un raisonnement en plusieurs étapes."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons également certaines limitations."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose, comme mentionné, est que la distribution de probabilité étant déséquilibrée à différents moments, il est également assez difficile d'appliquer la recherche par faisceau."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "C'est donc la fin de la présentation, et les questions sont les bienvenues. Merci."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je suis de l'Université de Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai mon travail de conception avec Jerry, qui porte sur un nouveau jeu de données pour la recherche d'articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions juridiques font partie intégrante de la vie de nombreuses personnes."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et les procédures judiciaires fondamentales."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, de nombreux citoyens vulnérables qui ne peuvent se permettre l'assistance coûteuse d'un expert juridique se retrouvent sans protection, voire, pire encore, exploités."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les citoyens et le droit en développant des systèmes de recherche efficaces pour les articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "un tel système pourrait offrir un service d'assistance juridique professionnelle gratuit aux personnes sans compétences spécifiques."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de nous plonger dans la contribution principale de ce travail, décrivons d’abord le problème de la recherche d’articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une question simple concernant une question mineure, comme les risques encourus en cas de violation du secret professionnel ?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est requis pour extraire de la vaste législation tous les articles législatifs pertinents."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de recherche d'information comporte son propre ensemble de difficultés."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, il s'agit de deux types de langage."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "Un langage courant et naturel pour les questions, et un langage juridique complexe pour les statuts."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans les distributions linguistiques rend plus difficile pour un système de récupérer des candidats pertinents, car elle exige indirectement un système d'interprétation inhérent capable de traduire une question exprimée en langage naturel en une question juridique qui correspond à la terminologie des lois."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le droit statutaire n'est pas un ensemble d'articles indépendants qui puissent être considérés comme une source d'information exhaustive en soi, contrairement à l'actualité ou aux recettes, par exemple."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, il s'agit d'un ensemble structuré de dispositions juridiques qui n'acquièrent un sens complet que lorsqu'elles sont considérées dans leur contexte global, c'est-à-dire conjointement avec les informations complémentaires tirées de leurs articles voisins, les domaines et sous-domaines auxquels elles appartiennent, et leur place dans la structure du droit."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles statutaires ne sont pas de petits paragraphes, ce qui constitue généralement l'unité de recherche typique dans la plupart des travaux de recherche."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, il existe de longs documents qui peuvent atteindre six."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récents progrès en TALN ont suscité un vif intérêt pour de nombreuses tâches juridiques, telles que la prédiction de décisions de justice ou l’examen automatisé de contrats."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la recherche d'articles législatifs est restée pour l'essentiel inexplorée en raison du manque d'ensembles de données étiquetés importants et de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce travail, nous présentons un nouveau jeu de données, d'origine française et centré sur l'usager, afin d'étudier si un modèle de recherche peut approximer l'efficacité et la fiabilité d'un expert juridique pour la tâche de recherche d'articles de loi."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "Notre ensemble de données de récupération d'articles législatifs belges, PSART, se compose de plus de 1 100 textes juridiques."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions abordent un large éventail de sujets, allant de la famille, au logement, en passant par l'argent, le travail et la sécurité sociale."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun d'entre eux a été étiqueté par des juristes expérimentés, avec des références à des articles pertinents tirés d'un corpus de plus de 22 600."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Les codes de droit belge. Parlons maintenant de la manière dont nous avons collecté ces ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, nous avons commencé par compiler un vaste corpus d'articles juridiques."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné 32 codes belges accessibles au public et extrait de chacun tous les articles, ainsi que les titres de section correspondants."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous avons rassemblé des questions juridiques faisant référence aux lois applicables."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous collaborons avec un cabinet d'avocats belge qui reçoit chaque année environ 4 000 courriels de la part de citoyens belges demandant des conseils sur une question juridique personnelle."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'accéder à leurs sites web, où leur équipe d'experts juristes traite des questions juridiques les plus courantes en Belgique."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons recueilli des milliers de questions, annotées avec des catégories, des sous-catégories et des références juridiques aux lois applicables."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons analysé les références juridiques et éliminé les questions dont les références ne correspondaient pas à des articles de l'un des codes de droit que nous avions pris en compte."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été mises en correspondance et converties aux identifiants d'articles correspondants de Ocorpus."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons fini par obtenir 1108 questions, chacune étant soigneusement étiquetée avec les identifiants des articles pertinents provenant de"}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est accompagnée d’une catégorie principale et d’une concaténation de sous-catégories."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "et chaque article est accompagné d'une concaténation de ses titres suivants dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Ces informations supplémentaires ne sont pas utilisées dans le présent travail, mais pourraient intéresser les recherches futures concernant la recherche d'information juridique ou la classification juridique en matière fiscale."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons maintenant quelques caractéristiques de nos ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions comptent entre 5 et 44 mots, avec une médiane de 14 mots."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur médiane de 77 mots, dont 142"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "dépassant 1000."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, les questions couvrent un large éventail de sujets, environ 85 % d’entre elles portant soit sur la famille, le logement, l’argent, soit sur la justice."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que les 15 % restants concernent soit la sécurité sociale, soit les étrangers ou le travail."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers, puisqu’ils proviennent de 32 différents codes belges qui couvrent un grand nombre de sujets juridiques."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles compilés à partir de chacun de ces codes belges."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Sur les 22 633 articles, seulement 1 612 sont considérés comme pertinents pour au moins"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "une question dans les ensembles de données. Et environ 80 % de ces articles cités proviennent soit du code civil, du code de procédure judiciaire, du code de procédure pénale, soit des codes pénal."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant ce temps, 18 des 32 codes comportent moins de 5 articles mentionnés comme pertinents pour au moins une question."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Ce qui peut s'expliquer par le fait que ces codes se concentrent moins sur les individus et leurs préoccupations."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le nombre médian de citations pour ces articles référencés est de 2, et moins de 25 % d'entre eux le sont."}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos ensembles de données, nous évaluons plusieurs approches de recherche, notamment lexicales et basées sur des architectures denses."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une requête dans un article, un modèle lexical attribue un score au couple requête-article en calculant la somme des poids de chaque terme présent dans cet article."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec les fonctions de classement TF-IDF et BM25 standard."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que des articles contenant des mots-clés présents dans la requête."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour pallier cette limitation, nous expérimentons avec une architecture basée sur un réseau neuronal capable de saisir les relations sémantiques entre les requêtes et les articles."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle b-encodeur qui projette les requêtes et les articles dans des représentations vectorielles denses et calcule un score de pertinence entre une paire requête-article par la similarité de leurs intégrations."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces embeddings résultent généralement d'une opération de pooling appliquée à la sortie d'un modèle d'intégration de mots."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, nous étudions l'efficacité des b-encodeurs siamois dans un contexte d'évaluation en zéro coup, ce qui signifie que les modèles d'intégration de bois pré-entraînés sont appliqués tels quels, sans aucun ajustement supplémentaire."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec des encodeurs de texte indépendants du contexte, notamment Word2Vec et FastText, ainsi qu’avec des modèles d’intégration dépendants du contexte, notamment Robota et, plus spécifiquement, CamemBERT, qui est un modèle Robota français."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous formons notre propre modèle basé sur Camembert, au-delà des codeurs."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "sur tous les jeux de données. Notons que pour l'entraînement, nous expérimentons avec les deux variantes de l'architecture Bianco."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, qui utilise un modèle d’intégration de mots unique qui associe la requête et l’article dans un espace vectoriel dense partagé. Et Tutowa, qui utilise deux modèles d’intégration de mots indépendants qui encodent la requête et l’article séparément dans des espaces d’intégration différents."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec le pooling moyen, maximal et CLS, ainsi que le produit scalaire et le cosinus pour le calcul des similarités."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre évaluation de référence sur l’ensemble de test."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "avec les méthodes lexicales susmentionnées, les b-encodeurs siamois évalués en configuration zéro-shot au centre, et les b-encodeurs affinés ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le B-encodeur affiné surpasse significativement toutes les autres lignes de basse."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle à deux tours améliore la variante siamois en termes de rappel à 100, mais présente des performances similaires pour les autres métriques."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que BM25 ait été inférieur au Biancoda entraîné de manière significative, sa performance indique qu'il reste une référence solide pour la recherche d'informations spécifique à un domaine."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "Concernant l'évaluation en zéro coup de tir des siamese biencodeurs, nous constatons que l'utilisation directe des plongements d'un modèle CamemBERT pré-entraîné, sans optimisation pour la tâche de recherche d'information, donne de mauvais résultats, ce qui est conforme aux constatations antérieures."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous avons constaté que le modèle biancoder basé sur Word2Vec surpassait significativement les modèles FastText et Bird, ce qui suggère que, peut-être, les plongements (embeddings) de mots pré-entraînés sont plus adaptés à cette tâche que les plongements de caractères ou de sous-mots lorsqu'ils sont utilisés directement."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteuses, ces résultats suggèrent une marge d'amélioration considérable par rapport à un juriste compétent, capable de retrouver à terme tous les articles pertinents à toute question et d'obtenir ainsi des scores parfaits."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Concluons en abordant deux limitations communes à tous les ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, le corpus d’articles se limite à ceux collectés à partir des 32 codes belges pris en compte, ce qui ne couvre pas l’intégralité du droit belge, étant donné l’absence d’articles provenant de décrets, de directives et d’ordonnances."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Lors de la construction du jeu de données, toutes les références à ces articles non collectés sont ignorées, ce qui peut entraîner le fait que certaines questions ne disposent plus que d'une fraction du nombre initial d'articles pertinents."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'information implique que la réponse contenue dans les articles restants pertinents pourrait être incomplète, bien qu'elle reste tout à fait appropriée."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent pas être résolues uniquement par des lois."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question suivante : puis-je affecter mes locataires s’ils font trop de bruit ?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "il se pourrait qu'il n'existe pas de réponse détaillée dans la législation en vigueur qui quantifie un seuil sonore spécifique à partir duquel l'expulsion est autorisée."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "À la place, le propriétaire devrait probablement s'appuyer davantage sur la jurisprudence et trouver des précédents similaires à sa situation actuelle."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Le locataire reçoit deux soirées par semaine jusqu’à 2h du matin."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, certaines questions se prêtent mieux que d'autres à la tâche de recherche d'articles législatifs, et le domaine de celles qui sont moins appropriées reste à déterminer."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que chaque travail suscitera un intérêt pour le développement de modèles de recherche d’articles législatifs pratiques et fiables."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut contribuer à améliorer l'accès à la justice pour tous."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre article, DATSET&CODE, aux liens suivants. Merci."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour ! Nous sommes heureux de vous présenter notre travail sur VAUS, un point de référence indépendant de toute tâche, conçu pour tester les modèles de vision et de langage avec des phénomènes linguistiques spécifiques."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous pris la peine de mettre en place cette référence ?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, au cours des dernières années, nous avons assisté à une explosion des modèles de vision et de langage basés sur les transformeurs, pré-entraînés sur de vastes quantités de paires image-texte."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun de ces modèles repousse les limites de l’état de l’art dans les tâches de vision et de langage, telles que la réponse à des questions visuelles, le raisonnement de bon sens visuel, la recherche d'images, l'ancrage de phrases."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc reçu un message. Les niveaux de précision sur ces références spécifiques aux tâches augmentent régulièrement."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous réellement ce que les modèles ont appris ?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformeur vision-langage a saisi lorsqu'il a attribué un score élevé à cette image et à cette phrase pour indiquer une correspondance ?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "et une faible note pour celui-ci."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur les aspects pertinents ?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou se concentrent-ils plutôt sur les biais, comme le démontrent des travaux antérieurs ?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour mieux éclairer cet aspect, nous proposons une approche plus indépendante des tâches et introduisons des valves qui testent la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques qui affectent à la fois les modalités linguistiques et visuelles."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la coréférence d'entités."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment tester si les modèles de vision et de langage ont capturé ces phénomènes ?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "par l'utilisation de la méthode FOIL, appliquée précédemment aux modèles de vision et de langage, uniquement aux groupes nominaux par Ravi Shekhar et ses collaborateurs, et à la comptage dans nos travaux antérieurs."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le \"foiling\" consiste essentiellement à prendre la légende d'une image et à en produire un faux-semblant en modifiant la légende de sorte qu'elle ne décrive plus l'image."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous réalisons ces modifications de phrases en nous concentrant sur six éléments spécifiques, tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la référence centrale des entités, chaque élément pouvant comprendre un ou plusieurs instruments, au cas où nous trouverions plus d'une manière intéressante de créer des instances FOIL."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour la partie concernant les actions, nous avons deux instruments : l'un où le verbe d'action est modifié par un autre verbe d'action, et l'autre où les acteurs sont intervertis."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la coréférence sont également des éléments qui nécessitent plus d'un instrument."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces faux-semblants en veillant à ce qu'ils ne décrivent pas l'image, qu'ils soient des phrases grammaticalement correctes et valides à tous égards."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas chose aisée, car une légende infructueuse risque d'être moins probable que la légende originale."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que ce ne soit pas impossible, il est statistiquement moins probable qu'une plante blesse un homme qu'un homme ne blesse une plante, et les grands modèles de vision et de langage pourraient en tenir compte."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des lames de comparaison valables, nous devons agir."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, nous utilisons des modèles linguistiques robustes pour proposer des contre-exemples."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence de langage naturel, ou NLI en abrégé, pour éliminer les leurres qui pourraient encore décrire l'image, étant donné que, lors de la construction de ces leurres, nous devons nous assurer qu'ils ne parviennent pas à décrire l'image."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester ceci automatiquement, nous appliquons l'inférence du langage naturel avec la justification suivante."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons qu'une image constitue la prémisse et sa légende, l'hypothèse découlant de celle-ci."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous considérons la légende comme la prémisse et le FOIL comme son hypothèse."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le FOIL contredit ou est neutre par rapport à la légende, nous considérons cela comme un indicateur d'un FOIL valide."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si une NLI prédit que le FOIL est impliqué par la légende, il ne peut s'agir d'un bon FOIL, car par transitivité, il fournira une description véridique de l'image, et nous filtrons ces FOILs."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite, elle n'est qu'un indicateur de validité des feuilles."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, en tant que troisième mesure pour générer des FOI valides, nous faisons appel à des annotateurs humains pour valider les données utilisées dans VALS."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après filtrage et évaluation humaine, nous disposons du nombre d'exemples de test tel que décrit dans ce tableau."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "VALS ne fournit aucune donnée d'entraînement, mais uniquement des données de test."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "puisqu'il s'agit uniquement d'un point de référence de test en situation de zéro coup. Il est conçu pour tirer parti des capacités existantes des modèles de vision et de langage après pré-entraînement."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "Le réglage fin ne permettrait qu'aux modèles d'exploiter des artefacts ou des biais statistiques présents dans les données."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles ont tendance à tricher et à prendre des raccourcis."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l’avons mentionné, nous sommes intéressés par l’évaluation des capacités des modèles vision et langage après pré-entraînement."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles de vision et de langage sur les voyelles, à savoir CLIP, LXMIRT, VILBERT, VILBERT12IN1 et VISUALBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d'évaluation les plus importantes concernent la précision des modèles dans la classification des paires image-phrase en légendes et leurres."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Peut-être plus pertinent pour cette vidéo, nous présenterons notre métrique plus permissive, l'exactitude appariée (pairwise accuracy), qui mesure si le score d'alignement image-texte est plus élevé pour la paire image-texte correcte que pour sa paire déjouée."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de mesures et de résultats à leur sujet, veuillez consulter notre article."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats concernant la précision par paires sont présentés ici et ils sont cohérents avec les résultats obtenus grâce aux autres métriques. Il ressort que la meilleure performance zéro-shot est atteinte par Wilbert 12 en 1, suivi de Wilbert, Alexmert, Klip et enfin Visualbert."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est notoire de constater que les instruments axés sur des objets individuels tels que l'existence et les groupes nominaux sont presque résolus par Wilbert 12 en 1, ce qui met en évidence la capacité des modèles à identifier les objets nommés et leur présence dans les images."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucun des fragments restants ne peut être résolu de manière fiable dans nos configurations de neutralisation d'adversaires."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons, d'après les outils de pluralité et de comptage, que les modèles de vision et de langage ont des difficultés à distinguer les références à un seul objet ou à plusieurs objets, ou à les compter dans une image."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La mesure de performance révèle qu'ils éprouvent des difficultés à classifier correctement une relation spatiale nommée entre des objets dans une image."}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même lorsque des biais de plausibilité sont présents, comme nous le constatons dans la partie consacrée aux actions."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "D'après l'étude de la coréférence, il s'avère que le suivi de multiples références au même objet dans une image, en utilisant des pronoms, est également difficile pour les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "Pour une vérification de cohérence, et parce que c'est une expérience intéressante, nous avons également évalué les performances de deux modèles textuels uniquement, GPT-1 et GPT-2, afin de déterminer si VALS peut être résolu par ces modèles unimodaux en calculant la perplexité de la légende correcte et de la légende déjouée, et en prédisant l'entrée présentant la perplexité la plus faible."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour le FOIL, nous interprétons cela comme une indication que la légende FOILée pourrait souffrir d'un biais de plausibilité ou d'autres biais linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de constater que, dans certains cas, les modèles GPT basés uniquement sur du texte ont mieux saisi la plausibilité du monde que les modèles combinant vision et langage."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, VALS est un point de référence qui utilise le prisme des constructions linguistiques afin d'aider la communauté à améliorer les modèles de vision et de langage en soumettant rigoureusement à l'épreuve leurs capacités d'ancrage visuel."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences démontrent que les modèles de vision et de langage identifient bien les objets nommés et leur présence dans les images, comme le prouve l'existence d'éléments spécifiques, mais ont du mal à ancrer leur interdépendance et leurs relations dans les scènes visuelles lorsqu'ils sont contraints de respecter les indicateurs linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous souhaiterions vivement encourager la communauté à utiliser VALS pour mesurer les progrès réalisés dans l'ancrage linguistique avec les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "Et plus encore, VALS pourrait servir d'évaluation indirecte d'ensembles de données, les modèles pouvant être évalués avant et après leur entraînement ou leur affinage afin de déterminer si un ensemble de données contribue à améliorer les modèles sur l'un ou l'autre des aspects testés par VALS."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si cela vous intéresse, n'hésitez pas à consulter les données VALS sur GitHub et, pour toute question, n'hésitez pas à nous contacter."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kami Zerua, de l'Université de Tokyo."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai une communication intitulée RNSUM, un ensemble de données à grande échelle pour la notation automatique de listes par le biais de la summarisation des journaux de commits."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais expliquer dans cet ordre."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Pour commencer, je présenterai la notification automatique des risques sur laquelle nous travaillons dans cette recherche."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "ReleaseNode est un document technique qui résume les modifications distribuées avec chaque version d’un produit logiciel."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image présente les notes de publication pour la version 2.6.1."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas jouer un rôle important dans le développement open source, mais leur préparation manuelle prend beaucoup de temps."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, il serait très utile de pouvoir générer automatiquement des notes de publication de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je ferai référence à deux recherches antérieures sur la génération automatique d'auditeurs."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "La première est un système appelé Arena, lancé en 2014."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il adopte une approche basée sur des règles, par exemple, en utilisant l'extracteur de modifications pour extraire les différences essentielles, les modifications de bibliothèque et les modifications de la documentation à partir des différences entre les versions, puis en les combinant."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus notable de ce système est l'extracteur de problèmes, situé dans le coin supérieur droit."}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "qui doit être lié à Jira, le système de suivi des problèmes, et ne peut être appliqué qu’aux projets qui utilisent Jira."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "Autrement dit, il ne peut être utilisé pour de nombreux projets sur GitHub."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "Le second est GRIF. Récemment annoncé en 2020,"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "Il est disponible sur internet et peut être stocké via PIP."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système intègre un module simple de classification de texte basé sur l’apprentissage et produit l’une des cinq variables suivantes, telles que des fonctionnalités ou des corrections de bogues, pour chaque message de commit entrant."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un exemple d'utilisation qui renvoie une étiquette de correction ou de correction de bogues."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données d'entraînement de Goyafet sont relativement limitées, environ 5000, et seront présentées dans les expériences décrites ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "La performance du modèle de classification de texte n’est pas élevée."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches apparentées, mais elles souffraient de problèmes de portée limitée et de ressources de données restreintes."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des nœuds de publication de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le programme d'applicabilité limitée, nous proposons une méthode de résumé de classificateur de haute qualité utilisant uniquement le message de commit comme entrée."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour toutes les bibliothèques anglophones."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le second problème lié à la rareté des ressources de données, nous avons créé un ensemble de données RNSUM constitué d'environ 82 000 éléments en collectant des données à partir de dépôts publics GitHub via l’API GitHub."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décrirai leur position assise."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de données."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche correspond au message de commit, et le côté droit à la note de publication."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de publication sont étiquetées comme améliorations, environnements de travail, etc."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons mis en place une tâche qui prend les messages confirmés en entrée et produit les nœuds de pièces câblées brutes en sortie."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de synthèse."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons défini quatre niveaux : fonctionnalités, améliorations, corrections de bogues, dépréciations, suppressions et modifications incompatibles."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces affirmations reposaient sur des recherches antérieures et d’autres facteurs."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "Les annotations concernant le guirlande situées en bas à droite sont extraites des annotations concernant le guirlande affichées en bas à gauche."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce stade, il est nécessaire de détecter les quatre niveaux qui ont été préalablement définis."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "mais les niveaux ne sont pas toujours uniformes selon les bibliothèques."}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Le niveau d'amélioration englobe les améliorations, les perfectionnements, les optimisations, et ainsi de suite."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire par niveau d'étude pour chacune de ces variations de notation."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter la classe des notes de version et corriger le texte de la liste qui suit en tant que phrase de note de version pour la classe."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, un message de commit."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages ne sont pas liés à chaque liste."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme le montre l'image ci-dessous, si la liste actuelle est de la version 2.5 à 19, il faut identifier"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "la version précédente, 2.5.18, et creuser le sujet en profondeur. Cela peut s'avérer un peu fastidieux, et il ne suffit pas de simplement obtenir une liste des versions et de comparer les états avant et après."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons conçu une règle heuristique d'appariement pour obtenir les versions précédentes et suivantes."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Ceci est Tanarsis."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "Finalement, 7200 dépôts."}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de jetons de nœud de sortie est de 63, ce qui est relativement élevé pour une tâche de résumé."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre de jetons uniques est assez important, avec 8 830 000."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "en raison du grand nombre de noms de classes et de méthodes uniques découverts dans le référentiel."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, j'expliquerai la méthode proposée."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé extractif puis abstrait, par classe, se compose de deux modules neuronaux,"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "un classificateur utilisant BERT ou CodeBert, et un générateur utilisant BERT."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, CAS utilise un classificateur pour catégoriser chaque message de commit en cinq classes de notes de publication : implémentations, corrections de bugs, suppressions, améliorations, et autres."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de commit classés dans la catégorie « autres » sont supprimés."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, CES applique le générateur aux quatre documents d'étiquette de manière indépendante et génère des nœuds de publication pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages de validation et les nœuds lus ne sont pas connues."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classificateur, nous attribuons des pseudo-étiquettes à chaque message de commit en utilisant les 10 premiers caractères de chaque message."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons la summarisation abstraite par classe par le biais de notre approche, en utilisant deux méthodes distinctes."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons cssingle, se compose d'un réseau unique homme-femme et génère un seul bloc de texte de nœud long, à partir d'une concaténation de messages de commit d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte de sortie peut être divisé en segments à l'échelle de la classe, basés sur des symboles de points finaux spécifiques à chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons CAS merge, consiste en quatre réseaux sec-à-sec différents, chacun correspondant à l’une des classes les moins connues."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "Bien, laissez-moi vous expliquer l'expérience."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : CAS, CS unique, CS fusion, clustering et les difficultés de l'étude précédente."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation, dans certains cas, ces nœuds sont exprimés en plusieurs phrases."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné qu'il est difficile de calculer le nombre de phrases, celles-ci sont regroupées avec des espaces et considérées comme une longue phrase unique."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bleu est divisé en blocs, lorsque le système produit une phrase courte."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité se traduit par une valeur de bleu inférieure dans les résultats expérimentaux décrits ci-après."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous calculons également la spécificité, car le rouge et le bleu ne peuvent pas être calculés si les nœuds de libération sont vides."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une forte spécificité signifie que le modèle renvoie correctement un texte vide lorsque les nœuds de libération présument qu'il est vide."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que l'ensemble de données contient des adresses électroniques, des valeurs hachées, etc., nous avons également évalué l'ensemble de données nettoyé, qui les exclut."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Les scores L obtenus par CEAS et CAS étaient supérieurs de plus de 10 points aux seuils de référence."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur l'ensemble de test propre, l'écart de score entre les méthodes proposées et la méthode de base a atteint plus de 20 points."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent que le CES et le GS sont significativement efficaces."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "CAS a obtenu un meilleur score d'échec de la racine que CAS, ce qui suggère que la combinaison d'un classificateur et d'un générateur est efficace pour entraîner le classificateur en utilisant des faux doubles."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "La couverture élevée de CAS peut probablement être obtenue parce que le classificateur peut se concentrer sur la sélection de messages de commit pertinents pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Les correspondances CAS produisent généralement des résultats supérieurs aux correspondances CAS uniques."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "suggérant qu'il est également efficace de développer de manière indépendante des modèles de synthèse présentant des capacités d'absorption différentes pour chaque classe de nœud de publication."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Analyse des héros et des erreurs"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes CS ont tendance à produire des phrases plus courtes que les phrases de référence rédigées par des humains."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure ci-contre, la phrase de référence comporte 3 ou 4 phrases, tandis que CAS n'en contient qu'une."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette hésitation du modèle est que, dans les données d'entraînement, seulement 33 % des phrases sont présentes dans l'étiquette des caractéristiques et 40 % dans l'étiquette des améliorations."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes CES ne peuvent générer de VsNode précis sans informations supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut à droite illustre un message de commentaire particulièrement désordonné, et la phrase complète ne peut être générée sans référence à la requête d'extraction ou au problème correspondant."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre que les deux messages de commit dans l'entrée sont liés et devraient être combinés en une seule phrase, mais cela ne se produit pas."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Finalement, une conclusion."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons développé un nouveau système automatisé de validation de dossiers."}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également pris en charge la tâche d'enregistrer les messages de validation et de les synthétiser afin qu'ils soient pertinents pour tous les projets rédigés en anglais."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Notre expérience démontre que la méthode proposée a généré des pistes moins bruitées à un taux de couverture plus élevé que les méthodes de référence."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez vérifier le code pour l'onglet de vérification du désert."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Asaf Harari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "et je présenterai notre article intitulé \"Enrichissement de Données Tabulaires en Few-Shot par le Fine-Tuning d'Architectures Transformer\"."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "C'est ainsi que les scientifiques analysent les données et se concentrent principalement sur la manipulation des caractéristiques existantes des données."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "mais parfois, ces caractéristiques sont limitées."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de caractéristiques à partir d'une autre source de données peut apporter des informations substantielles."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l’enrichissement automatique de données tabulaires à partir de textes libres provenant de sources externes."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Admettons que nous disposions d'un jeu de données tabulaire et d'une base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatisé qui implique l'association d'entités et l'analyse de texte afin d'extraire de nouvelles caractéristiques du texte libre de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre est, dans un premier temps, précisément ce processus automatisé."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple avec un ensemble de données transmis à FAST."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données est un jeu de données universitaire."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "quand son objectif est de classer les universités en universités de rang inférieur et universités de rang supérieur."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de FAST est l'établissement de liens d'entités."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque chaque entité, dans cet exemple le nom de l'université, est associée à une entité au sein de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "et le texte des entités de la base de connaissances est extrait et ajouté au jeu de données."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "L'intelligence artificielle (IA) est la capacité d'une machine à imiter les fonctions cognitives des êtres humains, telles que l'apprentissage, le raisonnement et la résolution de problèmes. Elle englobe un large éventail de techniques, allant de systèmes experts et de réseaux neuronaux artificiels à l'apprentissage automatique et au traitement du langage naturel. L'IA est de plus en plus utilisée dans divers secteurs, notamment la santé, la finance, les transports et l'industrie manufacturière, pour automatiser des tâches, améliorer l'efficacité et prendre des décisions plus éclairées. Son développement soulève des questions éthiques et sociétales importantes, notamment en matière de biais algorithmiques, de confidentialité des données et d'impact sur l'emploi."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Maintenant, nous devons générer ou extraire des caractéristiques du texte récupéré."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'une phase d'extraction de caractéristiques qui inclue une analyse textuelle."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "et c’est là la principale nouveauté de cet article, et je l’analyserai plus en profondeur dans les prochaines diapositives."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction de caractéristiques, il y a une phase de génération de caractéristiques au cours de laquelle nous utilisons les caractéristiques extraites pour générer un nombre limité de nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "générez d'abord les caractéristiques en fonction du nombre de classes du jeu de données original."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données original comporte deux classes,"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Générez rapidement deux nouvelles fonctionnalités."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si l'ensemble de données comporte cinq classes, générez d'abord cinq nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons les techniques d'analyse textuelle les plus récentes, à savoir les modèles de langage basés sur des transformateurs tels que BERT, GPT, XNL, et ainsi de suite."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "mais il est peu probable que nous puissions entraîner des modèles de langage à partir des ensembles de données d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, une approche naïve consistera en un ajustement fin sur une tâche cible."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, lors de la phase d'extraction future, nous pourrons télécharger le modèle linguistique peritrain, puis affiner ce modèle sur l'ensemble de données cible."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, pour affiner le modèle de langage, pour classifier le texte en classes, l'abstraire en classes, bas ou élevé,"}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "recevoir la sortie du modèle de langage, qui est la probabilité pour chaque classe, et l'utiliser comme nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que le jeu de données peut comporter peu d'étiquettes d'entités distinctes."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, presque la moitié des ensembles de données contiennent moins de 400 échantillons, et le plus petit ensemble de données comporte 35 échantillons dans son ensemble d'apprentissage."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, affiner un modèle de langage sur cet ensemble de données s'avérera inefficace."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous pouvons exploiter les connaissances préalables concernant des ensembles de données pré-analysés,"}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "puisque nous appliquons FAST à plusieurs ensembles de données, nous pouvons utiliser les N moins un ensembles de données pour recueillir des informations sur ces mêmes N moins un ensembles de données et utiliser ces informations lors de l'analyse du Nième ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Ce que nous proposons, c'est d'ajouter une phase supplémentaire de réglage fin."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "une phase préliminaire d'affinage multitâche."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "lorsque vous effectuez un ajustement précis du modèle linguistique sur N-1 ensembles de données,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "et ensuite, nous exécutons une autre phase d'ajustement fin, qui est un ajustement fin spécifique à une tâche cible, lorsque nous ajustons le modèle linguistique sur le n-ième ensemble de données cible."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "l'état de l'art en matière d'affinage multitâche, appelé DNN vide."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "En MTDNN, les têtes MTDNN sont maintenues au nombre de tâches dans l'ensemble d'apprentissage."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans cet exemple, il y a quatre tâches dans l'ensemble d'apprentissage. Donc, DNN vide, maintenir quatre têtes, comme vous pouvez le constater sur l'image."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "et elle échantillonne un lot aléatoire à partir de l'ensemble d'apprentissage."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire appartient, par exemple, à des tâches de classification de phrases uniques, il effectue une passe avant et une passe arrière à travers la première tête."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Si le lot aléatoire appartient à une tâche de classement par paires, il effectue une passe avant et arrière à travers la dernière tête."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, un jeu de données tabulaire exécutera le nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, il existe de nombreuses tâches."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "mtDNN conserve le nombre de têtes de classes, les couches de sortie,"}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, emptyDNA doit initialiser de nouvelles têtes pour un nouvel ensemble de données avec une nouvelle tâche."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche, appelée ajustement fin par reformulation de tâche, consiste, au lieu de maintenir plusieurs têtes, à reformuler chaque jeu de données en une phrase par problème de classification, ce qui correspond à des tâches à deux classes."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Alors, examinons un exemple."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre ensemble de données, qui comprend des entités, des caractéristiques, du texte et des classes."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous reformulons la tâche : au lieu de classer le texte en « bas » et « haut », nous classons le texte, l'abstrait et la classe en vrai ou faux."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "Autrement dit, nous entraînons le modèle de langage à classifier l'abstrait et la classe, à abstraire et à classer, pour déterminer si l'abstrait appartient ou non à la classe."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le vecteur d'étiquette dans ce cas demeure constant, et est toujours composé de deux classes."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche de fine-tuning reformulée."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Alors, examinons l'ensemble du cadre."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "Cela a accéléré le rythme de la Fed."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "et ensuite une phase rapide d'établissement de liens d'entités."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "il extrait le texte de la base de connaissances, qui, dans cet exemple, est le résumé de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il faut reformuler la tâche en une phrase par tâche de classification."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "appliqué le modèle de langage à la nouvelle tâche et la probabilité de sortie pour chaque classe,"}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle de langage a déjà été affiné sur un ensemble de données N-1 grâce à un ajustement préalable multiforme."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous utilisons le vecteur de sortie du modèle de langage comme une nouvelle caractéristique dans le nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un jeu de données de classification tabulaire de 17 exemples, qui vérifie la taille, les caractéristiques, l'équilibre, le domaine et la performance initiale."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation en direct, en entraînant notre modèle sur 16 ensembles de données et en l'appliquant au 17e ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également divisé chaque ensemble de données en quatre groupes et appliqué une validation croisée à quatre groupes."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous générons la nouvelle caractéristique et l’évaluons à l'aide de cinq classificateurs d'évaluation."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "nous utilisons dans notre expérience une architecture basée sur BERT."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez constater que nous comparons notre cadre aux ajustements fins sur l'ensemble de données cible, aux ajustements fins sur la tâche cible et aux ajustements fins préliminaires avec MTDNN."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "et notre affinage reformulé obtient le meilleur résultat, la meilleure performance."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que le modèle DNN vide atteignait une amélioration de deux pour cent par rapport à l'ensemble de données cible lors d'un ajustement précis."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche a permis d'obtenir une amélioration de 6 %."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit jeu de données, nous constatons que la performance de mtDNN diminue et que l'amélioration de la phase préliminaire de fine-tuning multitasque diminue jusqu'à 1,5 pour cent."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "mais nos performances ont augmenté à 11 % par rapport à l'ajustement fin unique à la tâche."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "Pour la sommation, FAST permet un enrichissement rapide à partir de 35 exemples dans notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une architecture unique pour tous les ensembles de données de tâches."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela conserve la tête du modèle."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "mais elle ajoute une phase de reformulation."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "son train modèle augmenté et ses besoins, une valeur cible dotée d'une signification sémantique pour pouvoir la soumettre au modèle de langage et l'utiliser dans la phrase pour chaque problème de classification."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
