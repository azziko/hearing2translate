{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，今天我将为大家介绍我们的研究工作——“学习演绎推理：将代谢问题解决视为复杂区域提取”。"}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我是字节跳动 AI 实验室的 Alan，这篇工作是与德克萨斯大学奥斯汀分校的 Jerry 和新加坡科技设计与工程学院的 Weilu 合作完成的。"}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我想谈谈我们进行推理的动机。"}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示一个多步推理用处的例子。"}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "此图节选自庞德的论文，其中他们采用提示方法，在少样本学习场景中解决数学问题。"}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "在左侧，如果我们仅提供一些包含问题和答案的样本，可能无法获得正确的答案。"}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "但是，如果我们提供更详细的推理描述，模型就能够预测该推理描述，并且在此做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "因此，将可解释的、多步骤推理作为输出是值得提倡的。"}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "我们同时也认为方法问题是一个直接的应用，用于评估这种推理能力。"}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在本问题设定中，给定问题后，我们需要解决此问题并获得数值答案。"}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的数据集里，我们还被提供了一个数学表达式，这也导出了这个特定的答案。"}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "某些假设也同样适用，如同先前的工作中所述。"}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设数量的精确度是已知的。"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "我们仅考虑加、减、乘、除以及指数运算等基本操作。"}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "此外，复杂的运算符实际上可以分解成这些基本运算符。"}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "之前在方法问题解决方面的研究实际上可以归纳为序列到序列和序列到树模型的范畴。"}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。"}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "而且它很容易实现，并且可以推广到许多不同的复杂问题。"}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "但这种方法的局限性实际上通常并不优于结构化模型，并且缺乏对预测结果的可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "但实际上，由于Transformer模型，这个方向仍然相当受欢迎。"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在基于树的模型中，我们实际上以树的形式构建这些表达式，并在树的生成过程中遵循先序遍历。"}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们持续生成操作符，直到抵达叶节点，这些叶节点代表着量。"}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里的好处在于，它实际上为我们提供了这种二叉树结构。但其实这有些反直觉，因为我们首先生成操作符，然后在最后生成量。"}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "第二个问题是，它还包含一些重复的计算。"}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "如果在这里观察这个表达式，8乘以3加上3实际上被计算了两次。但事实上，我们应该重用结果。"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的建议方法中，我们希望以循序渐进且可解释的方式来解决这些问题。"}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "所以，例如，在第二步这里，我们可以得到这个除数，即27。"}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以回溯到最初的问题，以查找相关内容。"}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "在这些步骤中，我们得到除数。"}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "那么，在第三步，我们实际上得到了商。"}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "好的，在完成这三个步骤之后，我们实际上可以利用第二步的结果，从而得到第四步的结果。然后最终，我们可以获得收益。"}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们实际上直接生成整个表达式，而不是生成单个的操作数或量。"}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "这使得过程更为精确。"}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的演绎系统中，我们首先从问题中给定的若干量开始，同时也包括一些作为初始状态的常数。"}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "因此，该表达式用 EIJOP 表示。"}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "我们执行从 QI 到 QJ 的操作，而这种表达式实际上是有向的。"}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们这里也运用减法逆向来表示相反的方向。"}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "这与关系抽取非常相似。"}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在一个正式的演绎系统中，在时间步 t，我们对 qi 和 qj 对应用操作符，然后我们得到这些新的表达式。"}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "我们将它添加到下一个状态，从而成为一个新的量。"}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "这张幻灯片实际上可视化了状态的演变过程，我们不断地向当前状态添加表达式。"}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的模型实现中，我们首先使用一个预训练的语言模型，可以是BERT或RoBERTa，然后对句子进行编码，接着我们获得这些数量表示。"}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "一旦我们获得数量表示，我们就可以开始进行推断了。"}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们展示一个例子，说明如何通过Q1除以Q2，再乘以Q4来获得该表示。"}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们获得配对表示，这基本上只是 Q1 和 Q2 的连接。然后我们应用一个前馈网络，该网络由操作符参数化。"}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "然后最终我们得到表达式表示 Q1 除以 Q2"}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "但事实上，在实践中，在推理阶段，我们也有可能得到错误的表达。"}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "因此，所有可能的表达式等于操作符数量的3倍。"}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "所以这里的好处在于，我们可以轻松地添加约束来控制这个搜索空间。"}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "如果此表达式不允许，我们可以直接从搜索空间中移除此表达式。"}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "所以在第二步中，我们做同样的事情，唯一的区别是多了一个量。"}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "这个数值来源于之前的计算表达式。"}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们最终可以得到这个最终表达式 Q"}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "times Q4。并且我们可以看到所有可能的表达式的数量与上一步不同。"}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。"}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "因此，训练过程类似于训练序列到序列模型，我们在每个时间步优化损失函数。"}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，我们同样使用这个τ来表示何时应该终止这个生成过程。"}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "而在这里，空间与序列到序列不同，因为在每个时间步长，空间都是不同的；而在传统的序列到序列模型中，它是词汇的数量。"}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "并且它也允许我们施加一些基于先前知识的约束。"}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们在常用的方法问题数据集 MAWPS、MAT23K、MATQA 和 SWAMP 上进行实验。"}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们简要展示与先前批处理方法相比的结果。"}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们表现最佳的变体是 Robeta 释言推理器。"}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "实际上，我们并不使用集束搜索，与那些显而易见采用集束搜索的方法形成对比。"}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "好吧，所以最佳方法通常是基于树的模型。"}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，我们的推理器能够显著优于这种基于树的模型。"}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "但我们可以看到，Mathqa或SWAM上的绝对数值并不高。"}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步研究关于…的结果。"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "而且这个数据集具有挑战性，因为作者尝试手动添加一些内容来迷惑自然语言处理模型，例如添加无关信息和额外的数量。"}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的预测中，我们发现一些中间值实际上是负数。"}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在这些问题中，我们是在问德雷克有多少个苹果？"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "但是我们有一些额外的信息，比如比原计划少17次投球。\n而史蒂文有8次投球，这完全无关紧要。"}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的模型会做出类似这样的预测，即产生负值。"}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们观察到这两个表达式。"}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以实际缩小搜索范围，通过移除那些负面结果，从而确保答案的正确性。"}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步发现这种约束实际上对某些模型而言，能有很大程度的提升。"}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "对于鸟类，我们改进了七个方面。\n然后，对于基于Robeta的模型，我们实际上改进了两个方面。"}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "因此，更好的语言模型具有更强的语言理解能力，从而使得此处Robita的数值较高，而Bird的数值较低。"}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "我们也会尝试分析其背后的困难。"}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设此处未使用的数量可以被视为无关信息。"}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以看到，这里显示了未使用数量的样本百分比，而SWAMP数据集具有最高的比例。"}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "在此，我们还展示了整体表现。"}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "对于那些没有剩余量的样本而言。因此，整体表现实际上高于整体表现。"}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "但对于那些未使用完的样本，情况实际上比想象中糟糕得多，糟糕得多。"}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "性能。对于MAWPS来说，我们实际上并没有太多磁盘案例，所以我直接忽略这部分内容。"}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们希望通过一个崩溃和扰动示例来展示其可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的模型在第一步就做出了错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以实际将这个表达式与这里的句子进行关联。"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们认为这句话可能会误导模型做出错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，再打印35个，就会让模型认为它应该是一个加法运算符。"}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们会尝试将这句话修改成类似于“梨树的数量比苹果树少55棵”的形式。"}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们努力使其传递更准确的语义，以便模型能够做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这项研究表明可解释的预测结果有助于我们理解模型的行为。"}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "所以，为了总结我们的工作，首先我们的模型实际上相当高效。"}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "我们能够提供可解释的求解过程。"}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们可以轻松地将一些先验知识作为约束条件融入其中，这有助于提高性能。"}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "最重要的一点是，其底层机制不仅适用于地图测绘问题解决任务，也适用于涉及多步推理的其他任务。"}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也有一定的局限性。"}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "如果运算符或常数数量庞大，内存消耗可能会相当高。"}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "第二点是，正如之前提到的，由于不同时间步长的概率分布是不平衡的，因此应用波束搜索也相当具有挑战性。"}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "是这样，演讲到此结束，欢迎提问。 谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我叫安托万，来自马斯特里赫特大学。"}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "我将与杰瑞一同展示我的图文作品，内容是关于一个用于法规条文检索的新数据集。"}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "法律问题是许多人生活中不可或缺的一部分。"}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "然而，绝大多数公民对自身权利和基本的法律程序知之甚少。"}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "因此，许多无力承担法律专家高昂援助的弱势公民， 往往缺乏保护，或更糟糕的是，遭受剥削。"}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "我们的工作致力于弥合人民与法律之间的差距，通过开发有效的法定条文检索系统来实现这一目标。"}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "这样的系统可以为缺乏专业技能的人类提供免费的专业法律援助服务。"}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "在深入探讨本研究的主要贡献之前，我们首先来描述一下法定条文检索的问题。"}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "针对一个关于小事的问题，例如，如果我违反职业保密规定，我将承担哪些风险？"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "需要一个模型来检索大量立法中的所有相关法规条文。"}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "这项信息检索任务伴随着其自身的一系列挑战。"}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "首先，它处理的是两种类型的语言。"}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "日常口语用于问题，而复杂的法律术语则用于法规。"}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "这种语言分布的差异使得系统更难以检索相关候选条目，因为它间接需要一种内在的解释系统，能够将自然语言问题转化为与法规术语相匹配的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "此外，成文法并非像新闻或食谱那样，可以独立成篇，作为完整的信息来源。"}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "相反，它是一个结构化的法律条文集合，其完整意义只有在整体语境下才能体现，即与相邻条款的补充信息、其所属的领域和子领域，以及它在法律体系中的位置共同考量时才能实现。"}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "最后，法定条文并非小段落，而这通常是大多数检索工作中典型的检索单元。"}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "这里有长篇文档，篇幅可能长达六个。"}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "近期的自然语言处理（NLP）领域进展，引发了对诸多法律任务的巨大兴趣，例如法律判决预测或自动化合同审查。"}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "但法定条文检索领域主要仍未得到显著发展，这主要是由于缺乏大规模且高质量的标注数据集。"}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "在这项研究中，我们提出了一个新的、源自法国的、以公民为中心的dataset，旨在研究一个检索模型是否能够近似于法律专家的效率和可靠性，以执行法定条文检索的任务。"}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "我们的比利时法定条文检索数据集，PSART，包含超过1100个法律条文。"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "这些问题涵盖了广泛的主题，从家庭、住房、金钱，到工作和社会保障。"}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "他们每个人都已由经验丰富的法学家标注，并引用了超过 22,600 篇文章的语料库中的相关条款。"}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "比利时法律规范。现在我们来讨论一下我们是如何收集这些数据集的。"}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们从整理一份包含大量法律文章的语料库开始。"}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "我们研究了32部公开可用的比利时规范，并从中提取了所有条款以及相应的章节标题。"}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "随后，我们收集了与相关法规有出处的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们与一家比利时律师事务所合作，该事务所每年收到来自比利时公民约 4,000 封电子邮件，寻求有关个人法律问题的建议。"}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "我们很幸运地获得了访问他们网站的机会，在那里，他们的专业法律专家团队会处理比利时最常见的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "我们收集了数千个问题，并对其进行了分类，包括类别、子类别以及与相关法规的法律参考。"}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们解析了法律引文，并筛选掉了其引文并非我们在考虑范围内法律法典条款的问题。"}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "其余参考文献已匹配并转换为Ocorpus中的相应文献编号。"}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "我们最终得到了1108道题目，每一道都经过仔细标注，注明了来自相关文章的ID。"}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "此外，每个问题都附带一个主要类别以及子类别的连接。"}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "并且每一篇文章都附带其后续标题的连贯组合，依照法律的结构呈现。"}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "这些额外的信息在本研究中未使用，但可能对未来在法律信息检索或法律税务分类方面的研究感兴趣。"}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "让我们考察一下我们数据集的一些特征。"}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "这些问题长度在5到44个单词之间，中位数为14个单词。"}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "这些文章篇幅更长，中位数为 77 个词，共 142"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "超过一千。"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "如前所述，这些问题涵盖了广泛的主题，其中约85%的问题都与家庭、住房、金钱或司法相关。"}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "其余15%则涉及社会保障、外籍人士或工作相关事宜。"}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "这些文章内容也十分多样，因为它们来源于32部不同的比利时法规，涵盖了大量的法律主题。"}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "以下是从这些比利时法规中收集到的条款总数。"}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "在22,633篇文章中，仅有1,612篇被认为是与至少...相关。"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "数据集中的一个问题。并且大约80%的这些引用文章均出自民法典、司法代码、刑事诉讼法或刑法典。"}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时，32个代码中，18个代码提及的文章少于5篇，且这些文章与至少一个问题相关。"}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "这可以由一个事实来解释，即这些代码更少关注个体及其顾虑。"}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，这些被引文集的文章的中位数引用次数为2，且少于25%的文章是"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "利用我们的数据集，我们对几种检索方法进行了基准测试，包括词汇方法和密集架构。"}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "给定一篇文档中的查询，词汇模型通过计算该查询词项在文档中权重的总和，为查询-文档对赋予一个分数。"}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "我们试验了标准的 TF-IDF 和 BM25 排序函数。"}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法的主要问题在于，它们只能检索到包含查询中关键词的文章。"}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这一局限性，我们尝试一种基于神经网络的架构，该架构能够捕捉查询与文章之间的语义关系。"}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一种 b-encoder 模型，该模型将查询和文章映射为稠密向量表示，并通过计算其嵌入向量的相似度来评估查询-文章对之间的相关性得分。"}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "这些嵌入通常是词嵌入模型的输出经过池化操作所得。"}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们研究暹罗b编码器在零样本评估设置下的有效性，这意味着预训练的木结构嵌入模型直接应用，无需任何额外的微调。"}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试了无上下文文本编码器，例如 Word2Vec 和 FastText，以及有上下文的嵌入模型，例如 Robota，特别是 Camembert，这是一种法语 Robota 模型。"}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们还在基于Camembert的模型基础上进行了额外的训练，超越了编码器。"}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "在所有数据集上进行评估。需要注意的是，在训练过程中，我们对 Bianco 架构的两种变体进行了实验。"}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "暹罗模型，它采用一种独特的词嵌入模型，将查询和文章共同映射到一个共享的稠密向量空间。而图瓦模型，则采用两个独立的词嵌入模型，分别将查询和文章编码到不同的嵌入空间中。"}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试使用均值、最大值和 CLS 池化，以及点积和余弦相似度来计算相似性。"}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "以下是在测试集上的基线结果。"}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "利用上述词汇方法，中间评估了零样本设置下的暹罗 b-编码器，下方则评估了微调后的 b-编码器。"}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，经过微调的 B-encoder 明显优于其他所有基线模型。"}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "双塔模型在召回率@100指标上优于其孪生网络变体，但在其他指标上的表现则相近。"}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "尽管 BM25 的表现不如训练后的 Biancoda 显著，但其结果表明它仍然是领域特定检索的强大基线。"}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "关于暹罗双编码器（Siamese biancoder）的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入表示，而未针对信息检索任务进行优化，会产生较差的结果，这与先前的研究结果一致。"}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们观察到基于Word2Vec的联编器明显优于FastText和Bird模型，这表明，在无需额外调整的情况下，预训练的词级别嵌入可能比字符级别或子词级别的嵌入更适合这项任务。"}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "尽管前景可期，但这些结果表明，与一位能够最终检索到任何问题相关的所有文献，并因此获得完美成绩的专业法律专家相比，仍有很大的改进空间。"}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "让我们最后讨论所有数据集的两个局限性。"}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "首先，文章语料库仅限于从32部已考虑的比利时法规中收集的文件，这并不涵盖全部的比利时法律，因为缺少来自法令、指导方针和行政命令的文章。"}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "在数据集构建过程中，对这些未收集的文章的所有引用都被忽略，这导致一些问题最终只有初始相关文章数量的一部分被纳入。"}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "这种信息丢失意味着剩余相关文献中包含的答案可能是不完整的，尽管这仍然完全合理。"}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们应当注意的是，并非所有法律问题都可以仅用成文法来解答。"}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "例如，问题是，如果租客制造过多的噪音，我是否可以干预？"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "可能在成文法中找不到对何时允许驱逐出户而量化具体噪声水平的详细规定。"}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "相反，房东可能更应该依赖案例法，并寻找与当前情况相似的先例。"}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "租客每周与两人聚会直到凌晨两点。"}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "因此，某些问题比其他问题更适合法定条文检索任务，而不太适合的问题领域尚待确定。"}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望所有工作都能激发对开发实用且可靠的法定条文检索模型的兴趣。"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "这有助于改善所有人获得公正的途径。"}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "您可以在以下链接中查阅我们的论文 DATSET&CODE。 谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "您好！我们很高兴地呈现我们的工作，关于VAUS，这是一个任务无关的基准测试，旨在针对具有特定语言现象的视觉和语言模型进行测试。"}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "我们为何费时费力地建立这个基准？"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "嗯，在过去的几年里，我们见证了基于Transformer的视觉和语言模型爆发式增长，这些模型是在大量图像-文本对上进行预训练的。"}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型均在视觉与语言任务方面实现了最先进水平，例如视觉问答、视觉常识推理、图像检索、短语定位。"}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "我们收到了一条消息。这些特定任务基准上的准确率正在稳步提高。"}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们真的了解模型实际上学习了什么吗？"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "当视觉语言转换器为这张图像和这句话赋予高分时，它理解了什么？"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "并且，该项得分较低。"}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "视觉和语言模型是否关注了正确的事物？"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "或者，他们是否侧重于先前研究所揭示的偏见？"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "为了更深入地阐释这一方面，我们提出一种更具通用性的研究方向，并引入阀门（valves）机制，以测试视觉和语言模型对特定语言现象的敏感性，这些现象会影响语言和视觉模态。"}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "我们针对存在性、复数性、计数、空间关系、行为以及实体指代进行研究。"}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们如何测试视觉和语言模型是否捕捉到了这些现象呢？"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "通过对齐法（FOILing），一种先前应用于视觉和语言模型的方法，仅由拉维·谢卡尔及其合作者应用于名词短语，以及我们之前工作中的计数。"}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "“Foiling” 的基本含义是，我们获取一张图片的标题，然后对其进行修改，使修改后的标题不再描述这张图片。"}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过关注六个特定的要素来进行这些短语调整，例如存在、复数、计数、空间关系、动作和实体指代，其中每个要素可以由一个或多个工具构成，以防我们发现超过一种有趣的方式来创建 FOIL 实例。"}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "举例来说，在行为片段这一部分，我们有两个实例：一个实例中动词被替换为不同的动作，另一个实例中行为主体被互换。"}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "计数和共指也都是涉及多于一种乐器的部分。"}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过确保它们无法描述图像，同时又保持其语法和其它方面的有效性，来创造这些反例。"}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "这并非易事，因为被篡改的标题可能比原始标题的可能性更小。"}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "虽然这并非不可能，但从统计学角度来看，植物砍伐人类的可能性要比人类砍伐植物低，大型视觉和语言模型或许可以捕捉到这一点。"}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了获得有效的对照组，我们必须采取行动。"}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们利用强大的语言模型来提出对比项。"}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们使用自然语言推理，简称NLI，来过滤掉那些可能仍然在描述图像的干扰项，因为在构建干扰项时，我们需要确保它们无法描述图像。"}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "为自动测试此项内容，我们采用自然语言推理，并以此为理由。"}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "我们将图像视为前提，而其标题则视为由此推导出的假设。"}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们认为标题是前提，而FOIL是其假设。"}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "如果一个 NLI 模型预测 FOIL 与标题相悖或保持中立，我们将其视为有效 FOIL 的指标。"}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "如果一个NLI预测FOIL被标题所蕴含，那么它不能是一个好的FOIL，因为根据传递性，它将提供对图像的真实描述，而我们会过滤掉这些FOIL。"}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "但此程序并不完美，它仅仅是有效箔材的指标。"}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "因此，作为生成有效信息请求的第三项措施，我们聘请人工标注员来验证VALS中使用的相关数据。"}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "因此，经过筛选和人工评估后，我们得到了如表中所示的测试样本数量。"}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "请注意，VALS 不提供任何训练数据，仅提供测试数据。"}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "由于它仅是一个零样本测试基准。它的设计旨在利用视觉和语言模型在预训练之后已有的能力。"}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "微调仅能使模型利用数据中的伪影或统计偏差。"}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "而且我们都知道，这些模型倾向于作弊并走捷径。"}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们之前所说，我们感兴趣的是评估在预训练之后，视觉和语言模型所具备的能力。"}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "我们对五种视觉语言模型进行了实验，这些模型分别基于 CLIP、LXMIRT、VILBERT、VILBERT12IN1 和 VISUALBERT。"}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "我们最重要的评估指标之一是模型将图像-句子对分类为标题和干扰样本的准确性。"}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "或许对于本视频而言，更相关的是我们将展示我们的更为宽松的指标——成对准确率，它衡量的是正确的图像文本对的匹配得分是否高于其欺骗对的得分。"}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "欲了解更多指标及结果，请查阅我们的论文。"}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "成对准确率的结果在此呈现，与我们从其他指标获得的结果一致。最佳零样本性能由 Wilbert 12 in 1 实现，其次是 Wilbert、Alexmert、Klip，最后是 Visualbert。"}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "值得注意的是，那些以个体对象（如存在和名词短语）为中心的仪器，几乎已被Wilbert 12 in 1 所解决，这突显了模型识别命名对象及其在图像中存在的能力。"}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "然而，在我们的对抗规避设置中，剩余的各个片段都无法可靠地解决。"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "从数量词和计数工具中可以看出，视觉和语言模型在区分对单个物体与多个物体的引用，或在图像中对其进行计数时存在困难。"}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "关系单元显示，他们在正确分类图像中命名空间关系方面存在困难。"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "他们也难以区分行为及其参与者，即使在合理性偏见的支持下，正如我们在行为片段中所观察到的那样。"}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "从指代消解部分来看，我们发现，即使对于视觉与语言模型而言，利用代词追踪图像中对同一对象的多次引用也是一项困难的任务。"}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "为了进行一个常识性验证，并且因为这是一个有趣的实验，我们还对两个仅使用文本的模型，GPT-1 和 GPT-2，进行了基准测试，以评估这些单模态模型是否能够解决 VALS 问题。具体做法是计算正确标题和被欺骗标题的困惑度，并预测困惑度最低的条目。"}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "如果 FOIL 的困惑度更高，我们将此视为 FOIL 化标题可能存在合理性偏差或其他语言偏差的指示。"}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "而且很有意思的是，在某些情况下，纯文本GPT模型捕捉到了对世界真实性的理解，比具备视觉和语言能力的模型还要更好。"}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "总而言之，VALS 是一个基准，它运用语言构建的视角，旨在通过严格测试，帮助社区改进视觉和语言模型，提升其视觉 grounding 能力。"}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，视觉与语言模型能够很好地识别图像中的命名对象及其存在，正如存在片段所体现的；然而，当被迫遵循语言指示时，它们在视觉场景中理解这些对象间的相互依赖关系和关联性方面却面临挑战。"}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们衷诚地鼓励社区成员利用VALS来衡量视觉与语言模型在语言落地方面的进展。"}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "更重要的是，VALS 还可以作为对数据集的间接评估手段，通过在训练或微调前后对模型进行评估，来判断数据集是否能帮助模型在 VALS 测试的任何方面有所改进。"}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "如果您感兴趣，请查阅GitHub上的VALS数据。如有任何疑问，请随时与我们联系。"}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫Kami Zerua，来自东京大学。"}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我将发表一篇题为“RNSUM”的论文，该论文介绍了一个大规模数据集，用于通过提交日志摘要实现自动列表标注。"}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "我将按照以下顺序进行解释。"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我将介绍我们在本研究中正在开发的自动风险通知系统。"}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "ReleaseNode 是一份技术文档，总结了软件产品每次发布所包含的变更。"}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "图像显示了 2.6.1 版本的发布说明。"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "这在开源开发中并不起重要作用，但手动准备它们却耗时费力。"}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "因此，能够自动生成高质量的发布说明将非常有用。"}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我将参考两项之前的自动听众生成研究。"}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "第一种是名为 Arena 的系统，于 2014 年发布。"}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "它采用基于规则的方法，例如，使用变更提取器从版本之间的差异中提取核心差异、库变更和文档变更，最终将它们组合起来。"}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "该系统的最显著特点是位于右上角的 issue 提取器。"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "必须与 Jira，即问题跟踪系统，关联，并且只能应用于使用 Jira 的项目。"}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "换句话说，它不能用于GitHub上许多项目。"}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "其二是GRIF。该项目于2020年正式宣布。"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "它可在互联网上获取，并可通过PIP存储。"}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "该系统包含一个基于简单学习的文本分类模块，并为每个输入提交信息输出五个变量之一，例如特征或错误修复。"}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "这张图片是一个示例用法，用于返回校正或错误修复的标签。"}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "Goyafet 的训练数据集相对较小，大约为 5000 个，将在以下描述的实验中呈现。"}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "文本分类模型的性能不高。"}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "我在此介绍两项相关研究，但存在适用性有限和数据资源匮乏的问题。"}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文解决了这两个问题，并自动生成高质量的发布节点。"}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "针对适用性有限的程序，我们提出一种仅使用提交消息作为输入的高质量分类器摘要方法。"}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "该方法可应用于所有英文库。"}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "针对数据资源匮乏的第二个问题，我们构建了一个RNSUM数据集，通过使用GitHub API从公共GitHub仓库收集数据，该数据集包含约8.2万条数据。"}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我将描述他们的坐姿。"}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "这是一组数据的例子。"}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "左侧为提交消息，右侧为发布说明。"}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "发布说明被标记为改进、工作场所等。"}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们建立了一个任务，该任务以已提交的消息作为输入，并输出原始连接的节点。"}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "这可以被视为一种概括任务。"}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "我们已预定义了四个级别：特性、改进、错误修复、弃用、移除以及破坏性变更。"}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "这些话是基于先前研究和其他因素得出的。"}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "底右方的花环注释是从底左方展示的花环注释中提取出来的。"}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "目前，有必要检测先前设置好的四个级别。"}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "但这些级别并不总是与每个库一致。"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "改进程度包括改进、增强、优化等等。"}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们为这些记号变式准备了一份词汇表，其中包含不同学习阶段的词汇。"}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "利用其检测发布说明类别，并校正其后列表中的文本，作为该类别的发布说明句。"}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "接下来是提交信息。"}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "连接消息不与任何一个列表绑定。"}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，如果当前列表的版本为 2.5 到 19，我们需要识别"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "获取之前的发布版本，即 2.5.18，并深入研究。这有些繁琐，仅仅获取发布列表并比较前后版本是不够的。"}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们设计了一种启发式匹配规则以获取前向和后向版本。"}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "这是坦纳西斯。"}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "最终，7200个仓库。"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "此外，发布节点令牌的平均数量为63，这对于摘要任务而言相当高。"}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "此外，该词汇量也相当庞大，达到了 883 万。"}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "由于存储库中包含大量的、独特的类名和方法名。"}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我将阐述所提方法。"}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "分班式抽取-抽象式摘要模型包含两个神经模块，"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "一个使用BERT或CodeBert的分类器，以及一个使用BERT的生成器。"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "首先，CAS 使用分类器将每个提交消息分类为五个发布说明类别。我们选择实施、错误修复、弃用、增强以及其他。"}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "被归类为其他类型的提交信息将被丢弃。"}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "随后，CES 将生成器分别应用于四个标签文档，并为每个类别生成发布节点。"}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "在这个任务中，提交消息与读取节点之间的直接对应关系并未知。"}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了训练分类器，我们利用每个提交信息的最初10个字符，为每个输入提交消息赋予伪标签。"}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过两种不同的方法，采用我们的方法对按类别进行的抽象式摘要建模。"}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "第一个模型，我们称之为cssingle，由一个单一的性别到性别的网络构成，并根据输入提交消息的连接生成一段单独的长节点文本。"}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "输出文本可以根据特定课程的专用端点符号划分为全班段落。"}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "第二种方法，我们称之为CAS融合，由四个不同的段落间网络构成，每个网络分别对应于一个最不常见的类别。"}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "好的，我来解释一下这个实验。"}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "比较了五种方法：CAS、CS 单独、CS 合并、聚类和先前研究的不足。"}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "关于评估而言，在某些情况下，这些节点会以多句话的形式输出。"}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "由于计算句子数量较为困难，因此将它们用空格连接起来，并作为一长句进行处理。"}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "蓝色区域被分割显示，当系统输出简短的句子时。"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "这种惩罚会导致后续实验结果中蓝色值降低。"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们还会计算特异性，因为如果释放节点为空，则无法计算rouge和蓝色值。"}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "高特异性意味着，当释放节点假定为空时，模型能够正确地输出空文本。"}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "以下是结果。"}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "由于数据集包含电子邮件地址、哈希值等，我们还评估了剔除这些信息的清洗后的数据集。"}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "CEAS 和 CAS 的松弛 L 分数比基线水平高出 10 分以上。"}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "尤其是在干净的测试集上，所提出的方法与基线模型之间的分数差距跃升至超过20个点。"}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "这些结果表明，CES和GS具有显著的有效性。"}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "CAS 在根失败指标上优于 CAS，表明结合分类器和生成器，利用伪双份数据训练分类器是有效的。"}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "高覆盖率的CAS可能归功于分类器能够专注于为每个类别选择相关的提交消息。"}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "CAS匹配通常比CAS单次匹配产生更高的结果。"}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "建议对每个发布节点类别，独立开发具有不同吸收性的摘要模型也是有效的。"}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "英雄与错误分析"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "CS 方法往往会输出比人工参考句更短的句子。"}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示，参考句包含 3 或 4 个句子，而 CAS 仅包含一个句子。"}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "这种模型迟疑的原因在于，在训练数据中，仅有33%的句子出现在特征标签中，而40%的句子出现在改进标签中。"}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "此外，CES方法无法在没有额外信息的情况下生成准确的VsNode。"}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "右侧的顶部示例是一个非常混乱的评论消息，在没有参考相应的拉取请求或问题的情况下，无法生成完整的句子。"}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "以下示例表明，输入中的两个提交消息相关联，应当合并成一个句子，但未能做到。"}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "最后，结论。"}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "我们构建了一个新的自动化案件公证系统。"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "我们还承担了记录提交信息并进行总结的任务，以便其适用于所有用英语编写的项目。"}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，与基线方法相比，所提出的方法在更高覆盖率下产生了更少的噪声线索记录。"}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "请检查代码中的关于沙漠审计的标签。"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫阿萨夫·哈拉里。"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "我将介绍我们的论文，题目是《利用微调Transformer架构进行少样本表格数据增强》。"}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "这就是科学家们分析数据的方式，主要集中于操控现有数据的特征。"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "但有时这些特征受到限制。"}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "利用另一数据源生成特征可能增加大量信息。"}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究目标是利用外部来源的自由文本实现自动表格数据增强。"}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "假设我们拥有一个表格数据集和一个知识库。"}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们需要一个自动化的流程，该流程涉及实体链接和文本分析，以便从知识库的自由文本中提取新的特征。"}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架首先正是这个自动过程。"}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "让我们看一个例子，即输入到 FAST 中的数据集。"}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，数据集为大学数据集。"}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "当其目标是将其大学划分为低等级大学和高等级大学时。"}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "作为知识库，我们使用维基百科。"}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "FAST的首要阶段是实体链接。"}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "当每个实体，在此示例中是大学名称，与知识库中的实体相关联时。"}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "并且知识库中的实体文本被提取并添加到数据集中。"}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "请提供您需要翻译的英文文本。"}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们需要从检索到的文本中生成或提取特征。"}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "我们需要一个特征提取阶段，其中包含文本分析。"}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "而这正是本文的主要创新之处，我将在接下来的幻灯片中深入探讨。"}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "在特征提取阶段之后，是特征生成阶段，在该阶段我们利用提取的特征生成少量新的特征。"}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "首先，根据原始数据集的类别数量生成特征。"}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，原始数据集包含两个类别，"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "请快速生成两个新特征。"}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "但如果数据集有五个类别，首先生成五个新的特征。"}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "每个特征代表每个类别出现的可能性。"}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "为了分析文本，我们采用当前最先进的文本分析技术，即基于Transformer的语言模型，例如BERT、GPT、XNL等。"}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "但我们不太可能使用这些输入数据集来训练语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "因此，一种简单的策略将是目标任务微调。"}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "在未来的抽取阶段，我们可以下载预训练语言模型，并在目标数据集上对该语言模型进行微调。"}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在此示例中，为了微调语言模型，将文本分类到类别中，抽象为类别，低或高。"}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "接收语言模型输出，即每个类别的概率值，并将其作为新的特征使用。"}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的局限性在于数据集可能包含少量不同的实体标签。"}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，几乎一半的数据集包含少于400个样本，而最小的数据集在训练集中仅包含35个样本。"}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "因此，针对此数据集对语言模型进行微调将是无效的。"}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "但我们可以利用对预分析数据集的先验知识。"}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "由于我们对多个数据集应用FAST，我们可以利用N减一的数据集来收集关于N减一的数据集的信息，并在分析第N个数据集时使用这些信息。"}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "我们建议增加一个额外的微调阶段。"}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "一个初步的多任务微调阶段。"}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "在您针对 N-1 个数据集对语言模型进行微调时，"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们执行另一个微调阶段，这是一个目标任务微调，即我们在第 n 个目标数据集上对语言模型进行微调。"}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "多任务微调领域的最新技术，即空神经网络（empty DNN）。"}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "在 MTDNN 中，MTDNN 保留了与训练集任务数量相匹配的头。"}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，训练集包含四个任务。因此，空神经网络保持四个头，如图所示。"}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "并且它会从训练集中抽取一个随机批次。"}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于，例如，单句分类任务，则会在第一个头中执行前向和后向传播。"}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于pairwise排序任务，则其态度在最后一层头进行前向和后向传播。"}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的场景中，一个表格数据集将运行类别数量。"}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "所以有很多任务。"}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "mtDNN 保留了多分类头的数量，以及输出层。"}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "此外，emptyDNA 需要为新的数据集和新的任务初始化新的头部。"}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法，即任务重塑微调，在我们的方法中，任务重塑微调，不是维持多个头部，而是将每个数据集重新表述为针对每个分类问题的单个句子，即二元分类任务。"}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "那么，我们来看一个例子。"}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的数据集，它由实体、特征、文本和类别组成。"}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我们重新将任务定义为：不再是将文本划分为低价值和高价值两类，而是将文本、摘要和类别这三者分别判断为真或假。"}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "换言之，我们训练语言模型对摘要和类别进行分类，判断摘要是否属于该类别。"}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，标签向量始终保持不变，它总是由两个类别组成。"}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "而这便是我们重新表述的微调方法的算法。"}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "那么，让我们看看完整的框架。"}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "这加速了美联储的行动。"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "然后是快速的实体链接执行阶段。"}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "它从知识库中提取文本，在这个例子中，就是维基百科页面的摘要。"}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "然后，将其任务重新表述为每个分类任务对应一句。"}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "将语言模型应用于新任务，并获得每个类别的输出概率。"}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "请注意，该语言模型已经在N-1数据集上进行过初步的多任务微调。"}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们使用语言模型的输出向量作为新生成的特征，融入到类别数量中。"}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的框架，我们使用了一个包含17个表格分类数据集，用于验证规模、特征、平衡性、领域以及初始性能。"}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "作为知识库，我们使用维基百科。"}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "我们设计实验，采用“一次性评估”方法，在16个数据集上进行快速训练，然后将其应用于第17个数据集。"}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将每个数据集划分为四个fold，并应用四折交叉验证。"}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们生成新的特征，并使用五个评估分类器对其进行评估。"}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "我们实验中采用的基于BERT的架构。"}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们实验的结果。"}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "您可以看到，我们将我们的框架与目标数据集微调、目标任务微调以及MTDNN预备微调进行比较。"}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "并且我们的重新调整后的微调模型取得了最佳结果，表现最佳。"}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "在空化的 DNN 中，它在目标数据集上的微调中实现了百分之二的提升。"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法实现了6%的改进。"}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "当我们观察小数据集时，可以看到 mtDNN 的性能有所下降，并且初步的多任务微调阶段的提升幅度降低至 1.5%。"}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "但我们的表现提高了 11%，相比仅进行目标任务微调而言。"}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "对于求和任务，在我们的实验中，FAST 能够利用仅 35 个样本实现少样本增强。"}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "它使用单一架构处理所有任务数据集。"}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "并且它保留了模型的头部。"}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "但它增加了重塑阶段。"}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "其增强型火车模型及其需求，一个具有语义意义的目标值，以便将其输入到语言模型中，并在每个分类问题中使用它。"}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。"}
